G:\conda\envs\gfl\Lib\site-packages\torch_geometric\data\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
Associating local subgraph with global graph...: 100%|████████████████████████████| 146/146 [00:00<00:00, 12396.12it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 192/192 [00:00<00:00, 27291.12it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 148/148 [00:00<00:00, 15846.96it/s]
Associating local subgraph with global graph...: 100%|█████████████████████████████| 156/156 [00:00<00:00, 8266.83it/s]
Associating local subgraph with global graph...: 100%|█████████████████████████████| 176/176 [00:00<00:00, 8834.02it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████████| 90/90 [00:00<00:00, 19257.59it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████████| 96/96 [00:00<00:00, 15065.97it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████████| 84/84 [00:00<00:00, 12889.50it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 244/244 [00:00<00:00, 17199.59it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 118/118 [00:00<00:00, 14369.06it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 252/252 [00:00<00:00, 16579.84it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 104/104 [00:00<00:00, 13947.93it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 180/180 [00:00<00:00, 15459.07it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 204/204 [00:00<00:00, 11001.45it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 144/144 [00:00<00:00, 22367.14it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 216/216 [00:00<00:00, 21753.54it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 328/328 [00:00<00:00, 18898.45it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████████| 66/66 [00:00<00:00, 15804.97it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 108/108 [00:00<00:00, 16605.02it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 168/168 [00:00<00:00, 18921.16it/s]
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.1667	loss_train: 0.0838	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 1.6126	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.6042	loss_train: 0.0780	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 1.4983	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.6667	loss_train: 0.0734	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 1.4057	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.2353	loss_train: 0.0868	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.6085	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.5882	loss_train: 0.0839	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.5511	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.6863	loss_train: 0.0815	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.5031	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.1887	loss_train: 0.0866	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.6086	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.4528	loss_train: 0.0840	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.5577	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.6415	loss_train: 0.0819	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.5145	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.8000	acc_cls: 0.1600	loss_train: 0.0883	loss_degree: 0.1533	loss_feat: 0.0000	loss_cls: 1.6122	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.8000	acc_cls: 0.5000	loss_train: 0.0835	loss_degree: 0.1269	loss_feat: 0.0000	loss_cls: 1.5426	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.8000	acc_cls: 0.6000	loss_train: 0.0796	loss_degree: 0.1076	loss_feat: 0.0000	loss_cls: 1.4850	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.2692	loss_train: 0.0889	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 1.6045	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.5769	loss_train: 0.0844	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 1.5158	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.6731	loss_train: 0.0809	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 1.4446	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.1930	loss_train: 0.0830	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.6157	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.4912	loss_train: 0.0807	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.5698	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.5789	loss_train: 0.0787	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.5309	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.8936	acc_cls: 0.2766	loss_train: 0.0856	loss_degree: 0.0940	loss_feat: 0.0000	loss_cls: 1.6170	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.8936	acc_cls: 0.7234	loss_train: 0.0801	loss_degree: 0.0904	loss_feat: 0.0000	loss_cls: 1.5123	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.8936	acc_cls: 0.7660	loss_train: 0.0756	loss_degree: 0.0815	loss_feat: 0.0000	loss_cls: 1.4302	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.2200	loss_train: 0.0825	loss_degree: 0.0486	loss_feat: 0.0000	loss_cls: 1.6020	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.5600	loss_train: 0.0786	loss_degree: 0.0445	loss_feat: 0.0000	loss_cls: 1.5284	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.6800	loss_train: 0.0754	loss_degree: 0.0412	loss_feat: 0.0000	loss_cls: 1.4676	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6852	acc_cls: 0.0926	loss_train: 0.0925	loss_degree: 0.2388	loss_feat: 0.0000	loss_cls: 1.6114	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6852	acc_cls: 0.6667	loss_train: 0.0872	loss_degree: 0.2023	loss_feat: 0.0000	loss_cls: 1.5420	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6852	acc_cls: 0.7222	loss_train: 0.0827	loss_degree: 0.1720	loss_feat: 0.0000	loss_cls: 1.4822	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.1837	loss_train: 0.0867	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 1.6113	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.4898	loss_train: 0.0827	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 1.5319	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.6122	loss_train: 0.0794	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 1.4662	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8596	acc_cls: 0.2456	loss_train: 0.0869	loss_degree: 0.1336	loss_feat: 0.0000	loss_cls: 1.6049	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8596	acc_cls: 0.3860	loss_train: 0.0821	loss_degree: 0.1197	loss_feat: 0.0000	loss_cls: 1.5233	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8596	acc_cls: 0.5439	loss_train: 0.0785	loss_degree: 0.1120	loss_feat: 0.0000	loss_cls: 1.4574	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.1860	loss_train: 0.0825	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 1.6157	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.6047	loss_train: 0.0787	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 1.5398	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.6512	loss_train: 0.0757	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 1.4787	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.7917	acc_cls: 0.2292	loss_train: 0.0899	loss_degree: 0.1838	loss_feat: 0.0000	loss_cls: 1.6150	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.7917	acc_cls: 0.3750	loss_train: 0.0860	loss_degree: 0.1622	loss_feat: 0.0000	loss_cls: 1.5570	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.7917	acc_cls: 0.4792	loss_train: 0.0826	loss_degree: 0.1442	loss_feat: 0.0000	loss_cls: 1.5081	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.2222	loss_train: 0.0832	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.6090	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.6667	loss_train: 0.0797	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.5390	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.6825	loss_train: 0.0768	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.4808	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8043	acc_cls: 0.2826	loss_train: 0.0860	loss_degree: 0.1176	loss_feat: 0.0000	loss_cls: 1.6034	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8043	acc_cls: 0.6739	loss_train: 0.0819	loss_degree: 0.1030	loss_feat: 0.0000	loss_cls: 1.5353	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8043	acc_cls: 0.7391	loss_train: 0.0785	loss_degree: 0.0915	loss_feat: 0.0000	loss_cls: 1.4781	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.6400	acc_cls: 0.2200	loss_train: 0.0902	loss_degree: 0.1950	loss_feat: 0.0000	loss_cls: 1.6087	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.6400	acc_cls: 0.6800	loss_train: 0.0848	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 1.5422	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.6400	acc_cls: 0.8200	loss_train: 0.0802	loss_degree: 0.1189	loss_feat: 0.0000	loss_cls: 1.4854	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.5323	acc_cls: 0.1774	loss_train: 0.0953	loss_degree: 0.2978	loss_feat: 0.0000	loss_cls: 1.6092	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.5323	acc_cls: 0.3710	loss_train: 0.0914	loss_degree: 0.2836	loss_feat: 0.0000	loss_cls: 1.5442	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.5323	acc_cls: 0.4839	loss_train: 0.0874	loss_degree: 0.2579	loss_feat: 0.0000	loss_cls: 1.4891	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.2667	loss_train: 0.0835	loss_degree: 0.0555	loss_feat: 0.0000	loss_cls: 1.6154	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.6667	loss_train: 0.0806	loss_degree: 0.0545	loss_feat: 0.0000	loss_cls: 1.5574	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.8000	loss_train: 0.0781	loss_degree: 0.0532	loss_feat: 0.0000	loss_cls: 1.5092	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.3175	loss_train: 0.0830	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.6037	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.5397	loss_train: 0.0799	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.5430	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.5714	loss_train: 0.0773	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.4913	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7241	acc_cls: 0.1207	loss_train: 0.0917	loss_degree: 0.2166	loss_feat: 0.0000	loss_cls: 1.6183	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7241	acc_cls: 0.7414	loss_train: 0.0873	loss_degree: 0.1983	loss_feat: 0.0000	loss_cls: 1.5473	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7241	acc_cls: 0.8103	loss_train: 0.0834	loss_degree: 0.1824	loss_feat: 0.0000	loss_cls: 1.4854	loss_other: 0.0000
[server]	loss_train: 1.6215	loss_val: 1.6212	loss_test: 1.6242	accuracy_train: 0.1667	accuracy_val: 0.1111	accuracy_test: 0.1304
[server]	loss_train: 1.6154	loss_val: 1.6178	loss_test: 1.6157	accuracy_train: 0.1176	accuracy_val: 0.1111	accuracy_test: 0.1250
[server]	loss_train: 1.6059	loss_val: 1.6056	loss_test: 1.6097	accuracy_train: 0.1698	accuracy_val: 0.2564	accuracy_test: 0.2800
[server]	loss_train: 1.6074	loss_val: 1.6066	loss_test: 1.6154	accuracy_train: 0.4000	accuracy_val: 0.3529	accuracy_test: 0.3043
[server]	loss_train: 1.6220	loss_val: 1.6199	loss_test: 1.6224	accuracy_train: 0.1731	accuracy_val: 0.1081	accuracy_test: 0.0417
[server]	loss_train: 1.6030	loss_val: 1.6072	loss_test: 1.6067	accuracy_train: 0.1930	accuracy_val: 0.3000	accuracy_test: 0.2308
[server]	loss_train: 1.6139	loss_val: 1.6231	loss_test: 1.6215	accuracy_train: 0.2340	accuracy_val: 0.1212	accuracy_test: 0.2273
[server]	loss_train: 1.6052	loss_val: 1.6095	loss_test: 1.6079	accuracy_train: 0.2200	accuracy_val: 0.1944	accuracy_test: 0.1739
[server]	loss_train: 1.6163	loss_val: 1.6138	loss_test: 1.6178	accuracy_train: 0.0926	accuracy_val: 0.2368	accuracy_test: 0.1923
[server]	loss_train: 1.6110	loss_val: 1.6147	loss_test: 1.6156	accuracy_train: 0.2245	accuracy_val: 0.1143	accuracy_test: 0.1304
[server]	loss_train: 1.6179	loss_val: 1.6192	loss_test: 1.6155	accuracy_train: 0.1579	accuracy_val: 0.1795	accuracy_test: 0.1923
[server]	loss_train: 1.6131	loss_val: 1.6070	loss_test: 1.6073	accuracy_train: 0.1395	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.5987	loss_val: 1.6030	loss_test: 1.6040	accuracy_train: 0.2292	accuracy_val: 0.2857	accuracy_test: 0.2500
[server]	loss_train: 1.6051	loss_val: 1.6090	loss_test: 1.6075	accuracy_train: 0.2381	accuracy_val: 0.2045	accuracy_test: 0.1786
[server]	loss_train: 1.6129	loss_val: 1.6121	loss_test: 1.6102	accuracy_train: 0.2391	accuracy_val: 0.1515	accuracy_test: 0.2273
[server]	loss_train: 1.6077	loss_val: 1.6136	loss_test: 1.6074	accuracy_train: 0.2400	accuracy_val: 0.0571	accuracy_test: 0.1600
[server]	loss_train: 1.6134	loss_val: 1.6116	loss_test: 1.6250	accuracy_train: 0.1290	accuracy_val: 0.1818	accuracy_test: 0.1034
[server]	loss_train: 1.6065	loss_val: 1.6122	loss_test: 1.6121	accuracy_train: 0.2000	accuracy_val: 0.1250	accuracy_test: 0.1429
[server]	loss_train: 1.6110	loss_val: 1.6123	loss_test: 1.6156	accuracy_train: 0.1905	accuracy_val: 0.2045	accuracy_test: 0.2414
[server]	loss_train: 1.6229	loss_val: 1.6220	loss_test: 1.6174	accuracy_train: 0.1379	accuracy_val: 0.1026	accuracy_test: 0.1786
curr_round: 0	curr_val_accuracy: 0.1837	curr_test_accuracy: 0.1873
best_round: 0	best_val_accuracy: 0.1837	best_test_accuracy: 0.1873
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.7708	loss_train: 0.0691	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 1.3196	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.7708	loss_train: 0.0650	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 1.2380	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.7708	loss_train: 0.0613	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 1.1634	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.7647	loss_train: 0.0793	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.4588	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.8235	loss_train: 0.0771	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.4147	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.8824	loss_train: 0.0749	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.3705	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8113	loss_train: 0.0799	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.4755	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8113	loss_train: 0.0780	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.4381	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8302	loss_train: 0.0762	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.4013	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.8000	acc_cls: 0.6600	loss_train: 0.0762	loss_degree: 0.0918	loss_feat: 0.0000	loss_cls: 1.4318	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.8200	acc_cls: 0.7800	loss_train: 0.0730	loss_degree: 0.0792	loss_feat: 0.0001	loss_cls: 1.3792	loss_other: 0.0025
[client 3 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.8000	loss_train: 0.0700	loss_degree: 0.0697	loss_feat: 0.0002	loss_cls: 1.3266	loss_other: 0.0042
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.6923	loss_train: 0.0777	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 1.3815	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.7308	loss_train: 0.0748	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 1.3222	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.7500	loss_train: 0.0719	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 1.2656	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.6491	loss_train: 0.0770	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.4955	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.7193	loss_train: 0.0753	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.4616	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.8070	loss_train: 0.0736	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.4277	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.8936	acc_cls: 0.8085	loss_train: 0.0715	loss_degree: 0.0743	loss_feat: 0.0000	loss_cls: 1.3566	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.8936	acc_cls: 0.8723	loss_train: 0.0678	loss_degree: 0.0679	loss_feat: 0.0000	loss_cls: 1.2887	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.8936	acc_cls: 0.8723	loss_train: 0.0645	loss_degree: 0.0623	loss_feat: 0.0000	loss_cls: 1.2268	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.7400	loss_train: 0.0726	loss_degree: 0.0382	loss_feat: 0.0000	loss_cls: 1.4132	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.7600	loss_train: 0.0698	loss_degree: 0.0354	loss_feat: 0.0000	loss_cls: 1.3611	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.8200	loss_train: 0.0671	loss_degree: 0.0324	loss_feat: 0.0000	loss_cls: 1.3100	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6852	acc_cls: 0.7037	loss_train: 0.0786	loss_degree: 0.1462	loss_feat: 0.0000	loss_cls: 1.4268	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.7407	acc_cls: 0.7037	loss_train: 0.0754	loss_degree: 0.1313	loss_feat: 0.0003	loss_cls: 1.3725	loss_other: 0.0035
[client 8 neighGen phase]	acc_degree: 0.8333	acc_cls: 0.7593	loss_train: 0.0728	loss_degree: 0.1300	loss_feat: 0.0008	loss_cls: 1.3179	loss_other: 0.0075
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.6327	loss_train: 0.0764	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 1.4062	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.6735	loss_train: 0.0736	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 1.3487	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.6939	loss_train: 0.0708	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 1.2929	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8596	acc_cls: 0.5965	loss_train: 0.0752	loss_degree: 0.1045	loss_feat: 0.0000	loss_cls: 1.3985	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8596	acc_cls: 0.6140	loss_train: 0.0720	loss_degree: 0.0968	loss_feat: 0.0000	loss_cls: 1.3427	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8596	acc_cls: 0.6667	loss_train: 0.0690	loss_degree: 0.0897	loss_feat: 0.0001	loss_cls: 1.2904	loss_other: 0.0009
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.7209	loss_train: 0.0729	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 1.4234	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.7209	loss_train: 0.0703	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 1.3706	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.7442	loss_train: 0.0677	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 1.3186	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.7917	acc_cls: 0.6250	loss_train: 0.0795	loss_degree: 0.1271	loss_feat: 0.0000	loss_cls: 1.4636	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.7917	acc_cls: 0.6667	loss_train: 0.0766	loss_degree: 0.1104	loss_feat: 0.0000	loss_cls: 1.4211	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.7917	acc_cls: 0.7083	loss_train: 0.0739	loss_degree: 0.0957	loss_feat: 0.0003	loss_cls: 1.3792	loss_other: 0.0037
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.6984	loss_train: 0.0742	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.4285	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.6825	loss_train: 0.0717	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.3787	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.6984	loss_train: 0.0693	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.3299	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8043	acc_cls: 0.8043	loss_train: 0.0753	loss_degree: 0.0809	loss_feat: 0.0000	loss_cls: 1.4258	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8043	acc_cls: 0.8478	loss_train: 0.0723	loss_degree: 0.0704	loss_feat: 0.0000	loss_cls: 1.3747	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8043	acc_cls: 0.8913	loss_train: 0.0692	loss_degree: 0.0603	loss_feat: 0.0000	loss_cls: 1.3236	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.6400	acc_cls: 0.8400	loss_train: 0.0762	loss_degree: 0.0918	loss_feat: 0.0000	loss_cls: 1.4330	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7200	acc_cls: 0.8600	loss_train: 0.0733	loss_degree: 0.0758	loss_feat: 0.0004	loss_cls: 1.3818	loss_other: 0.0077
[client 15 neighGen phase]	acc_degree: 0.7800	acc_cls: 0.9000	loss_train: 0.0706	loss_degree: 0.0689	loss_feat: 0.0007	loss_cls: 1.3310	loss_other: 0.0108
[client 16 neighGen phase]	acc_degree: 0.5323	acc_cls: 0.5645	loss_train: 0.0832	loss_degree: 0.2261	loss_feat: 0.0001	loss_cls: 1.4373	loss_other: 0.0011
[client 16 neighGen phase]	acc_degree: 0.5323	acc_cls: 0.6452	loss_train: 0.0792	loss_degree: 0.1958	loss_feat: 0.0000	loss_cls: 1.3870	loss_other: 0.0008
[client 16 neighGen phase]	acc_degree: 0.5645	acc_cls: 0.6613	loss_train: 0.0759	loss_degree: 0.1750	loss_feat: 0.0002	loss_cls: 1.3393	loss_other: 0.0030
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.8222	loss_train: 0.0759	loss_degree: 0.0519	loss_feat: 0.0000	loss_cls: 1.4655	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.8222	loss_train: 0.0737	loss_degree: 0.0508	loss_feat: 0.0000	loss_cls: 1.4237	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.8667	loss_train: 0.0716	loss_degree: 0.0498	loss_feat: 0.0000	loss_cls: 1.3825	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.6190	loss_train: 0.0749	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.4427	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.6349	loss_train: 0.0725	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.3949	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.6349	loss_train: 0.0701	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.3471	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7241	acc_cls: 0.8621	loss_train: 0.0796	loss_degree: 0.1661	loss_feat: 0.0000	loss_cls: 1.4268	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7241	acc_cls: 0.9138	loss_train: 0.0758	loss_degree: 0.1476	loss_feat: 0.0000	loss_cls: 1.3684	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7241	acc_cls: 0.9483	loss_train: 0.0718	loss_degree: 0.1267	loss_feat: 0.0001	loss_cls: 1.3089	loss_other: 0.0011
[server]	loss_train: 1.6215	loss_val: 1.6212	loss_test: 1.6242	accuracy_train: 0.1667	accuracy_val: 0.1111	accuracy_test: 0.1304
[server]	loss_train: 1.6154	loss_val: 1.6178	loss_test: 1.6157	accuracy_train: 0.1176	accuracy_val: 0.1111	accuracy_test: 0.1250
[server]	loss_train: 1.6059	loss_val: 1.6056	loss_test: 1.6097	accuracy_train: 0.1698	accuracy_val: 0.2564	accuracy_test: 0.2800
[server]	loss_train: 1.6074	loss_val: 1.6066	loss_test: 1.6154	accuracy_train: 0.4000	accuracy_val: 0.3529	accuracy_test: 0.3043
[server]	loss_train: 1.6220	loss_val: 1.6199	loss_test: 1.6224	accuracy_train: 0.1731	accuracy_val: 0.1081	accuracy_test: 0.0417
[server]	loss_train: 1.6030	loss_val: 1.6072	loss_test: 1.6067	accuracy_train: 0.1930	accuracy_val: 0.3000	accuracy_test: 0.2308
[server]	loss_train: 1.6139	loss_val: 1.6231	loss_test: 1.6215	accuracy_train: 0.2340	accuracy_val: 0.1212	accuracy_test: 0.2273
[server]	loss_train: 1.6052	loss_val: 1.6095	loss_test: 1.6079	accuracy_train: 0.2200	accuracy_val: 0.1944	accuracy_test: 0.1739
[server]	loss_train: 1.6163	loss_val: 1.6138	loss_test: 1.6178	accuracy_train: 0.0926	accuracy_val: 0.2368	accuracy_test: 0.1923
[server]	loss_train: 1.6110	loss_val: 1.6147	loss_test: 1.6156	accuracy_train: 0.2245	accuracy_val: 0.1143	accuracy_test: 0.1304
[server]	loss_train: 1.6179	loss_val: 1.6192	loss_test: 1.6155	accuracy_train: 0.1579	accuracy_val: 0.1795	accuracy_test: 0.1923
[server]	loss_train: 1.6131	loss_val: 1.6070	loss_test: 1.6073	accuracy_train: 0.1395	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.5987	loss_val: 1.6030	loss_test: 1.6040	accuracy_train: 0.2292	accuracy_val: 0.2857	accuracy_test: 0.2500
[server]	loss_train: 1.6051	loss_val: 1.6090	loss_test: 1.6075	accuracy_train: 0.2381	accuracy_val: 0.2045	accuracy_test: 0.1786
[server]	loss_train: 1.6129	loss_val: 1.6121	loss_test: 1.6102	accuracy_train: 0.2391	accuracy_val: 0.1515	accuracy_test: 0.2273
[server]	loss_train: 1.6077	loss_val: 1.6136	loss_test: 1.6074	accuracy_train: 0.2400	accuracy_val: 0.0571	accuracy_test: 0.1600
[server]	loss_train: 1.6134	loss_val: 1.6116	loss_test: 1.6250	accuracy_train: 0.1290	accuracy_val: 0.1818	accuracy_test: 0.1034
[server]	loss_train: 1.6065	loss_val: 1.6122	loss_test: 1.6121	accuracy_train: 0.2000	accuracy_val: 0.1250	accuracy_test: 0.1429
[server]	loss_train: 1.6110	loss_val: 1.6123	loss_test: 1.6156	accuracy_train: 0.1905	accuracy_val: 0.2045	accuracy_test: 0.2414
[server]	loss_train: 1.6229	loss_val: 1.6220	loss_test: 1.6174	accuracy_train: 0.1379	accuracy_val: 0.1026	accuracy_test: 0.1786
curr_round: 1	curr_val_accuracy: 0.1837	curr_test_accuracy: 0.1873
best_round: 0	best_val_accuracy: 0.1837	best_test_accuracy: 0.1873
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.7708	loss_train: 0.0580	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 1.0983	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.7917	loss_train: 0.0553	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 1.0429	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.7917	loss_train: 0.0529	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.9957	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.8824	loss_train: 0.0727	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.3263	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9020	loss_train: 0.0705	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.2830	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9020	loss_train: 0.0684	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.2409	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8302	loss_train: 0.0743	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.3641	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8302	loss_train: 0.0724	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.3262	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8302	loss_train: 0.0705	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.2878	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.8400	loss_train: 0.0670	loss_degree: 0.0622	loss_feat: 0.0002	loss_cls: 1.2744	loss_other: 0.0036
[client 3 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.8400	loss_train: 0.0641	loss_degree: 0.0562	loss_feat: 0.0001	loss_cls: 1.2233	loss_other: 0.0033
[client 3 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.8800	loss_train: 0.0614	loss_degree: 0.0516	loss_feat: 0.0001	loss_cls: 1.1742	loss_other: 0.0027
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.7885	loss_train: 0.0692	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 1.2118	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.8077	loss_train: 0.0667	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 1.1615	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.8269	loss_train: 0.0644	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 1.1142	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.8070	loss_train: 0.0718	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.3930	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.8421	loss_train: 0.0701	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.3575	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.8421	loss_train: 0.0683	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.3213	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.8936	acc_cls: 0.8936	loss_train: 0.0614	loss_degree: 0.0577	loss_feat: 0.0000	loss_cls: 1.1707	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9149	acc_cls: 0.8936	loss_train: 0.0588	loss_degree: 0.0543	loss_feat: 0.0001	loss_cls: 1.1196	loss_other: 0.0014
[client 6 neighGen phase]	acc_degree: 0.9362	acc_cls: 0.9362	loss_train: 0.0563	loss_degree: 0.0518	loss_feat: 0.0002	loss_cls: 1.0727	loss_other: 0.0019
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.8400	loss_train: 0.0644	loss_degree: 0.0292	loss_feat: 0.0000	loss_cls: 1.2596	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.8400	loss_train: 0.0618	loss_degree: 0.0257	loss_feat: 0.0000	loss_cls: 1.2102	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.8400	loss_train: 0.0592	loss_degree: 0.0217	loss_feat: 0.0000	loss_cls: 1.1623	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.8519	acc_cls: 0.7593	loss_train: 0.0701	loss_degree: 0.1299	loss_feat: 0.0008	loss_cls: 1.2627	loss_other: 0.0083
[client 8 neighGen phase]	acc_degree: 0.8519	acc_cls: 0.7963	loss_train: 0.0669	loss_degree: 0.1238	loss_feat: 0.0008	loss_cls: 1.2074	loss_other: 0.0060
[client 8 neighGen phase]	acc_degree: 0.8519	acc_cls: 0.7963	loss_train: 0.0637	loss_degree: 0.1157	loss_feat: 0.0007	loss_cls: 1.1521	loss_other: 0.0059
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.7347	loss_train: 0.0681	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 1.2388	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.7959	loss_train: 0.0655	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 1.1867	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.7959	loss_train: 0.0630	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 1.1370	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8772	acc_cls: 0.7368	loss_train: 0.0663	loss_degree: 0.0826	loss_feat: 0.0001	loss_cls: 1.2413	loss_other: 0.0020
[client 10 neighGen phase]	acc_degree: 0.8947	acc_cls: 0.7719	loss_train: 0.0636	loss_degree: 0.0747	loss_feat: 0.0001	loss_cls: 1.1952	loss_other: 0.0024
[client 10 neighGen phase]	acc_degree: 0.8947	acc_cls: 0.7895	loss_train: 0.0610	loss_degree: 0.0663	loss_feat: 0.0002	loss_cls: 1.1514	loss_other: 0.0029
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.7674	loss_train: 0.0651	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 1.2673	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.7907	loss_train: 0.0626	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 1.2167	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.7907	loss_train: 0.0601	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 1.1674	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8125	acc_cls: 0.7500	loss_train: 0.0715	loss_degree: 0.0862	loss_feat: 0.0004	loss_cls: 1.3370	loss_other: 0.0056
[client 12 neighGen phase]	acc_degree: 0.8125	acc_cls: 0.7917	loss_train: 0.0691	loss_degree: 0.0827	loss_feat: 0.0003	loss_cls: 1.2944	loss_other: 0.0048
[client 12 neighGen phase]	acc_degree: 0.8333	acc_cls: 0.8125	loss_train: 0.0669	loss_degree: 0.0804	loss_feat: 0.0004	loss_cls: 1.2517	loss_other: 0.0051
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.6984	loss_train: 0.0669	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.2816	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.6984	loss_train: 0.0645	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.2344	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.6984	loss_train: 0.0622	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.1886	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8043	acc_cls: 0.9348	loss_train: 0.0662	loss_degree: 0.0508	loss_feat: 0.0000	loss_cls: 1.2727	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8261	acc_cls: 0.9348	loss_train: 0.0633	loss_degree: 0.0426	loss_feat: 0.0001	loss_cls: 1.2225	loss_other: 0.0014
[client 14 neighGen phase]	acc_degree: 0.8478	acc_cls: 0.9565	loss_train: 0.0606	loss_degree: 0.0359	loss_feat: 0.0001	loss_cls: 1.1736	loss_other: 0.0024
[client 15 neighGen phase]	acc_degree: 0.8200	acc_cls: 0.9000	loss_train: 0.0676	loss_degree: 0.0614	loss_feat: 0.0007	loss_cls: 1.2805	loss_other: 0.0101
[client 15 neighGen phase]	acc_degree: 0.8400	acc_cls: 0.9000	loss_train: 0.0646	loss_degree: 0.0504	loss_feat: 0.0006	loss_cls: 1.2311	loss_other: 0.0095
[client 15 neighGen phase]	acc_degree: 0.8400	acc_cls: 0.9000	loss_train: 0.0616	loss_degree: 0.0403	loss_feat: 0.0006	loss_cls: 1.1833	loss_other: 0.0086
[client 16 neighGen phase]	acc_degree: 0.6290	acc_cls: 0.7581	loss_train: 0.0733	loss_degree: 0.1642	loss_feat: 0.0003	loss_cls: 1.2950	loss_other: 0.0059
[client 16 neighGen phase]	acc_degree: 0.6290	acc_cls: 0.8226	loss_train: 0.0706	loss_degree: 0.1521	loss_feat: 0.0003	loss_cls: 1.2542	loss_other: 0.0047
[client 16 neighGen phase]	acc_degree: 0.6290	acc_cls: 0.8871	loss_train: 0.0678	loss_degree: 0.1358	loss_feat: 0.0002	loss_cls: 1.2164	loss_other: 0.0041
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0695	loss_degree: 0.0489	loss_feat: 0.0000	loss_cls: 1.3419	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0675	loss_degree: 0.0480	loss_feat: 0.0000	loss_cls: 1.3021	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0655	loss_degree: 0.0471	loss_feat: 0.0000	loss_cls: 1.2634	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.6667	loss_train: 0.0678	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.2995	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.6825	loss_train: 0.0654	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.2524	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.7143	loss_train: 0.0631	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.2060	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7414	acc_cls: 0.9483	loss_train: 0.0678	loss_degree: 0.1053	loss_feat: 0.0002	loss_cls: 1.2482	loss_other: 0.0031
[client 19 neighGen phase]	acc_degree: 0.7586	acc_cls: 0.9655	loss_train: 0.0638	loss_degree: 0.0849	loss_feat: 0.0003	loss_cls: 1.1869	loss_other: 0.0039
[client 19 neighGen phase]	acc_degree: 0.7759	acc_cls: 0.9655	loss_train: 0.0600	loss_degree: 0.0674	loss_feat: 0.0005	loss_cls: 1.1259	loss_other: 0.0053
[server]	loss_train: 1.6215	loss_val: 1.6212	loss_test: 1.6242	accuracy_train: 0.1667	accuracy_val: 0.1111	accuracy_test: 0.1304
[server]	loss_train: 1.6154	loss_val: 1.6178	loss_test: 1.6157	accuracy_train: 0.1176	accuracy_val: 0.1111	accuracy_test: 0.1250
[server]	loss_train: 1.6059	loss_val: 1.6056	loss_test: 1.6097	accuracy_train: 0.1698	accuracy_val: 0.2564	accuracy_test: 0.2800
[server]	loss_train: 1.6074	loss_val: 1.6066	loss_test: 1.6154	accuracy_train: 0.4000	accuracy_val: 0.3529	accuracy_test: 0.3043
[server]	loss_train: 1.6220	loss_val: 1.6199	loss_test: 1.6224	accuracy_train: 0.1731	accuracy_val: 0.1081	accuracy_test: 0.0417
[server]	loss_train: 1.6030	loss_val: 1.6072	loss_test: 1.6067	accuracy_train: 0.1930	accuracy_val: 0.3000	accuracy_test: 0.2308
[server]	loss_train: 1.6139	loss_val: 1.6231	loss_test: 1.6215	accuracy_train: 0.2340	accuracy_val: 0.1212	accuracy_test: 0.2273
[server]	loss_train: 1.6052	loss_val: 1.6095	loss_test: 1.6079	accuracy_train: 0.2200	accuracy_val: 0.1944	accuracy_test: 0.1739
[server]	loss_train: 1.6163	loss_val: 1.6138	loss_test: 1.6178	accuracy_train: 0.0926	accuracy_val: 0.2368	accuracy_test: 0.1923
[server]	loss_train: 1.6110	loss_val: 1.6147	loss_test: 1.6156	accuracy_train: 0.2245	accuracy_val: 0.1143	accuracy_test: 0.1304
[server]	loss_train: 1.6179	loss_val: 1.6192	loss_test: 1.6155	accuracy_train: 0.1579	accuracy_val: 0.1795	accuracy_test: 0.1923
[server]	loss_train: 1.6131	loss_val: 1.6070	loss_test: 1.6073	accuracy_train: 0.1395	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.5987	loss_val: 1.6030	loss_test: 1.6040	accuracy_train: 0.2292	accuracy_val: 0.2857	accuracy_test: 0.2500
[server]	loss_train: 1.6051	loss_val: 1.6090	loss_test: 1.6075	accuracy_train: 0.2381	accuracy_val: 0.2045	accuracy_test: 0.1786
[server]	loss_train: 1.6129	loss_val: 1.6121	loss_test: 1.6102	accuracy_train: 0.2391	accuracy_val: 0.1515	accuracy_test: 0.2273
[server]	loss_train: 1.6077	loss_val: 1.6136	loss_test: 1.6074	accuracy_train: 0.2400	accuracy_val: 0.0571	accuracy_test: 0.1600
[server]	loss_train: 1.6134	loss_val: 1.6116	loss_test: 1.6250	accuracy_train: 0.1290	accuracy_val: 0.1818	accuracy_test: 0.1034
[server]	loss_train: 1.6065	loss_val: 1.6122	loss_test: 1.6121	accuracy_train: 0.2000	accuracy_val: 0.1250	accuracy_test: 0.1429
[server]	loss_train: 1.6110	loss_val: 1.6123	loss_test: 1.6156	accuracy_train: 0.1905	accuracy_val: 0.2045	accuracy_test: 0.2414
[server]	loss_train: 1.6229	loss_val: 1.6220	loss_test: 1.6174	accuracy_train: 0.1379	accuracy_val: 0.1026	accuracy_test: 0.1786
curr_round: 2	curr_val_accuracy: 0.1837	curr_test_accuracy: 0.1873
best_round: 0	best_val_accuracy: 0.1837	best_test_accuracy: 0.1873
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.7917	loss_train: 0.0509	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.9547	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.8333	loss_train: 0.0490	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.9181	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.8333	loss_train: 0.0474	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.8846	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9216	loss_train: 0.0664	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.2000	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0644	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.1601	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0624	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.1212	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8491	loss_train: 0.0686	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.2490	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8491	loss_train: 0.0666	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.2100	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8491	loss_train: 0.0647	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.1710	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.8800	acc_cls: 0.8600	loss_train: 0.0589	loss_degree: 0.0479	loss_feat: 0.0001	loss_cls: 1.1273	loss_other: 0.0031
[client 3 neighGen phase]	acc_degree: 0.9000	acc_cls: 0.8600	loss_train: 0.0566	loss_degree: 0.0449	loss_feat: 0.0001	loss_cls: 1.0827	loss_other: 0.0037
[client 3 neighGen phase]	acc_degree: 0.9000	acc_cls: 0.8600	loss_train: 0.0543	loss_degree: 0.0427	loss_feat: 0.0001	loss_cls: 1.0402	loss_other: 0.0037
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.8269	loss_train: 0.0621	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 1.0697	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.8846	loss_train: 0.0600	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 1.0274	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.8846	loss_train: 0.0580	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.9867	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.8421	loss_train: 0.0664	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.2845	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.8772	loss_train: 0.0646	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.2473	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.8947	loss_train: 0.0627	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.2099	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9362	acc_cls: 0.9362	loss_train: 0.0540	loss_degree: 0.0493	loss_feat: 0.0002	loss_cls: 1.0293	loss_other: 0.0017
[client 6 neighGen phase]	acc_degree: 0.9362	acc_cls: 0.9574	loss_train: 0.0519	loss_degree: 0.0464	loss_feat: 0.0002	loss_cls: 0.9890	loss_other: 0.0017
[client 6 neighGen phase]	acc_degree: 0.9574	acc_cls: 0.9574	loss_train: 0.0499	loss_degree: 0.0431	loss_feat: 0.0002	loss_cls: 0.9517	loss_other: 0.0024
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.8400	loss_train: 0.0567	loss_degree: 0.0173	loss_feat: 0.0000	loss_cls: 1.1165	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9600	acc_cls: 0.8400	loss_train: 0.0544	loss_degree: 0.0128	loss_feat: 0.0001	loss_cls: 1.0732	loss_other: 0.0025
[client 7 neighGen phase]	acc_degree: 0.9600	acc_cls: 0.8400	loss_train: 0.0522	loss_degree: 0.0089	loss_feat: 0.0001	loss_cls: 1.0328	loss_other: 0.0020
[client 8 neighGen phase]	acc_degree: 0.8148	acc_cls: 0.7963	loss_train: 0.0606	loss_degree: 0.1097	loss_feat: 0.0006	loss_cls: 1.0976	loss_other: 0.0039
[client 8 neighGen phase]	acc_degree: 0.7778	acc_cls: 0.7963	loss_train: 0.0578	loss_degree: 0.1070	loss_feat: 0.0004	loss_cls: 1.0446	loss_other: 0.0030
[client 8 neighGen phase]	acc_degree: 0.7037	acc_cls: 0.7963	loss_train: 0.0550	loss_degree: 0.1064	loss_feat: 0.0001	loss_cls: 0.9937	loss_other: 0.0005
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.7959	loss_train: 0.0606	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 1.0899	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.7959	loss_train: 0.0584	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 1.0455	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.7959	loss_train: 0.0563	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 1.0037	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8947	acc_cls: 0.8070	loss_train: 0.0586	loss_degree: 0.0605	loss_feat: 0.0002	loss_cls: 1.1090	loss_other: 0.0027
[client 10 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.8421	loss_train: 0.0564	loss_degree: 0.0574	loss_feat: 0.0002	loss_cls: 1.0677	loss_other: 0.0030
[client 10 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.8421	loss_train: 0.0543	loss_degree: 0.0551	loss_feat: 0.0002	loss_cls: 1.0275	loss_other: 0.0025
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.8140	loss_train: 0.0577	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 1.1197	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.8372	loss_train: 0.0554	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 1.0735	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.8372	loss_train: 0.0532	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 1.0295	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8333	acc_cls: 0.8333	loss_train: 0.0645	loss_degree: 0.0750	loss_feat: 0.0004	loss_cls: 1.2090	loss_other: 0.0051
[client 12 neighGen phase]	acc_degree: 0.8125	acc_cls: 0.8542	loss_train: 0.0619	loss_degree: 0.0670	loss_feat: 0.0003	loss_cls: 1.1668	loss_other: 0.0031
[client 12 neighGen phase]	acc_degree: 0.8125	acc_cls: 0.8542	loss_train: 0.0594	loss_degree: 0.0588	loss_feat: 0.0003	loss_cls: 1.1251	loss_other: 0.0028
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.7143	loss_train: 0.0600	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.1445	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.7302	loss_train: 0.0579	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.1023	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.7302	loss_train: 0.0559	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.0621	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8913	acc_cls: 0.9565	loss_train: 0.0581	loss_degree: 0.0310	loss_feat: 0.0002	loss_cls: 1.1266	loss_other: 0.0046
[client 14 neighGen phase]	acc_degree: 0.9130	acc_cls: 0.9565	loss_train: 0.0557	loss_degree: 0.0274	loss_feat: 0.0002	loss_cls: 1.0816	loss_other: 0.0058
[client 14 neighGen phase]	acc_degree: 0.9130	acc_cls: 0.9783	loss_train: 0.0534	loss_degree: 0.0242	loss_feat: 0.0002	loss_cls: 1.0384	loss_other: 0.0046
[client 15 neighGen phase]	acc_degree: 0.8200	acc_cls: 0.9200	loss_train: 0.0590	loss_degree: 0.0340	loss_feat: 0.0005	loss_cls: 1.1375	loss_other: 0.0070
[client 15 neighGen phase]	acc_degree: 0.7600	acc_cls: 0.9400	loss_train: 0.0565	loss_degree: 0.0308	loss_feat: 0.0004	loss_cls: 1.0942	loss_other: 0.0047
[client 15 neighGen phase]	acc_degree: 0.7400	acc_cls: 0.9400	loss_train: 0.0543	loss_degree: 0.0287	loss_feat: 0.0003	loss_cls: 1.0534	loss_other: 0.0039
[client 16 neighGen phase]	acc_degree: 0.6129	acc_cls: 0.9032	loss_train: 0.0652	loss_degree: 0.1191	loss_feat: 0.0002	loss_cls: 1.1808	loss_other: 0.0035
[client 16 neighGen phase]	acc_degree: 0.6129	acc_cls: 0.9032	loss_train: 0.0628	loss_degree: 0.1054	loss_feat: 0.0002	loss_cls: 1.1467	loss_other: 0.0034
[client 16 neighGen phase]	acc_degree: 0.6129	acc_cls: 0.9194	loss_train: 0.0606	loss_degree: 0.0951	loss_feat: 0.0002	loss_cls: 1.1135	loss_other: 0.0040
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9333	loss_train: 0.0636	loss_degree: 0.0461	loss_feat: 0.0000	loss_cls: 1.2261	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9556	loss_train: 0.0618	loss_degree: 0.0452	loss_feat: 0.0000	loss_cls: 1.1900	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9778	loss_train: 0.0600	loss_degree: 0.0441	loss_feat: 0.0000	loss_cls: 1.1552	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.7143	loss_train: 0.0608	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.1607	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.7302	loss_train: 0.0586	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.1161	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.7460	loss_train: 0.0564	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.0727	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7931	acc_cls: 0.9655	loss_train: 0.0565	loss_degree: 0.0570	loss_feat: 0.0005	loss_cls: 1.0660	loss_other: 0.0065
[client 19 neighGen phase]	acc_degree: 0.7931	acc_cls: 0.9655	loss_train: 0.0533	loss_degree: 0.0512	loss_feat: 0.0006	loss_cls: 1.0080	loss_other: 0.0065
[client 19 neighGen phase]	acc_degree: 0.7931	acc_cls: 0.9655	loss_train: 0.0502	loss_degree: 0.0460	loss_feat: 0.0006	loss_cls: 0.9526	loss_other: 0.0054
[server]	loss_train: 1.6215	loss_val: 1.6212	loss_test: 1.6242	accuracy_train: 0.1667	accuracy_val: 0.1111	accuracy_test: 0.1304
[server]	loss_train: 1.6154	loss_val: 1.6178	loss_test: 1.6157	accuracy_train: 0.1176	accuracy_val: 0.1111	accuracy_test: 0.1250
[server]	loss_train: 1.6059	loss_val: 1.6056	loss_test: 1.6097	accuracy_train: 0.1698	accuracy_val: 0.2564	accuracy_test: 0.2800
[server]	loss_train: 1.6074	loss_val: 1.6066	loss_test: 1.6154	accuracy_train: 0.4000	accuracy_val: 0.3529	accuracy_test: 0.3043
[server]	loss_train: 1.6220	loss_val: 1.6199	loss_test: 1.6224	accuracy_train: 0.1731	accuracy_val: 0.1081	accuracy_test: 0.0417
[server]	loss_train: 1.6030	loss_val: 1.6072	loss_test: 1.6067	accuracy_train: 0.1930	accuracy_val: 0.3000	accuracy_test: 0.2308
[server]	loss_train: 1.6139	loss_val: 1.6231	loss_test: 1.6215	accuracy_train: 0.2340	accuracy_val: 0.1212	accuracy_test: 0.2273
[server]	loss_train: 1.6052	loss_val: 1.6095	loss_test: 1.6079	accuracy_train: 0.2200	accuracy_val: 0.1944	accuracy_test: 0.1739
[server]	loss_train: 1.6163	loss_val: 1.6138	loss_test: 1.6178	accuracy_train: 0.0926	accuracy_val: 0.2368	accuracy_test: 0.1923
[server]	loss_train: 1.6110	loss_val: 1.6147	loss_test: 1.6156	accuracy_train: 0.2245	accuracy_val: 0.1143	accuracy_test: 0.1304
[server]	loss_train: 1.6179	loss_val: 1.6192	loss_test: 1.6155	accuracy_train: 0.1579	accuracy_val: 0.1795	accuracy_test: 0.1923
[server]	loss_train: 1.6131	loss_val: 1.6070	loss_test: 1.6073	accuracy_train: 0.1395	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.5987	loss_val: 1.6030	loss_test: 1.6040	accuracy_train: 0.2292	accuracy_val: 0.2857	accuracy_test: 0.2500
[server]	loss_train: 1.6051	loss_val: 1.6090	loss_test: 1.6075	accuracy_train: 0.2381	accuracy_val: 0.2045	accuracy_test: 0.1786
[server]	loss_train: 1.6129	loss_val: 1.6121	loss_test: 1.6102	accuracy_train: 0.2391	accuracy_val: 0.1515	accuracy_test: 0.2273
[server]	loss_train: 1.6077	loss_val: 1.6136	loss_test: 1.6074	accuracy_train: 0.2400	accuracy_val: 0.0571	accuracy_test: 0.1600
[server]	loss_train: 1.6134	loss_val: 1.6116	loss_test: 1.6250	accuracy_train: 0.1290	accuracy_val: 0.1818	accuracy_test: 0.1034
[server]	loss_train: 1.6065	loss_val: 1.6122	loss_test: 1.6121	accuracy_train: 0.2000	accuracy_val: 0.1250	accuracy_test: 0.1429
[server]	loss_train: 1.6110	loss_val: 1.6123	loss_test: 1.6156	accuracy_train: 0.1905	accuracy_val: 0.2045	accuracy_test: 0.2414
[server]	loss_train: 1.6229	loss_val: 1.6220	loss_test: 1.6174	accuracy_train: 0.1379	accuracy_val: 0.1026	accuracy_test: 0.1786
curr_round: 3	curr_val_accuracy: 0.1837	curr_test_accuracy: 0.1873
best_round: 0	best_val_accuracy: 0.1837	best_test_accuracy: 0.1873
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.8542	loss_train: 0.0458	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.8534	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.8542	loss_train: 0.0443	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.8240	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.8750	loss_train: 0.0429	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.7961	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0605	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.0829	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0586	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.0452	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0568	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 1.0081	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8679	loss_train: 0.0627	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.1323	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8868	loss_train: 0.0608	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.0939	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.9057	loss_train: 0.0589	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.0561	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.8800	loss_train: 0.0521	loss_degree: 0.0411	loss_feat: 0.0001	loss_cls: 0.9994	loss_other: 0.0021
[client 3 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.8800	loss_train: 0.0501	loss_degree: 0.0398	loss_feat: 0.0001	loss_cls: 0.9603	loss_other: 0.0024
[client 3 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.9000	loss_train: 0.0482	loss_degree: 0.0383	loss_feat: 0.0001	loss_cls: 0.9224	loss_other: 0.0024
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9038	loss_train: 0.0560	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.9472	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9038	loss_train: 0.0541	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.9088	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9231	loss_train: 0.0522	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.8715	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9298	loss_train: 0.0608	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.1727	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9649	loss_train: 0.0590	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.1359	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9649	loss_train: 0.0572	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.0999	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9574	acc_cls: 0.9574	loss_train: 0.0480	loss_degree: 0.0397	loss_feat: 0.0002	loss_cls: 0.9170	loss_other: 0.0021
[client 6 neighGen phase]	acc_degree: 0.9362	acc_cls: 0.9574	loss_train: 0.0462	loss_degree: 0.0364	loss_feat: 0.0002	loss_cls: 0.8847	loss_other: 0.0020
[client 6 neighGen phase]	acc_degree: 0.9149	acc_cls: 0.9574	loss_train: 0.0445	loss_degree: 0.0335	loss_feat: 0.0001	loss_cls: 0.8546	loss_other: 0.0015
[client 7 neighGen phase]	acc_degree: 0.9600	acc_cls: 0.8400	loss_train: 0.0502	loss_degree: 0.0061	loss_feat: 0.0001	loss_cls: 0.9953	loss_other: 0.0020
[client 7 neighGen phase]	acc_degree: 0.9600	acc_cls: 0.8400	loss_train: 0.0483	loss_degree: 0.0047	loss_feat: 0.0001	loss_cls: 0.9606	loss_other: 0.0013
[client 7 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.8400	loss_train: 0.0468	loss_degree: 0.0044	loss_feat: 0.0001	loss_cls: 0.9287	loss_other: 0.0022
[client 8 neighGen phase]	acc_degree: 0.7037	acc_cls: 0.8148	loss_train: 0.0526	loss_degree: 0.1061	loss_feat: 0.0001	loss_cls: 0.9454	loss_other: 0.0006
[client 8 neighGen phase]	acc_degree: 0.7222	acc_cls: 0.8148	loss_train: 0.0503	loss_degree: 0.1048	loss_feat: 0.0001	loss_cls: 0.8999	loss_other: 0.0011
[client 8 neighGen phase]	acc_degree: 0.7407	acc_cls: 0.8333	loss_train: 0.0481	loss_degree: 0.1023	loss_feat: 0.0002	loss_cls: 0.8572	loss_other: 0.0014
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.7959	loss_train: 0.0543	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.9645	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.7959	loss_train: 0.0525	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.9281	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.8367	loss_train: 0.0508	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.8943	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.8772	loss_train: 0.0522	loss_degree: 0.0531	loss_feat: 0.0002	loss_cls: 0.9886	loss_other: 0.0030
[client 10 neighGen phase]	acc_degree: 0.8772	acc_cls: 0.8772	loss_train: 0.0502	loss_degree: 0.0514	loss_feat: 0.0001	loss_cls: 0.9510	loss_other: 0.0020
[client 10 neighGen phase]	acc_degree: 0.8772	acc_cls: 0.8772	loss_train: 0.0483	loss_degree: 0.0501	loss_feat: 0.0001	loss_cls: 0.9148	loss_other: 0.0014
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.8372	loss_train: 0.0511	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.9879	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.8605	loss_train: 0.0492	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.9487	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.8605	loss_train: 0.0473	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.9119	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8125	acc_cls: 0.8750	loss_train: 0.0570	loss_degree: 0.0525	loss_feat: 0.0003	loss_cls: 1.0840	loss_other: 0.0034
[client 12 neighGen phase]	acc_degree: 0.8333	acc_cls: 0.8958	loss_train: 0.0548	loss_degree: 0.0486	loss_feat: 0.0002	loss_cls: 1.0435	loss_other: 0.0032
[client 12 neighGen phase]	acc_degree: 0.8333	acc_cls: 0.9167	loss_train: 0.0526	loss_degree: 0.0463	loss_feat: 0.0002	loss_cls: 1.0035	loss_other: 0.0027
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.7302	loss_train: 0.0540	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.0236	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.7302	loss_train: 0.0521	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.9865	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.7460	loss_train: 0.0503	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.9507	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9130	acc_cls: 0.9783	loss_train: 0.0511	loss_degree: 0.0212	loss_feat: 0.0001	loss_cls: 0.9970	loss_other: 0.0045
[client 14 neighGen phase]	acc_degree: 0.8913	acc_cls: 0.9783	loss_train: 0.0490	loss_degree: 0.0183	loss_feat: 0.0001	loss_cls: 0.9578	loss_other: 0.0042
[client 14 neighGen phase]	acc_degree: 0.8913	acc_cls: 0.9783	loss_train: 0.0470	loss_degree: 0.0159	loss_feat: 0.0001	loss_cls: 0.9207	loss_other: 0.0035
[client 15 neighGen phase]	acc_degree: 0.7200	acc_cls: 0.9400	loss_train: 0.0522	loss_degree: 0.0259	loss_feat: 0.0002	loss_cls: 1.0150	loss_other: 0.0037
[client 15 neighGen phase]	acc_degree: 0.7200	acc_cls: 0.9400	loss_train: 0.0502	loss_degree: 0.0222	loss_feat: 0.0001	loss_cls: 0.9792	loss_other: 0.0034
[client 15 neighGen phase]	acc_degree: 0.7400	acc_cls: 0.9400	loss_train: 0.0484	loss_degree: 0.0180	loss_feat: 0.0002	loss_cls: 0.9460	loss_other: 0.0034
[client 16 neighGen phase]	acc_degree: 0.5806	acc_cls: 0.9194	loss_train: 0.0585	loss_degree: 0.0870	loss_feat: 0.0001	loss_cls: 1.0810	loss_other: 0.0027
[client 16 neighGen phase]	acc_degree: 0.6129	acc_cls: 0.9194	loss_train: 0.0566	loss_degree: 0.0798	loss_feat: 0.0001	loss_cls: 1.0490	loss_other: 0.0031
[client 16 neighGen phase]	acc_degree: 0.6129	acc_cls: 0.9194	loss_train: 0.0547	loss_degree: 0.0729	loss_feat: 0.0001	loss_cls: 1.0174	loss_other: 0.0036
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.8889	loss_train: 0.0582	loss_degree: 0.0430	loss_feat: 0.0000	loss_cls: 1.1215	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.8889	loss_train: 0.0565	loss_degree: 0.0417	loss_feat: 0.0000	loss_cls: 1.0889	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0549	loss_degree: 0.0403	loss_feat: 0.0000	loss_cls: 1.0574	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.7778	loss_train: 0.0543	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 1.0302	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.7778	loss_train: 0.0522	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.9890	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.7778	loss_train: 0.0502	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.9492	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.8448	acc_cls: 0.9483	loss_train: 0.0473	loss_degree: 0.0396	loss_feat: 0.0006	loss_cls: 0.9006	loss_other: 0.0059
[client 19 neighGen phase]	acc_degree: 0.8103	acc_cls: 0.9655	loss_train: 0.0446	loss_degree: 0.0331	loss_feat: 0.0005	loss_cls: 0.8522	loss_other: 0.0051
[client 19 neighGen phase]	acc_degree: 0.7931	acc_cls: 0.9655	loss_train: 0.0420	loss_degree: 0.0288	loss_feat: 0.0005	loss_cls: 0.8078	loss_other: 0.0039
[server]	loss_train: 1.6215	loss_val: 1.6212	loss_test: 1.6242	accuracy_train: 0.1667	accuracy_val: 0.1111	accuracy_test: 0.1304
[server]	loss_train: 1.6154	loss_val: 1.6178	loss_test: 1.6157	accuracy_train: 0.1176	accuracy_val: 0.1111	accuracy_test: 0.1250
[server]	loss_train: 1.6059	loss_val: 1.6056	loss_test: 1.6097	accuracy_train: 0.1698	accuracy_val: 0.2564	accuracy_test: 0.2800
[server]	loss_train: 1.6074	loss_val: 1.6066	loss_test: 1.6154	accuracy_train: 0.4000	accuracy_val: 0.3529	accuracy_test: 0.3043
[server]	loss_train: 1.6220	loss_val: 1.6199	loss_test: 1.6224	accuracy_train: 0.1731	accuracy_val: 0.1081	accuracy_test: 0.0417
[server]	loss_train: 1.6030	loss_val: 1.6072	loss_test: 1.6067	accuracy_train: 0.1930	accuracy_val: 0.3000	accuracy_test: 0.2308
[server]	loss_train: 1.6139	loss_val: 1.6231	loss_test: 1.6215	accuracy_train: 0.2340	accuracy_val: 0.1212	accuracy_test: 0.2273
[server]	loss_train: 1.6052	loss_val: 1.6095	loss_test: 1.6079	accuracy_train: 0.2200	accuracy_val: 0.1944	accuracy_test: 0.1739
[server]	loss_train: 1.6163	loss_val: 1.6138	loss_test: 1.6178	accuracy_train: 0.0926	accuracy_val: 0.2368	accuracy_test: 0.1923
[server]	loss_train: 1.6110	loss_val: 1.6147	loss_test: 1.6156	accuracy_train: 0.2245	accuracy_val: 0.1143	accuracy_test: 0.1304
[server]	loss_train: 1.6179	loss_val: 1.6192	loss_test: 1.6155	accuracy_train: 0.1579	accuracy_val: 0.1795	accuracy_test: 0.1923
[server]	loss_train: 1.6131	loss_val: 1.6070	loss_test: 1.6073	accuracy_train: 0.1395	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.5987	loss_val: 1.6030	loss_test: 1.6040	accuracy_train: 0.2292	accuracy_val: 0.2857	accuracy_test: 0.2500
[server]	loss_train: 1.6051	loss_val: 1.6090	loss_test: 1.6075	accuracy_train: 0.2381	accuracy_val: 0.2045	accuracy_test: 0.1786
[server]	loss_train: 1.6129	loss_val: 1.6121	loss_test: 1.6102	accuracy_train: 0.2391	accuracy_val: 0.1515	accuracy_test: 0.2273
[server]	loss_train: 1.6077	loss_val: 1.6136	loss_test: 1.6074	accuracy_train: 0.2400	accuracy_val: 0.0571	accuracy_test: 0.1600
[server]	loss_train: 1.6134	loss_val: 1.6116	loss_test: 1.6250	accuracy_train: 0.1290	accuracy_val: 0.1818	accuracy_test: 0.1034
[server]	loss_train: 1.6065	loss_val: 1.6122	loss_test: 1.6121	accuracy_train: 0.2000	accuracy_val: 0.1250	accuracy_test: 0.1429
[server]	loss_train: 1.6110	loss_val: 1.6123	loss_test: 1.6156	accuracy_train: 0.1905	accuracy_val: 0.2045	accuracy_test: 0.2414
[server]	loss_train: 1.6229	loss_val: 1.6220	loss_test: 1.6174	accuracy_train: 0.1379	accuracy_val: 0.1026	accuracy_test: 0.1786
curr_round: 4	curr_val_accuracy: 0.1837	curr_test_accuracy: 0.1873
best_round: 0	best_val_accuracy: 0.1837	best_test_accuracy: 0.1873
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.8750	loss_train: 0.0416	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.7695	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.8750	loss_train: 0.0403	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.7442	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.8750	loss_train: 0.0391	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.7200	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0550	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.9717	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0532	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.9362	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0515	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.9016	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8868	loss_train: 0.0571	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 1.0192	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8868	loss_train: 0.0553	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.9831	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8868	loss_train: 0.0535	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.9482	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.9000	loss_train: 0.0463	loss_degree: 0.0366	loss_feat: 0.0001	loss_cls: 0.8859	loss_other: 0.0025
[client 3 neighGen phase]	acc_degree: 0.8800	acc_cls: 0.9000	loss_train: 0.0444	loss_degree: 0.0345	loss_feat: 0.0001	loss_cls: 0.8506	loss_other: 0.0025
[client 3 neighGen phase]	acc_degree: 0.9000	acc_cls: 0.9000	loss_train: 0.0426	loss_degree: 0.0323	loss_feat: 0.0001	loss_cls: 0.8166	loss_other: 0.0036
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9615	loss_train: 0.0504	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.8357	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9615	loss_train: 0.0487	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.8018	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9615	loss_train: 0.0471	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.7696	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9649	loss_train: 0.0554	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.0648	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9649	loss_train: 0.0537	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 1.0308	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9649	loss_train: 0.0521	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 0.9978	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9149	acc_cls: 0.9574	loss_train: 0.0429	loss_degree: 0.0308	loss_feat: 0.0001	loss_cls: 0.8265	loss_other: 0.0012
[client 6 neighGen phase]	acc_degree: 0.9149	acc_cls: 0.9574	loss_train: 0.0415	loss_degree: 0.0283	loss_feat: 0.0001	loss_cls: 0.8001	loss_other: 0.0010
[client 6 neighGen phase]	acc_degree: 0.9149	acc_cls: 0.9574	loss_train: 0.0401	loss_degree: 0.0261	loss_feat: 0.0001	loss_cls: 0.7755	loss_other: 0.0012
[client 7 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.8400	loss_train: 0.0453	loss_degree: 0.0047	loss_feat: 0.0001	loss_cls: 0.8990	loss_other: 0.0020
[client 7 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.8400	loss_train: 0.0439	loss_degree: 0.0047	loss_feat: 0.0001	loss_cls: 0.8715	loss_other: 0.0020
[client 7 neighGen phase]	acc_degree: 0.9600	acc_cls: 0.8600	loss_train: 0.0426	loss_degree: 0.0043	loss_feat: 0.0000	loss_cls: 0.8458	loss_other: 0.0014
[client 8 neighGen phase]	acc_degree: 0.7593	acc_cls: 0.8333	loss_train: 0.0459	loss_degree: 0.0989	loss_feat: 0.0002	loss_cls: 0.8172	loss_other: 0.0017
[client 8 neighGen phase]	acc_degree: 0.7593	acc_cls: 0.8704	loss_train: 0.0439	loss_degree: 0.0951	loss_feat: 0.0002	loss_cls: 0.7798	loss_other: 0.0021
[client 8 neighGen phase]	acc_degree: 0.7778	acc_cls: 0.8704	loss_train: 0.0420	loss_degree: 0.0917	loss_feat: 0.0003	loss_cls: 0.7449	loss_other: 0.0028
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.8571	loss_train: 0.0493	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.8629	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.8776	loss_train: 0.0478	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.8338	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.8776	loss_train: 0.0465	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.8068	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8772	acc_cls: 0.8772	loss_train: 0.0465	loss_degree: 0.0491	loss_feat: 0.0001	loss_cls: 0.8799	loss_other: 0.0016
[client 10 neighGen phase]	acc_degree: 0.8596	acc_cls: 0.8772	loss_train: 0.0448	loss_degree: 0.0486	loss_feat: 0.0001	loss_cls: 0.8462	loss_other: 0.0010
[client 10 neighGen phase]	acc_degree: 0.8596	acc_cls: 0.8772	loss_train: 0.0431	loss_degree: 0.0476	loss_feat: 0.0001	loss_cls: 0.8137	loss_other: 0.0013
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.8837	loss_train: 0.0456	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.8775	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.9070	loss_train: 0.0440	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.8454	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.9302	loss_train: 0.0425	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.8152	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8125	acc_cls: 0.9167	loss_train: 0.0505	loss_degree: 0.0438	loss_feat: 0.0002	loss_cls: 0.9642	loss_other: 0.0021
[client 12 neighGen phase]	acc_degree: 0.8542	acc_cls: 0.9167	loss_train: 0.0484	loss_degree: 0.0396	loss_feat: 0.0002	loss_cls: 0.9256	loss_other: 0.0033
[client 12 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.9167	loss_train: 0.0463	loss_degree: 0.0338	loss_feat: 0.0003	loss_cls: 0.8879	loss_other: 0.0050
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.7619	loss_train: 0.0486	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.9163	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.8095	loss_train: 0.0469	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.8831	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.8254	loss_train: 0.0453	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.8512	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8696	acc_cls: 0.9783	loss_train: 0.0451	loss_degree: 0.0140	loss_feat: 0.0001	loss_cls: 0.8856	loss_other: 0.0022
[client 14 neighGen phase]	acc_degree: 0.8696	acc_cls: 0.9783	loss_train: 0.0434	loss_degree: 0.0126	loss_feat: 0.0001	loss_cls: 0.8526	loss_other: 0.0023
[client 14 neighGen phase]	acc_degree: 0.8261	acc_cls: 0.9783	loss_train: 0.0417	loss_degree: 0.0118	loss_feat: 0.0001	loss_cls: 0.8216	loss_other: 0.0011
[client 15 neighGen phase]	acc_degree: 0.7400	acc_cls: 0.9600	loss_train: 0.0467	loss_degree: 0.0144	loss_feat: 0.0002	loss_cls: 0.9150	loss_other: 0.0035
[client 15 neighGen phase]	acc_degree: 0.8000	acc_cls: 0.9600	loss_train: 0.0452	loss_degree: 0.0122	loss_feat: 0.0003	loss_cls: 0.8861	loss_other: 0.0053
[client 15 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.9200	loss_train: 0.0439	loss_degree: 0.0111	loss_feat: 0.0004	loss_cls: 0.8590	loss_other: 0.0068
[client 16 neighGen phase]	acc_degree: 0.6290	acc_cls: 0.9194	loss_train: 0.0528	loss_degree: 0.0663	loss_feat: 0.0001	loss_cls: 0.9863	loss_other: 0.0037
[client 16 neighGen phase]	acc_degree: 0.6452	acc_cls: 0.9677	loss_train: 0.0511	loss_degree: 0.0609	loss_feat: 0.0002	loss_cls: 0.9558	loss_other: 0.0044
[client 16 neighGen phase]	acc_degree: 0.6774	acc_cls: 0.9677	loss_train: 0.0494	loss_degree: 0.0566	loss_feat: 0.0002	loss_cls: 0.9258	loss_other: 0.0048
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0533	loss_degree: 0.0387	loss_feat: 0.0000	loss_cls: 1.0270	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0517	loss_degree: 0.0370	loss_feat: 0.0000	loss_cls: 0.9978	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0502	loss_degree: 0.0351	loss_feat: 0.0000	loss_cls: 0.9696	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.7778	loss_train: 0.0483	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.9111	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.7778	loss_train: 0.0465	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.8750	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.7937	loss_train: 0.0448	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.8409	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7759	acc_cls: 0.9655	loss_train: 0.0400	loss_degree: 0.0274	loss_feat: 0.0004	loss_cls: 0.7673	loss_other: 0.0040
[client 19 neighGen phase]	acc_degree: 0.7586	acc_cls: 0.9655	loss_train: 0.0381	loss_degree: 0.0280	loss_feat: 0.0004	loss_cls: 0.7306	loss_other: 0.0033
[client 19 neighGen phase]	acc_degree: 0.7586	acc_cls: 0.9483	loss_train: 0.0365	loss_degree: 0.0285	loss_feat: 0.0004	loss_cls: 0.6977	loss_other: 0.0030
[server]	loss_train: 1.6215	loss_val: 1.6212	loss_test: 1.6242	accuracy_train: 0.1667	accuracy_val: 0.1111	accuracy_test: 0.1304
[server]	loss_train: 1.6154	loss_val: 1.6178	loss_test: 1.6157	accuracy_train: 0.1176	accuracy_val: 0.1111	accuracy_test: 0.1250
[server]	loss_train: 1.6059	loss_val: 1.6056	loss_test: 1.6097	accuracy_train: 0.1698	accuracy_val: 0.2564	accuracy_test: 0.2800
[server]	loss_train: 1.6074	loss_val: 1.6066	loss_test: 1.6154	accuracy_train: 0.4000	accuracy_val: 0.3529	accuracy_test: 0.3043
[server]	loss_train: 1.6220	loss_val: 1.6199	loss_test: 1.6224	accuracy_train: 0.1731	accuracy_val: 0.1081	accuracy_test: 0.0417
[server]	loss_train: 1.6030	loss_val: 1.6072	loss_test: 1.6067	accuracy_train: 0.1930	accuracy_val: 0.3000	accuracy_test: 0.2308
[server]	loss_train: 1.6139	loss_val: 1.6231	loss_test: 1.6215	accuracy_train: 0.2340	accuracy_val: 0.1212	accuracy_test: 0.2273
[server]	loss_train: 1.6052	loss_val: 1.6095	loss_test: 1.6079	accuracy_train: 0.2200	accuracy_val: 0.1944	accuracy_test: 0.1739
[server]	loss_train: 1.6163	loss_val: 1.6138	loss_test: 1.6178	accuracy_train: 0.0926	accuracy_val: 0.2368	accuracy_test: 0.1923
[server]	loss_train: 1.6110	loss_val: 1.6147	loss_test: 1.6156	accuracy_train: 0.2245	accuracy_val: 0.1143	accuracy_test: 0.1304
[server]	loss_train: 1.6179	loss_val: 1.6192	loss_test: 1.6155	accuracy_train: 0.1579	accuracy_val: 0.1795	accuracy_test: 0.1923
[server]	loss_train: 1.6131	loss_val: 1.6070	loss_test: 1.6073	accuracy_train: 0.1395	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.5987	loss_val: 1.6030	loss_test: 1.6040	accuracy_train: 0.2292	accuracy_val: 0.2857	accuracy_test: 0.2500
[server]	loss_train: 1.6051	loss_val: 1.6090	loss_test: 1.6075	accuracy_train: 0.2381	accuracy_val: 0.2045	accuracy_test: 0.1786
[server]	loss_train: 1.6129	loss_val: 1.6121	loss_test: 1.6102	accuracy_train: 0.2391	accuracy_val: 0.1515	accuracy_test: 0.2273
[server]	loss_train: 1.6077	loss_val: 1.6136	loss_test: 1.6074	accuracy_train: 0.2400	accuracy_val: 0.0571	accuracy_test: 0.1600
[server]	loss_train: 1.6134	loss_val: 1.6116	loss_test: 1.6250	accuracy_train: 0.1290	accuracy_val: 0.1818	accuracy_test: 0.1034
[server]	loss_train: 1.6065	loss_val: 1.6122	loss_test: 1.6121	accuracy_train: 0.2000	accuracy_val: 0.1250	accuracy_test: 0.1429
[server]	loss_train: 1.6110	loss_val: 1.6123	loss_test: 1.6156	accuracy_train: 0.1905	accuracy_val: 0.2045	accuracy_test: 0.2414
[server]	loss_train: 1.6229	loss_val: 1.6220	loss_test: 1.6174	accuracy_train: 0.1379	accuracy_val: 0.1026	accuracy_test: 0.1786
curr_round: 5	curr_val_accuracy: 0.1837	curr_test_accuracy: 0.1873
best_round: 0	best_val_accuracy: 0.1837	best_test_accuracy: 0.1873
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.8750	loss_train: 0.0380	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.6969	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.8750	loss_train: 0.0369	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.6750	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.9167	loss_train: 0.0358	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.6541	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0498	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.8681	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0482	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.8357	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0466	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.8046	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8679	loss_train: 0.0519	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.9145	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8679	loss_train: 0.0502	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.8821	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8679	loss_train: 0.0487	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.8509	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9000	acc_cls: 0.9200	loss_train: 0.0409	loss_degree: 0.0301	loss_feat: 0.0001	loss_cls: 0.7841	loss_other: 0.0032
[client 3 neighGen phase]	acc_degree: 0.9000	acc_cls: 0.9200	loss_train: 0.0392	loss_degree: 0.0280	loss_feat: 0.0001	loss_cls: 0.7533	loss_other: 0.0034
[client 3 neighGen phase]	acc_degree: 0.9200	acc_cls: 0.9200	loss_train: 0.0377	loss_degree: 0.0261	loss_feat: 0.0001	loss_cls: 0.7240	loss_other: 0.0042
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9808	loss_train: 0.0456	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.7392	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9808	loss_train: 0.0442	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.7102	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9808	loss_train: 0.0428	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.6825	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9649	loss_train: 0.0505	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 0.9658	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9649	loss_train: 0.0489	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 0.9348	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9825	loss_train: 0.0474	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 0.9046	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9149	acc_cls: 0.9574	loss_train: 0.0389	loss_degree: 0.0243	loss_feat: 0.0001	loss_cls: 0.7523	loss_other: 0.0009
[client 6 neighGen phase]	acc_degree: 0.9362	acc_cls: 0.9574	loss_train: 0.0377	loss_degree: 0.0231	loss_feat: 0.0001	loss_cls: 0.7304	loss_other: 0.0014
[client 6 neighGen phase]	acc_degree: 0.9787	acc_cls: 0.9574	loss_train: 0.0368	loss_degree: 0.0224	loss_feat: 0.0002	loss_cls: 0.7096	loss_other: 0.0029
[client 7 neighGen phase]	acc_degree: 0.9600	acc_cls: 0.8600	loss_train: 0.0414	loss_degree: 0.0038	loss_feat: 0.0000	loss_cls: 0.8217	loss_other: 0.0017
[client 7 neighGen phase]	acc_degree: 0.9600	acc_cls: 0.8800	loss_train: 0.0402	loss_degree: 0.0033	loss_feat: 0.0000	loss_cls: 0.7992	loss_other: 0.0011
[client 7 neighGen phase]	acc_degree: 0.9600	acc_cls: 0.8800	loss_train: 0.0391	loss_degree: 0.0031	loss_feat: 0.0000	loss_cls: 0.7780	loss_other: 0.0010
[client 8 neighGen phase]	acc_degree: 0.8333	acc_cls: 0.8704	loss_train: 0.0403	loss_degree: 0.0889	loss_feat: 0.0005	loss_cls: 0.7123	loss_other: 0.0045
[client 8 neighGen phase]	acc_degree: 0.9074	acc_cls: 0.8704	loss_train: 0.0388	loss_degree: 0.0864	loss_feat: 0.0008	loss_cls: 0.6819	loss_other: 0.0068
[client 8 neighGen phase]	acc_degree: 0.9259	acc_cls: 0.8889	loss_train: 0.0372	loss_degree: 0.0837	loss_feat: 0.0009	loss_cls: 0.6536	loss_other: 0.0060
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.8980	loss_train: 0.0452	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.7818	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.8980	loss_train: 0.0440	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.7585	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.8980	loss_train: 0.0430	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.7367	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8596	acc_cls: 0.9123	loss_train: 0.0415	loss_degree: 0.0459	loss_feat: 0.0001	loss_cls: 0.7824	loss_other: 0.0007
[client 10 neighGen phase]	acc_degree: 0.8596	acc_cls: 0.9123	loss_train: 0.0399	loss_degree: 0.0442	loss_feat: 0.0001	loss_cls: 0.7522	loss_other: 0.0008
[client 10 neighGen phase]	acc_degree: 0.8596	acc_cls: 0.9123	loss_train: 0.0383	loss_degree: 0.0425	loss_feat: 0.0001	loss_cls: 0.7231	loss_other: 0.0009
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.9535	loss_train: 0.0411	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.7869	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.9535	loss_train: 0.0398	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.7601	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.9535	loss_train: 0.0385	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.7347	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.9375	loss_train: 0.0442	loss_degree: 0.0281	loss_feat: 0.0003	loss_cls: 0.8511	loss_other: 0.0039
[client 12 neighGen phase]	acc_degree: 0.8958	acc_cls: 0.9375	loss_train: 0.0422	loss_degree: 0.0242	loss_feat: 0.0003	loss_cls: 0.8153	loss_other: 0.0047
[client 12 neighGen phase]	acc_degree: 0.8958	acc_cls: 0.9375	loss_train: 0.0404	loss_degree: 0.0222	loss_feat: 0.0003	loss_cls: 0.7806	loss_other: 0.0052
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.8254	loss_train: 0.0438	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.8208	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.8254	loss_train: 0.0424	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.7919	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.8413	loss_train: 0.0410	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.7646	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8043	acc_cls: 0.9783	loss_train: 0.0402	loss_degree: 0.0113	loss_feat: 0.0000	loss_cls: 0.7925	loss_other: 0.0008
[client 14 neighGen phase]	acc_degree: 0.8261	acc_cls: 0.9783	loss_train: 0.0389	loss_degree: 0.0111	loss_feat: 0.0001	loss_cls: 0.7651	loss_other: 0.0013
[client 14 neighGen phase]	acc_degree: 0.8261	acc_cls: 0.9783	loss_train: 0.0376	loss_degree: 0.0110	loss_feat: 0.0001	loss_cls: 0.7393	loss_other: 0.0016
[client 15 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.9200	loss_train: 0.0425	loss_degree: 0.0103	loss_feat: 0.0004	loss_cls: 0.8335	loss_other: 0.0068
[client 15 neighGen phase]	acc_degree: 0.8200	acc_cls: 0.9200	loss_train: 0.0412	loss_degree: 0.0093	loss_feat: 0.0003	loss_cls: 0.8094	loss_other: 0.0051
[client 15 neighGen phase]	acc_degree: 0.7800	acc_cls: 0.9200	loss_train: 0.0400	loss_degree: 0.0085	loss_feat: 0.0002	loss_cls: 0.7865	loss_other: 0.0046
[client 16 neighGen phase]	acc_degree: 0.7097	acc_cls: 0.9677	loss_train: 0.0478	loss_degree: 0.0531	loss_feat: 0.0002	loss_cls: 0.8965	loss_other: 0.0054
[client 16 neighGen phase]	acc_degree: 0.7581	acc_cls: 0.9677	loss_train: 0.0462	loss_degree: 0.0496	loss_feat: 0.0003	loss_cls: 0.8680	loss_other: 0.0068
[client 16 neighGen phase]	acc_degree: 0.7419	acc_cls: 0.9677	loss_train: 0.0447	loss_degree: 0.0458	loss_feat: 0.0003	loss_cls: 0.8403	loss_other: 0.0067
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0488	loss_degree: 0.0330	loss_feat: 0.0000	loss_cls: 0.9425	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0473	loss_degree: 0.0307	loss_feat: 0.0000	loss_cls: 0.9163	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0460	loss_degree: 0.0282	loss_feat: 0.0000	loss_cls: 0.8911	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.7937	loss_train: 0.0432	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.8089	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.8095	loss_train: 0.0417	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.7791	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.8095	loss_train: 0.0404	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.7515	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7414	acc_cls: 0.9483	loss_train: 0.0349	loss_degree: 0.0275	loss_feat: 0.0003	loss_cls: 0.6682	loss_other: 0.0024
[client 19 neighGen phase]	acc_degree: 0.7414	acc_cls: 0.9483	loss_train: 0.0335	loss_degree: 0.0249	loss_feat: 0.0003	loss_cls: 0.6417	loss_other: 0.0027
[client 19 neighGen phase]	acc_degree: 0.7414	acc_cls: 0.9483	loss_train: 0.0321	loss_degree: 0.0214	loss_feat: 0.0003	loss_cls: 0.6179	loss_other: 0.0030
[server]	loss_train: 1.6215	loss_val: 1.6212	loss_test: 1.6242	accuracy_train: 0.1667	accuracy_val: 0.1111	accuracy_test: 0.1304
[server]	loss_train: 1.6154	loss_val: 1.6178	loss_test: 1.6157	accuracy_train: 0.1176	accuracy_val: 0.1111	accuracy_test: 0.1250
[server]	loss_train: 1.6059	loss_val: 1.6056	loss_test: 1.6097	accuracy_train: 0.1698	accuracy_val: 0.2564	accuracy_test: 0.2800
[server]	loss_train: 1.6074	loss_val: 1.6066	loss_test: 1.6154	accuracy_train: 0.4000	accuracy_val: 0.3529	accuracy_test: 0.3043
[server]	loss_train: 1.6220	loss_val: 1.6199	loss_test: 1.6224	accuracy_train: 0.1731	accuracy_val: 0.1081	accuracy_test: 0.0417
[server]	loss_train: 1.6030	loss_val: 1.6072	loss_test: 1.6067	accuracy_train: 0.1930	accuracy_val: 0.3000	accuracy_test: 0.2308
[server]	loss_train: 1.6139	loss_val: 1.6231	loss_test: 1.6215	accuracy_train: 0.2340	accuracy_val: 0.1212	accuracy_test: 0.2273
[server]	loss_train: 1.6052	loss_val: 1.6095	loss_test: 1.6079	accuracy_train: 0.2200	accuracy_val: 0.1944	accuracy_test: 0.1739
[server]	loss_train: 1.6163	loss_val: 1.6138	loss_test: 1.6178	accuracy_train: 0.0926	accuracy_val: 0.2368	accuracy_test: 0.1923
[server]	loss_train: 1.6110	loss_val: 1.6147	loss_test: 1.6156	accuracy_train: 0.2245	accuracy_val: 0.1143	accuracy_test: 0.1304
[server]	loss_train: 1.6179	loss_val: 1.6192	loss_test: 1.6155	accuracy_train: 0.1579	accuracy_val: 0.1795	accuracy_test: 0.1923
[server]	loss_train: 1.6131	loss_val: 1.6070	loss_test: 1.6073	accuracy_train: 0.1395	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.5987	loss_val: 1.6030	loss_test: 1.6040	accuracy_train: 0.2292	accuracy_val: 0.2857	accuracy_test: 0.2500
[server]	loss_train: 1.6051	loss_val: 1.6090	loss_test: 1.6075	accuracy_train: 0.2381	accuracy_val: 0.2045	accuracy_test: 0.1786
[server]	loss_train: 1.6129	loss_val: 1.6121	loss_test: 1.6102	accuracy_train: 0.2391	accuracy_val: 0.1515	accuracy_test: 0.2273
[server]	loss_train: 1.6077	loss_val: 1.6136	loss_test: 1.6074	accuracy_train: 0.2400	accuracy_val: 0.0571	accuracy_test: 0.1600
[server]	loss_train: 1.6134	loss_val: 1.6116	loss_test: 1.6250	accuracy_train: 0.1290	accuracy_val: 0.1818	accuracy_test: 0.1034
[server]	loss_train: 1.6065	loss_val: 1.6122	loss_test: 1.6121	accuracy_train: 0.2000	accuracy_val: 0.1250	accuracy_test: 0.1429
[server]	loss_train: 1.6110	loss_val: 1.6123	loss_test: 1.6156	accuracy_train: 0.1905	accuracy_val: 0.2045	accuracy_test: 0.2414
[server]	loss_train: 1.6229	loss_val: 1.6220	loss_test: 1.6174	accuracy_train: 0.1379	accuracy_val: 0.1026	accuracy_test: 0.1786
curr_round: 6	curr_val_accuracy: 0.1837	curr_test_accuracy: 0.1873
best_round: 0	best_val_accuracy: 0.1837	best_test_accuracy: 0.1873
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.9167	loss_train: 0.0348	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.6341	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.9375	loss_train: 0.0339	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.6150	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.9375	loss_train: 0.0330	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.5967	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0451	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.7746	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0437	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.7457	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0423	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.7179	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8679	loss_train: 0.0472	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.8211	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8679	loss_train: 0.0458	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.7926	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8679	loss_train: 0.0444	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.7653	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.9400	loss_train: 0.0362	loss_degree: 0.0243	loss_feat: 0.0001	loss_cls: 0.6964	loss_other: 0.0024
[client 3 neighGen phase]	acc_degree: 0.8800	acc_cls: 0.9400	loss_train: 0.0348	loss_degree: 0.0225	loss_feat: 0.0001	loss_cls: 0.6702	loss_other: 0.0037
[client 3 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.9400	loss_train: 0.0334	loss_degree: 0.0208	loss_feat: 0.0000	loss_cls: 0.6455	loss_other: 0.0023
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9808	loss_train: 0.0415	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.6560	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9808	loss_train: 0.0402	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.6309	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9808	loss_train: 0.0390	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.6072	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9825	loss_train: 0.0460	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 0.8753	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9825	loss_train: 0.0445	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 0.8468	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9825	loss_train: 0.0432	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 0.8191	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9574	acc_cls: 0.9574	loss_train: 0.0357	loss_degree: 0.0221	loss_feat: 0.0002	loss_cls: 0.6898	loss_other: 0.0019
[client 6 neighGen phase]	acc_degree: 0.9574	acc_cls: 0.9574	loss_train: 0.0347	loss_degree: 0.0217	loss_feat: 0.0002	loss_cls: 0.6709	loss_other: 0.0020
[client 6 neighGen phase]	acc_degree: 0.9362	acc_cls: 0.9574	loss_train: 0.0338	loss_degree: 0.0212	loss_feat: 0.0001	loss_cls: 0.6528	loss_other: 0.0020
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.8800	loss_train: 0.0381	loss_degree: 0.0030	loss_feat: 0.0000	loss_cls: 0.7578	loss_other: 0.0008
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.9000	loss_train: 0.0371	loss_degree: 0.0031	loss_feat: 0.0000	loss_cls: 0.7386	loss_other: 0.0005
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.9000	loss_train: 0.0362	loss_degree: 0.0031	loss_feat: 0.0000	loss_cls: 0.7203	loss_other: 0.0006
[client 8 neighGen phase]	acc_degree: 0.9259	acc_cls: 0.8889	loss_train: 0.0357	loss_degree: 0.0806	loss_feat: 0.0009	loss_cls: 0.6271	loss_other: 0.0061
[client 8 neighGen phase]	acc_degree: 0.8704	acc_cls: 0.8889	loss_train: 0.0343	loss_degree: 0.0774	loss_feat: 0.0007	loss_cls: 0.6024	loss_other: 0.0053
[client 8 neighGen phase]	acc_degree: 0.8333	acc_cls: 0.8889	loss_train: 0.0330	loss_degree: 0.0744	loss_feat: 0.0006	loss_cls: 0.5794	loss_other: 0.0046
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.8980	loss_train: 0.0419	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.7162	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.8980	loss_train: 0.0410	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.6968	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.8980	loss_train: 0.0400	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.6784	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8947	acc_cls: 0.9123	loss_train: 0.0369	loss_degree: 0.0411	loss_feat: 0.0001	loss_cls: 0.6950	loss_other: 0.0020
[client 10 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9298	loss_train: 0.0355	loss_degree: 0.0403	loss_feat: 0.0001	loss_cls: 0.6679	loss_other: 0.0020
[client 10 neighGen phase]	acc_degree: 0.9298	acc_cls: 0.9298	loss_train: 0.0342	loss_degree: 0.0392	loss_feat: 0.0001	loss_cls: 0.6418	loss_other: 0.0024
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.9535	loss_train: 0.0373	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.7104	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.9535	loss_train: 0.0361	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.6871	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.9535	loss_train: 0.0350	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.6648	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8958	acc_cls: 0.9375	loss_train: 0.0386	loss_degree: 0.0205	loss_feat: 0.0003	loss_cls: 0.7469	loss_other: 0.0050
[client 12 neighGen phase]	acc_degree: 0.8958	acc_cls: 0.9375	loss_train: 0.0369	loss_degree: 0.0180	loss_feat: 0.0003	loss_cls: 0.7141	loss_other: 0.0046
[client 12 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.9375	loss_train: 0.0351	loss_degree: 0.0157	loss_feat: 0.0003	loss_cls: 0.6824	loss_other: 0.0040
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.8571	loss_train: 0.0397	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.7388	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.8889	loss_train: 0.0385	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.7146	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.8889	loss_train: 0.0374	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.6919	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8478	acc_cls: 0.9783	loss_train: 0.0364	loss_degree: 0.0108	loss_feat: 0.0001	loss_cls: 0.7149	loss_other: 0.0014
[client 14 neighGen phase]	acc_degree: 0.8696	acc_cls: 0.9783	loss_train: 0.0353	loss_degree: 0.0106	loss_feat: 0.0001	loss_cls: 0.6919	loss_other: 0.0025
[client 14 neighGen phase]	acc_degree: 0.8696	acc_cls: 0.9783	loss_train: 0.0342	loss_degree: 0.0102	loss_feat: 0.0001	loss_cls: 0.6701	loss_other: 0.0025
[client 15 neighGen phase]	acc_degree: 0.6800	acc_cls: 0.9200	loss_train: 0.0388	loss_degree: 0.0081	loss_feat: 0.0001	loss_cls: 0.7648	loss_other: 0.0021
[client 15 neighGen phase]	acc_degree: 0.6800	acc_cls: 0.9200	loss_train: 0.0377	loss_degree: 0.0081	loss_feat: 0.0001	loss_cls: 0.7442	loss_other: 0.0021
[client 15 neighGen phase]	acc_degree: 0.6800	acc_cls: 0.9200	loss_train: 0.0367	loss_degree: 0.0080	loss_feat: 0.0001	loss_cls: 0.7245	loss_other: 0.0018
[client 16 neighGen phase]	acc_degree: 0.6935	acc_cls: 0.9839	loss_train: 0.0431	loss_degree: 0.0421	loss_feat: 0.0002	loss_cls: 0.8135	loss_other: 0.0053
[client 16 neighGen phase]	acc_degree: 0.6452	acc_cls: 0.9839	loss_train: 0.0416	loss_degree: 0.0393	loss_feat: 0.0002	loss_cls: 0.7876	loss_other: 0.0041
[client 16 neighGen phase]	acc_degree: 0.6290	acc_cls: 0.9839	loss_train: 0.0402	loss_degree: 0.0373	loss_feat: 0.0002	loss_cls: 0.7624	loss_other: 0.0032
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0446	loss_degree: 0.0254	loss_feat: 0.0000	loss_cls: 0.8665	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0433	loss_degree: 0.0225	loss_feat: 0.0000	loss_cls: 0.8426	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0420	loss_degree: 0.0193	loss_feat: 0.0000	loss_cls: 0.8194	loss_other: 0.0013
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.8413	loss_train: 0.0391	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.7259	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.8571	loss_train: 0.0379	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.7022	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.8730	loss_train: 0.0368	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.6803	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7586	acc_cls: 0.9483	loss_train: 0.0309	loss_degree: 0.0182	loss_feat: 0.0003	loss_cls: 0.5963	loss_other: 0.0029
[client 19 neighGen phase]	acc_degree: 0.7931	acc_cls: 0.9828	loss_train: 0.0298	loss_degree: 0.0157	loss_feat: 0.0004	loss_cls: 0.5767	loss_other: 0.0036
[client 19 neighGen phase]	acc_degree: 0.8448	acc_cls: 0.9828	loss_train: 0.0289	loss_degree: 0.0143	loss_feat: 0.0005	loss_cls: 0.5588	loss_other: 0.0046
[server]	loss_train: 1.6215	loss_val: 1.6212	loss_test: 1.6242	accuracy_train: 0.1667	accuracy_val: 0.1111	accuracy_test: 0.1304
[server]	loss_train: 1.6154	loss_val: 1.6178	loss_test: 1.6157	accuracy_train: 0.1176	accuracy_val: 0.1111	accuracy_test: 0.1250
[server]	loss_train: 1.6059	loss_val: 1.6056	loss_test: 1.6097	accuracy_train: 0.1698	accuracy_val: 0.2564	accuracy_test: 0.2800
[server]	loss_train: 1.6074	loss_val: 1.6066	loss_test: 1.6154	accuracy_train: 0.4000	accuracy_val: 0.3529	accuracy_test: 0.3043
[server]	loss_train: 1.6220	loss_val: 1.6199	loss_test: 1.6224	accuracy_train: 0.1731	accuracy_val: 0.1081	accuracy_test: 0.0417
[server]	loss_train: 1.6030	loss_val: 1.6072	loss_test: 1.6067	accuracy_train: 0.1930	accuracy_val: 0.3000	accuracy_test: 0.2308
[server]	loss_train: 1.6139	loss_val: 1.6231	loss_test: 1.6215	accuracy_train: 0.2340	accuracy_val: 0.1212	accuracy_test: 0.2273
[server]	loss_train: 1.6052	loss_val: 1.6095	loss_test: 1.6079	accuracy_train: 0.2200	accuracy_val: 0.1944	accuracy_test: 0.1739
[server]	loss_train: 1.6163	loss_val: 1.6138	loss_test: 1.6178	accuracy_train: 0.0926	accuracy_val: 0.2368	accuracy_test: 0.1923
[server]	loss_train: 1.6110	loss_val: 1.6147	loss_test: 1.6156	accuracy_train: 0.2245	accuracy_val: 0.1143	accuracy_test: 0.1304
[server]	loss_train: 1.6179	loss_val: 1.6192	loss_test: 1.6155	accuracy_train: 0.1579	accuracy_val: 0.1795	accuracy_test: 0.1923
[server]	loss_train: 1.6131	loss_val: 1.6070	loss_test: 1.6073	accuracy_train: 0.1395	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.5987	loss_val: 1.6030	loss_test: 1.6040	accuracy_train: 0.2292	accuracy_val: 0.2857	accuracy_test: 0.2500
[server]	loss_train: 1.6051	loss_val: 1.6090	loss_test: 1.6075	accuracy_train: 0.2381	accuracy_val: 0.2045	accuracy_test: 0.1786
[server]	loss_train: 1.6129	loss_val: 1.6121	loss_test: 1.6102	accuracy_train: 0.2391	accuracy_val: 0.1515	accuracy_test: 0.2273
[server]	loss_train: 1.6077	loss_val: 1.6136	loss_test: 1.6074	accuracy_train: 0.2400	accuracy_val: 0.0571	accuracy_test: 0.1600
[server]	loss_train: 1.6134	loss_val: 1.6116	loss_test: 1.6250	accuracy_train: 0.1290	accuracy_val: 0.1818	accuracy_test: 0.1034
[server]	loss_train: 1.6065	loss_val: 1.6122	loss_test: 1.6121	accuracy_train: 0.2000	accuracy_val: 0.1250	accuracy_test: 0.1429
[server]	loss_train: 1.6110	loss_val: 1.6123	loss_test: 1.6156	accuracy_train: 0.1905	accuracy_val: 0.2045	accuracy_test: 0.2414
[server]	loss_train: 1.6229	loss_val: 1.6220	loss_test: 1.6174	accuracy_train: 0.1379	accuracy_val: 0.1026	accuracy_test: 0.1786
curr_round: 7	curr_val_accuracy: 0.1837	curr_test_accuracy: 0.1873
best_round: 0	best_val_accuracy: 0.1837	best_test_accuracy: 0.1873
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.9375	loss_train: 0.0321	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.5793	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.9375	loss_train: 0.0313	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.5626	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.9375	loss_train: 0.0305	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.5467	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0409	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.6912	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0397	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.6656	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0384	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.6410	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8868	loss_train: 0.0431	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.7393	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8868	loss_train: 0.0419	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.7144	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8868	loss_train: 0.0407	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.6908	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.9400	loss_train: 0.0322	loss_degree: 0.0189	loss_feat: 0.0000	loss_cls: 0.6222	loss_other: 0.0027
[client 3 neighGen phase]	acc_degree: 0.8400	acc_cls: 0.9400	loss_train: 0.0309	loss_degree: 0.0168	loss_feat: 0.0000	loss_cls: 0.6001	loss_other: 0.0019
[client 3 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.9400	loss_train: 0.0298	loss_degree: 0.0143	loss_feat: 0.0001	loss_cls: 0.5791	loss_other: 0.0029
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9808	loss_train: 0.0379	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.5850	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9808	loss_train: 0.0369	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.5640	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9808	loss_train: 0.0359	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.5443	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9825	loss_train: 0.0418	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 0.7922	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 1.0000	loss_train: 0.0405	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 0.7660	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 1.0000	loss_train: 0.0392	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 0.7407	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9149	acc_cls: 0.9574	loss_train: 0.0328	loss_degree: 0.0206	loss_feat: 0.0001	loss_cls: 0.6353	loss_other: 0.0009
[client 6 neighGen phase]	acc_degree: 0.9149	acc_cls: 0.9574	loss_train: 0.0320	loss_degree: 0.0199	loss_feat: 0.0001	loss_cls: 0.6184	loss_other: 0.0010
[client 6 neighGen phase]	acc_degree: 0.9149	acc_cls: 0.9574	loss_train: 0.0311	loss_degree: 0.0190	loss_feat: 0.0001	loss_cls: 0.6021	loss_other: 0.0013
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.9000	loss_train: 0.0353	loss_degree: 0.0031	loss_feat: 0.0000	loss_cls: 0.7027	loss_other: 0.0004
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.9000	loss_train: 0.0344	loss_degree: 0.0029	loss_feat: 0.0000	loss_cls: 0.6858	loss_other: 0.0002
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.9000	loss_train: 0.0336	loss_degree: 0.0026	loss_feat: 0.0000	loss_cls: 0.6696	loss_other: 0.0005
[client 8 neighGen phase]	acc_degree: 0.8148	acc_cls: 0.8889	loss_train: 0.0317	loss_degree: 0.0715	loss_feat: 0.0005	loss_cls: 0.5577	loss_other: 0.0036
[client 8 neighGen phase]	acc_degree: 0.7593	acc_cls: 0.8889	loss_train: 0.0304	loss_degree: 0.0682	loss_feat: 0.0003	loss_cls: 0.5374	loss_other: 0.0022
[client 8 neighGen phase]	acc_degree: 0.7037	acc_cls: 0.8889	loss_train: 0.0292	loss_degree: 0.0642	loss_feat: 0.0001	loss_cls: 0.5182	loss_other: 0.0012
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.8980	loss_train: 0.0392	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.6609	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.8980	loss_train: 0.0383	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.6443	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.9184	loss_train: 0.0375	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.6283	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9298	acc_cls: 0.9298	loss_train: 0.0329	loss_degree: 0.0381	loss_feat: 0.0001	loss_cls: 0.6168	loss_other: 0.0029
[client 10 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9298	loss_train: 0.0316	loss_degree: 0.0368	loss_feat: 0.0001	loss_cls: 0.5928	loss_other: 0.0021
[client 10 neighGen phase]	acc_degree: 0.9123	acc_cls: 0.9298	loss_train: 0.0304	loss_degree: 0.0355	loss_feat: 0.0001	loss_cls: 0.5699	loss_other: 0.0022
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.9767	loss_train: 0.0339	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.6433	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.9767	loss_train: 0.0329	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.6226	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.9767	loss_train: 0.0319	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.6027	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8333	acc_cls: 0.9375	loss_train: 0.0335	loss_degree: 0.0150	loss_feat: 0.0002	loss_cls: 0.6516	loss_other: 0.0030
[client 12 neighGen phase]	acc_degree: 0.7917	acc_cls: 0.9375	loss_train: 0.0320	loss_degree: 0.0157	loss_feat: 0.0002	loss_cls: 0.6220	loss_other: 0.0016
[client 12 neighGen phase]	acc_degree: 0.8125	acc_cls: 0.9375	loss_train: 0.0306	loss_degree: 0.0166	loss_feat: 0.0002	loss_cls: 0.5936	loss_other: 0.0024
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.8889	loss_train: 0.0363	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.6706	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.8889	loss_train: 0.0353	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.6506	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.8889	loss_train: 0.0344	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.6317	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8696	acc_cls: 0.9783	loss_train: 0.0331	loss_degree: 0.0097	loss_feat: 0.0001	loss_cls: 0.6494	loss_other: 0.0024
[client 14 neighGen phase]	acc_degree: 0.8478	acc_cls: 0.9783	loss_train: 0.0320	loss_degree: 0.0091	loss_feat: 0.0001	loss_cls: 0.6297	loss_other: 0.0015
[client 14 neighGen phase]	acc_degree: 0.8478	acc_cls: 0.9783	loss_train: 0.0311	loss_degree: 0.0085	loss_feat: 0.0001	loss_cls: 0.6108	loss_other: 0.0016
[client 15 neighGen phase]	acc_degree: 0.6600	acc_cls: 0.9200	loss_train: 0.0357	loss_degree: 0.0075	loss_feat: 0.0001	loss_cls: 0.7058	loss_other: 0.0013
[client 15 neighGen phase]	acc_degree: 0.6800	acc_cls: 0.9200	loss_train: 0.0348	loss_degree: 0.0068	loss_feat: 0.0001	loss_cls: 0.6879	loss_other: 0.0022
[client 15 neighGen phase]	acc_degree: 0.7800	acc_cls: 0.9200	loss_train: 0.0341	loss_degree: 0.0062	loss_feat: 0.0003	loss_cls: 0.6707	loss_other: 0.0045
[client 16 neighGen phase]	acc_degree: 0.6129	acc_cls: 0.9839	loss_train: 0.0389	loss_degree: 0.0355	loss_feat: 0.0002	loss_cls: 0.7381	loss_other: 0.0037
[client 16 neighGen phase]	acc_degree: 0.6129	acc_cls: 0.9839	loss_train: 0.0376	loss_degree: 0.0335	loss_feat: 0.0002	loss_cls: 0.7144	loss_other: 0.0037
[client 16 neighGen phase]	acc_degree: 0.6129	acc_cls: 0.9355	loss_train: 0.0363	loss_degree: 0.0311	loss_feat: 0.0002	loss_cls: 0.6915	loss_other: 0.0034
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0407	loss_degree: 0.0161	loss_feat: 0.0000	loss_cls: 0.7968	loss_other: 0.0011
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0394	loss_degree: 0.0132	loss_feat: 0.0000	loss_cls: 0.7746	loss_other: 0.0011
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0382	loss_degree: 0.0107	loss_feat: 0.0000	loss_cls: 0.7530	loss_other: 0.0011
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.8889	loss_train: 0.0358	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.6600	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.8889	loss_train: 0.0348	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.6411	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.8889	loss_train: 0.0340	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.6235	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.8448	acc_cls: 0.9828	loss_train: 0.0281	loss_degree: 0.0135	loss_feat: 0.0005	loss_cls: 0.5424	loss_other: 0.0051
[client 19 neighGen phase]	acc_degree: 0.8448	acc_cls: 1.0000	loss_train: 0.0273	loss_degree: 0.0127	loss_feat: 0.0005	loss_cls: 0.5272	loss_other: 0.0056
[client 19 neighGen phase]	acc_degree: 0.8448	acc_cls: 1.0000	loss_train: 0.0265	loss_degree: 0.0117	loss_feat: 0.0005	loss_cls: 0.5130	loss_other: 0.0055
[server]	loss_train: 1.6215	loss_val: 1.6212	loss_test: 1.6242	accuracy_train: 0.1667	accuracy_val: 0.1111	accuracy_test: 0.1304
[server]	loss_train: 1.6154	loss_val: 1.6178	loss_test: 1.6157	accuracy_train: 0.1176	accuracy_val: 0.1111	accuracy_test: 0.1250
[server]	loss_train: 1.6059	loss_val: 1.6056	loss_test: 1.6097	accuracy_train: 0.1698	accuracy_val: 0.2564	accuracy_test: 0.2800
[server]	loss_train: 1.6074	loss_val: 1.6066	loss_test: 1.6154	accuracy_train: 0.4000	accuracy_val: 0.3529	accuracy_test: 0.3043
[server]	loss_train: 1.6220	loss_val: 1.6199	loss_test: 1.6224	accuracy_train: 0.1731	accuracy_val: 0.1081	accuracy_test: 0.0417
[server]	loss_train: 1.6030	loss_val: 1.6072	loss_test: 1.6067	accuracy_train: 0.1930	accuracy_val: 0.3000	accuracy_test: 0.2308
[server]	loss_train: 1.6139	loss_val: 1.6231	loss_test: 1.6215	accuracy_train: 0.2340	accuracy_val: 0.1212	accuracy_test: 0.2273
[server]	loss_train: 1.6052	loss_val: 1.6095	loss_test: 1.6079	accuracy_train: 0.2200	accuracy_val: 0.1944	accuracy_test: 0.1739
[server]	loss_train: 1.6163	loss_val: 1.6138	loss_test: 1.6178	accuracy_train: 0.0926	accuracy_val: 0.2368	accuracy_test: 0.1923
[server]	loss_train: 1.6110	loss_val: 1.6147	loss_test: 1.6156	accuracy_train: 0.2245	accuracy_val: 0.1143	accuracy_test: 0.1304
[server]	loss_train: 1.6179	loss_val: 1.6192	loss_test: 1.6155	accuracy_train: 0.1579	accuracy_val: 0.1795	accuracy_test: 0.1923
[server]	loss_train: 1.6131	loss_val: 1.6070	loss_test: 1.6073	accuracy_train: 0.1395	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.5987	loss_val: 1.6030	loss_test: 1.6040	accuracy_train: 0.2292	accuracy_val: 0.2857	accuracy_test: 0.2500
[server]	loss_train: 1.6051	loss_val: 1.6090	loss_test: 1.6075	accuracy_train: 0.2381	accuracy_val: 0.2045	accuracy_test: 0.1786
[server]	loss_train: 1.6129	loss_val: 1.6121	loss_test: 1.6102	accuracy_train: 0.2391	accuracy_val: 0.1515	accuracy_test: 0.2273
[server]	loss_train: 1.6077	loss_val: 1.6136	loss_test: 1.6074	accuracy_train: 0.2400	accuracy_val: 0.0571	accuracy_test: 0.1600
[server]	loss_train: 1.6134	loss_val: 1.6116	loss_test: 1.6250	accuracy_train: 0.1290	accuracy_val: 0.1818	accuracy_test: 0.1034
[server]	loss_train: 1.6065	loss_val: 1.6122	loss_test: 1.6121	accuracy_train: 0.2000	accuracy_val: 0.1250	accuracy_test: 0.1429
[server]	loss_train: 1.6110	loss_val: 1.6123	loss_test: 1.6156	accuracy_train: 0.1905	accuracy_val: 0.2045	accuracy_test: 0.2414
[server]	loss_train: 1.6229	loss_val: 1.6220	loss_test: 1.6174	accuracy_train: 0.1379	accuracy_val: 0.1026	accuracy_test: 0.1786
curr_round: 8	curr_val_accuracy: 0.1837	curr_test_accuracy: 0.1873
best_round: 0	best_val_accuracy: 0.1837	best_test_accuracy: 0.1873
--------------------------------------------------
round # 9		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.9375	loss_train: 0.0297	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.5314	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.9375	loss_train: 0.0290	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.5168	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.8750	acc_cls: 0.9375	loss_train: 0.0283	loss_degree: 0.0625	loss_feat: 0.0000	loss_cls: 0.5028	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0372	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.6174	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0361	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.5948	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7451	acc_cls: 0.9608	loss_train: 0.0350	loss_degree: 0.1275	loss_feat: 0.0000	loss_cls: 0.5731	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8868	loss_train: 0.0395	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.6682	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8868	loss_train: 0.0385	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.6466	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.8302	acc_cls: 0.8868	loss_train: 0.0374	loss_degree: 0.1226	loss_feat: 0.0000	loss_cls: 0.6260	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.8600	acc_cls: 0.9400	loss_train: 0.0287	loss_degree: 0.0118	loss_feat: 0.0001	loss_cls: 0.5591	loss_other: 0.0026
[client 3 neighGen phase]	acc_degree: 0.9000	acc_cls: 0.9400	loss_train: 0.0277	loss_degree: 0.0094	loss_feat: 0.0001	loss_cls: 0.5402	loss_other: 0.0045
[client 3 neighGen phase]	acc_degree: 0.9000	acc_cls: 0.9400	loss_train: 0.0267	loss_degree: 0.0073	loss_feat: 0.0001	loss_cls: 0.5223	loss_other: 0.0038
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9808	loss_train: 0.0349	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.5257	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9808	loss_train: 0.0341	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.5080	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8846	acc_cls: 0.9808	loss_train: 0.0332	loss_degree: 0.1731	loss_feat: 0.0000	loss_cls: 0.4912	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 1.0000	loss_train: 0.0380	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 0.7161	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 1.0000	loss_train: 0.0368	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 0.6922	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9123	acc_cls: 1.0000	loss_train: 0.0357	loss_degree: 0.0439	loss_feat: 0.0000	loss_cls: 0.6692	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9149	acc_cls: 0.9574	loss_train: 0.0302	loss_degree: 0.0179	loss_feat: 0.0001	loss_cls: 0.5863	loss_other: 0.0007
[client 6 neighGen phase]	acc_degree: 0.9149	acc_cls: 0.9574	loss_train: 0.0295	loss_degree: 0.0169	loss_feat: 0.0001	loss_cls: 0.5709	loss_other: 0.0011
[client 6 neighGen phase]	acc_degree: 0.9362	acc_cls: 0.9574	loss_train: 0.0287	loss_degree: 0.0158	loss_feat: 0.0002	loss_cls: 0.5561	loss_other: 0.0017
[client 7 neighGen phase]	acc_degree: 0.9400	acc_cls: 0.9000	loss_train: 0.0328	loss_degree: 0.0022	loss_feat: 0.0000	loss_cls: 0.6539	loss_other: 0.0004
[client 7 neighGen phase]	acc_degree: 0.9600	acc_cls: 0.9000	loss_train: 0.0321	loss_degree: 0.0018	loss_feat: 0.0000	loss_cls: 0.6387	loss_other: 0.0009
[client 7 neighGen phase]	acc_degree: 0.9600	acc_cls: 0.9000	loss_train: 0.0313	loss_degree: 0.0015	loss_feat: 0.0000	loss_cls: 0.6241	loss_other: 0.0013
[client 8 neighGen phase]	acc_degree: 0.7222	acc_cls: 0.8889	loss_train: 0.0281	loss_degree: 0.0596	loss_feat: 0.0002	loss_cls: 0.5002	loss_other: 0.0019
[client 8 neighGen phase]	acc_degree: 0.7593	acc_cls: 0.9074	loss_train: 0.0270	loss_degree: 0.0547	loss_feat: 0.0003	loss_cls: 0.4832	loss_other: 0.0020
[client 8 neighGen phase]	acc_degree: 0.8519	acc_cls: 0.9074	loss_train: 0.0262	loss_degree: 0.0496	loss_feat: 0.0006	loss_cls: 0.4674	loss_other: 0.0055
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.9184	loss_train: 0.0368	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.6129	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.9184	loss_train: 0.0360	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.5982	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.8367	acc_cls: 0.9184	loss_train: 0.0353	loss_degree: 0.1224	loss_feat: 0.0000	loss_cls: 0.5840	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8772	acc_cls: 0.9474	loss_train: 0.0292	loss_degree: 0.0345	loss_feat: 0.0001	loss_cls: 0.5480	loss_other: 0.0011
[client 10 neighGen phase]	acc_degree: 0.8596	acc_cls: 0.9474	loss_train: 0.0281	loss_degree: 0.0332	loss_feat: 0.0001	loss_cls: 0.5271	loss_other: 0.0011
[client 10 neighGen phase]	acc_degree: 0.8596	acc_cls: 0.9474	loss_train: 0.0270	loss_degree: 0.0319	loss_feat: 0.0001	loss_cls: 0.5072	loss_other: 0.0008
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 0.9767	loss_train: 0.0309	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.5834	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 1.0000	loss_train: 0.0300	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.5648	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9302	acc_cls: 1.0000	loss_train: 0.0291	loss_degree: 0.0349	loss_feat: 0.0000	loss_cls: 0.5468	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8125	acc_cls: 0.9375	loss_train: 0.0293	loss_degree: 0.0169	loss_feat: 0.0002	loss_cls: 0.5668	loss_other: 0.0026
[client 12 neighGen phase]	acc_degree: 0.8542	acc_cls: 0.9375	loss_train: 0.0281	loss_degree: 0.0166	loss_feat: 0.0004	loss_cls: 0.5413	loss_other: 0.0042
[client 12 neighGen phase]	acc_degree: 0.8542	acc_cls: 0.9375	loss_train: 0.0269	loss_degree: 0.0162	loss_feat: 0.0004	loss_cls: 0.5172	loss_other: 0.0034
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.8889	loss_train: 0.0335	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.6140	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.8889	loss_train: 0.0326	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.5972	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9206	acc_cls: 0.9048	loss_train: 0.0318	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.5813	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.8261	acc_cls: 0.9783	loss_train: 0.0301	loss_degree: 0.0081	loss_feat: 0.0000	loss_cls: 0.5928	loss_other: 0.0012
[client 14 neighGen phase]	acc_degree: 0.8261	acc_cls: 0.9783	loss_train: 0.0292	loss_degree: 0.0078	loss_feat: 0.0000	loss_cls: 0.5755	loss_other: 0.0008
[client 14 neighGen phase]	acc_degree: 0.8261	acc_cls: 0.9783	loss_train: 0.0284	loss_degree: 0.0075	loss_feat: 0.0000	loss_cls: 0.5588	loss_other: 0.0010
[client 15 neighGen phase]	acc_degree: 0.8000	acc_cls: 0.9200	loss_train: 0.0333	loss_degree: 0.0058	loss_feat: 0.0003	loss_cls: 0.6544	loss_other: 0.0052
[client 15 neighGen phase]	acc_degree: 0.8000	acc_cls: 0.9200	loss_train: 0.0325	loss_degree: 0.0055	loss_feat: 0.0003	loss_cls: 0.6388	loss_other: 0.0050
[client 15 neighGen phase]	acc_degree: 0.7600	acc_cls: 0.9200	loss_train: 0.0316	loss_degree: 0.0052	loss_feat: 0.0003	loss_cls: 0.6238	loss_other: 0.0033
[client 16 neighGen phase]	acc_degree: 0.6935	acc_cls: 0.9355	loss_train: 0.0352	loss_degree: 0.0286	loss_feat: 0.0003	loss_cls: 0.6693	loss_other: 0.0055
[client 16 neighGen phase]	acc_degree: 0.6935	acc_cls: 0.9355	loss_train: 0.0340	loss_degree: 0.0263	loss_feat: 0.0003	loss_cls: 0.6477	loss_other: 0.0058
[client 16 neighGen phase]	acc_degree: 0.6935	acc_cls: 0.9355	loss_train: 0.0328	loss_degree: 0.0241	loss_feat: 0.0003	loss_cls: 0.6268	loss_other: 0.0052
[client 17 neighGen phase]	acc_degree: 0.9333	acc_cls: 0.9111	loss_train: 0.0371	loss_degree: 0.0086	loss_feat: 0.0000	loss_cls: 0.7318	loss_other: 0.0007
[client 17 neighGen phase]	acc_degree: 0.9556	acc_cls: 0.9111	loss_train: 0.0360	loss_degree: 0.0071	loss_feat: 0.0000	loss_cls: 0.7111	loss_other: 0.0014
[client 17 neighGen phase]	acc_degree: 0.9556	acc_cls: 0.9111	loss_train: 0.0349	loss_degree: 0.0059	loss_feat: 0.0000	loss_cls: 0.6908	loss_other: 0.0016
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.8889	loss_train: 0.0331	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.6070	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.9048	loss_train: 0.0324	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.5916	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.8889	acc_cls: 0.9206	loss_train: 0.0316	loss_degree: 0.0556	loss_feat: 0.0000	loss_cls: 0.5770	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.8103	acc_cls: 1.0000	loss_train: 0.0257	loss_degree: 0.0107	loss_feat: 0.0004	loss_cls: 0.4997	loss_other: 0.0042
[client 19 neighGen phase]	acc_degree: 0.7931	acc_cls: 1.0000	loss_train: 0.0251	loss_degree: 0.0100	loss_feat: 0.0004	loss_cls: 0.4871	loss_other: 0.0037
[client 19 neighGen phase]	acc_degree: 0.7931	acc_cls: 1.0000	loss_train: 0.0244	loss_degree: 0.0096	loss_feat: 0.0004	loss_cls: 0.4752	loss_other: 0.0035
[server]	loss_train: 1.5685	loss_val: 1.5769	loss_test: 1.5790	accuracy_train: 0.2917	accuracy_val: 0.2778	accuracy_test: 0.2609
[server]	loss_train: 1.5916	loss_val: 1.5903	loss_test: 1.5995	accuracy_train: 0.1961	accuracy_val: 0.1944	accuracy_test: 0.1667
[server]	loss_train: 1.5923	loss_val: 1.5979	loss_test: 1.6038	accuracy_train: 0.1887	accuracy_val: 0.1795	accuracy_test: 0.1600
[server]	loss_train: 1.5679	loss_val: 1.5895	loss_test: 1.5884	accuracy_train: 0.2000	accuracy_val: 0.2059	accuracy_test: 0.1739
[server]	loss_train: 1.5758	loss_val: 1.5851	loss_test: 1.5920	accuracy_train: 0.2500	accuracy_val: 0.2703	accuracy_test: 0.2917
[server]	loss_train: 1.5856	loss_val: 1.5810	loss_test: 1.5962	accuracy_train: 0.2281	accuracy_val: 0.2250	accuracy_test: 0.2308
[server]	loss_train: 1.5603	loss_val: 1.5538	loss_test: 1.5606	accuracy_train: 0.2766	accuracy_val: 0.2727	accuracy_test: 0.2727
[server]	loss_train: 1.5730	loss_val: 1.5818	loss_test: 1.5843	accuracy_train: 0.2800	accuracy_val: 0.2778	accuracy_test: 0.2174
[server]	loss_train: 1.5741	loss_val: 1.5724	loss_test: 1.5784	accuracy_train: 0.3148	accuracy_val: 0.2632	accuracy_test: 0.2308
[server]	loss_train: 1.5792	loss_val: 1.5844	loss_test: 1.5822	accuracy_train: 0.2449	accuracy_val: 0.1429	accuracy_test: 0.1304
[server]	loss_train: 1.5880	loss_val: 1.5956	loss_test: 1.6048	accuracy_train: 0.1930	accuracy_val: 0.1538	accuracy_test: 0.1538
[server]	loss_train: 1.5695	loss_val: 1.5894	loss_test: 1.5825	accuracy_train: 0.2791	accuracy_val: 0.2258	accuracy_test: 0.2000
[server]	loss_train: 1.5989	loss_val: 1.5850	loss_test: 1.5920	accuracy_train: 0.1042	accuracy_val: 0.1429	accuracy_test: 0.1667
[server]	loss_train: 1.5668	loss_val: 1.5724	loss_test: 1.5656	accuracy_train: 0.3810	accuracy_val: 0.3636	accuracy_test: 0.3929
[server]	loss_train: 1.5720	loss_val: 1.5824	loss_test: 1.5858	accuracy_train: 0.2174	accuracy_val: 0.1818	accuracy_test: 0.1818
[server]	loss_train: 1.5685	loss_val: 1.5845	loss_test: 1.5885	accuracy_train: 0.2600	accuracy_val: 0.2286	accuracy_test: 0.2800
[server]	loss_train: 1.5901	loss_val: 1.5911	loss_test: 1.6051	accuracy_train: 0.2419	accuracy_val: 0.2045	accuracy_test: 0.2069
[server]	loss_train: 1.5713	loss_val: 1.5761	loss_test: 1.5945	accuracy_train: 0.2667	accuracy_val: 0.2500	accuracy_test: 0.2381
[server]	loss_train: 1.5692	loss_val: 1.5875	loss_test: 1.5762	accuracy_train: 0.3016	accuracy_val: 0.2727	accuracy_test: 0.2759
[server]	loss_train: 1.5549	loss_val: 1.5693	loss_test: 1.5735	accuracy_train: 0.3793	accuracy_val: 0.3590	accuracy_test: 0.3571
curr_round: 9	curr_val_accuracy: 0.2367	curr_test_accuracy: 0.2322
best_round: 9	best_val_accuracy: 0.2367	best_test_accuracy: 0.2322
--------------------------------------------------
round # 10		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5394	loss_val: 1.5567	loss_test: 1.5616	accuracy_train: 0.2917	accuracy_val: 0.2778	accuracy_test: 0.2609
[server]	loss_train: 1.5815	loss_val: 1.5794	loss_test: 1.5947	accuracy_train: 0.1765	accuracy_val: 0.1944	accuracy_test: 0.1667
[server]	loss_train: 1.5867	loss_val: 1.5974	loss_test: 1.6041	accuracy_train: 0.1698	accuracy_val: 0.1795	accuracy_test: 0.1600
[server]	loss_train: 1.5534	loss_val: 1.5823	loss_test: 1.5758	accuracy_train: 0.1800	accuracy_val: 0.1765	accuracy_test: 0.1739
[server]	loss_train: 1.5613	loss_val: 1.5798	loss_test: 1.5820	accuracy_train: 0.2500	accuracy_val: 0.2432	accuracy_test: 0.2500
[server]	loss_train: 1.5762	loss_val: 1.5719	loss_test: 1.5969	accuracy_train: 0.2281	accuracy_val: 0.2250	accuracy_test: 0.2308
[server]	loss_train: 1.5307	loss_val: 1.5327	loss_test: 1.5388	accuracy_train: 0.2766	accuracy_val: 0.2727	accuracy_test: 0.2727
[server]	loss_train: 1.5569	loss_val: 1.5712	loss_test: 1.5707	accuracy_train: 0.2400	accuracy_val: 0.2222	accuracy_test: 0.2174
[server]	loss_train: 1.5548	loss_val: 1.5542	loss_test: 1.5658	accuracy_train: 0.2778	accuracy_val: 0.2632	accuracy_test: 0.2692
[server]	loss_train: 1.5598	loss_val: 1.5662	loss_test: 1.5663	accuracy_train: 0.1633	accuracy_val: 0.1714	accuracy_test: 0.1739
[server]	loss_train: 1.5718	loss_val: 1.5905	loss_test: 1.5912	accuracy_train: 0.1579	accuracy_val: 0.1538	accuracy_test: 0.1538
[server]	loss_train: 1.5512	loss_val: 1.5815	loss_test: 1.5692	accuracy_train: 0.2093	accuracy_val: 0.2258	accuracy_test: 0.2000
[server]	loss_train: 1.5967	loss_val: 1.5792	loss_test: 1.5871	accuracy_train: 0.1042	accuracy_val: 0.1143	accuracy_test: 0.1250
[server]	loss_train: 1.5506	loss_val: 1.5590	loss_test: 1.5490	accuracy_train: 0.3651	accuracy_val: 0.3409	accuracy_test: 0.3571
[server]	loss_train: 1.5559	loss_val: 1.5768	loss_test: 1.5803	accuracy_train: 0.1739	accuracy_val: 0.1818	accuracy_test: 0.1818
[server]	loss_train: 1.5534	loss_val: 1.5791	loss_test: 1.5858	accuracy_train: 0.2400	accuracy_val: 0.2286	accuracy_test: 0.2400
[server]	loss_train: 1.5761	loss_val: 1.5846	loss_test: 1.5992	accuracy_train: 0.2097	accuracy_val: 0.2045	accuracy_test: 0.2069
[server]	loss_train: 1.5565	loss_val: 1.5608	loss_test: 1.5925	accuracy_train: 0.2444	accuracy_val: 0.2500	accuracy_test: 0.2381
[server]	loss_train: 1.5537	loss_val: 1.5785	loss_test: 1.5662	accuracy_train: 0.2698	accuracy_val: 0.2500	accuracy_test: 0.2759
[server]	loss_train: 1.5279	loss_val: 1.5470	loss_test: 1.5584	accuracy_train: 0.3448	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 10	curr_val_accuracy: 0.2272	curr_test_accuracy: 0.2262
best_round: 9	best_val_accuracy: 0.2367	best_test_accuracy: 0.2322
--------------------------------------------------
round # 11		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5033	loss_val: 1.5329	loss_test: 1.5406	accuracy_train: 0.2917	accuracy_val: 0.2778	accuracy_test: 0.2609
[server]	loss_train: 1.5690	loss_val: 1.5665	loss_test: 1.5894	accuracy_train: 0.1765	accuracy_val: 0.1944	accuracy_test: 0.1667
[server]	loss_train: 1.5793	loss_val: 1.5977	loss_test: 1.6052	accuracy_train: 0.1698	accuracy_val: 0.1795	accuracy_test: 0.1600
[server]	loss_train: 1.5354	loss_val: 1.5736	loss_test: 1.5612	accuracy_train: 0.1800	accuracy_val: 0.1765	accuracy_test: 0.1739
[server]	loss_train: 1.5437	loss_val: 1.5745	loss_test: 1.5712	accuracy_train: 0.2500	accuracy_val: 0.2432	accuracy_test: 0.2500
[server]	loss_train: 1.5646	loss_val: 1.5617	loss_test: 1.5990	accuracy_train: 0.2281	accuracy_val: 0.2250	accuracy_test: 0.2308
[server]	loss_train: 1.4944	loss_val: 1.5092	loss_test: 1.5144	accuracy_train: 0.2766	accuracy_val: 0.2727	accuracy_test: 0.2727
[server]	loss_train: 1.5367	loss_val: 1.5588	loss_test: 1.5555	accuracy_train: 0.2400	accuracy_val: 0.2222	accuracy_test: 0.2174
[server]	loss_train: 1.5306	loss_val: 1.5319	loss_test: 1.5504	accuracy_train: 0.2778	accuracy_val: 0.2632	accuracy_test: 0.2692
[server]	loss_train: 1.5349	loss_val: 1.5440	loss_test: 1.5475	accuracy_train: 0.1633	accuracy_val: 0.1714	accuracy_test: 0.1739
[server]	loss_train: 1.5505	loss_val: 1.5850	loss_test: 1.5714	accuracy_train: 0.1579	accuracy_val: 0.1538	accuracy_test: 0.1538
[server]	loss_train: 1.5286	loss_val: 1.5731	loss_test: 1.5542	accuracy_train: 0.2093	accuracy_val: 0.2258	accuracy_test: 0.2000
[server]	loss_train: 1.5935	loss_val: 1.5737	loss_test: 1.5822	accuracy_train: 0.1042	accuracy_val: 0.1143	accuracy_test: 0.1250
[server]	loss_train: 1.5313	loss_val: 1.5434	loss_test: 1.5300	accuracy_train: 0.3651	accuracy_val: 0.3409	accuracy_test: 0.3571
[server]	loss_train: 1.5353	loss_val: 1.5706	loss_test: 1.5747	accuracy_train: 0.1739	accuracy_val: 0.1818	accuracy_test: 0.1818
[server]	loss_train: 1.5349	loss_val: 1.5735	loss_test: 1.5834	accuracy_train: 0.2400	accuracy_val: 0.2286	accuracy_test: 0.2400
[server]	loss_train: 1.5582	loss_val: 1.5782	loss_test: 1.5937	accuracy_train: 0.2097	accuracy_val: 0.2045	accuracy_test: 0.2069
[server]	loss_train: 1.5376	loss_val: 1.5429	loss_test: 1.5915	accuracy_train: 0.2444	accuracy_val: 0.2500	accuracy_test: 0.2381
[server]	loss_train: 1.5340	loss_val: 1.5678	loss_test: 1.5543	accuracy_train: 0.2698	accuracy_val: 0.2500	accuracy_test: 0.2759
[server]	loss_train: 1.4936	loss_val: 1.5199	loss_test: 1.5401	accuracy_train: 0.3448	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 11	curr_val_accuracy: 0.2272	curr_test_accuracy: 0.2262
best_round: 9	best_val_accuracy: 0.2367	best_test_accuracy: 0.2322
--------------------------------------------------
round # 12		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4703	loss_val: 1.5130	loss_test: 1.5217	accuracy_train: 0.2917	accuracy_val: 0.2778	accuracy_test: 0.2609
[server]	loss_train: 1.5560	loss_val: 1.5552	loss_test: 1.5842	accuracy_train: 0.1765	accuracy_val: 0.1944	accuracy_test: 0.1667
[server]	loss_train: 1.5703	loss_val: 1.5981	loss_test: 1.6055	accuracy_train: 0.1698	accuracy_val: 0.1795	accuracy_test: 0.1600
[server]	loss_train: 1.5174	loss_val: 1.5651	loss_test: 1.5481	accuracy_train: 0.1800	accuracy_val: 0.1765	accuracy_test: 0.1739
[server]	loss_train: 1.5263	loss_val: 1.5699	loss_test: 1.5618	accuracy_train: 0.2500	accuracy_val: 0.2432	accuracy_test: 0.2500
[server]	loss_train: 1.5530	loss_val: 1.5523	loss_test: 1.6008	accuracy_train: 0.2281	accuracy_val: 0.2250	accuracy_test: 0.2308
[server]	loss_train: 1.4619	loss_val: 1.4899	loss_test: 1.4947	accuracy_train: 0.2766	accuracy_val: 0.2727	accuracy_test: 0.2727
[server]	loss_train: 1.5169	loss_val: 1.5478	loss_test: 1.5435	accuracy_train: 0.2400	accuracy_val: 0.2222	accuracy_test: 0.2174
[server]	loss_train: 1.5072	loss_val: 1.5114	loss_test: 1.5357	accuracy_train: 0.2778	accuracy_val: 0.2632	accuracy_test: 0.2692
[server]	loss_train: 1.5104	loss_val: 1.5242	loss_test: 1.5315	accuracy_train: 0.1633	accuracy_val: 0.1714	accuracy_test: 0.1739
[server]	loss_train: 1.5288	loss_val: 1.5803	loss_test: 1.5503	accuracy_train: 0.1579	accuracy_val: 0.1538	accuracy_test: 0.1538
[server]	loss_train: 1.5072	loss_val: 1.5672	loss_test: 1.5421	accuracy_train: 0.2093	accuracy_val: 0.2258	accuracy_test: 0.2000
[server]	loss_train: 1.5879	loss_val: 1.5691	loss_test: 1.5770	accuracy_train: 0.1042	accuracy_val: 0.1143	accuracy_test: 0.1250
[server]	loss_train: 1.5137	loss_val: 1.5295	loss_test: 1.5138	accuracy_train: 0.3651	accuracy_val: 0.3409	accuracy_test: 0.3571
[server]	loss_train: 1.5143	loss_val: 1.5642	loss_test: 1.5702	accuracy_train: 0.1739	accuracy_val: 0.1818	accuracy_test: 0.1818
[server]	loss_train: 1.5169	loss_val: 1.5684	loss_test: 1.5809	accuracy_train: 0.2400	accuracy_val: 0.2286	accuracy_test: 0.2400
[server]	loss_train: 1.5398	loss_val: 1.5726	loss_test: 1.5899	accuracy_train: 0.2097	accuracy_val: 0.2045	accuracy_test: 0.2069
[server]	loss_train: 1.5185	loss_val: 1.5274	loss_test: 1.5912	accuracy_train: 0.2444	accuracy_val: 0.2500	accuracy_test: 0.2381
[server]	loss_train: 1.5143	loss_val: 1.5582	loss_test: 1.5433	accuracy_train: 0.2698	accuracy_val: 0.2500	accuracy_test: 0.2759
[server]	loss_train: 1.4612	loss_val: 1.4965	loss_test: 1.5244	accuracy_train: 0.3448	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 12	curr_val_accuracy: 0.2272	curr_test_accuracy: 0.2262
best_round: 9	best_val_accuracy: 0.2367	best_test_accuracy: 0.2322
--------------------------------------------------
round # 13		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4423	loss_val: 1.4979	loss_test: 1.5065	accuracy_train: 0.2917	accuracy_val: 0.2778	accuracy_test: 0.2609
[server]	loss_train: 1.5427	loss_val: 1.5450	loss_test: 1.5781	accuracy_train: 0.1765	accuracy_val: 0.1944	accuracy_test: 0.1667
[server]	loss_train: 1.5593	loss_val: 1.5975	loss_test: 1.6037	accuracy_train: 0.1887	accuracy_val: 0.1795	accuracy_test: 0.1600
[server]	loss_train: 1.4997	loss_val: 1.5571	loss_test: 1.5367	accuracy_train: 0.1800	accuracy_val: 0.1765	accuracy_test: 0.1739
[server]	loss_train: 1.5098	loss_val: 1.5653	loss_test: 1.5535	accuracy_train: 0.2500	accuracy_val: 0.2432	accuracy_test: 0.2917
[server]	loss_train: 1.5417	loss_val: 1.5434	loss_test: 1.6012	accuracy_train: 0.2281	accuracy_val: 0.2250	accuracy_test: 0.2308
[server]	loss_train: 1.4347	loss_val: 1.4748	loss_test: 1.4802	accuracy_train: 0.2766	accuracy_val: 0.2727	accuracy_test: 0.2727
[server]	loss_train: 1.4980	loss_val: 1.5384	loss_test: 1.5349	accuracy_train: 0.2600	accuracy_val: 0.2222	accuracy_test: 0.2174
[server]	loss_train: 1.4862	loss_val: 1.4936	loss_test: 1.5218	accuracy_train: 0.2778	accuracy_val: 0.2632	accuracy_test: 0.2692
[server]	loss_train: 1.4880	loss_val: 1.5072	loss_test: 1.5185	accuracy_train: 0.1633	accuracy_val: 0.1714	accuracy_test: 0.1739
[server]	loss_train: 1.5082	loss_val: 1.5756	loss_test: 1.5313	accuracy_train: 0.1579	accuracy_val: 0.1538	accuracy_test: 0.1538
[server]	loss_train: 1.4879	loss_val: 1.5636	loss_test: 1.5327	accuracy_train: 0.2326	accuracy_val: 0.2258	accuracy_test: 0.2000
[server]	loss_train: 1.5795	loss_val: 1.5646	loss_test: 1.5706	accuracy_train: 0.1250	accuracy_val: 0.1143	accuracy_test: 0.1250
[server]	loss_train: 1.4988	loss_val: 1.5177	loss_test: 1.5012	accuracy_train: 0.3651	accuracy_val: 0.3409	accuracy_test: 0.3571
[server]	loss_train: 1.4940	loss_val: 1.5571	loss_test: 1.5661	accuracy_train: 0.1957	accuracy_val: 0.1818	accuracy_test: 0.1818
[server]	loss_train: 1.4995	loss_val: 1.5634	loss_test: 1.5775	accuracy_train: 0.2400	accuracy_val: 0.2286	accuracy_test: 0.2400
[server]	loss_train: 1.5219	loss_val: 1.5671	loss_test: 1.5874	accuracy_train: 0.2097	accuracy_val: 0.2045	accuracy_test: 0.2069
[server]	loss_train: 1.4998	loss_val: 1.5148	loss_test: 1.5907	accuracy_train: 0.2667	accuracy_val: 0.2500	accuracy_test: 0.2381
[server]	loss_train: 1.4957	loss_val: 1.5500	loss_test: 1.5338	accuracy_train: 0.2698	accuracy_val: 0.2500	accuracy_test: 0.2759
[server]	loss_train: 1.4329	loss_val: 1.4782	loss_test: 1.5118	accuracy_train: 0.3448	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 13	curr_val_accuracy: 0.2272	curr_test_accuracy: 0.2283
best_round: 9	best_val_accuracy: 0.2367	best_test_accuracy: 0.2322
--------------------------------------------------
round # 14		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4192	loss_val: 1.4872	loss_test: 1.4944	accuracy_train: 0.3542	accuracy_val: 0.2500	accuracy_test: 0.2609
[server]	loss_train: 1.5288	loss_val: 1.5357	loss_test: 1.5704	accuracy_train: 0.1961	accuracy_val: 0.1944	accuracy_test: 0.1667
[server]	loss_train: 1.5463	loss_val: 1.5954	loss_test: 1.5995	accuracy_train: 0.2075	accuracy_val: 0.1795	accuracy_test: 0.1600
[server]	loss_train: 1.4821	loss_val: 1.5496	loss_test: 1.5266	accuracy_train: 0.2200	accuracy_val: 0.2059	accuracy_test: 0.1739
[server]	loss_train: 1.4936	loss_val: 1.5601	loss_test: 1.5458	accuracy_train: 0.2692	accuracy_val: 0.2432	accuracy_test: 0.2917
[server]	loss_train: 1.5300	loss_val: 1.5344	loss_test: 1.5994	accuracy_train: 0.2281	accuracy_val: 0.2250	accuracy_test: 0.2308
[server]	loss_train: 1.4119	loss_val: 1.4628	loss_test: 1.4697	accuracy_train: 0.3191	accuracy_val: 0.2727	accuracy_test: 0.2727
[server]	loss_train: 1.4797	loss_val: 1.5296	loss_test: 1.5288	accuracy_train: 0.2800	accuracy_val: 0.2222	accuracy_test: 0.2174
[server]	loss_train: 1.4675	loss_val: 1.4783	loss_test: 1.5085	accuracy_train: 0.2778	accuracy_val: 0.2632	accuracy_test: 0.2692
[server]	loss_train: 1.4676	loss_val: 1.4925	loss_test: 1.5076	accuracy_train: 0.2041	accuracy_val: 0.2000	accuracy_test: 0.1739
[server]	loss_train: 1.4890	loss_val: 1.5700	loss_test: 1.5156	accuracy_train: 0.1754	accuracy_val: 0.1538	accuracy_test: 0.1538
[server]	loss_train: 1.4705	loss_val: 1.5618	loss_test: 1.5256	accuracy_train: 0.2558	accuracy_val: 0.2258	accuracy_test: 0.2000
[server]	loss_train: 1.5681	loss_val: 1.5591	loss_test: 1.5628	accuracy_train: 0.1250	accuracy_val: 0.1143	accuracy_test: 0.1250
[server]	loss_train: 1.4861	loss_val: 1.5076	loss_test: 1.4918	accuracy_train: 0.3651	accuracy_val: 0.3409	accuracy_test: 0.3571
[server]	loss_train: 1.4746	loss_val: 1.5489	loss_test: 1.5614	accuracy_train: 0.2609	accuracy_val: 0.1818	accuracy_test: 0.1818
[server]	loss_train: 1.4822	loss_val: 1.5572	loss_test: 1.5727	accuracy_train: 0.2400	accuracy_val: 0.2286	accuracy_test: 0.2400
[server]	loss_train: 1.5049	loss_val: 1.5606	loss_test: 1.5851	accuracy_train: 0.2581	accuracy_val: 0.2045	accuracy_test: 0.2414
[server]	loss_train: 1.4819	loss_val: 1.5048	loss_test: 1.5887	accuracy_train: 0.2889	accuracy_val: 0.2500	accuracy_test: 0.2381
[server]	loss_train: 1.4784	loss_val: 1.5429	loss_test: 1.5259	accuracy_train: 0.2698	accuracy_val: 0.2500	accuracy_test: 0.2759
[server]	loss_train: 1.4087	loss_val: 1.4644	loss_test: 1.5020	accuracy_train: 0.3793	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 14	curr_val_accuracy: 0.2286	curr_test_accuracy: 0.2304
best_round: 9	best_val_accuracy: 0.2367	best_test_accuracy: 0.2322
--------------------------------------------------
round # 15		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4003	loss_val: 1.4801	loss_test: 1.4847	accuracy_train: 0.3750	accuracy_val: 0.2500	accuracy_test: 0.2609
[server]	loss_train: 1.5145	loss_val: 1.5268	loss_test: 1.5613	accuracy_train: 0.2353	accuracy_val: 0.1944	accuracy_test: 0.1667
[server]	loss_train: 1.5319	loss_val: 1.5915	loss_test: 1.5934	accuracy_train: 0.2453	accuracy_val: 0.1795	accuracy_test: 0.2000
[server]	loss_train: 1.4645	loss_val: 1.5428	loss_test: 1.5174	accuracy_train: 0.2600	accuracy_val: 0.2353	accuracy_test: 0.1739
[server]	loss_train: 1.4777	loss_val: 1.5539	loss_test: 1.5385	accuracy_train: 0.3654	accuracy_val: 0.2703	accuracy_test: 0.3333
[server]	loss_train: 1.5177	loss_val: 1.5251	loss_test: 1.5955	accuracy_train: 0.2982	accuracy_val: 0.2750	accuracy_test: 0.2308
[server]	loss_train: 1.3932	loss_val: 1.4532	loss_test: 1.4619	accuracy_train: 0.4043	accuracy_val: 0.3030	accuracy_test: 0.2727
[server]	loss_train: 1.4621	loss_val: 1.5214	loss_test: 1.5246	accuracy_train: 0.3400	accuracy_val: 0.2222	accuracy_test: 0.2174
[server]	loss_train: 1.4509	loss_val: 1.4651	loss_test: 1.4957	accuracy_train: 0.3333	accuracy_val: 0.2632	accuracy_test: 0.2692
[server]	loss_train: 1.4494	loss_val: 1.4800	loss_test: 1.4983	accuracy_train: 0.3265	accuracy_val: 0.1714	accuracy_test: 0.1739
[server]	loss_train: 1.4712	loss_val: 1.5636	loss_test: 1.5029	accuracy_train: 0.2281	accuracy_val: 0.1282	accuracy_test: 0.2308
[server]	loss_train: 1.4547	loss_val: 1.5609	loss_test: 1.5201	accuracy_train: 0.2558	accuracy_val: 0.2258	accuracy_test: 0.2000
[server]	loss_train: 1.5545	loss_val: 1.5525	loss_test: 1.5538	accuracy_train: 0.1458	accuracy_val: 0.1143	accuracy_test: 0.1667
[server]	loss_train: 1.4752	loss_val: 1.4986	loss_test: 1.4846	accuracy_train: 0.3968	accuracy_val: 0.3636	accuracy_test: 0.3571
[server]	loss_train: 1.4562	loss_val: 1.5399	loss_test: 1.5560	accuracy_train: 0.2609	accuracy_val: 0.2424	accuracy_test: 0.1818
[server]	loss_train: 1.4651	loss_val: 1.5498	loss_test: 1.5667	accuracy_train: 0.3000	accuracy_val: 0.2286	accuracy_test: 0.3200
[server]	loss_train: 1.4890	loss_val: 1.5527	loss_test: 1.5825	accuracy_train: 0.3226	accuracy_val: 0.3182	accuracy_test: 0.2414
[server]	loss_train: 1.4648	loss_val: 1.4968	loss_test: 1.5849	accuracy_train: 0.3333	accuracy_val: 0.2500	accuracy_test: 0.2857
[server]	loss_train: 1.4624	loss_val: 1.5366	loss_test: 1.5194	accuracy_train: 0.2857	accuracy_val: 0.2727	accuracy_test: 0.3103
[server]	loss_train: 1.3882	loss_val: 1.4541	loss_test: 1.4941	accuracy_train: 0.4655	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 15	curr_val_accuracy: 0.2448	curr_test_accuracy: 0.2485
best_round: 15	best_val_accuracy: 0.2448	best_test_accuracy: 0.2485
--------------------------------------------------
round # 16		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3843	loss_val: 1.4752	loss_test: 1.4762	accuracy_train: 0.4375	accuracy_val: 0.2222	accuracy_test: 0.3043
[server]	loss_train: 1.5000	loss_val: 1.5181	loss_test: 1.5512	accuracy_train: 0.2353	accuracy_val: 0.1944	accuracy_test: 0.1667
[server]	loss_train: 1.5165	loss_val: 1.5865	loss_test: 1.5864	accuracy_train: 0.2642	accuracy_val: 0.1795	accuracy_test: 0.2000
[server]	loss_train: 1.4474	loss_val: 1.5363	loss_test: 1.5088	accuracy_train: 0.3400	accuracy_val: 0.2353	accuracy_test: 0.2174
[server]	loss_train: 1.4619	loss_val: 1.5471	loss_test: 1.5313	accuracy_train: 0.3654	accuracy_val: 0.2703	accuracy_test: 0.3333
[server]	loss_train: 1.5049	loss_val: 1.5154	loss_test: 1.5898	accuracy_train: 0.3158	accuracy_val: 0.3250	accuracy_test: 0.2308
[server]	loss_train: 1.3775	loss_val: 1.4452	loss_test: 1.4558	accuracy_train: 0.4681	accuracy_val: 0.3030	accuracy_test: 0.2727
[server]	loss_train: 1.4452	loss_val: 1.5138	loss_test: 1.5216	accuracy_train: 0.3400	accuracy_val: 0.2500	accuracy_test: 0.2174
[server]	loss_train: 1.4360	loss_val: 1.4534	loss_test: 1.4832	accuracy_train: 0.3889	accuracy_val: 0.3158	accuracy_test: 0.2692
[server]	loss_train: 1.4330	loss_val: 1.4696	loss_test: 1.4902	accuracy_train: 0.3878	accuracy_val: 0.2000	accuracy_test: 0.1739
[server]	loss_train: 1.4548	loss_val: 1.5566	loss_test: 1.4922	accuracy_train: 0.2807	accuracy_val: 0.2051	accuracy_test: 0.3462
[server]	loss_train: 1.4400	loss_val: 1.5604	loss_test: 1.5156	accuracy_train: 0.3953	accuracy_val: 0.2258	accuracy_test: 0.2000
[server]	loss_train: 1.5395	loss_val: 1.5448	loss_test: 1.5440	accuracy_train: 0.2083	accuracy_val: 0.1714	accuracy_test: 0.2083
[server]	loss_train: 1.4651	loss_val: 1.4901	loss_test: 1.4785	accuracy_train: 0.4286	accuracy_val: 0.4091	accuracy_test: 0.3929
[server]	loss_train: 1.4389	loss_val: 1.5305	loss_test: 1.5497	accuracy_train: 0.3261	accuracy_val: 0.3030	accuracy_test: 0.2273
[server]	loss_train: 1.4485	loss_val: 1.5418	loss_test: 1.5599	accuracy_train: 0.3600	accuracy_val: 0.2857	accuracy_test: 0.3600
[server]	loss_train: 1.4737	loss_val: 1.5437	loss_test: 1.5792	accuracy_train: 0.4516	accuracy_val: 0.3409	accuracy_test: 0.3103
[server]	loss_train: 1.4485	loss_val: 1.4901	loss_test: 1.5795	accuracy_train: 0.3556	accuracy_val: 0.2500	accuracy_test: 0.2857
[server]	loss_train: 1.4477	loss_val: 1.5308	loss_test: 1.5137	accuracy_train: 0.3333	accuracy_val: 0.2727	accuracy_test: 0.3103
[server]	loss_train: 1.3706	loss_val: 1.4461	loss_test: 1.4876	accuracy_train: 0.5000	accuracy_val: 0.3333	accuracy_test: 0.3929
curr_round: 16	curr_val_accuracy: 0.2679	curr_test_accuracy: 0.2748
best_round: 16	best_val_accuracy: 0.2679	best_test_accuracy: 0.2748
--------------------------------------------------
round # 17		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3695	loss_val: 1.4709	loss_test: 1.4679	accuracy_train: 0.4375	accuracy_val: 0.2222	accuracy_test: 0.3043
[server]	loss_train: 1.4853	loss_val: 1.5094	loss_test: 1.5406	accuracy_train: 0.3333	accuracy_val: 0.1944	accuracy_test: 0.2083
[server]	loss_train: 1.5006	loss_val: 1.5808	loss_test: 1.5791	accuracy_train: 0.3208	accuracy_val: 0.1795	accuracy_test: 0.2400
[server]	loss_train: 1.4308	loss_val: 1.5297	loss_test: 1.5002	accuracy_train: 0.3800	accuracy_val: 0.2941	accuracy_test: 0.2174
[server]	loss_train: 1.4462	loss_val: 1.5396	loss_test: 1.5238	accuracy_train: 0.3654	accuracy_val: 0.2432	accuracy_test: 0.3333
[server]	loss_train: 1.4915	loss_val: 1.5049	loss_test: 1.5831	accuracy_train: 0.3333	accuracy_val: 0.3500	accuracy_test: 0.2308
[server]	loss_train: 1.3632	loss_val: 1.4377	loss_test: 1.4498	accuracy_train: 0.4681	accuracy_val: 0.3333	accuracy_test: 0.3182
[server]	loss_train: 1.4286	loss_val: 1.5066	loss_test: 1.5190	accuracy_train: 0.5000	accuracy_val: 0.2778	accuracy_test: 0.2174
[server]	loss_train: 1.4218	loss_val: 1.4424	loss_test: 1.4709	accuracy_train: 0.4074	accuracy_val: 0.3421	accuracy_test: 0.3077
[server]	loss_train: 1.4178	loss_val: 1.4607	loss_test: 1.4825	accuracy_train: 0.4286	accuracy_val: 0.2286	accuracy_test: 0.2609
[server]	loss_train: 1.4391	loss_val: 1.5493	loss_test: 1.4825	accuracy_train: 0.4386	accuracy_val: 0.2564	accuracy_test: 0.3462
[server]	loss_train: 1.4258	loss_val: 1.5598	loss_test: 1.5117	accuracy_train: 0.4186	accuracy_val: 0.2581	accuracy_test: 0.2000
[server]	loss_train: 1.5241	loss_val: 1.5363	loss_test: 1.5337	accuracy_train: 0.2917	accuracy_val: 0.2286	accuracy_test: 0.3750
[server]	loss_train: 1.4553	loss_val: 1.4814	loss_test: 1.4722	accuracy_train: 0.4603	accuracy_val: 0.4318	accuracy_test: 0.3929
[server]	loss_train: 1.4221	loss_val: 1.5214	loss_test: 1.5431	accuracy_train: 0.4348	accuracy_val: 0.3030	accuracy_test: 0.2273
[server]	loss_train: 1.4323	loss_val: 1.5337	loss_test: 1.5532	accuracy_train: 0.4600	accuracy_val: 0.3143	accuracy_test: 0.4000
[server]	loss_train: 1.4585	loss_val: 1.5341	loss_test: 1.5751	accuracy_train: 0.4839	accuracy_val: 0.3636	accuracy_test: 0.3103
[server]	loss_train: 1.4325	loss_val: 1.4837	loss_test: 1.5733	accuracy_train: 0.3778	accuracy_val: 0.2812	accuracy_test: 0.2857
[server]	loss_train: 1.4339	loss_val: 1.5249	loss_test: 1.5084	accuracy_train: 0.3651	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.3545	loss_val: 1.4390	loss_test: 1.4818	accuracy_train: 0.5345	accuracy_val: 0.3590	accuracy_test: 0.3929
curr_round: 17	curr_val_accuracy: 0.2937	curr_test_accuracy: 0.2989
best_round: 17	best_val_accuracy: 0.2937	best_test_accuracy: 0.2989
--------------------------------------------------
round # 18		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3548	loss_val: 1.4662	loss_test: 1.4588	accuracy_train: 0.4792	accuracy_val: 0.2222	accuracy_test: 0.3043
[server]	loss_train: 1.4703	loss_val: 1.5004	loss_test: 1.5297	accuracy_train: 0.3922	accuracy_val: 0.2778	accuracy_test: 0.2917
[server]	loss_train: 1.4846	loss_val: 1.5750	loss_test: 1.5718	accuracy_train: 0.3585	accuracy_val: 0.2308	accuracy_test: 0.2800
[server]	loss_train: 1.4144	loss_val: 1.5228	loss_test: 1.4913	accuracy_train: 0.4000	accuracy_val: 0.2941	accuracy_test: 0.2174
[server]	loss_train: 1.4301	loss_val: 1.5317	loss_test: 1.5155	accuracy_train: 0.3846	accuracy_val: 0.2432	accuracy_test: 0.3750
[server]	loss_train: 1.4774	loss_val: 1.4937	loss_test: 1.5759	accuracy_train: 0.3509	accuracy_val: 0.3500	accuracy_test: 0.2308
[server]	loss_train: 1.3489	loss_val: 1.4299	loss_test: 1.4433	accuracy_train: 0.4894	accuracy_val: 0.3636	accuracy_test: 0.3636
[server]	loss_train: 1.4121	loss_val: 1.4996	loss_test: 1.5163	accuracy_train: 0.5200	accuracy_val: 0.3056	accuracy_test: 0.2174
[server]	loss_train: 1.4076	loss_val: 1.4315	loss_test: 1.4583	accuracy_train: 0.5185	accuracy_val: 0.4474	accuracy_test: 0.2692
[server]	loss_train: 1.4029	loss_val: 1.4527	loss_test: 1.4749	accuracy_train: 0.4694	accuracy_val: 0.2857	accuracy_test: 0.2174
[server]	loss_train: 1.4234	loss_val: 1.5421	loss_test: 1.4723	accuracy_train: 0.4561	accuracy_val: 0.2564	accuracy_test: 0.3846
[server]	loss_train: 1.4115	loss_val: 1.5588	loss_test: 1.5076	accuracy_train: 0.4419	accuracy_val: 0.2581	accuracy_test: 0.2000
[server]	loss_train: 1.5086	loss_val: 1.5272	loss_test: 1.5229	accuracy_train: 0.3333	accuracy_val: 0.2571	accuracy_test: 0.3750
[server]	loss_train: 1.4449	loss_val: 1.4722	loss_test: 1.4651	accuracy_train: 0.4603	accuracy_val: 0.4318	accuracy_test: 0.3929
[server]	loss_train: 1.4053	loss_val: 1.5127	loss_test: 1.5363	accuracy_train: 0.4565	accuracy_val: 0.3030	accuracy_test: 0.1818
[server]	loss_train: 1.4163	loss_val: 1.5256	loss_test: 1.5467	accuracy_train: 0.4600	accuracy_val: 0.3143	accuracy_test: 0.4400
[server]	loss_train: 1.4429	loss_val: 1.5242	loss_test: 1.5703	accuracy_train: 0.5161	accuracy_val: 0.3864	accuracy_test: 0.3793
[server]	loss_train: 1.4165	loss_val: 1.4769	loss_test: 1.5666	accuracy_train: 0.4000	accuracy_val: 0.2812	accuracy_test: 0.2381
[server]	loss_train: 1.4203	loss_val: 1.5184	loss_test: 1.5029	accuracy_train: 0.4127	accuracy_val: 0.3636	accuracy_test: 0.3448
[server]	loss_train: 1.3387	loss_val: 1.4319	loss_test: 1.4764	accuracy_train: 0.5345	accuracy_val: 0.3590	accuracy_test: 0.4286
curr_round: 18	curr_val_accuracy: 0.3153	curr_test_accuracy: 0.3110
best_round: 18	best_val_accuracy: 0.3153	best_test_accuracy: 0.3110
--------------------------------------------------
round # 19		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3398	loss_val: 1.4609	loss_test: 1.4492	accuracy_train: 0.5000	accuracy_val: 0.2500	accuracy_test: 0.3043
[server]	loss_train: 1.4551	loss_val: 1.4913	loss_test: 1.5188	accuracy_train: 0.4314	accuracy_val: 0.2778	accuracy_test: 0.2500
[server]	loss_train: 1.4685	loss_val: 1.5691	loss_test: 1.5648	accuracy_train: 0.3774	accuracy_val: 0.2564	accuracy_test: 0.3600
[server]	loss_train: 1.3982	loss_val: 1.5154	loss_test: 1.4820	accuracy_train: 0.4600	accuracy_val: 0.2941	accuracy_test: 0.2174
[server]	loss_train: 1.4137	loss_val: 1.5237	loss_test: 1.5065	accuracy_train: 0.3846	accuracy_val: 0.3243	accuracy_test: 0.3750
[server]	loss_train: 1.4630	loss_val: 1.4822	loss_test: 1.5686	accuracy_train: 0.3860	accuracy_val: 0.3250	accuracy_test: 0.2308
[server]	loss_train: 1.3342	loss_val: 1.4219	loss_test: 1.4362	accuracy_train: 0.5106	accuracy_val: 0.3636	accuracy_test: 0.3636
[server]	loss_train: 1.3954	loss_val: 1.4928	loss_test: 1.5134	accuracy_train: 0.5200	accuracy_val: 0.2778	accuracy_test: 0.2174
[server]	loss_train: 1.3930	loss_val: 1.4208	loss_test: 1.4456	accuracy_train: 0.5926	accuracy_val: 0.4474	accuracy_test: 0.3462
[server]	loss_train: 1.3879	loss_val: 1.4449	loss_test: 1.4671	accuracy_train: 0.4898	accuracy_val: 0.2857	accuracy_test: 0.1739
[server]	loss_train: 1.4074	loss_val: 1.5351	loss_test: 1.4613	accuracy_train: 0.4912	accuracy_val: 0.2564	accuracy_test: 0.3846
[server]	loss_train: 1.3969	loss_val: 1.5576	loss_test: 1.5033	accuracy_train: 0.4419	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.4932	loss_val: 1.5176	loss_test: 1.5121	accuracy_train: 0.3542	accuracy_val: 0.2286	accuracy_test: 0.3750
[server]	loss_train: 1.4339	loss_val: 1.4629	loss_test: 1.4574	accuracy_train: 0.5079	accuracy_val: 0.4318	accuracy_test: 0.3929
[server]	loss_train: 1.3884	loss_val: 1.5043	loss_test: 1.5297	accuracy_train: 0.4783	accuracy_val: 0.3030	accuracy_test: 0.1818
[server]	loss_train: 1.4002	loss_val: 1.5174	loss_test: 1.5405	accuracy_train: 0.4800	accuracy_val: 0.3143	accuracy_test: 0.4400
[server]	loss_train: 1.4267	loss_val: 1.5142	loss_test: 1.5650	accuracy_train: 0.5161	accuracy_val: 0.3864	accuracy_test: 0.3793
[server]	loss_train: 1.4005	loss_val: 1.4695	loss_test: 1.5600	accuracy_train: 0.4444	accuracy_val: 0.2812	accuracy_test: 0.2857
[server]	loss_train: 1.4067	loss_val: 1.5114	loss_test: 1.4973	accuracy_train: 0.4444	accuracy_val: 0.3182	accuracy_test: 0.3448
[server]	loss_train: 1.3227	loss_val: 1.4247	loss_test: 1.4712	accuracy_train: 0.5345	accuracy_val: 0.3590	accuracy_test: 0.4286
curr_round: 19	curr_val_accuracy: 0.3152	curr_test_accuracy: 0.3192
best_round: 18	best_val_accuracy: 0.3153	best_test_accuracy: 0.3110
--------------------------------------------------
round # 20		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3246	loss_val: 1.4554	loss_test: 1.4393	accuracy_train: 0.5208	accuracy_val: 0.2778	accuracy_test: 0.3043
[server]	loss_train: 1.4399	loss_val: 1.4822	loss_test: 1.5077	accuracy_train: 0.4314	accuracy_val: 0.2778	accuracy_test: 0.2500
[server]	loss_train: 1.4524	loss_val: 1.5633	loss_test: 1.5578	accuracy_train: 0.3774	accuracy_val: 0.2564	accuracy_test: 0.4400
[server]	loss_train: 1.3821	loss_val: 1.5079	loss_test: 1.4725	accuracy_train: 0.4600	accuracy_val: 0.2941	accuracy_test: 0.3043
[server]	loss_train: 1.3973	loss_val: 1.5156	loss_test: 1.4971	accuracy_train: 0.3846	accuracy_val: 0.3243	accuracy_test: 0.3750
[server]	loss_train: 1.4486	loss_val: 1.4709	loss_test: 1.5616	accuracy_train: 0.4561	accuracy_val: 0.3750	accuracy_test: 0.2692
[server]	loss_train: 1.3193	loss_val: 1.4140	loss_test: 1.4292	accuracy_train: 0.5319	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.3788	loss_val: 1.4864	loss_test: 1.5106	accuracy_train: 0.5400	accuracy_val: 0.2778	accuracy_test: 0.1739
[server]	loss_train: 1.3782	loss_val: 1.4104	loss_test: 1.4329	accuracy_train: 0.5926	accuracy_val: 0.5000	accuracy_test: 0.3462
[server]	loss_train: 1.3729	loss_val: 1.4373	loss_test: 1.4591	accuracy_train: 0.5102	accuracy_val: 0.3143	accuracy_test: 0.1739
[server]	loss_train: 1.3912	loss_val: 1.5283	loss_test: 1.4494	accuracy_train: 0.5088	accuracy_val: 0.2564	accuracy_test: 0.3846
[server]	loss_train: 1.3822	loss_val: 1.5565	loss_test: 1.4988	accuracy_train: 0.4651	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.4779	loss_val: 1.5080	loss_test: 1.5013	accuracy_train: 0.3958	accuracy_val: 0.2286	accuracy_test: 0.3750
[server]	loss_train: 1.4226	loss_val: 1.4539	loss_test: 1.4499	accuracy_train: 0.5079	accuracy_val: 0.4545	accuracy_test: 0.3929
[server]	loss_train: 1.3714	loss_val: 1.4961	loss_test: 1.5233	accuracy_train: 0.5000	accuracy_val: 0.3030	accuracy_test: 0.2273
[server]	loss_train: 1.3840	loss_val: 1.5093	loss_test: 1.5346	accuracy_train: 0.5000	accuracy_val: 0.3143	accuracy_test: 0.4400
[server]	loss_train: 1.4102	loss_val: 1.5042	loss_test: 1.5594	accuracy_train: 0.5000	accuracy_val: 0.4091	accuracy_test: 0.3793
[server]	loss_train: 1.3846	loss_val: 1.4617	loss_test: 1.5535	accuracy_train: 0.4667	accuracy_val: 0.3125	accuracy_test: 0.2857
[server]	loss_train: 1.3929	loss_val: 1.5042	loss_test: 1.4918	accuracy_train: 0.5079	accuracy_val: 0.2955	accuracy_test: 0.3448
[server]	loss_train: 1.3067	loss_val: 1.4176	loss_test: 1.4662	accuracy_train: 0.5862	accuracy_val: 0.3846	accuracy_test: 0.4643
curr_round: 20	curr_val_accuracy: 0.3287	curr_test_accuracy: 0.3313
best_round: 20	best_val_accuracy: 0.3287	best_test_accuracy: 0.3313
--------------------------------------------------
round # 21		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3098	loss_val: 1.4504	loss_test: 1.4299	accuracy_train: 0.5625	accuracy_val: 0.3056	accuracy_test: 0.3043
[server]	loss_train: 1.4249	loss_val: 1.4734	loss_test: 1.4966	accuracy_train: 0.4706	accuracy_val: 0.4167	accuracy_test: 0.2917
[server]	loss_train: 1.4365	loss_val: 1.5576	loss_test: 1.5507	accuracy_train: 0.4717	accuracy_val: 0.2821	accuracy_test: 0.4000
[server]	loss_train: 1.3664	loss_val: 1.5004	loss_test: 1.4631	accuracy_train: 0.5600	accuracy_val: 0.3529	accuracy_test: 0.3913
[server]	loss_train: 1.3812	loss_val: 1.5075	loss_test: 1.4879	accuracy_train: 0.4615	accuracy_val: 0.4324	accuracy_test: 0.3750
[server]	loss_train: 1.4345	loss_val: 1.4598	loss_test: 1.5548	accuracy_train: 0.4912	accuracy_val: 0.4750	accuracy_test: 0.3077
[server]	loss_train: 1.3048	loss_val: 1.4064	loss_test: 1.4228	accuracy_train: 0.5745	accuracy_val: 0.4848	accuracy_test: 0.3636
[server]	loss_train: 1.3625	loss_val: 1.4805	loss_test: 1.5081	accuracy_train: 0.6400	accuracy_val: 0.4444	accuracy_test: 0.2609
[server]	loss_train: 1.3636	loss_val: 1.4004	loss_test: 1.4205	accuracy_train: 0.5926	accuracy_val: 0.5526	accuracy_test: 0.3462
[server]	loss_train: 1.3581	loss_val: 1.4300	loss_test: 1.4514	accuracy_train: 0.5510	accuracy_val: 0.3714	accuracy_test: 0.2609
[server]	loss_train: 1.3750	loss_val: 1.5218	loss_test: 1.4373	accuracy_train: 0.5263	accuracy_val: 0.2821	accuracy_test: 0.3462
[server]	loss_train: 1.3676	loss_val: 1.5556	loss_test: 1.4944	accuracy_train: 0.5581	accuracy_val: 0.3548	accuracy_test: 0.2500
[server]	loss_train: 1.4625	loss_val: 1.4985	loss_test: 1.4907	accuracy_train: 0.3958	accuracy_val: 0.2857	accuracy_test: 0.4167
[server]	loss_train: 1.4115	loss_val: 1.4452	loss_test: 1.4429	accuracy_train: 0.5556	accuracy_val: 0.4318	accuracy_test: 0.4286
[server]	loss_train: 1.3546	loss_val: 1.4877	loss_test: 1.5169	accuracy_train: 0.5870	accuracy_val: 0.3939	accuracy_test: 0.2727
[server]	loss_train: 1.3677	loss_val: 1.5013	loss_test: 1.5287	accuracy_train: 0.6400	accuracy_val: 0.3143	accuracy_test: 0.5200
[server]	loss_train: 1.3937	loss_val: 1.4941	loss_test: 1.5537	accuracy_train: 0.5000	accuracy_val: 0.5227	accuracy_test: 0.4138
[server]	loss_train: 1.3690	loss_val: 1.4540	loss_test: 1.5470	accuracy_train: 0.5556	accuracy_val: 0.4375	accuracy_test: 0.3333
[server]	loss_train: 1.3793	loss_val: 1.4971	loss_test: 1.4865	accuracy_train: 0.5714	accuracy_val: 0.3182	accuracy_test: 0.3793
[server]	loss_train: 1.2912	loss_val: 1.4112	loss_test: 1.4613	accuracy_train: 0.5862	accuracy_val: 0.4615	accuracy_test: 0.4643
curr_round: 21	curr_val_accuracy: 0.3976	curr_test_accuracy: 0.3598
best_round: 21	best_val_accuracy: 0.3976	best_test_accuracy: 0.3598
--------------------------------------------------
round # 22		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.2955	loss_val: 1.4462	loss_test: 1.4210	accuracy_train: 0.5833	accuracy_val: 0.3611	accuracy_test: 0.3478
[server]	loss_train: 1.4099	loss_val: 1.4649	loss_test: 1.4855	accuracy_train: 0.5098	accuracy_val: 0.4722	accuracy_test: 0.3333
[server]	loss_train: 1.4205	loss_val: 1.5519	loss_test: 1.5433	accuracy_train: 0.4906	accuracy_val: 0.2564	accuracy_test: 0.4400
[server]	loss_train: 1.3509	loss_val: 1.4930	loss_test: 1.4538	accuracy_train: 0.5600	accuracy_val: 0.3529	accuracy_test: 0.4348
[server]	loss_train: 1.3654	loss_val: 1.4995	loss_test: 1.4789	accuracy_train: 0.5000	accuracy_val: 0.4595	accuracy_test: 0.5000
[server]	loss_train: 1.4207	loss_val: 1.4490	loss_test: 1.5481	accuracy_train: 0.5263	accuracy_val: 0.5000	accuracy_test: 0.3077
[server]	loss_train: 1.2910	loss_val: 1.3993	loss_test: 1.4170	accuracy_train: 0.5745	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.3466	loss_val: 1.4752	loss_test: 1.5060	accuracy_train: 0.6400	accuracy_val: 0.4444	accuracy_test: 0.2609
[server]	loss_train: 1.3494	loss_val: 1.3911	loss_test: 1.4085	accuracy_train: 0.5926	accuracy_val: 0.5263	accuracy_test: 0.3846
[server]	loss_train: 1.3435	loss_val: 1.4230	loss_test: 1.4442	accuracy_train: 0.5714	accuracy_val: 0.3429	accuracy_test: 0.2609
[server]	loss_train: 1.3593	loss_val: 1.5156	loss_test: 1.4253	accuracy_train: 0.5614	accuracy_val: 0.2821	accuracy_test: 0.3846
[server]	loss_train: 1.3535	loss_val: 1.5551	loss_test: 1.4903	accuracy_train: 0.6279	accuracy_val: 0.2903	accuracy_test: 0.2500
[server]	loss_train: 1.4470	loss_val: 1.4892	loss_test: 1.4800	accuracy_train: 0.4375	accuracy_val: 0.2857	accuracy_test: 0.4167
[server]	loss_train: 1.4008	loss_val: 1.4370	loss_test: 1.4368	accuracy_train: 0.5556	accuracy_val: 0.4545	accuracy_test: 0.4286
[server]	loss_train: 1.3381	loss_val: 1.4790	loss_test: 1.5106	accuracy_train: 0.6087	accuracy_val: 0.4545	accuracy_test: 0.3636
[server]	loss_train: 1.3514	loss_val: 1.4935	loss_test: 1.5229	accuracy_train: 0.6400	accuracy_val: 0.3143	accuracy_test: 0.4800
[server]	loss_train: 1.3773	loss_val: 1.4839	loss_test: 1.5477	accuracy_train: 0.5161	accuracy_val: 0.5455	accuracy_test: 0.4138
[server]	loss_train: 1.3537	loss_val: 1.4467	loss_test: 1.5405	accuracy_train: 0.5778	accuracy_val: 0.4062	accuracy_test: 0.2857
[server]	loss_train: 1.3659	loss_val: 1.4905	loss_test: 1.4817	accuracy_train: 0.5873	accuracy_val: 0.2955	accuracy_test: 0.4138
[server]	loss_train: 1.2765	loss_val: 1.4057	loss_test: 1.4569	accuracy_train: 0.6034	accuracy_val: 0.4615	accuracy_test: 0.3929
curr_round: 22	curr_val_accuracy: 0.3989	curr_test_accuracy: 0.3764
best_round: 22	best_val_accuracy: 0.3989	best_test_accuracy: 0.3764
--------------------------------------------------
round # 23		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.2821	loss_val: 1.4429	loss_test: 1.4126	accuracy_train: 0.5833	accuracy_val: 0.3611	accuracy_test: 0.3478
[server]	loss_train: 1.3950	loss_val: 1.4566	loss_test: 1.4746	accuracy_train: 0.5686	accuracy_val: 0.4722	accuracy_test: 0.3333
[server]	loss_train: 1.4045	loss_val: 1.5462	loss_test: 1.5353	accuracy_train: 0.5283	accuracy_val: 0.2564	accuracy_test: 0.4400
[server]	loss_train: 1.3358	loss_val: 1.4857	loss_test: 1.4448	accuracy_train: 0.5600	accuracy_val: 0.3529	accuracy_test: 0.4348
[server]	loss_train: 1.3500	loss_val: 1.4914	loss_test: 1.4701	accuracy_train: 0.5000	accuracy_val: 0.4595	accuracy_test: 0.4583
[server]	loss_train: 1.4069	loss_val: 1.4384	loss_test: 1.5413	accuracy_train: 0.5439	accuracy_val: 0.5000	accuracy_test: 0.3077
[server]	loss_train: 1.2780	loss_val: 1.3927	loss_test: 1.4120	accuracy_train: 0.5532	accuracy_val: 0.4242	accuracy_test: 0.4091
[server]	loss_train: 1.3314	loss_val: 1.4705	loss_test: 1.5044	accuracy_train: 0.6400	accuracy_val: 0.5000	accuracy_test: 0.2609
[server]	loss_train: 1.3358	loss_val: 1.3823	loss_test: 1.3971	accuracy_train: 0.6111	accuracy_val: 0.5526	accuracy_test: 0.5000
[server]	loss_train: 1.3296	loss_val: 1.4167	loss_test: 1.4378	accuracy_train: 0.5510	accuracy_val: 0.3714	accuracy_test: 0.2609
[server]	loss_train: 1.3442	loss_val: 1.5098	loss_test: 1.4136	accuracy_train: 0.5789	accuracy_val: 0.2821	accuracy_test: 0.3462
[server]	loss_train: 1.3400	loss_val: 1.5551	loss_test: 1.4864	accuracy_train: 0.6512	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.4313	loss_val: 1.4802	loss_test: 1.4691	accuracy_train: 0.4375	accuracy_val: 0.2857	accuracy_test: 0.4583
[server]	loss_train: 1.3905	loss_val: 1.4292	loss_test: 1.4313	accuracy_train: 0.5873	accuracy_val: 0.4545	accuracy_test: 0.4286
[server]	loss_train: 1.3221	loss_val: 1.4702	loss_test: 1.5042	accuracy_train: 0.6304	accuracy_val: 0.4545	accuracy_test: 0.3636
[server]	loss_train: 1.3352	loss_val: 1.4860	loss_test: 1.5170	accuracy_train: 0.6600	accuracy_val: 0.3143	accuracy_test: 0.4800
[server]	loss_train: 1.3611	loss_val: 1.4736	loss_test: 1.5414	accuracy_train: 0.5323	accuracy_val: 0.5227	accuracy_test: 0.4138
[server]	loss_train: 1.3387	loss_val: 1.4399	loss_test: 1.5339	accuracy_train: 0.6222	accuracy_val: 0.4375	accuracy_test: 0.2857
[server]	loss_train: 1.3529	loss_val: 1.4843	loss_test: 1.4774	accuracy_train: 0.6190	accuracy_val: 0.3182	accuracy_test: 0.4483
[server]	loss_train: 1.2630	loss_val: 1.4012	loss_test: 1.4530	accuracy_train: 0.6552	accuracy_val: 0.4359	accuracy_test: 0.3929
curr_round: 23	curr_val_accuracy: 0.4028	curr_test_accuracy: 0.3864
best_round: 23	best_val_accuracy: 0.4028	best_test_accuracy: 0.3864
--------------------------------------------------
round # 24		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.2693	loss_val: 1.4404	loss_test: 1.4046	accuracy_train: 0.5833	accuracy_val: 0.4167	accuracy_test: 0.3913
[server]	loss_train: 1.3801	loss_val: 1.4486	loss_test: 1.4638	accuracy_train: 0.5490	accuracy_val: 0.4444	accuracy_test: 0.2917
[server]	loss_train: 1.3886	loss_val: 1.5406	loss_test: 1.5269	accuracy_train: 0.5283	accuracy_val: 0.2821	accuracy_test: 0.5200
[server]	loss_train: 1.3211	loss_val: 1.4785	loss_test: 1.4359	accuracy_train: 0.5600	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.3348	loss_val: 1.4832	loss_test: 1.4616	accuracy_train: 0.5192	accuracy_val: 0.4865	accuracy_test: 0.4583
[server]	loss_train: 1.3931	loss_val: 1.4277	loss_test: 1.5342	accuracy_train: 0.5439	accuracy_val: 0.5000	accuracy_test: 0.3077
[server]	loss_train: 1.2658	loss_val: 1.3865	loss_test: 1.4075	accuracy_train: 0.5319	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.3168	loss_val: 1.4664	loss_test: 1.5030	accuracy_train: 0.6600	accuracy_val: 0.5000	accuracy_test: 0.3043
[server]	loss_train: 1.3226	loss_val: 1.3742	loss_test: 1.3862	accuracy_train: 0.5741	accuracy_val: 0.5789	accuracy_test: 0.5385
[server]	loss_train: 1.3165	loss_val: 1.4110	loss_test: 1.4321	accuracy_train: 0.5510	accuracy_val: 0.3429	accuracy_test: 0.2609
[server]	loss_train: 1.3298	loss_val: 1.5046	loss_test: 1.4023	accuracy_train: 0.5789	accuracy_val: 0.2821	accuracy_test: 0.3462
[server]	loss_train: 1.3270	loss_val: 1.5555	loss_test: 1.4826	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.4155	loss_val: 1.4714	loss_test: 1.4580	accuracy_train: 0.4375	accuracy_val: 0.3429	accuracy_test: 0.4167
[server]	loss_train: 1.3806	loss_val: 1.4214	loss_test: 1.4263	accuracy_train: 0.5714	accuracy_val: 0.4773	accuracy_test: 0.4643
[server]	loss_train: 1.3065	loss_val: 1.4613	loss_test: 1.4979	accuracy_train: 0.6739	accuracy_val: 0.4848	accuracy_test: 0.4545
[server]	loss_train: 1.3193	loss_val: 1.4786	loss_test: 1.5111	accuracy_train: 0.6800	accuracy_val: 0.2857	accuracy_test: 0.4400
[server]	loss_train: 1.3449	loss_val: 1.4633	loss_test: 1.5349	accuracy_train: 0.5323	accuracy_val: 0.5000	accuracy_test: 0.4483
[server]	loss_train: 1.3240	loss_val: 1.4335	loss_test: 1.5272	accuracy_train: 0.6444	accuracy_val: 0.4375	accuracy_test: 0.2857
[server]	loss_train: 1.3403	loss_val: 1.4786	loss_test: 1.4735	accuracy_train: 0.6032	accuracy_val: 0.2727	accuracy_test: 0.4483
[server]	loss_train: 1.2504	loss_val: 1.3976	loss_test: 1.4498	accuracy_train: 0.6552	accuracy_val: 0.4359	accuracy_test: 0.3929
curr_round: 24	curr_val_accuracy: 0.4053	curr_test_accuracy: 0.3989
best_round: 24	best_val_accuracy: 0.4053	best_test_accuracy: 0.3989
--------------------------------------------------
round # 25		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.2571	loss_val: 1.4384	loss_test: 1.3969	accuracy_train: 0.5833	accuracy_val: 0.4167	accuracy_test: 0.3913
[server]	loss_train: 1.3655	loss_val: 1.4407	loss_test: 1.4533	accuracy_train: 0.5882	accuracy_val: 0.4444	accuracy_test: 0.2917
[server]	loss_train: 1.3729	loss_val: 1.5350	loss_test: 1.5182	accuracy_train: 0.5283	accuracy_val: 0.2821	accuracy_test: 0.5200
[server]	loss_train: 1.3069	loss_val: 1.4715	loss_test: 1.4273	accuracy_train: 0.5600	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.3199	loss_val: 1.4750	loss_test: 1.4531	accuracy_train: 0.5385	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.3791	loss_val: 1.4168	loss_test: 1.5269	accuracy_train: 0.5614	accuracy_val: 0.5000	accuracy_test: 0.3077
[server]	loss_train: 1.2542	loss_val: 1.3807	loss_test: 1.4034	accuracy_train: 0.5532	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.3029	loss_val: 1.4629	loss_test: 1.5016	accuracy_train: 0.6600	accuracy_val: 0.5000	accuracy_test: 0.3043
[server]	loss_train: 1.3100	loss_val: 1.3666	loss_test: 1.3758	accuracy_train: 0.6111	accuracy_val: 0.5789	accuracy_test: 0.5385
[server]	loss_train: 1.3040	loss_val: 1.4059	loss_test: 1.4270	accuracy_train: 0.5510	accuracy_val: 0.3429	accuracy_test: 0.2609
[server]	loss_train: 1.3160	loss_val: 1.4999	loss_test: 1.3915	accuracy_train: 0.5789	accuracy_val: 0.2821	accuracy_test: 0.3077
[server]	loss_train: 1.3145	loss_val: 1.5563	loss_test: 1.4787	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.3998	loss_val: 1.4629	loss_test: 1.4468	accuracy_train: 0.4375	accuracy_val: 0.3714	accuracy_test: 0.4167
[server]	loss_train: 1.3712	loss_val: 1.4137	loss_test: 1.4218	accuracy_train: 0.5873	accuracy_val: 0.4773	accuracy_test: 0.4286
[server]	loss_train: 1.2914	loss_val: 1.4525	loss_test: 1.4917	accuracy_train: 0.6739	accuracy_val: 0.4848	accuracy_test: 0.4545
[server]	loss_train: 1.3036	loss_val: 1.4714	loss_test: 1.5053	accuracy_train: 0.7000	accuracy_val: 0.2857	accuracy_test: 0.4400
[server]	loss_train: 1.3288	loss_val: 1.4531	loss_test: 1.5281	accuracy_train: 0.5323	accuracy_val: 0.5000	accuracy_test: 0.4483
[server]	loss_train: 1.3096	loss_val: 1.4275	loss_test: 1.5207	accuracy_train: 0.6444	accuracy_val: 0.4375	accuracy_test: 0.2857
[server]	loss_train: 1.3283	loss_val: 1.4732	loss_test: 1.4698	accuracy_train: 0.6190	accuracy_val: 0.2727	accuracy_test: 0.4138
[server]	loss_train: 1.2388	loss_val: 1.3946	loss_test: 1.4473	accuracy_train: 0.6552	accuracy_val: 0.4359	accuracy_test: 0.3571
curr_round: 25	curr_val_accuracy: 0.4080	curr_test_accuracy: 0.3927
best_round: 25	best_val_accuracy: 0.4080	best_test_accuracy: 0.3927
--------------------------------------------------
round # 26		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.2455	loss_val: 1.4367	loss_test: 1.3894	accuracy_train: 0.5417	accuracy_val: 0.4167	accuracy_test: 0.3478
[server]	loss_train: 1.3511	loss_val: 1.4330	loss_test: 1.4429	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.3333
[server]	loss_train: 1.3575	loss_val: 1.5296	loss_test: 1.5095	accuracy_train: 0.5472	accuracy_val: 0.2821	accuracy_test: 0.5200
[server]	loss_train: 1.2932	loss_val: 1.4647	loss_test: 1.4188	accuracy_train: 0.5800	accuracy_val: 0.3235	accuracy_test: 0.4783
[server]	loss_train: 1.3055	loss_val: 1.4669	loss_test: 1.4448	accuracy_train: 0.5192	accuracy_val: 0.5405	accuracy_test: 0.5000
[server]	loss_train: 1.3652	loss_val: 1.4060	loss_test: 1.5196	accuracy_train: 0.6316	accuracy_val: 0.5250	accuracy_test: 0.3077
[server]	loss_train: 1.2431	loss_val: 1.3751	loss_test: 1.3996	accuracy_train: 0.5532	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.2897	loss_val: 1.4599	loss_test: 1.5000	accuracy_train: 0.6800	accuracy_val: 0.4722	accuracy_test: 0.3043
[server]	loss_train: 1.2979	loss_val: 1.3595	loss_test: 1.3659	accuracy_train: 0.6296	accuracy_val: 0.5789	accuracy_test: 0.5385
[server]	loss_train: 1.2923	loss_val: 1.4011	loss_test: 1.4223	accuracy_train: 0.5510	accuracy_val: 0.3429	accuracy_test: 0.2609
[server]	loss_train: 1.3028	loss_val: 1.4957	loss_test: 1.3811	accuracy_train: 0.5789	accuracy_val: 0.2821	accuracy_test: 0.3077
[server]	loss_train: 1.3024	loss_val: 1.5573	loss_test: 1.4747	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3500
[server]	loss_train: 1.3842	loss_val: 1.4545	loss_test: 1.4355	accuracy_train: 0.4583	accuracy_val: 0.3143	accuracy_test: 0.4167
[server]	loss_train: 1.3621	loss_val: 1.4061	loss_test: 1.4175	accuracy_train: 0.5714	accuracy_val: 0.4545	accuracy_test: 0.4286
[server]	loss_train: 1.2767	loss_val: 1.4440	loss_test: 1.4857	accuracy_train: 0.6739	accuracy_val: 0.5152	accuracy_test: 0.4545
[server]	loss_train: 1.2882	loss_val: 1.4645	loss_test: 1.4997	accuracy_train: 0.6800	accuracy_val: 0.3143	accuracy_test: 0.4400
[server]	loss_train: 1.3131	loss_val: 1.4433	loss_test: 1.5214	accuracy_train: 0.5323	accuracy_val: 0.5000	accuracy_test: 0.4483
[server]	loss_train: 1.2956	loss_val: 1.4220	loss_test: 1.5144	accuracy_train: 0.6222	accuracy_val: 0.4688	accuracy_test: 0.2857
[server]	loss_train: 1.3166	loss_val: 1.4680	loss_test: 1.4665	accuracy_train: 0.6349	accuracy_val: 0.2727	accuracy_test: 0.4138
[server]	loss_train: 1.2280	loss_val: 1.3922	loss_test: 1.4453	accuracy_train: 0.6897	accuracy_val: 0.4615	accuracy_test: 0.3571
curr_round: 26	curr_val_accuracy: 0.4081	curr_test_accuracy: 0.3948
best_round: 26	best_val_accuracy: 0.4081	best_test_accuracy: 0.3948
--------------------------------------------------
round # 27		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.2342	loss_val: 1.4352	loss_test: 1.3822	accuracy_train: 0.5417	accuracy_val: 0.4167	accuracy_test: 0.3478
[server]	loss_train: 1.3371	loss_val: 1.4255	loss_test: 1.4329	accuracy_train: 0.5686	accuracy_val: 0.4167	accuracy_test: 0.3750
[server]	loss_train: 1.3424	loss_val: 1.5244	loss_test: 1.5009	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.5200
[server]	loss_train: 1.2799	loss_val: 1.4579	loss_test: 1.4103	accuracy_train: 0.6200	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.2914	loss_val: 1.4590	loss_test: 1.4367	accuracy_train: 0.5577	accuracy_val: 0.5405	accuracy_test: 0.5417
[server]	loss_train: 1.3514	loss_val: 1.3952	loss_test: 1.5125	accuracy_train: 0.6140	accuracy_val: 0.5250	accuracy_test: 0.3077
[server]	loss_train: 1.2325	loss_val: 1.3699	loss_test: 1.3961	accuracy_train: 0.5532	accuracy_val: 0.3939	accuracy_test: 0.3182
[server]	loss_train: 1.2771	loss_val: 1.4573	loss_test: 1.4984	accuracy_train: 0.7000	accuracy_val: 0.4444	accuracy_test: 0.3043
[server]	loss_train: 1.2864	loss_val: 1.3529	loss_test: 1.3566	accuracy_train: 0.6111	accuracy_val: 0.5789	accuracy_test: 0.5385
[server]	loss_train: 1.2812	loss_val: 1.3966	loss_test: 1.4179	accuracy_train: 0.5510	accuracy_val: 0.3714	accuracy_test: 0.2609
[server]	loss_train: 1.2903	loss_val: 1.4922	loss_test: 1.3713	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.3077
[server]	loss_train: 1.2907	loss_val: 1.5584	loss_test: 1.4707	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.3691	loss_val: 1.4463	loss_test: 1.4244	accuracy_train: 0.4792	accuracy_val: 0.3714	accuracy_test: 0.4167
[server]	loss_train: 1.3535	loss_val: 1.3986	loss_test: 1.4137	accuracy_train: 0.5714	accuracy_val: 0.4545	accuracy_test: 0.4286
[server]	loss_train: 1.2624	loss_val: 1.4358	loss_test: 1.4800	accuracy_train: 0.6739	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 1.2733	loss_val: 1.4578	loss_test: 1.4943	accuracy_train: 0.7200	accuracy_val: 0.3143	accuracy_test: 0.4000
[server]	loss_train: 1.2977	loss_val: 1.4339	loss_test: 1.5147	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.4138
[server]	loss_train: 1.2820	loss_val: 1.4169	loss_test: 1.5083	accuracy_train: 0.6222	accuracy_val: 0.4688	accuracy_test: 0.3333
[server]	loss_train: 1.3054	loss_val: 1.4632	loss_test: 1.4634	accuracy_train: 0.6508	accuracy_val: 0.2955	accuracy_test: 0.4138
[server]	loss_train: 1.2180	loss_val: 1.3902	loss_test: 1.4437	accuracy_train: 0.6552	accuracy_val: 0.4615	accuracy_test: 0.3571
curr_round: 27	curr_val_accuracy: 0.4149	curr_test_accuracy: 0.3949
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 28		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.2235	loss_val: 1.4341	loss_test: 1.3753	accuracy_train: 0.5417	accuracy_val: 0.4444	accuracy_test: 0.3478
[server]	loss_train: 1.3236	loss_val: 1.4182	loss_test: 1.4232	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.3750
[server]	loss_train: 1.3278	loss_val: 1.5195	loss_test: 1.4927	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.2671	loss_val: 1.4513	loss_test: 1.4021	accuracy_train: 0.6400	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.2778	loss_val: 1.4513	loss_test: 1.4289	accuracy_train: 0.5577	accuracy_val: 0.5405	accuracy_test: 0.5417
[server]	loss_train: 1.3378	loss_val: 1.3845	loss_test: 1.5056	accuracy_train: 0.5965	accuracy_val: 0.5000	accuracy_test: 0.3462
[server]	loss_train: 1.2224	loss_val: 1.3651	loss_test: 1.3930	accuracy_train: 0.5745	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.2651	loss_val: 1.4552	loss_test: 1.4966	accuracy_train: 0.7000	accuracy_val: 0.4444	accuracy_test: 0.3043
[server]	loss_train: 1.2754	loss_val: 1.3468	loss_test: 1.3477	accuracy_train: 0.6481	accuracy_val: 0.5263	accuracy_test: 0.5385
[server]	loss_train: 1.2707	loss_val: 1.3924	loss_test: 1.4136	accuracy_train: 0.5510	accuracy_val: 0.3429	accuracy_test: 0.2609
[server]	loss_train: 1.2783	loss_val: 1.4892	loss_test: 1.3617	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.3077
[server]	loss_train: 1.2794	loss_val: 1.5596	loss_test: 1.4666	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.3543	loss_val: 1.4383	loss_test: 1.4137	accuracy_train: 0.4792	accuracy_val: 0.4000	accuracy_test: 0.4167
[server]	loss_train: 1.3453	loss_val: 1.3914	loss_test: 1.4102	accuracy_train: 0.5238	accuracy_val: 0.4773	accuracy_test: 0.4286
[server]	loss_train: 1.2485	loss_val: 1.4280	loss_test: 1.4745	accuracy_train: 0.6739	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 1.2587	loss_val: 1.4516	loss_test: 1.4892	accuracy_train: 0.7600	accuracy_val: 0.3143	accuracy_test: 0.4000
[server]	loss_train: 1.2829	loss_val: 1.4251	loss_test: 1.5083	accuracy_train: 0.5645	accuracy_val: 0.5000	accuracy_test: 0.4138
[server]	loss_train: 1.2689	loss_val: 1.4122	loss_test: 1.5025	accuracy_train: 0.6222	accuracy_val: 0.4688	accuracy_test: 0.3810
[server]	loss_train: 1.2945	loss_val: 1.4586	loss_test: 1.4606	accuracy_train: 0.6508	accuracy_val: 0.3182	accuracy_test: 0.4138
[server]	loss_train: 1.2086	loss_val: 1.3886	loss_test: 1.4425	accuracy_train: 0.6552	accuracy_val: 0.4359	accuracy_test: 0.3571
curr_round: 28	curr_val_accuracy: 0.4121	curr_test_accuracy: 0.3990
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 29		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.2132	loss_val: 1.4333	loss_test: 1.3688	accuracy_train: 0.5417	accuracy_val: 0.4444	accuracy_test: 0.3913
[server]	loss_train: 1.3106	loss_val: 1.4112	loss_test: 1.4140	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.3333
[server]	loss_train: 1.3136	loss_val: 1.5147	loss_test: 1.4849	accuracy_train: 0.5660	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.2547	loss_val: 1.4449	loss_test: 1.3940	accuracy_train: 0.6400	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.2645	loss_val: 1.4440	loss_test: 1.4212	accuracy_train: 0.5577	accuracy_val: 0.5405	accuracy_test: 0.5417
[server]	loss_train: 1.3244	loss_val: 1.3740	loss_test: 1.4991	accuracy_train: 0.5789	accuracy_val: 0.5250	accuracy_test: 0.3462
[server]	loss_train: 1.2127	loss_val: 1.3606	loss_test: 1.3901	accuracy_train: 0.5745	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.2538	loss_val: 1.4534	loss_test: 1.4948	accuracy_train: 0.7000	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.2651	loss_val: 1.3412	loss_test: 1.3395	accuracy_train: 0.6481	accuracy_val: 0.5263	accuracy_test: 0.5385
[server]	loss_train: 1.2608	loss_val: 1.3885	loss_test: 1.4095	accuracy_train: 0.5714	accuracy_val: 0.3429	accuracy_test: 0.3043
[server]	loss_train: 1.2670	loss_val: 1.4867	loss_test: 1.3526	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.3077
[server]	loss_train: 1.2685	loss_val: 1.5608	loss_test: 1.4625	accuracy_train: 0.6512	accuracy_val: 0.2258	accuracy_test: 0.3000
[server]	loss_train: 1.3400	loss_val: 1.4303	loss_test: 1.4033	accuracy_train: 0.4792	accuracy_val: 0.4571	accuracy_test: 0.4167
[server]	loss_train: 1.3374	loss_val: 1.3844	loss_test: 1.4071	accuracy_train: 0.5238	accuracy_val: 0.4773	accuracy_test: 0.3571
[server]	loss_train: 1.2349	loss_val: 1.4206	loss_test: 1.4692	accuracy_train: 0.6739	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 1.2446	loss_val: 1.4457	loss_test: 1.4847	accuracy_train: 0.7200	accuracy_val: 0.3143	accuracy_test: 0.4000
[server]	loss_train: 1.2685	loss_val: 1.4168	loss_test: 1.5021	accuracy_train: 0.5484	accuracy_val: 0.5000	accuracy_test: 0.4138
[server]	loss_train: 1.2563	loss_val: 1.4081	loss_test: 1.4970	accuracy_train: 0.6444	accuracy_val: 0.4688	accuracy_test: 0.3810
[server]	loss_train: 1.2840	loss_val: 1.4543	loss_test: 1.4579	accuracy_train: 0.6190	accuracy_val: 0.2955	accuracy_test: 0.4138
[server]	loss_train: 1.1999	loss_val: 1.3873	loss_test: 1.4416	accuracy_train: 0.6552	accuracy_val: 0.4615	accuracy_test: 0.3571
curr_round: 29	curr_val_accuracy: 0.4135	curr_test_accuracy: 0.3968
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 30		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.2032	loss_val: 1.4326	loss_test: 1.3625	accuracy_train: 0.5417	accuracy_val: 0.4444	accuracy_test: 0.3913
[server]	loss_train: 1.2982	loss_val: 1.4044	loss_test: 1.4052	accuracy_train: 0.6078	accuracy_val: 0.4167	accuracy_test: 0.3750
[server]	loss_train: 1.2999	loss_val: 1.5102	loss_test: 1.4775	accuracy_train: 0.5660	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.2428	loss_val: 1.4387	loss_test: 1.3860	accuracy_train: 0.6400	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.2517	loss_val: 1.4371	loss_test: 1.4138	accuracy_train: 0.5577	accuracy_val: 0.5135	accuracy_test: 0.5417
[server]	loss_train: 1.3114	loss_val: 1.3637	loss_test: 1.4930	accuracy_train: 0.5789	accuracy_val: 0.5250	accuracy_test: 0.3462
[server]	loss_train: 1.2034	loss_val: 1.3566	loss_test: 1.3874	accuracy_train: 0.5745	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.2430	loss_val: 1.4520	loss_test: 1.4930	accuracy_train: 0.7000	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.2553	loss_val: 1.3362	loss_test: 1.3317	accuracy_train: 0.6481	accuracy_val: 0.5263	accuracy_test: 0.5385
[server]	loss_train: 1.2514	loss_val: 1.3848	loss_test: 1.4056	accuracy_train: 0.5714	accuracy_val: 0.3429	accuracy_test: 0.3043
[server]	loss_train: 1.2564	loss_val: 1.4849	loss_test: 1.3438	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.2692
[server]	loss_train: 1.2579	loss_val: 1.5621	loss_test: 1.4584	accuracy_train: 0.6744	accuracy_val: 0.2258	accuracy_test: 0.3000
[server]	loss_train: 1.3262	loss_val: 1.4226	loss_test: 1.3933	accuracy_train: 0.5000	accuracy_val: 0.4571	accuracy_test: 0.4167
[server]	loss_train: 1.3299	loss_val: 1.3777	loss_test: 1.4044	accuracy_train: 0.5397	accuracy_val: 0.4545	accuracy_test: 0.3571
[server]	loss_train: 1.2218	loss_val: 1.4137	loss_test: 1.4642	accuracy_train: 0.6739	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.2310	loss_val: 1.4402	loss_test: 1.4806	accuracy_train: 0.7200	accuracy_val: 0.2857	accuracy_test: 0.4000
[server]	loss_train: 1.2549	loss_val: 1.4091	loss_test: 1.4963	accuracy_train: 0.5484	accuracy_val: 0.5000	accuracy_test: 0.4138
[server]	loss_train: 1.2443	loss_val: 1.4045	loss_test: 1.4919	accuracy_train: 0.6444	accuracy_val: 0.4688	accuracy_test: 0.3810
[server]	loss_train: 1.2739	loss_val: 1.4502	loss_test: 1.4555	accuracy_train: 0.6190	accuracy_val: 0.2955	accuracy_test: 0.3793
[server]	loss_train: 1.1917	loss_val: 1.3864	loss_test: 1.4411	accuracy_train: 0.6552	accuracy_val: 0.4359	accuracy_test: 0.3571
curr_round: 30	curr_val_accuracy: 0.4067	curr_test_accuracy: 0.3947
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 31		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1938	loss_val: 1.4322	loss_test: 1.3567	accuracy_train: 0.5417	accuracy_val: 0.4444	accuracy_test: 0.4348
[server]	loss_train: 1.2863	loss_val: 1.3981	loss_test: 1.3970	accuracy_train: 0.6078	accuracy_val: 0.4167	accuracy_test: 0.3750
[server]	loss_train: 1.2867	loss_val: 1.5058	loss_test: 1.4706	accuracy_train: 0.5660	accuracy_val: 0.2308	accuracy_test: 0.4400
[server]	loss_train: 1.2314	loss_val: 1.4327	loss_test: 1.3783	accuracy_train: 0.6400	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.2393	loss_val: 1.4306	loss_test: 1.4067	accuracy_train: 0.5577	accuracy_val: 0.5676	accuracy_test: 0.5417
[server]	loss_train: 1.2987	loss_val: 1.3537	loss_test: 1.4873	accuracy_train: 0.5789	accuracy_val: 0.5000	accuracy_test: 0.3077
[server]	loss_train: 1.1945	loss_val: 1.3531	loss_test: 1.3851	accuracy_train: 0.5745	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.2327	loss_val: 1.4509	loss_test: 1.4913	accuracy_train: 0.7000	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.2462	loss_val: 1.3316	loss_test: 1.3245	accuracy_train: 0.6667	accuracy_val: 0.5263	accuracy_test: 0.5385
[server]	loss_train: 1.2426	loss_val: 1.3813	loss_test: 1.4018	accuracy_train: 0.5714	accuracy_val: 0.3429	accuracy_test: 0.3478
[server]	loss_train: 1.2465	loss_val: 1.4836	loss_test: 1.3355	accuracy_train: 0.5789	accuracy_val: 0.2821	accuracy_test: 0.2692
[server]	loss_train: 1.2478	loss_val: 1.5635	loss_test: 1.4545	accuracy_train: 0.6512	accuracy_val: 0.2258	accuracy_test: 0.3000
[server]	loss_train: 1.3131	loss_val: 1.4151	loss_test: 1.3838	accuracy_train: 0.5208	accuracy_val: 0.4286	accuracy_test: 0.4167
[server]	loss_train: 1.3228	loss_val: 1.3714	loss_test: 1.4020	accuracy_train: 0.5238	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 1.2091	loss_val: 1.4073	loss_test: 1.4594	accuracy_train: 0.6957	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.2178	loss_val: 1.4352	loss_test: 1.4771	accuracy_train: 0.7200	accuracy_val: 0.3143	accuracy_test: 0.4000
[server]	loss_train: 1.2419	loss_val: 1.4020	loss_test: 1.4908	accuracy_train: 0.5484	accuracy_val: 0.4773	accuracy_test: 0.4138
[server]	loss_train: 1.2328	loss_val: 1.4014	loss_test: 1.4872	accuracy_train: 0.6667	accuracy_val: 0.4062	accuracy_test: 0.3810
[server]	loss_train: 1.2643	loss_val: 1.4464	loss_test: 1.4534	accuracy_train: 0.6032	accuracy_val: 0.3182	accuracy_test: 0.3793
[server]	loss_train: 1.1841	loss_val: 1.3859	loss_test: 1.4409	accuracy_train: 0.6552	accuracy_val: 0.4359	accuracy_test: 0.3571
curr_round: 31	curr_val_accuracy: 0.4027	curr_test_accuracy: 0.3925
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 32		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1847	loss_val: 1.4321	loss_test: 1.3512	accuracy_train: 0.5417	accuracy_val: 0.4167	accuracy_test: 0.4348
[server]	loss_train: 1.2752	loss_val: 1.3922	loss_test: 1.3893	accuracy_train: 0.6078	accuracy_val: 0.4167	accuracy_test: 0.3750
[server]	loss_train: 1.2741	loss_val: 1.5018	loss_test: 1.4642	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4400
[server]	loss_train: 1.2204	loss_val: 1.4269	loss_test: 1.3709	accuracy_train: 0.6200	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.2274	loss_val: 1.4247	loss_test: 1.4000	accuracy_train: 0.5577	accuracy_val: 0.5676	accuracy_test: 0.5417
[server]	loss_train: 1.2865	loss_val: 1.3441	loss_test: 1.4821	accuracy_train: 0.5789	accuracy_val: 0.5250	accuracy_test: 0.2692
[server]	loss_train: 1.1860	loss_val: 1.3501	loss_test: 1.3830	accuracy_train: 0.5745	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.2229	loss_val: 1.4502	loss_test: 1.4897	accuracy_train: 0.7000	accuracy_val: 0.4444	accuracy_test: 0.3043
[server]	loss_train: 1.2376	loss_val: 1.3275	loss_test: 1.3179	accuracy_train: 0.6667	accuracy_val: 0.5263	accuracy_test: 0.5385
[server]	loss_train: 1.2344	loss_val: 1.3781	loss_test: 1.3982	accuracy_train: 0.5714	accuracy_val: 0.3429	accuracy_test: 0.3478
[server]	loss_train: 1.2372	loss_val: 1.4828	loss_test: 1.3277	accuracy_train: 0.5789	accuracy_val: 0.3077	accuracy_test: 0.2692
[server]	loss_train: 1.2379	loss_val: 1.5649	loss_test: 1.4508	accuracy_train: 0.6744	accuracy_val: 0.2258	accuracy_test: 0.3000
[server]	loss_train: 1.3005	loss_val: 1.4078	loss_test: 1.3748	accuracy_train: 0.5000	accuracy_val: 0.4286	accuracy_test: 0.4167
[server]	loss_train: 1.3161	loss_val: 1.3653	loss_test: 1.4000	accuracy_train: 0.5238	accuracy_val: 0.4091	accuracy_test: 0.3214
[server]	loss_train: 1.1968	loss_val: 1.4013	loss_test: 1.4548	accuracy_train: 0.6957	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.2052	loss_val: 1.4306	loss_test: 1.4741	accuracy_train: 0.7200	accuracy_val: 0.3143	accuracy_test: 0.4400
[server]	loss_train: 1.2297	loss_val: 1.3955	loss_test: 1.4859	accuracy_train: 0.5484	accuracy_val: 0.4773	accuracy_test: 0.4138
[server]	loss_train: 1.2220	loss_val: 1.3989	loss_test: 1.4829	accuracy_train: 0.6444	accuracy_val: 0.4062	accuracy_test: 0.3810
[server]	loss_train: 1.2550	loss_val: 1.4429	loss_test: 1.4514	accuracy_train: 0.6190	accuracy_val: 0.3182	accuracy_test: 0.4138
[server]	loss_train: 1.1769	loss_val: 1.3855	loss_test: 1.4410	accuracy_train: 0.6552	accuracy_val: 0.4103	accuracy_test: 0.3571
curr_round: 32	curr_val_accuracy: 0.4027	curr_test_accuracy: 0.3945
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 33		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1760	loss_val: 1.4322	loss_test: 1.3462	accuracy_train: 0.5417	accuracy_val: 0.4167	accuracy_test: 0.3913
[server]	loss_train: 1.2647	loss_val: 1.3868	loss_test: 1.3822	accuracy_train: 0.6078	accuracy_val: 0.4444	accuracy_test: 0.4167
[server]	loss_train: 1.2621	loss_val: 1.4980	loss_test: 1.4584	accuracy_train: 0.5283	accuracy_val: 0.2564	accuracy_test: 0.4400
[server]	loss_train: 1.2098	loss_val: 1.4213	loss_test: 1.3637	accuracy_train: 0.6000	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.2160	loss_val: 1.4192	loss_test: 1.3937	accuracy_train: 0.5577	accuracy_val: 0.5676	accuracy_test: 0.5417
[server]	loss_train: 1.2749	loss_val: 1.3349	loss_test: 1.4775	accuracy_train: 0.5789	accuracy_val: 0.5250	accuracy_test: 0.2692
[server]	loss_train: 1.1779	loss_val: 1.3474	loss_test: 1.3812	accuracy_train: 0.5745	accuracy_val: 0.3636	accuracy_test: 0.3636
[server]	loss_train: 1.2137	loss_val: 1.4498	loss_test: 1.4881	accuracy_train: 0.6800	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.2295	loss_val: 1.3238	loss_test: 1.3117	accuracy_train: 0.6667	accuracy_val: 0.5263	accuracy_test: 0.5769
[server]	loss_train: 1.2266	loss_val: 1.3751	loss_test: 1.3946	accuracy_train: 0.5714	accuracy_val: 0.3143	accuracy_test: 0.3478
[server]	loss_train: 1.2286	loss_val: 1.4825	loss_test: 1.3204	accuracy_train: 0.5614	accuracy_val: 0.3077	accuracy_test: 0.2692
[server]	loss_train: 1.2285	loss_val: 1.5663	loss_test: 1.4472	accuracy_train: 0.6977	accuracy_val: 0.2258	accuracy_test: 0.3000
[server]	loss_train: 1.2886	loss_val: 1.4008	loss_test: 1.3662	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.4167
[server]	loss_train: 1.3097	loss_val: 1.3596	loss_test: 1.3983	accuracy_train: 0.5079	accuracy_val: 0.4091	accuracy_test: 0.3214
[server]	loss_train: 1.1850	loss_val: 1.3959	loss_test: 1.4504	accuracy_train: 0.6957	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.1932	loss_val: 1.4265	loss_test: 1.4718	accuracy_train: 0.7000	accuracy_val: 0.3143	accuracy_test: 0.4400
[server]	loss_train: 1.2183	loss_val: 1.3897	loss_test: 1.4814	accuracy_train: 0.5645	accuracy_val: 0.4773	accuracy_test: 0.4138
[server]	loss_train: 1.2118	loss_val: 1.3969	loss_test: 1.4790	accuracy_train: 0.6222	accuracy_val: 0.4062	accuracy_test: 0.3810
[server]	loss_train: 1.2461	loss_val: 1.4396	loss_test: 1.4497	accuracy_train: 0.6349	accuracy_val: 0.3182	accuracy_test: 0.3793
[server]	loss_train: 1.1702	loss_val: 1.3855	loss_test: 1.4412	accuracy_train: 0.6552	accuracy_val: 0.4103	accuracy_test: 0.3571
curr_round: 33	curr_val_accuracy: 0.3987	curr_test_accuracy: 0.3944
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 34		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1677	loss_val: 1.4325	loss_test: 1.3414	accuracy_train: 0.5208	accuracy_val: 0.4444	accuracy_test: 0.3913
[server]	loss_train: 1.2549	loss_val: 1.3818	loss_test: 1.3758	accuracy_train: 0.6078	accuracy_val: 0.4444	accuracy_test: 0.4167
[server]	loss_train: 1.2508	loss_val: 1.4944	loss_test: 1.4532	accuracy_train: 0.5283	accuracy_val: 0.2564	accuracy_test: 0.4400
[server]	loss_train: 1.1997	loss_val: 1.4160	loss_test: 1.3569	accuracy_train: 0.6200	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.2051	loss_val: 1.4143	loss_test: 1.3878	accuracy_train: 0.5577	accuracy_val: 0.5676	accuracy_test: 0.5417
[server]	loss_train: 1.2637	loss_val: 1.3262	loss_test: 1.4735	accuracy_train: 0.5789	accuracy_val: 0.5500	accuracy_test: 0.2692
[server]	loss_train: 1.1702	loss_val: 1.3451	loss_test: 1.3795	accuracy_train: 0.5745	accuracy_val: 0.3636	accuracy_test: 0.3636
[server]	loss_train: 1.2049	loss_val: 1.4497	loss_test: 1.4867	accuracy_train: 0.6800	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.2219	loss_val: 1.3206	loss_test: 1.3061	accuracy_train: 0.6667	accuracy_val: 0.5263	accuracy_test: 0.5769
[server]	loss_train: 1.2193	loss_val: 1.3723	loss_test: 1.3912	accuracy_train: 0.5714	accuracy_val: 0.3429	accuracy_test: 0.3478
[server]	loss_train: 1.2206	loss_val: 1.4826	loss_test: 1.3134	accuracy_train: 0.5614	accuracy_val: 0.3077	accuracy_test: 0.2692
[server]	loss_train: 1.2194	loss_val: 1.5678	loss_test: 1.4439	accuracy_train: 0.6977	accuracy_val: 0.2258	accuracy_test: 0.3000
[server]	loss_train: 1.2774	loss_val: 1.3940	loss_test: 1.3582	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.4167
[server]	loss_train: 1.3036	loss_val: 1.3542	loss_test: 1.3969	accuracy_train: 0.4921	accuracy_val: 0.4091	accuracy_test: 0.2500
[server]	loss_train: 1.1736	loss_val: 1.3910	loss_test: 1.4462	accuracy_train: 0.6957	accuracy_val: 0.4545	accuracy_test: 0.5000
[server]	loss_train: 1.1817	loss_val: 1.4228	loss_test: 1.4699	accuracy_train: 0.7000	accuracy_val: 0.3143	accuracy_test: 0.4000
[server]	loss_train: 1.2076	loss_val: 1.3845	loss_test: 1.4775	accuracy_train: 0.5645	accuracy_val: 0.4773	accuracy_test: 0.4138
[server]	loss_train: 1.2021	loss_val: 1.3954	loss_test: 1.4755	accuracy_train: 0.6222	accuracy_val: 0.4062	accuracy_test: 0.3810
[server]	loss_train: 1.2377	loss_val: 1.4366	loss_test: 1.4482	accuracy_train: 0.6508	accuracy_val: 0.3182	accuracy_test: 0.3793
[server]	loss_train: 1.1639	loss_val: 1.3857	loss_test: 1.4416	accuracy_train: 0.6552	accuracy_val: 0.3846	accuracy_test: 0.3214
curr_round: 34	curr_val_accuracy: 0.3999	curr_test_accuracy: 0.3863
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 35		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1598	loss_val: 1.4329	loss_test: 1.3369	accuracy_train: 0.5417	accuracy_val: 0.4444	accuracy_test: 0.4348
[server]	loss_train: 1.2457	loss_val: 1.3774	loss_test: 1.3699	accuracy_train: 0.6078	accuracy_val: 0.4444	accuracy_test: 0.4167
[server]	loss_train: 1.2400	loss_val: 1.4912	loss_test: 1.4484	accuracy_train: 0.5283	accuracy_val: 0.2564	accuracy_test: 0.4400
[server]	loss_train: 1.1901	loss_val: 1.4109	loss_test: 1.3503	accuracy_train: 0.6200	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.1948	loss_val: 1.4100	loss_test: 1.3824	accuracy_train: 0.5769	accuracy_val: 0.5405	accuracy_test: 0.5417
[server]	loss_train: 1.2530	loss_val: 1.3179	loss_test: 1.4701	accuracy_train: 0.5614	accuracy_val: 0.5500	accuracy_test: 0.2692
[server]	loss_train: 1.1627	loss_val: 1.3432	loss_test: 1.3781	accuracy_train: 0.5745	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.1966	loss_val: 1.4499	loss_test: 1.4855	accuracy_train: 0.6800	accuracy_val: 0.4167	accuracy_test: 0.3478
[server]	loss_train: 1.2147	loss_val: 1.3176	loss_test: 1.3009	accuracy_train: 0.6296	accuracy_val: 0.5263	accuracy_test: 0.5769
[server]	loss_train: 1.2125	loss_val: 1.3698	loss_test: 1.3880	accuracy_train: 0.5714	accuracy_val: 0.3143	accuracy_test: 0.3478
[server]	loss_train: 1.2132	loss_val: 1.4832	loss_test: 1.3069	accuracy_train: 0.5789	accuracy_val: 0.2821	accuracy_test: 0.3462
[server]	loss_train: 1.2107	loss_val: 1.5694	loss_test: 1.4410	accuracy_train: 0.6977	accuracy_val: 0.2258	accuracy_test: 0.2500
[server]	loss_train: 1.2669	loss_val: 1.3874	loss_test: 1.3506	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.4167
[server]	loss_train: 1.2979	loss_val: 1.3491	loss_test: 1.3956	accuracy_train: 0.4762	accuracy_val: 0.4091	accuracy_test: 0.2500
[server]	loss_train: 1.1627	loss_val: 1.3866	loss_test: 1.4421	accuracy_train: 0.6957	accuracy_val: 0.4545	accuracy_test: 0.4545
[server]	loss_train: 1.1708	loss_val: 1.4196	loss_test: 1.4686	accuracy_train: 0.6800	accuracy_val: 0.3143	accuracy_test: 0.4000
[server]	loss_train: 1.1977	loss_val: 1.3799	loss_test: 1.4740	accuracy_train: 0.5645	accuracy_val: 0.4773	accuracy_test: 0.4138
[server]	loss_train: 1.1930	loss_val: 1.3945	loss_test: 1.4724	accuracy_train: 0.6222	accuracy_val: 0.4062	accuracy_test: 0.3810
[server]	loss_train: 1.2297	loss_val: 1.4338	loss_test: 1.4469	accuracy_train: 0.6508	accuracy_val: 0.3182	accuracy_test: 0.3793
[server]	loss_train: 1.1579	loss_val: 1.3860	loss_test: 1.4420	accuracy_train: 0.6552	accuracy_val: 0.3846	accuracy_test: 0.3214
curr_round: 35	curr_val_accuracy: 0.3972	curr_test_accuracy: 0.3904
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 36		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1522	loss_val: 1.4335	loss_test: 1.3328	accuracy_train: 0.5417	accuracy_val: 0.4444	accuracy_test: 0.4348
[server]	loss_train: 1.2372	loss_val: 1.3735	loss_test: 1.3647	accuracy_train: 0.6078	accuracy_val: 0.4444	accuracy_test: 0.4167
[server]	loss_train: 1.2297	loss_val: 1.4882	loss_test: 1.4441	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4400
[server]	loss_train: 1.1809	loss_val: 1.4060	loss_test: 1.3441	accuracy_train: 0.6200	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.1849	loss_val: 1.4062	loss_test: 1.3774	accuracy_train: 0.5769	accuracy_val: 0.5405	accuracy_test: 0.5000
[server]	loss_train: 1.2429	loss_val: 1.3102	loss_test: 1.4672	accuracy_train: 0.5614	accuracy_val: 0.5500	accuracy_test: 0.2692
[server]	loss_train: 1.1555	loss_val: 1.3416	loss_test: 1.3768	accuracy_train: 0.5745	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.1887	loss_val: 1.4503	loss_test: 1.4843	accuracy_train: 0.6800	accuracy_val: 0.4167	accuracy_test: 0.3478
[server]	loss_train: 1.2079	loss_val: 1.3150	loss_test: 1.2960	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.5385
[server]	loss_train: 1.2060	loss_val: 1.3674	loss_test: 1.3848	accuracy_train: 0.5714	accuracy_val: 0.3143	accuracy_test: 0.3478
[server]	loss_train: 1.2063	loss_val: 1.4841	loss_test: 1.3007	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.3846
[server]	loss_train: 1.2024	loss_val: 1.5710	loss_test: 1.4383	accuracy_train: 0.6977	accuracy_val: 0.2258	accuracy_test: 0.2500
[server]	loss_train: 1.2569	loss_val: 1.3812	loss_test: 1.3435	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.4167
[server]	loss_train: 1.2925	loss_val: 1.3443	loss_test: 1.3946	accuracy_train: 0.4762	accuracy_val: 0.4091	accuracy_test: 0.2500
[server]	loss_train: 1.1522	loss_val: 1.3827	loss_test: 1.4381	accuracy_train: 0.6957	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.1603	loss_val: 1.4167	loss_test: 1.4678	accuracy_train: 0.6600	accuracy_val: 0.3143	accuracy_test: 0.4000
[server]	loss_train: 1.1884	loss_val: 1.3758	loss_test: 1.4711	accuracy_train: 0.5645	accuracy_val: 0.4773	accuracy_test: 0.4138
[server]	loss_train: 1.1845	loss_val: 1.3939	loss_test: 1.4697	accuracy_train: 0.6222	accuracy_val: 0.4062	accuracy_test: 0.3810
[server]	loss_train: 1.2222	loss_val: 1.4313	loss_test: 1.4457	accuracy_train: 0.6508	accuracy_val: 0.3182	accuracy_test: 0.3793
[server]	loss_train: 1.1523	loss_val: 1.3865	loss_test: 1.4426	accuracy_train: 0.6379	accuracy_val: 0.3846	accuracy_test: 0.2857
curr_round: 36	curr_val_accuracy: 0.3986	curr_test_accuracy: 0.3885
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 37		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1450	loss_val: 1.4342	loss_test: 1.3290	accuracy_train: 0.5625	accuracy_val: 0.4444	accuracy_test: 0.4348
[server]	loss_train: 1.2293	loss_val: 1.3701	loss_test: 1.3599	accuracy_train: 0.5882	accuracy_val: 0.4444	accuracy_test: 0.4167
[server]	loss_train: 1.2201	loss_val: 1.4854	loss_test: 1.4403	accuracy_train: 0.5849	accuracy_val: 0.2564	accuracy_test: 0.4400
[server]	loss_train: 1.1721	loss_val: 1.4014	loss_test: 1.3383	accuracy_train: 0.6200	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.1755	loss_val: 1.4029	loss_test: 1.3729	accuracy_train: 0.5962	accuracy_val: 0.5405	accuracy_test: 0.5000
[server]	loss_train: 1.2333	loss_val: 1.3029	loss_test: 1.4649	accuracy_train: 0.5789	accuracy_val: 0.5500	accuracy_test: 0.2692
[server]	loss_train: 1.1487	loss_val: 1.3404	loss_test: 1.3758	accuracy_train: 0.5745	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.1812	loss_val: 1.4508	loss_test: 1.4833	accuracy_train: 0.7000	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.2014	loss_val: 1.3127	loss_test: 1.2916	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.5385
[server]	loss_train: 1.1999	loss_val: 1.3652	loss_test: 1.3819	accuracy_train: 0.5510	accuracy_val: 0.3714	accuracy_test: 0.3478
[server]	loss_train: 1.1999	loss_val: 1.4853	loss_test: 1.2949	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.3846
[server]	loss_train: 1.1945	loss_val: 1.5726	loss_test: 1.4359	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.2476	loss_val: 1.3752	loss_test: 1.3369	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.4167
[server]	loss_train: 1.2873	loss_val: 1.3398	loss_test: 1.3938	accuracy_train: 0.4762	accuracy_val: 0.4318	accuracy_test: 0.2500
[server]	loss_train: 1.1421	loss_val: 1.3792	loss_test: 1.4343	accuracy_train: 0.6957	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.1504	loss_val: 1.4142	loss_test: 1.4674	accuracy_train: 0.6600	accuracy_val: 0.3143	accuracy_test: 0.4000
[server]	loss_train: 1.1799	loss_val: 1.3722	loss_test: 1.4686	accuracy_train: 0.5806	accuracy_val: 0.5000	accuracy_test: 0.4138
[server]	loss_train: 1.1764	loss_val: 1.3937	loss_test: 1.4674	accuracy_train: 0.6000	accuracy_val: 0.4375	accuracy_test: 0.3810
[server]	loss_train: 1.2150	loss_val: 1.4290	loss_test: 1.4447	accuracy_train: 0.6667	accuracy_val: 0.3182	accuracy_test: 0.4138
[server]	loss_train: 1.1469	loss_val: 1.3872	loss_test: 1.4432	accuracy_train: 0.6379	accuracy_val: 0.3846	accuracy_test: 0.2857
curr_round: 37	curr_val_accuracy: 0.4053	curr_test_accuracy: 0.3885
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 38		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1381	loss_val: 1.4351	loss_test: 1.3255	accuracy_train: 0.5625	accuracy_val: 0.4444	accuracy_test: 0.4348
[server]	loss_train: 1.2219	loss_val: 1.3672	loss_test: 1.3557	accuracy_train: 0.5882	accuracy_val: 0.4444	accuracy_test: 0.4167
[server]	loss_train: 1.2109	loss_val: 1.4829	loss_test: 1.4369	accuracy_train: 0.6038	accuracy_val: 0.2564	accuracy_test: 0.4400
[server]	loss_train: 1.1638	loss_val: 1.3970	loss_test: 1.3328	accuracy_train: 0.6200	accuracy_val: 0.3235	accuracy_test: 0.4783
[server]	loss_train: 1.1667	loss_val: 1.4001	loss_test: 1.3687	accuracy_train: 0.6154	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.2242	loss_val: 1.2962	loss_test: 1.4630	accuracy_train: 0.5789	accuracy_val: 0.5500	accuracy_test: 0.2692
[server]	loss_train: 1.1421	loss_val: 1.3394	loss_test: 1.3749	accuracy_train: 0.5745	accuracy_val: 0.3333	accuracy_test: 0.3636
[server]	loss_train: 1.1741	loss_val: 1.4516	loss_test: 1.4823	accuracy_train: 0.7000	accuracy_val: 0.3889	accuracy_test: 0.2609
[server]	loss_train: 1.1953	loss_val: 1.3107	loss_test: 1.2874	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.5385
[server]	loss_train: 1.1941	loss_val: 1.3633	loss_test: 1.3791	accuracy_train: 0.5510	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1939	loss_val: 1.4868	loss_test: 1.2895	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.3846
[server]	loss_train: 1.1869	loss_val: 1.5743	loss_test: 1.4339	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.2389	loss_val: 1.3695	loss_test: 1.3307	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.4167
[server]	loss_train: 1.2824	loss_val: 1.3355	loss_test: 1.3931	accuracy_train: 0.4603	accuracy_val: 0.4318	accuracy_test: 0.2500
[server]	loss_train: 1.1324	loss_val: 1.3762	loss_test: 1.4306	accuracy_train: 0.6957	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 1.1410	loss_val: 1.4121	loss_test: 1.4673	accuracy_train: 0.6600	accuracy_val: 0.3143	accuracy_test: 0.4000
[server]	loss_train: 1.1720	loss_val: 1.3691	loss_test: 1.4666	accuracy_train: 0.5806	accuracy_val: 0.5000	accuracy_test: 0.3448
[server]	loss_train: 1.1688	loss_val: 1.3938	loss_test: 1.4655	accuracy_train: 0.6000	accuracy_val: 0.4375	accuracy_test: 0.3810
[server]	loss_train: 1.2082	loss_val: 1.4270	loss_test: 1.4439	accuracy_train: 0.6667	accuracy_val: 0.3182	accuracy_test: 0.4138
[server]	loss_train: 1.1418	loss_val: 1.3879	loss_test: 1.4438	accuracy_train: 0.6379	accuracy_val: 0.3846	accuracy_test: 0.2857
curr_round: 38	curr_val_accuracy: 0.4025	curr_test_accuracy: 0.3782
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 39		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1315	loss_val: 1.4360	loss_test: 1.3223	accuracy_train: 0.5625	accuracy_val: 0.4444	accuracy_test: 0.4348
[server]	loss_train: 1.2150	loss_val: 1.3648	loss_test: 1.3520	accuracy_train: 0.5882	accuracy_val: 0.4444	accuracy_test: 0.4167
[server]	loss_train: 1.2023	loss_val: 1.4806	loss_test: 1.4339	accuracy_train: 0.6038	accuracy_val: 0.2564	accuracy_test: 0.4400
[server]	loss_train: 1.1558	loss_val: 1.3928	loss_test: 1.3275	accuracy_train: 0.6200	accuracy_val: 0.3235	accuracy_test: 0.4783
[server]	loss_train: 1.1583	loss_val: 1.3978	loss_test: 1.3650	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.2156	loss_val: 1.2899	loss_test: 1.4616	accuracy_train: 0.5789	accuracy_val: 0.5500	accuracy_test: 0.2692
[server]	loss_train: 1.1357	loss_val: 1.3387	loss_test: 1.3742	accuracy_train: 0.5745	accuracy_val: 0.3333	accuracy_test: 0.3636
[server]	loss_train: 1.1673	loss_val: 1.4525	loss_test: 1.4814	accuracy_train: 0.7000	accuracy_val: 0.3889	accuracy_test: 0.2609
[server]	loss_train: 1.1894	loss_val: 1.3089	loss_test: 1.2836	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.5385
[server]	loss_train: 1.1886	loss_val: 1.3614	loss_test: 1.3764	accuracy_train: 0.5510	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1884	loss_val: 1.4884	loss_test: 1.2843	accuracy_train: 0.5965	accuracy_val: 0.2821	accuracy_test: 0.3846
[server]	loss_train: 1.1796	loss_val: 1.5760	loss_test: 1.4321	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.2307	loss_val: 1.3641	loss_test: 1.3250	accuracy_train: 0.4792	accuracy_val: 0.4000	accuracy_test: 0.4167
[server]	loss_train: 1.2777	loss_val: 1.3315	loss_test: 1.3925	accuracy_train: 0.4603	accuracy_val: 0.4318	accuracy_test: 0.2500
[server]	loss_train: 1.1231	loss_val: 1.3736	loss_test: 1.4270	accuracy_train: 0.6957	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 1.1320	loss_val: 1.4102	loss_test: 1.4677	accuracy_train: 0.6600	accuracy_val: 0.3143	accuracy_test: 0.4000
[server]	loss_train: 1.1646	loss_val: 1.3664	loss_test: 1.4650	accuracy_train: 0.5806	accuracy_val: 0.5000	accuracy_test: 0.3448
[server]	loss_train: 1.1617	loss_val: 1.3942	loss_test: 1.4639	accuracy_train: 0.6000	accuracy_val: 0.4062	accuracy_test: 0.3810
[server]	loss_train: 1.2017	loss_val: 1.4252	loss_test: 1.4433	accuracy_train: 0.6667	accuracy_val: 0.3182	accuracy_test: 0.4138
[server]	loss_train: 1.1370	loss_val: 1.3888	loss_test: 1.4445	accuracy_train: 0.6379	accuracy_val: 0.3846	accuracy_test: 0.2857
curr_round: 39	curr_val_accuracy: 0.3998	curr_test_accuracy: 0.3782
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 40		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1252	loss_val: 1.4371	loss_test: 1.3193	accuracy_train: 0.5625	accuracy_val: 0.4444	accuracy_test: 0.4348
[server]	loss_train: 1.2087	loss_val: 1.3627	loss_test: 1.3487	accuracy_train: 0.5882	accuracy_val: 0.4444	accuracy_test: 0.4167
[server]	loss_train: 1.1941	loss_val: 1.4785	loss_test: 1.4313	accuracy_train: 0.6038	accuracy_val: 0.2564	accuracy_test: 0.4400
[server]	loss_train: 1.1482	loss_val: 1.3889	loss_test: 1.3226	accuracy_train: 0.6200	accuracy_val: 0.3235	accuracy_test: 0.4783
[server]	loss_train: 1.1504	loss_val: 1.3959	loss_test: 1.3616	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.2074	loss_val: 1.2841	loss_test: 1.4606	accuracy_train: 0.5789	accuracy_val: 0.5500	accuracy_test: 0.2692
[server]	loss_train: 1.1296	loss_val: 1.3382	loss_test: 1.3736	accuracy_train: 0.5957	accuracy_val: 0.3333	accuracy_test: 0.3636
[server]	loss_train: 1.1609	loss_val: 1.4536	loss_test: 1.4807	accuracy_train: 0.7000	accuracy_val: 0.3889	accuracy_test: 0.2609
[server]	loss_train: 1.1838	loss_val: 1.3073	loss_test: 1.2801	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.5385
[server]	loss_train: 1.1834	loss_val: 1.3597	loss_test: 1.3740	accuracy_train: 0.5510	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1832	loss_val: 1.4903	loss_test: 1.2794	accuracy_train: 0.5965	accuracy_val: 0.2821	accuracy_test: 0.3846
[server]	loss_train: 1.1726	loss_val: 1.5778	loss_test: 1.4307	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.2230	loss_val: 1.3589	loss_test: 1.3196	accuracy_train: 0.4792	accuracy_val: 0.4000	accuracy_test: 0.4167
[server]	loss_train: 1.2733	loss_val: 1.3277	loss_test: 1.3920	accuracy_train: 0.4603	accuracy_val: 0.4545	accuracy_test: 0.2500
[server]	loss_train: 1.1142	loss_val: 1.3713	loss_test: 1.4235	accuracy_train: 0.7174	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 1.1235	loss_val: 1.4087	loss_test: 1.4683	accuracy_train: 0.6600	accuracy_val: 0.3143	accuracy_test: 0.4000
[server]	loss_train: 1.1577	loss_val: 1.3640	loss_test: 1.4637	accuracy_train: 0.5645	accuracy_val: 0.5000	accuracy_test: 0.3448
[server]	loss_train: 1.1550	loss_val: 1.3948	loss_test: 1.4626	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1956	loss_val: 1.4236	loss_test: 1.4427	accuracy_train: 0.6667	accuracy_val: 0.3182	accuracy_test: 0.4138
[server]	loss_train: 1.1324	loss_val: 1.3897	loss_test: 1.4451	accuracy_train: 0.6379	accuracy_val: 0.3846	accuracy_test: 0.2857
curr_round: 40	curr_val_accuracy: 0.3998	curr_test_accuracy: 0.3782
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 41		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1191	loss_val: 1.4382	loss_test: 1.3165	accuracy_train: 0.5625	accuracy_val: 0.4444	accuracy_test: 0.4348
[server]	loss_train: 1.2027	loss_val: 1.3611	loss_test: 1.3457	accuracy_train: 0.5882	accuracy_val: 0.4444	accuracy_test: 0.4167
[server]	loss_train: 1.1863	loss_val: 1.4767	loss_test: 1.4289	accuracy_train: 0.6038	accuracy_val: 0.2564	accuracy_test: 0.4400
[server]	loss_train: 1.1411	loss_val: 1.3852	loss_test: 1.3179	accuracy_train: 0.6200	accuracy_val: 0.3235	accuracy_test: 0.4783
[server]	loss_train: 1.1428	loss_val: 1.3945	loss_test: 1.3583	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1997	loss_val: 1.2787	loss_test: 1.4599	accuracy_train: 0.5789	accuracy_val: 0.5500	accuracy_test: 0.2692
[server]	loss_train: 1.1236	loss_val: 1.3379	loss_test: 1.3731	accuracy_train: 0.5745	accuracy_val: 0.3333	accuracy_test: 0.3636
[server]	loss_train: 1.1547	loss_val: 1.4548	loss_test: 1.4799	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.2609
[server]	loss_train: 1.1784	loss_val: 1.3058	loss_test: 1.2768	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.5385
[server]	loss_train: 1.1784	loss_val: 1.3581	loss_test: 1.3717	accuracy_train: 0.5510	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1784	loss_val: 1.4923	loss_test: 1.2748	accuracy_train: 0.5965	accuracy_val: 0.2821	accuracy_test: 0.3846
[server]	loss_train: 1.1660	loss_val: 1.5795	loss_test: 1.4296	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.2158	loss_val: 1.3540	loss_test: 1.3146	accuracy_train: 0.4792	accuracy_val: 0.4286	accuracy_test: 0.4167
[server]	loss_train: 1.2691	loss_val: 1.3241	loss_test: 1.3916	accuracy_train: 0.4762	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.1056	loss_val: 1.3693	loss_test: 1.4201	accuracy_train: 0.7174	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 1.1154	loss_val: 1.4074	loss_test: 1.4692	accuracy_train: 0.6400	accuracy_val: 0.3143	accuracy_test: 0.4000
[server]	loss_train: 1.1513	loss_val: 1.3620	loss_test: 1.4628	accuracy_train: 0.5645	accuracy_val: 0.5000	accuracy_test: 0.3448
[server]	loss_train: 1.1486	loss_val: 1.3955	loss_test: 1.4616	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1899	loss_val: 1.4221	loss_test: 1.4423	accuracy_train: 0.6349	accuracy_val: 0.3182	accuracy_test: 0.4138
[server]	loss_train: 1.1280	loss_val: 1.3907	loss_test: 1.4457	accuracy_train: 0.6379	accuracy_val: 0.3846	accuracy_test: 0.2857
curr_round: 41	curr_val_accuracy: 0.4025	curr_test_accuracy: 0.3782
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 42		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1133	loss_val: 1.4393	loss_test: 1.3140	accuracy_train: 0.5625	accuracy_val: 0.4444	accuracy_test: 0.4348
[server]	loss_train: 1.1972	loss_val: 1.3598	loss_test: 1.3432	accuracy_train: 0.5882	accuracy_val: 0.4444	accuracy_test: 0.4167
[server]	loss_train: 1.1790	loss_val: 1.4750	loss_test: 1.4269	accuracy_train: 0.6038	accuracy_val: 0.2308	accuracy_test: 0.4400
[server]	loss_train: 1.1342	loss_val: 1.3817	loss_test: 1.3135	accuracy_train: 0.6200	accuracy_val: 0.3235	accuracy_test: 0.4783
[server]	loss_train: 1.1356	loss_val: 1.3934	loss_test: 1.3553	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1924	loss_val: 1.2738	loss_test: 1.4595	accuracy_train: 0.5789	accuracy_val: 0.5500	accuracy_test: 0.2692
[server]	loss_train: 1.1179	loss_val: 1.3377	loss_test: 1.3727	accuracy_train: 0.5745	accuracy_val: 0.3333	accuracy_test: 0.3182
[server]	loss_train: 1.1489	loss_val: 1.4560	loss_test: 1.4792	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.2609
[server]	loss_train: 1.1732	loss_val: 1.3045	loss_test: 1.2736	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.5385
[server]	loss_train: 1.1737	loss_val: 1.3567	loss_test: 1.3696	accuracy_train: 0.5510	accuracy_val: 0.3429	accuracy_test: 0.3043
[server]	loss_train: 1.1738	loss_val: 1.4945	loss_test: 1.2704	accuracy_train: 0.5965	accuracy_val: 0.2821	accuracy_test: 0.3846
[server]	loss_train: 1.1597	loss_val: 1.5813	loss_test: 1.4289	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.2090	loss_val: 1.3494	loss_test: 1.3099	accuracy_train: 0.4792	accuracy_val: 0.4286	accuracy_test: 0.4167
[server]	loss_train: 1.2650	loss_val: 1.3206	loss_test: 1.3914	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0974	loss_val: 1.3677	loss_test: 1.4169	accuracy_train: 0.7174	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 1.1077	loss_val: 1.4062	loss_test: 1.4704	accuracy_train: 0.6400	accuracy_val: 0.3143	accuracy_test: 0.3200
[server]	loss_train: 1.1454	loss_val: 1.3602	loss_test: 1.4621	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.1426	loss_val: 1.3963	loss_test: 1.4608	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1844	loss_val: 1.4208	loss_test: 1.4420	accuracy_train: 0.6508	accuracy_val: 0.3182	accuracy_test: 0.4138
[server]	loss_train: 1.1238	loss_val: 1.3918	loss_test: 1.4465	accuracy_train: 0.6379	accuracy_val: 0.3846	accuracy_test: 0.3214
curr_round: 42	curr_val_accuracy: 0.4012	curr_test_accuracy: 0.3742
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 43		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1077	loss_val: 1.4405	loss_test: 1.3116	accuracy_train: 0.5417	accuracy_val: 0.4444	accuracy_test: 0.4348
[server]	loss_train: 1.1920	loss_val: 1.3588	loss_test: 1.3409	accuracy_train: 0.5882	accuracy_val: 0.4444	accuracy_test: 0.4167
[server]	loss_train: 1.1720	loss_val: 1.4734	loss_test: 1.4250	accuracy_train: 0.5849	accuracy_val: 0.2308	accuracy_test: 0.4400
[server]	loss_train: 1.1277	loss_val: 1.3784	loss_test: 1.3095	accuracy_train: 0.6200	accuracy_val: 0.3235	accuracy_test: 0.4783
[server]	loss_train: 1.1288	loss_val: 1.3926	loss_test: 1.3525	accuracy_train: 0.6154	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1855	loss_val: 1.2692	loss_test: 1.4594	accuracy_train: 0.5789	accuracy_val: 0.5750	accuracy_test: 0.2692
[server]	loss_train: 1.1124	loss_val: 1.3377	loss_test: 1.3725	accuracy_train: 0.5957	accuracy_val: 0.3939	accuracy_test: 0.3182
[server]	loss_train: 1.1433	loss_val: 1.4573	loss_test: 1.4786	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.2609
[server]	loss_train: 1.1682	loss_val: 1.3033	loss_test: 1.2707	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.5385
[server]	loss_train: 1.1692	loss_val: 1.3554	loss_test: 1.3677	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1695	loss_val: 1.4967	loss_test: 1.2662	accuracy_train: 0.5965	accuracy_val: 0.2821	accuracy_test: 0.4231
[server]	loss_train: 1.1538	loss_val: 1.5831	loss_test: 1.4283	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.2500
[server]	loss_train: 1.2026	loss_val: 1.3451	loss_test: 1.3056	accuracy_train: 0.4792	accuracy_val: 0.4286	accuracy_test: 0.4167
[server]	loss_train: 1.2610	loss_val: 1.3173	loss_test: 1.3913	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0895	loss_val: 1.3663	loss_test: 1.4137	accuracy_train: 0.6957	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 1.1004	loss_val: 1.4053	loss_test: 1.4717	accuracy_train: 0.6400	accuracy_val: 0.3143	accuracy_test: 0.2800
[server]	loss_train: 1.1398	loss_val: 1.3586	loss_test: 1.4617	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.1370	loss_val: 1.3973	loss_test: 1.4602	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1793	loss_val: 1.4197	loss_test: 1.4418	accuracy_train: 0.6508	accuracy_val: 0.3182	accuracy_test: 0.3793
[server]	loss_train: 1.1198	loss_val: 1.3929	loss_test: 1.4472	accuracy_train: 0.6379	accuracy_val: 0.3846	accuracy_test: 0.3214
curr_round: 43	curr_val_accuracy: 0.4066	curr_test_accuracy: 0.3723
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 44		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1023	loss_val: 1.4417	loss_test: 1.3093	accuracy_train: 0.5625	accuracy_val: 0.4444	accuracy_test: 0.4348
[server]	loss_train: 1.1872	loss_val: 1.3581	loss_test: 1.3389	accuracy_train: 0.5882	accuracy_val: 0.4444	accuracy_test: 0.4167
[server]	loss_train: 1.1654	loss_val: 1.4721	loss_test: 1.4235	accuracy_train: 0.5849	accuracy_val: 0.2051	accuracy_test: 0.4400
[server]	loss_train: 1.1216	loss_val: 1.3754	loss_test: 1.3056	accuracy_train: 0.6200	accuracy_val: 0.3235	accuracy_test: 0.4783
[server]	loss_train: 1.1223	loss_val: 1.3922	loss_test: 1.3500	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1789	loss_val: 1.2651	loss_test: 1.4595	accuracy_train: 0.5789	accuracy_val: 0.5750	accuracy_test: 0.2692
[server]	loss_train: 1.1071	loss_val: 1.3378	loss_test: 1.3723	accuracy_train: 0.6170	accuracy_val: 0.3939	accuracy_test: 0.3182
[server]	loss_train: 1.1380	loss_val: 1.4586	loss_test: 1.4780	accuracy_train: 0.6600	accuracy_val: 0.3611	accuracy_test: 0.2609
[server]	loss_train: 1.1634	loss_val: 1.3022	loss_test: 1.2680	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.5000
[server]	loss_train: 1.1648	loss_val: 1.3542	loss_test: 1.3658	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1655	loss_val: 1.4990	loss_test: 1.2622	accuracy_train: 0.5965	accuracy_val: 0.2821	accuracy_test: 0.4231
[server]	loss_train: 1.1480	loss_val: 1.5849	loss_test: 1.4281	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1966	loss_val: 1.3409	loss_test: 1.3016	accuracy_train: 0.4792	accuracy_val: 0.4286	accuracy_test: 0.4167
[server]	loss_train: 1.2573	loss_val: 1.3142	loss_test: 1.3912	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0819	loss_val: 1.3651	loss_test: 1.4107	accuracy_train: 0.6739	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 1.0934	loss_val: 1.4045	loss_test: 1.4731	accuracy_train: 0.6400	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.1345	loss_val: 1.3572	loss_test: 1.4615	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.1316	loss_val: 1.3984	loss_test: 1.4598	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1744	loss_val: 1.4188	loss_test: 1.4417	accuracy_train: 0.6508	accuracy_val: 0.3182	accuracy_test: 0.3793
[server]	loss_train: 1.1159	loss_val: 1.3941	loss_test: 1.4479	accuracy_train: 0.6379	accuracy_val: 0.4103	accuracy_test: 0.3214
curr_round: 44	curr_val_accuracy: 0.4068	curr_test_accuracy: 0.3724
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 45		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0971	loss_val: 1.4429	loss_test: 1.3072	accuracy_train: 0.5625	accuracy_val: 0.4444	accuracy_test: 0.4348
[server]	loss_train: 1.1827	loss_val: 1.3576	loss_test: 1.3371	accuracy_train: 0.5882	accuracy_val: 0.4444	accuracy_test: 0.4167
[server]	loss_train: 1.1591	loss_val: 1.4709	loss_test: 1.4221	accuracy_train: 0.5849	accuracy_val: 0.2051	accuracy_test: 0.4400
[server]	loss_train: 1.1157	loss_val: 1.3725	loss_test: 1.3021	accuracy_train: 0.6200	accuracy_val: 0.3235	accuracy_test: 0.4783
[server]	loss_train: 1.1160	loss_val: 1.3920	loss_test: 1.3477	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1727	loss_val: 1.2613	loss_test: 1.4599	accuracy_train: 0.5789	accuracy_val: 0.5750	accuracy_test: 0.2692
[server]	loss_train: 1.1021	loss_val: 1.3380	loss_test: 1.3721	accuracy_train: 0.6170	accuracy_val: 0.3636	accuracy_test: 0.3182
[server]	loss_train: 1.1329	loss_val: 1.4599	loss_test: 1.4774	accuracy_train: 0.6600	accuracy_val: 0.3611	accuracy_test: 0.2609
[server]	loss_train: 1.1587	loss_val: 1.3012	loss_test: 1.2655	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.5000
[server]	loss_train: 1.1607	loss_val: 1.3532	loss_test: 1.3642	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1617	loss_val: 1.5014	loss_test: 1.2584	accuracy_train: 0.5965	accuracy_val: 0.2821	accuracy_test: 0.4231
[server]	loss_train: 1.1426	loss_val: 1.5868	loss_test: 1.4280	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1909	loss_val: 1.3370	loss_test: 1.2979	accuracy_train: 0.4792	accuracy_val: 0.4286	accuracy_test: 0.4167
[server]	loss_train: 1.2537	loss_val: 1.3113	loss_test: 1.3913	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0746	loss_val: 1.3642	loss_test: 1.4078	accuracy_train: 0.6957	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 1.0867	loss_val: 1.4038	loss_test: 1.4747	accuracy_train: 0.6600	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.1295	loss_val: 1.3560	loss_test: 1.4615	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.1264	loss_val: 1.3994	loss_test: 1.4596	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1698	loss_val: 1.4180	loss_test: 1.4416	accuracy_train: 0.6508	accuracy_val: 0.3182	accuracy_test: 0.3793
[server]	loss_train: 1.1122	loss_val: 1.3953	loss_test: 1.4487	accuracy_train: 0.6379	accuracy_val: 0.4103	accuracy_test: 0.3214
curr_round: 45	curr_val_accuracy: 0.4054	curr_test_accuracy: 0.3724
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 46		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0921	loss_val: 1.4442	loss_test: 1.3052	accuracy_train: 0.5625	accuracy_val: 0.4444	accuracy_test: 0.4348
[server]	loss_train: 1.1784	loss_val: 1.3573	loss_test: 1.3356	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.1531	loss_val: 1.4698	loss_test: 1.4209	accuracy_train: 0.5849	accuracy_val: 0.2051	accuracy_test: 0.4400
[server]	loss_train: 1.1101	loss_val: 1.3699	loss_test: 1.2987	accuracy_train: 0.6200	accuracy_val: 0.3235	accuracy_test: 0.4783
[server]	loss_train: 1.1101	loss_val: 1.3921	loss_test: 1.3454	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1668	loss_val: 1.2578	loss_test: 1.4603	accuracy_train: 0.5789	accuracy_val: 0.5750	accuracy_test: 0.2692
[server]	loss_train: 1.0972	loss_val: 1.3383	loss_test: 1.3721	accuracy_train: 0.6170	accuracy_val: 0.3636	accuracy_test: 0.3182
[server]	loss_train: 1.1280	loss_val: 1.4612	loss_test: 1.4768	accuracy_train: 0.6600	accuracy_val: 0.3611	accuracy_test: 0.2609
[server]	loss_train: 1.1541	loss_val: 1.3003	loss_test: 1.2630	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.5000
[server]	loss_train: 1.1567	loss_val: 1.3521	loss_test: 1.3626	accuracy_train: 0.5918	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1580	loss_val: 1.5039	loss_test: 1.2547	accuracy_train: 0.5965	accuracy_val: 0.2821	accuracy_test: 0.4231
[server]	loss_train: 1.1374	loss_val: 1.5887	loss_test: 1.4282	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1855	loss_val: 1.3334	loss_test: 1.2945	accuracy_train: 0.4792	accuracy_val: 0.4571	accuracy_test: 0.4167
[server]	loss_train: 1.2503	loss_val: 1.3084	loss_test: 1.3914	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0676	loss_val: 1.3634	loss_test: 1.4050	accuracy_train: 0.6957	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.0803	loss_val: 1.4033	loss_test: 1.4763	accuracy_train: 0.6600	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.1248	loss_val: 1.3550	loss_test: 1.4616	accuracy_train: 0.5645	accuracy_val: 0.5000	accuracy_test: 0.3448
[server]	loss_train: 1.1215	loss_val: 1.4005	loss_test: 1.4596	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1654	loss_val: 1.4173	loss_test: 1.4416	accuracy_train: 0.6508	accuracy_val: 0.3182	accuracy_test: 0.3793
[server]	loss_train: 1.1086	loss_val: 1.3964	loss_test: 1.4495	accuracy_train: 0.6379	accuracy_val: 0.3846	accuracy_test: 0.3214
curr_round: 46	curr_val_accuracy: 0.4013	curr_test_accuracy: 0.3724
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 47		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0872	loss_val: 1.4454	loss_test: 1.3033	accuracy_train: 0.5833	accuracy_val: 0.4444	accuracy_test: 0.4783
[server]	loss_train: 1.1744	loss_val: 1.3572	loss_test: 1.3342	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.1474	loss_val: 1.4689	loss_test: 1.4199	accuracy_train: 0.5660	accuracy_val: 0.2308	accuracy_test: 0.4400
[server]	loss_train: 1.1048	loss_val: 1.3674	loss_test: 1.2956	accuracy_train: 0.6200	accuracy_val: 0.3235	accuracy_test: 0.4783
[server]	loss_train: 1.1043	loss_val: 1.3924	loss_test: 1.3433	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1611	loss_val: 1.2546	loss_test: 1.4609	accuracy_train: 0.5789	accuracy_val: 0.5750	accuracy_test: 0.2692
[server]	loss_train: 1.0925	loss_val: 1.3388	loss_test: 1.3721	accuracy_train: 0.6170	accuracy_val: 0.3636	accuracy_test: 0.3182
[server]	loss_train: 1.1234	loss_val: 1.4626	loss_test: 1.4762	accuracy_train: 0.6600	accuracy_val: 0.3611	accuracy_test: 0.2609
[server]	loss_train: 1.1497	loss_val: 1.2995	loss_test: 1.2608	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.5000
[server]	loss_train: 1.1529	loss_val: 1.3512	loss_test: 1.3612	accuracy_train: 0.5918	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1546	loss_val: 1.5065	loss_test: 1.2511	accuracy_train: 0.6140	accuracy_val: 0.2821	accuracy_test: 0.4231
[server]	loss_train: 1.1325	loss_val: 1.5906	loss_test: 1.4285	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1804	loss_val: 1.3299	loss_test: 1.2913	accuracy_train: 0.5000	accuracy_val: 0.4571	accuracy_test: 0.4167
[server]	loss_train: 1.2470	loss_val: 1.3058	loss_test: 1.3916	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0608	loss_val: 1.3628	loss_test: 1.4024	accuracy_train: 0.6739	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.0742	loss_val: 1.4028	loss_test: 1.4781	accuracy_train: 0.6600	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.1204	loss_val: 1.3540	loss_test: 1.4619	accuracy_train: 0.5645	accuracy_val: 0.5000	accuracy_test: 0.3448
[server]	loss_train: 1.1169	loss_val: 1.4016	loss_test: 1.4596	accuracy_train: 0.5778	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1613	loss_val: 1.4167	loss_test: 1.4417	accuracy_train: 0.6508	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.1051	loss_val: 1.3976	loss_test: 1.4503	accuracy_train: 0.6379	accuracy_val: 0.3846	accuracy_test: 0.3571
curr_round: 47	curr_val_accuracy: 0.4040	curr_test_accuracy: 0.3764
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 48		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0825	loss_val: 1.4466	loss_test: 1.3015	accuracy_train: 0.5833	accuracy_val: 0.4444	accuracy_test: 0.4783
[server]	loss_train: 1.1706	loss_val: 1.3573	loss_test: 1.3330	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.1420	loss_val: 1.4681	loss_test: 1.4191	accuracy_train: 0.5660	accuracy_val: 0.2308	accuracy_test: 0.4400
[server]	loss_train: 1.0998	loss_val: 1.3651	loss_test: 1.2927	accuracy_train: 0.6200	accuracy_val: 0.3235	accuracy_test: 0.4783
[server]	loss_train: 1.0987	loss_val: 1.3929	loss_test: 1.3413	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1558	loss_val: 1.2518	loss_test: 1.4615	accuracy_train: 0.5789	accuracy_val: 0.5750	accuracy_test: 0.2692
[server]	loss_train: 1.0880	loss_val: 1.3392	loss_test: 1.3722	accuracy_train: 0.6170	accuracy_val: 0.3939	accuracy_test: 0.3182
[server]	loss_train: 1.1189	loss_val: 1.4640	loss_test: 1.4756	accuracy_train: 0.6600	accuracy_val: 0.3611	accuracy_test: 0.2609
[server]	loss_train: 1.1454	loss_val: 1.2988	loss_test: 1.2587	accuracy_train: 0.6296	accuracy_val: 0.4737	accuracy_test: 0.5000
[server]	loss_train: 1.1492	loss_val: 1.3504	loss_test: 1.3599	accuracy_train: 0.5918	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1513	loss_val: 1.5090	loss_test: 1.2478	accuracy_train: 0.6140	accuracy_val: 0.2821	accuracy_test: 0.4231
[server]	loss_train: 1.1278	loss_val: 1.5925	loss_test: 1.4290	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1756	loss_val: 1.3266	loss_test: 1.2884	accuracy_train: 0.5000	accuracy_val: 0.4571	accuracy_test: 0.4167
[server]	loss_train: 1.2438	loss_val: 1.3032	loss_test: 1.3919	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0543	loss_val: 1.3623	loss_test: 1.3999	accuracy_train: 0.6739	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.0684	loss_val: 1.4024	loss_test: 1.4799	accuracy_train: 0.6600	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.1161	loss_val: 1.3532	loss_test: 1.4624	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3793
[server]	loss_train: 1.1124	loss_val: 1.4028	loss_test: 1.4598	accuracy_train: 0.5778	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1574	loss_val: 1.4162	loss_test: 1.4418	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.1018	loss_val: 1.3988	loss_test: 1.4510	accuracy_train: 0.6379	accuracy_val: 0.3846	accuracy_test: 0.3571
curr_round: 48	curr_val_accuracy: 0.4053	curr_test_accuracy: 0.3784
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 49		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0779	loss_val: 1.4479	loss_test: 1.2999	accuracy_train: 0.5833	accuracy_val: 0.4444	accuracy_test: 0.4783
[server]	loss_train: 1.1670	loss_val: 1.3575	loss_test: 1.3319	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.1369	loss_val: 1.4675	loss_test: 1.4184	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4400
[server]	loss_train: 1.0951	loss_val: 1.3629	loss_test: 1.2901	accuracy_train: 0.6200	accuracy_val: 0.3235	accuracy_test: 0.4783
[server]	loss_train: 1.0934	loss_val: 1.3936	loss_test: 1.3394	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1507	loss_val: 1.2492	loss_test: 1.4623	accuracy_train: 0.5789	accuracy_val: 0.5750	accuracy_test: 0.2692
[server]	loss_train: 1.0837	loss_val: 1.3398	loss_test: 1.3724	accuracy_train: 0.6170	accuracy_val: 0.3939	accuracy_test: 0.3182
[server]	loss_train: 1.1146	loss_val: 1.4653	loss_test: 1.4750	accuracy_train: 0.6600	accuracy_val: 0.3611	accuracy_test: 0.2609
[server]	loss_train: 1.1412	loss_val: 1.2981	loss_test: 1.2567	accuracy_train: 0.6481	accuracy_val: 0.4474	accuracy_test: 0.5000
[server]	loss_train: 1.1458	loss_val: 1.3497	loss_test: 1.3587	accuracy_train: 0.5918	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1482	loss_val: 1.5116	loss_test: 1.2446	accuracy_train: 0.6140	accuracy_val: 0.2821	accuracy_test: 0.4231
[server]	loss_train: 1.1233	loss_val: 1.5945	loss_test: 1.4297	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1710	loss_val: 1.3235	loss_test: 1.2857	accuracy_train: 0.5000	accuracy_val: 0.4571	accuracy_test: 0.4167
[server]	loss_train: 1.2407	loss_val: 1.3008	loss_test: 1.3923	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0481	loss_val: 1.3620	loss_test: 1.3975	accuracy_train: 0.6957	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.0629	loss_val: 1.4020	loss_test: 1.4817	accuracy_train: 0.6800	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.1121	loss_val: 1.3525	loss_test: 1.4629	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.1081	loss_val: 1.4039	loss_test: 1.4601	accuracy_train: 0.5556	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1537	loss_val: 1.4159	loss_test: 1.4421	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0986	loss_val: 1.4000	loss_test: 1.4517	accuracy_train: 0.6552	accuracy_val: 0.3846	accuracy_test: 0.3571
curr_round: 49	curr_val_accuracy: 0.4039	curr_test_accuracy: 0.3764
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 50		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0735	loss_val: 1.4492	loss_test: 1.2983	accuracy_train: 0.5833	accuracy_val: 0.4444	accuracy_test: 0.4783
[server]	loss_train: 1.1637	loss_val: 1.3578	loss_test: 1.3310	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.1319	loss_val: 1.4669	loss_test: 1.4178	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0905	loss_val: 1.3610	loss_test: 1.2876	accuracy_train: 0.6200	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.0882	loss_val: 1.3944	loss_test: 1.3375	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1458	loss_val: 1.2469	loss_test: 1.4630	accuracy_train: 0.5789	accuracy_val: 0.5750	accuracy_test: 0.2692
[server]	loss_train: 1.0795	loss_val: 1.3404	loss_test: 1.3725	accuracy_train: 0.6170	accuracy_val: 0.3939	accuracy_test: 0.3182
[server]	loss_train: 1.1105	loss_val: 1.4667	loss_test: 1.4744	accuracy_train: 0.6600	accuracy_val: 0.3611	accuracy_test: 0.2609
[server]	loss_train: 1.1372	loss_val: 1.2976	loss_test: 1.2548	accuracy_train: 0.6481	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1424	loss_val: 1.3490	loss_test: 1.3576	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1453	loss_val: 1.5142	loss_test: 1.2415	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.1190	loss_val: 1.5966	loss_test: 1.4304	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1666	loss_val: 1.3206	loss_test: 1.2832	accuracy_train: 0.5000	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2377	loss_val: 1.2985	loss_test: 1.3928	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0420	loss_val: 1.3617	loss_test: 1.3954	accuracy_train: 0.6957	accuracy_val: 0.4848	accuracy_test: 0.5455
[server]	loss_train: 1.0575	loss_val: 1.4017	loss_test: 1.4836	accuracy_train: 0.6800	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.1082	loss_val: 1.3519	loss_test: 1.4634	accuracy_train: 0.5484	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.1040	loss_val: 1.4049	loss_test: 1.4604	accuracy_train: 0.5556	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1502	loss_val: 1.4156	loss_test: 1.4423	accuracy_train: 0.6825	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0955	loss_val: 1.4012	loss_test: 1.4525	accuracy_train: 0.6552	accuracy_val: 0.3846	accuracy_test: 0.3571
curr_round: 50	curr_val_accuracy: 0.4080	curr_test_accuracy: 0.3824
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 51		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0692	loss_val: 1.4504	loss_test: 1.2967	accuracy_train: 0.5833	accuracy_val: 0.4444	accuracy_test: 0.4783
[server]	loss_train: 1.1605	loss_val: 1.3582	loss_test: 1.3301	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.1272	loss_val: 1.4664	loss_test: 1.4173	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0862	loss_val: 1.3592	loss_test: 1.2853	accuracy_train: 0.6200	accuracy_val: 0.3529	accuracy_test: 0.4783
[server]	loss_train: 1.0832	loss_val: 1.3954	loss_test: 1.3357	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1411	loss_val: 1.2447	loss_test: 1.4638	accuracy_train: 0.5789	accuracy_val: 0.5750	accuracy_test: 0.2692
[server]	loss_train: 1.0755	loss_val: 1.3411	loss_test: 1.3728	accuracy_train: 0.6170	accuracy_val: 0.3939	accuracy_test: 0.3182
[server]	loss_train: 1.1065	loss_val: 1.4680	loss_test: 1.4738	accuracy_train: 0.6800	accuracy_val: 0.3611	accuracy_test: 0.2609
[server]	loss_train: 1.1332	loss_val: 1.2970	loss_test: 1.2530	accuracy_train: 0.6481	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1392	loss_val: 1.3484	loss_test: 1.3566	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1424	loss_val: 1.5169	loss_test: 1.2385	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.1149	loss_val: 1.5986	loss_test: 1.4313	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1623	loss_val: 1.3178	loss_test: 1.2809	accuracy_train: 0.5208	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2349	loss_val: 1.2963	loss_test: 1.3933	accuracy_train: 0.4762	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0362	loss_val: 1.3616	loss_test: 1.3933	accuracy_train: 0.6957	accuracy_val: 0.4848	accuracy_test: 0.5455
[server]	loss_train: 1.0524	loss_val: 1.4015	loss_test: 1.4856	accuracy_train: 0.6800	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.1045	loss_val: 1.3513	loss_test: 1.4641	accuracy_train: 0.5484	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.1001	loss_val: 1.4060	loss_test: 1.4608	accuracy_train: 0.5556	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1468	loss_val: 1.4154	loss_test: 1.4426	accuracy_train: 0.6825	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0925	loss_val: 1.4024	loss_test: 1.4534	accuracy_train: 0.6552	accuracy_val: 0.3590	accuracy_test: 0.3571
curr_round: 51	curr_val_accuracy: 0.4066	curr_test_accuracy: 0.3824
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 52		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0651	loss_val: 1.4517	loss_test: 1.2953	accuracy_train: 0.5833	accuracy_val: 0.4444	accuracy_test: 0.4783
[server]	loss_train: 1.1575	loss_val: 1.3587	loss_test: 1.3294	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.1227	loss_val: 1.4661	loss_test: 1.4169	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0820	loss_val: 1.3575	loss_test: 1.2832	accuracy_train: 0.6200	accuracy_val: 0.3529	accuracy_test: 0.4348
[server]	loss_train: 1.0783	loss_val: 1.3965	loss_test: 1.3340	accuracy_train: 0.6154	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1367	loss_val: 1.2428	loss_test: 1.4647	accuracy_train: 0.5789	accuracy_val: 0.5750	accuracy_test: 0.2692
[server]	loss_train: 1.0717	loss_val: 1.3417	loss_test: 1.3731	accuracy_train: 0.6170	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.1027	loss_val: 1.4694	loss_test: 1.4731	accuracy_train: 0.6800	accuracy_val: 0.3611	accuracy_test: 0.2609
[server]	loss_train: 1.1294	loss_val: 1.2966	loss_test: 1.2513	accuracy_train: 0.6481	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1361	loss_val: 1.3478	loss_test: 1.3557	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1397	loss_val: 1.5197	loss_test: 1.2357	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.1110	loss_val: 1.6007	loss_test: 1.4322	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1582	loss_val: 1.3151	loss_test: 1.2788	accuracy_train: 0.5208	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2321	loss_val: 1.2942	loss_test: 1.3939	accuracy_train: 0.4762	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0306	loss_val: 1.3615	loss_test: 1.3914	accuracy_train: 0.6957	accuracy_val: 0.4848	accuracy_test: 0.5455
[server]	loss_train: 1.0475	loss_val: 1.4013	loss_test: 1.4875	accuracy_train: 0.6800	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.1010	loss_val: 1.3508	loss_test: 1.4647	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.0962	loss_val: 1.4071	loss_test: 1.4613	accuracy_train: 0.5556	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1436	loss_val: 1.4153	loss_test: 1.4430	accuracy_train: 0.6825	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0896	loss_val: 1.4036	loss_test: 1.4543	accuracy_train: 0.6552	accuracy_val: 0.3590	accuracy_test: 0.3571
curr_round: 52	curr_val_accuracy: 0.4066	curr_test_accuracy: 0.3824
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 53		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0611	loss_val: 1.4530	loss_test: 1.2939	accuracy_train: 0.6042	accuracy_val: 0.4167	accuracy_test: 0.4783
[server]	loss_train: 1.1546	loss_val: 1.3593	loss_test: 1.3287	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.1184	loss_val: 1.4658	loss_test: 1.4167	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0781	loss_val: 1.3559	loss_test: 1.2813	accuracy_train: 0.6400	accuracy_val: 0.3529	accuracy_test: 0.4348
[server]	loss_train: 1.0736	loss_val: 1.3977	loss_test: 1.3324	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1324	loss_val: 1.2411	loss_test: 1.4655	accuracy_train: 0.5789	accuracy_val: 0.5750	accuracy_test: 0.2692
[server]	loss_train: 1.0681	loss_val: 1.3425	loss_test: 1.3734	accuracy_train: 0.6170	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.0991	loss_val: 1.4707	loss_test: 1.4725	accuracy_train: 0.6800	accuracy_val: 0.3611	accuracy_test: 0.2609
[server]	loss_train: 1.1256	loss_val: 1.2961	loss_test: 1.2498	accuracy_train: 0.6481	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1331	loss_val: 1.3473	loss_test: 1.3547	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1371	loss_val: 1.5224	loss_test: 1.2330	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.1072	loss_val: 1.6028	loss_test: 1.4333	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1543	loss_val: 1.3126	loss_test: 1.2768	accuracy_train: 0.5208	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2295	loss_val: 1.2922	loss_test: 1.3945	accuracy_train: 0.4762	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0252	loss_val: 1.3615	loss_test: 1.3896	accuracy_train: 0.6739	accuracy_val: 0.4848	accuracy_test: 0.5455
[server]	loss_train: 1.0428	loss_val: 1.4011	loss_test: 1.4895	accuracy_train: 0.6800	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.0976	loss_val: 1.3504	loss_test: 1.4655	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.0926	loss_val: 1.4081	loss_test: 1.4618	accuracy_train: 0.5556	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1406	loss_val: 1.4152	loss_test: 1.4434	accuracy_train: 0.6825	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0868	loss_val: 1.4048	loss_test: 1.4551	accuracy_train: 0.6552	accuracy_val: 0.3333	accuracy_test: 0.3571
curr_round: 53	curr_val_accuracy: 0.4039	curr_test_accuracy: 0.3824
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 54		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0571	loss_val: 1.4543	loss_test: 1.2926	accuracy_train: 0.6042	accuracy_val: 0.4167	accuracy_test: 0.4783
[server]	loss_train: 1.1518	loss_val: 1.3599	loss_test: 1.3281	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.1142	loss_val: 1.4656	loss_test: 1.4165	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0743	loss_val: 1.3545	loss_test: 1.2794	accuracy_train: 0.6400	accuracy_val: 0.3824	accuracy_test: 0.4348
[server]	loss_train: 1.0690	loss_val: 1.3990	loss_test: 1.3309	accuracy_train: 0.6346	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1283	loss_val: 1.2397	loss_test: 1.4664	accuracy_train: 0.5789	accuracy_val: 0.5750	accuracy_test: 0.2692
[server]	loss_train: 1.0646	loss_val: 1.3433	loss_test: 1.3738	accuracy_train: 0.6170	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.0956	loss_val: 1.4720	loss_test: 1.4718	accuracy_train: 0.6800	accuracy_val: 0.3611	accuracy_test: 0.2609
[server]	loss_train: 1.1220	loss_val: 1.2957	loss_test: 1.2483	accuracy_train: 0.6481	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1302	loss_val: 1.3468	loss_test: 1.3539	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1345	loss_val: 1.5251	loss_test: 1.2304	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.1036	loss_val: 1.6049	loss_test: 1.4344	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1506	loss_val: 1.3102	loss_test: 1.2750	accuracy_train: 0.5208	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2269	loss_val: 1.2904	loss_test: 1.3953	accuracy_train: 0.4762	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0199	loss_val: 1.3616	loss_test: 1.3879	accuracy_train: 0.6739	accuracy_val: 0.4848	accuracy_test: 0.5455
[server]	loss_train: 1.0383	loss_val: 1.4010	loss_test: 1.4915	accuracy_train: 0.6800	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.0943	loss_val: 1.3501	loss_test: 1.4663	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.0890	loss_val: 1.4091	loss_test: 1.4624	accuracy_train: 0.5556	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1377	loss_val: 1.4153	loss_test: 1.4438	accuracy_train: 0.6825	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0841	loss_val: 1.4059	loss_test: 1.4559	accuracy_train: 0.6552	accuracy_val: 0.3333	accuracy_test: 0.3571
curr_round: 54	curr_val_accuracy: 0.4053	curr_test_accuracy: 0.3824
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 55		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0533	loss_val: 1.4555	loss_test: 1.2914	accuracy_train: 0.6042	accuracy_val: 0.4167	accuracy_test: 0.4783
[server]	loss_train: 1.1492	loss_val: 1.3606	loss_test: 1.3275	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.1103	loss_val: 1.4655	loss_test: 1.4164	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0707	loss_val: 1.3531	loss_test: 1.2777	accuracy_train: 0.6400	accuracy_val: 0.3824	accuracy_test: 0.4348
[server]	loss_train: 1.0646	loss_val: 1.4004	loss_test: 1.3294	accuracy_train: 0.6538	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1244	loss_val: 1.2383	loss_test: 1.4673	accuracy_train: 0.5965	accuracy_val: 0.5750	accuracy_test: 0.2692
[server]	loss_train: 1.0612	loss_val: 1.3441	loss_test: 1.3743	accuracy_train: 0.6170	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.0922	loss_val: 1.4733	loss_test: 1.4712	accuracy_train: 0.6800	accuracy_val: 0.3611	accuracy_test: 0.2609
[server]	loss_train: 1.1184	loss_val: 1.2954	loss_test: 1.2469	accuracy_train: 0.6481	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1275	loss_val: 1.3463	loss_test: 1.3531	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1322	loss_val: 1.5279	loss_test: 1.2279	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.1002	loss_val: 1.6070	loss_test: 1.4355	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1469	loss_val: 1.3079	loss_test: 1.2733	accuracy_train: 0.5208	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2244	loss_val: 1.2886	loss_test: 1.3961	accuracy_train: 0.4762	accuracy_val: 0.4773	accuracy_test: 0.2500
[server]	loss_train: 1.0149	loss_val: 1.3617	loss_test: 1.3864	accuracy_train: 0.6739	accuracy_val: 0.4848	accuracy_test: 0.5455
[server]	loss_train: 1.0340	loss_val: 1.4008	loss_test: 1.4936	accuracy_train: 0.6800	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.0912	loss_val: 1.3497	loss_test: 1.4670	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.0856	loss_val: 1.4102	loss_test: 1.4630	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1349	loss_val: 1.4154	loss_test: 1.4442	accuracy_train: 0.6825	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0814	loss_val: 1.4070	loss_test: 1.4569	accuracy_train: 0.6552	accuracy_val: 0.3333	accuracy_test: 0.3571
curr_round: 55	curr_val_accuracy: 0.4053	curr_test_accuracy: 0.3824
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 56		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0496	loss_val: 1.4568	loss_test: 1.2902	accuracy_train: 0.6042	accuracy_val: 0.4167	accuracy_test: 0.4783
[server]	loss_train: 1.1467	loss_val: 1.3613	loss_test: 1.3271	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.1065	loss_val: 1.4654	loss_test: 1.4163	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0673	loss_val: 1.3519	loss_test: 1.2762	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4348
[server]	loss_train: 1.0602	loss_val: 1.4019	loss_test: 1.3279	accuracy_train: 0.6538	accuracy_val: 0.5405	accuracy_test: 0.4583
[server]	loss_train: 1.1205	loss_val: 1.2371	loss_test: 1.4681	accuracy_train: 0.5965	accuracy_val: 0.5750	accuracy_test: 0.3077
[server]	loss_train: 1.0579	loss_val: 1.3450	loss_test: 1.3747	accuracy_train: 0.6170	accuracy_val: 0.3939	accuracy_test: 0.3636
[server]	loss_train: 1.0890	loss_val: 1.4745	loss_test: 1.4705	accuracy_train: 0.6800	accuracy_val: 0.3611	accuracy_test: 0.3043
[server]	loss_train: 1.1150	loss_val: 1.2951	loss_test: 1.2456	accuracy_train: 0.6481	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1248	loss_val: 1.3459	loss_test: 1.3524	accuracy_train: 0.5510	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1299	loss_val: 1.5307	loss_test: 1.2255	accuracy_train: 0.6316	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0969	loss_val: 1.6092	loss_test: 1.4367	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1434	loss_val: 1.3057	loss_test: 1.2718	accuracy_train: 0.5208	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2220	loss_val: 1.2868	loss_test: 1.3969	accuracy_train: 0.4762	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 1.0100	loss_val: 1.3619	loss_test: 1.3850	accuracy_train: 0.6739	accuracy_val: 0.4848	accuracy_test: 0.5455
[server]	loss_train: 1.0298	loss_val: 1.4006	loss_test: 1.4956	accuracy_train: 0.6800	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.0881	loss_val: 1.3494	loss_test: 1.4679	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.0822	loss_val: 1.4112	loss_test: 1.4637	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1323	loss_val: 1.4155	loss_test: 1.4447	accuracy_train: 0.6825	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0788	loss_val: 1.4082	loss_test: 1.4578	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 56	curr_val_accuracy: 0.4053	curr_test_accuracy: 0.3867
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 57		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0461	loss_val: 1.4581	loss_test: 1.2891	accuracy_train: 0.6042	accuracy_val: 0.4167	accuracy_test: 0.5217
[server]	loss_train: 1.1444	loss_val: 1.3621	loss_test: 1.3266	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.1028	loss_val: 1.4654	loss_test: 1.4164	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0640	loss_val: 1.3507	loss_test: 1.2747	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4348
[server]	loss_train: 1.0560	loss_val: 1.4035	loss_test: 1.3265	accuracy_train: 0.6538	accuracy_val: 0.5135	accuracy_test: 0.4583
[server]	loss_train: 1.1169	loss_val: 1.2361	loss_test: 1.4690	accuracy_train: 0.6140	accuracy_val: 0.6000	accuracy_test: 0.3077
[server]	loss_train: 1.0548	loss_val: 1.3458	loss_test: 1.3752	accuracy_train: 0.6170	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0859	loss_val: 1.4758	loss_test: 1.4698	accuracy_train: 0.6800	accuracy_val: 0.3611	accuracy_test: 0.3043
[server]	loss_train: 1.1116	loss_val: 1.2948	loss_test: 1.2444	accuracy_train: 0.6481	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1223	loss_val: 1.3455	loss_test: 1.3517	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1277	loss_val: 1.5334	loss_test: 1.2232	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0937	loss_val: 1.6113	loss_test: 1.4379	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1400	loss_val: 1.3036	loss_test: 1.2703	accuracy_train: 0.5833	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2197	loss_val: 1.2852	loss_test: 1.3977	accuracy_train: 0.4762	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 1.0053	loss_val: 1.3621	loss_test: 1.3837	accuracy_train: 0.6739	accuracy_val: 0.4848	accuracy_test: 0.5455
[server]	loss_train: 1.0257	loss_val: 1.4004	loss_test: 1.4976	accuracy_train: 0.6800	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.0852	loss_val: 1.3492	loss_test: 1.4687	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.0790	loss_val: 1.4122	loss_test: 1.4643	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.1298	loss_val: 1.4157	loss_test: 1.4452	accuracy_train: 0.6825	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0763	loss_val: 1.4093	loss_test: 1.4587	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 57	curr_val_accuracy: 0.4067	curr_test_accuracy: 0.3888
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 58		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0426	loss_val: 1.4593	loss_test: 1.2880	accuracy_train: 0.6042	accuracy_val: 0.4167	accuracy_test: 0.5217
[server]	loss_train: 1.1422	loss_val: 1.3629	loss_test: 1.3262	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0993	loss_val: 1.4655	loss_test: 1.4165	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0608	loss_val: 1.3496	loss_test: 1.2734	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4348
[server]	loss_train: 1.0519	loss_val: 1.4051	loss_test: 1.3252	accuracy_train: 0.6538	accuracy_val: 0.5135	accuracy_test: 0.4583
[server]	loss_train: 1.1133	loss_val: 1.2352	loss_test: 1.4698	accuracy_train: 0.6140	accuracy_val: 0.6000	accuracy_test: 0.3077
[server]	loss_train: 1.0518	loss_val: 1.3468	loss_test: 1.3757	accuracy_train: 0.6170	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0829	loss_val: 1.4770	loss_test: 1.4692	accuracy_train: 0.6800	accuracy_val: 0.3611	accuracy_test: 0.3043
[server]	loss_train: 1.1083	loss_val: 1.2946	loss_test: 1.2433	accuracy_train: 0.6481	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1197	loss_val: 1.3452	loss_test: 1.3511	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1255	loss_val: 1.5361	loss_test: 1.2211	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0906	loss_val: 1.6135	loss_test: 1.4392	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1367	loss_val: 1.3016	loss_test: 1.2690	accuracy_train: 0.5833	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2174	loss_val: 1.2837	loss_test: 1.3985	accuracy_train: 0.4762	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 1.0007	loss_val: 1.3624	loss_test: 1.3825	accuracy_train: 0.6739	accuracy_val: 0.4848	accuracy_test: 0.5455
[server]	loss_train: 1.0218	loss_val: 1.4003	loss_test: 1.4996	accuracy_train: 0.7200	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.0824	loss_val: 1.3491	loss_test: 1.4696	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.0759	loss_val: 1.4132	loss_test: 1.4650	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1273	loss_val: 1.4159	loss_test: 1.4457	accuracy_train: 0.6825	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0740	loss_val: 1.4104	loss_test: 1.4595	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 58	curr_val_accuracy: 0.4067	curr_test_accuracy: 0.3908
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 59		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0392	loss_val: 1.4606	loss_test: 1.2869	accuracy_train: 0.6042	accuracy_val: 0.3889	accuracy_test: 0.4783
[server]	loss_train: 1.1400	loss_val: 1.3638	loss_test: 1.3259	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0959	loss_val: 1.4656	loss_test: 1.4167	accuracy_train: 0.5283	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0578	loss_val: 1.3487	loss_test: 1.2721	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4348
[server]	loss_train: 1.0479	loss_val: 1.4068	loss_test: 1.3239	accuracy_train: 0.6538	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.1099	loss_val: 1.2344	loss_test: 1.4707	accuracy_train: 0.6140	accuracy_val: 0.6000	accuracy_test: 0.3077
[server]	loss_train: 1.0489	loss_val: 1.3477	loss_test: 1.3763	accuracy_train: 0.6170	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0800	loss_val: 1.4782	loss_test: 1.4685	accuracy_train: 0.6800	accuracy_val: 0.3611	accuracy_test: 0.3043
[server]	loss_train: 1.1051	loss_val: 1.2943	loss_test: 1.2422	accuracy_train: 0.6481	accuracy_val: 0.4211	accuracy_test: 0.5385
[server]	loss_train: 1.1173	loss_val: 1.3449	loss_test: 1.3505	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1235	loss_val: 1.5389	loss_test: 1.2189	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0876	loss_val: 1.6157	loss_test: 1.4406	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1335	loss_val: 1.2997	loss_test: 1.2678	accuracy_train: 0.5833	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2152	loss_val: 1.2822	loss_test: 1.3994	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 0.9962	loss_val: 1.3627	loss_test: 1.3814	accuracy_train: 0.6739	accuracy_val: 0.4848	accuracy_test: 0.5455
[server]	loss_train: 1.0181	loss_val: 1.4002	loss_test: 1.5017	accuracy_train: 0.7200	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.0796	loss_val: 1.3489	loss_test: 1.4705	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.0729	loss_val: 1.4141	loss_test: 1.4657	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1250	loss_val: 1.4162	loss_test: 1.4462	accuracy_train: 0.6825	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0716	loss_val: 1.4114	loss_test: 1.4604	accuracy_train: 0.6552	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 59	curr_val_accuracy: 0.4040	curr_test_accuracy: 0.3909
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 60		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0359	loss_val: 1.4618	loss_test: 1.2860	accuracy_train: 0.6042	accuracy_val: 0.3889	accuracy_test: 0.4783
[server]	loss_train: 1.1380	loss_val: 1.3647	loss_test: 1.3256	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0926	loss_val: 1.4658	loss_test: 1.4169	accuracy_train: 0.5283	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0549	loss_val: 1.3478	loss_test: 1.2710	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4348
[server]	loss_train: 1.0440	loss_val: 1.4085	loss_test: 1.3227	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.1066	loss_val: 1.2338	loss_test: 1.4715	accuracy_train: 0.5965	accuracy_val: 0.6000	accuracy_test: 0.3077
[server]	loss_train: 1.0461	loss_val: 1.3487	loss_test: 1.3769	accuracy_train: 0.6170	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0772	loss_val: 1.4794	loss_test: 1.4678	accuracy_train: 0.6800	accuracy_val: 0.3611	accuracy_test: 0.3043
[server]	loss_train: 1.1019	loss_val: 1.2941	loss_test: 1.2413	accuracy_train: 0.6481	accuracy_val: 0.4211	accuracy_test: 0.5385
[server]	loss_train: 1.1150	loss_val: 1.3445	loss_test: 1.3500	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1215	loss_val: 1.5417	loss_test: 1.2169	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0848	loss_val: 1.6179	loss_test: 1.4420	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1304	loss_val: 1.2978	loss_test: 1.2667	accuracy_train: 0.5833	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2131	loss_val: 1.2808	loss_test: 1.4004	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 0.9920	loss_val: 1.3630	loss_test: 1.3804	accuracy_train: 0.6739	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.0145	loss_val: 1.4001	loss_test: 1.5037	accuracy_train: 0.7200	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.0770	loss_val: 1.3488	loss_test: 1.4714	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.0699	loss_val: 1.4150	loss_test: 1.4664	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1228	loss_val: 1.4165	loss_test: 1.4468	accuracy_train: 0.6825	accuracy_val: 0.3636	accuracy_test: 0.3793
[server]	loss_train: 1.0694	loss_val: 1.4125	loss_test: 1.4613	accuracy_train: 0.6552	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 60	curr_val_accuracy: 0.4054	curr_test_accuracy: 0.3888
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 61		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0328	loss_val: 1.4631	loss_test: 1.2851	accuracy_train: 0.6042	accuracy_val: 0.3889	accuracy_test: 0.4783
[server]	loss_train: 1.1360	loss_val: 1.3656	loss_test: 1.3253	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0895	loss_val: 1.4660	loss_test: 1.4172	accuracy_train: 0.5283	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0521	loss_val: 1.3469	loss_test: 1.2700	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4348
[server]	loss_train: 1.0403	loss_val: 1.4103	loss_test: 1.3216	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.1034	loss_val: 1.2333	loss_test: 1.4723	accuracy_train: 0.5965	accuracy_val: 0.6000	accuracy_test: 0.3077
[server]	loss_train: 1.0434	loss_val: 1.3497	loss_test: 1.3775	accuracy_train: 0.6170	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0745	loss_val: 1.4805	loss_test: 1.4671	accuracy_train: 0.6800	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.0989	loss_val: 1.2940	loss_test: 1.2403	accuracy_train: 0.6481	accuracy_val: 0.4211	accuracy_test: 0.5385
[server]	loss_train: 1.1127	loss_val: 1.3443	loss_test: 1.3495	accuracy_train: 0.5714	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1196	loss_val: 1.5445	loss_test: 1.2149	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0821	loss_val: 1.6201	loss_test: 1.4434	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1274	loss_val: 1.2961	loss_test: 1.2657	accuracy_train: 0.5833	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2110	loss_val: 1.2795	loss_test: 1.4014	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 0.9878	loss_val: 1.3634	loss_test: 1.3796	accuracy_train: 0.6957	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.0110	loss_val: 1.4000	loss_test: 1.5058	accuracy_train: 0.7200	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.0744	loss_val: 1.3487	loss_test: 1.4723	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.0670	loss_val: 1.4160	loss_test: 1.4671	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1207	loss_val: 1.4169	loss_test: 1.4474	accuracy_train: 0.6825	accuracy_val: 0.3636	accuracy_test: 0.3793
[server]	loss_train: 1.0672	loss_val: 1.4135	loss_test: 1.4623	accuracy_train: 0.6552	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 61	curr_val_accuracy: 0.4067	curr_test_accuracy: 0.3888
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 62		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0297	loss_val: 1.4644	loss_test: 1.2843	accuracy_train: 0.6042	accuracy_val: 0.3889	accuracy_test: 0.4783
[server]	loss_train: 1.1342	loss_val: 1.3665	loss_test: 1.3250	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0865	loss_val: 1.4663	loss_test: 1.4175	accuracy_train: 0.5283	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0494	loss_val: 1.3461	loss_test: 1.2691	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4348
[server]	loss_train: 1.0366	loss_val: 1.4121	loss_test: 1.3205	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.1004	loss_val: 1.2329	loss_test: 1.4731	accuracy_train: 0.5965	accuracy_val: 0.6000	accuracy_test: 0.3077
[server]	loss_train: 1.0409	loss_val: 1.3507	loss_test: 1.3782	accuracy_train: 0.6170	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0719	loss_val: 1.4816	loss_test: 1.4664	accuracy_train: 0.6800	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.0959	loss_val: 1.2939	loss_test: 1.2395	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1105	loss_val: 1.3440	loss_test: 1.3491	accuracy_train: 0.5918	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1178	loss_val: 1.5473	loss_test: 1.2130	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0794	loss_val: 1.6224	loss_test: 1.4448	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1244	loss_val: 1.2944	loss_test: 1.2647	accuracy_train: 0.5833	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2091	loss_val: 1.2782	loss_test: 1.4024	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 0.9838	loss_val: 1.3638	loss_test: 1.3788	accuracy_train: 0.6957	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.0076	loss_val: 1.3999	loss_test: 1.5078	accuracy_train: 0.7200	accuracy_val: 0.3429	accuracy_test: 0.2800
[server]	loss_train: 1.0719	loss_val: 1.3487	loss_test: 1.4732	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.0643	loss_val: 1.4169	loss_test: 1.4678	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1187	loss_val: 1.4173	loss_test: 1.4479	accuracy_train: 0.6825	accuracy_val: 0.3636	accuracy_test: 0.3793
[server]	loss_train: 1.0651	loss_val: 1.4145	loss_test: 1.4632	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 62	curr_val_accuracy: 0.4080	curr_test_accuracy: 0.3868
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 63		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0266	loss_val: 1.4656	loss_test: 1.2835	accuracy_train: 0.6042	accuracy_val: 0.3889	accuracy_test: 0.4783
[server]	loss_train: 1.1324	loss_val: 1.3674	loss_test: 1.3248	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0836	loss_val: 1.4666	loss_test: 1.4179	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0469	loss_val: 1.3454	loss_test: 1.2682	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4348
[server]	loss_train: 1.0330	loss_val: 1.4139	loss_test: 1.3194	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0974	loss_val: 1.2325	loss_test: 1.4738	accuracy_train: 0.5965	accuracy_val: 0.6000	accuracy_test: 0.3077
[server]	loss_train: 1.0383	loss_val: 1.3518	loss_test: 1.3788	accuracy_train: 0.6170	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0694	loss_val: 1.4828	loss_test: 1.4657	accuracy_train: 0.6800	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0929	loss_val: 1.2937	loss_test: 1.2386	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1084	loss_val: 1.3438	loss_test: 1.3486	accuracy_train: 0.5918	accuracy_val: 0.3714	accuracy_test: 0.3043
[server]	loss_train: 1.1161	loss_val: 1.5500	loss_test: 1.2112	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0769	loss_val: 1.6246	loss_test: 1.4463	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1216	loss_val: 1.2927	loss_test: 1.2639	accuracy_train: 0.5833	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2071	loss_val: 1.2770	loss_test: 1.4034	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 0.9799	loss_val: 1.3642	loss_test: 1.3780	accuracy_train: 0.6957	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 1.0043	loss_val: 1.3998	loss_test: 1.5098	accuracy_train: 0.7200	accuracy_val: 0.3714	accuracy_test: 0.2800
[server]	loss_train: 1.0695	loss_val: 1.3487	loss_test: 1.4741	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.0616	loss_val: 1.4178	loss_test: 1.4686	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1168	loss_val: 1.4178	loss_test: 1.4485	accuracy_train: 0.6825	accuracy_val: 0.3636	accuracy_test: 0.3793
[server]	loss_train: 1.0631	loss_val: 1.4155	loss_test: 1.4641	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 63	curr_val_accuracy: 0.4108	curr_test_accuracy: 0.3868
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 64		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0237	loss_val: 1.4669	loss_test: 1.2827	accuracy_train: 0.6042	accuracy_val: 0.3889	accuracy_test: 0.4783
[server]	loss_train: 1.1307	loss_val: 1.3684	loss_test: 1.3245	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0808	loss_val: 1.4670	loss_test: 1.4183	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0444	loss_val: 1.3447	loss_test: 1.2674	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4348
[server]	loss_train: 1.0295	loss_val: 1.4158	loss_test: 1.3184	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0945	loss_val: 1.2323	loss_test: 1.4746	accuracy_train: 0.5965	accuracy_val: 0.6000	accuracy_test: 0.3077
[server]	loss_train: 1.0360	loss_val: 1.3528	loss_test: 1.3795	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0669	loss_val: 1.4839	loss_test: 1.4650	accuracy_train: 0.6800	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0901	loss_val: 1.2936	loss_test: 1.2379	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1063	loss_val: 1.3436	loss_test: 1.3482	accuracy_train: 0.5918	accuracy_val: 0.3714	accuracy_test: 0.2609
[server]	loss_train: 1.1144	loss_val: 1.5528	loss_test: 1.2094	accuracy_train: 0.5965	accuracy_val: 0.2821	accuracy_test: 0.4231
[server]	loss_train: 1.0744	loss_val: 1.6269	loss_test: 1.4478	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1188	loss_val: 1.2911	loss_test: 1.2631	accuracy_train: 0.5833	accuracy_val: 0.4857	accuracy_test: 0.4167
[server]	loss_train: 1.2053	loss_val: 1.2759	loss_test: 1.4045	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 0.9761	loss_val: 1.3646	loss_test: 1.3774	accuracy_train: 0.7174	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 1.0012	loss_val: 1.3997	loss_test: 1.5118	accuracy_train: 0.7400	accuracy_val: 0.3714	accuracy_test: 0.2800
[server]	loss_train: 1.0672	loss_val: 1.3487	loss_test: 1.4751	accuracy_train: 0.5645	accuracy_val: 0.5227	accuracy_test: 0.3448
[server]	loss_train: 1.0589	loss_val: 1.4187	loss_test: 1.4693	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1149	loss_val: 1.4182	loss_test: 1.4491	accuracy_train: 0.6825	accuracy_val: 0.3636	accuracy_test: 0.3448
[server]	loss_train: 1.0611	loss_val: 1.4165	loss_test: 1.4651	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 64	curr_val_accuracy: 0.4107	curr_test_accuracy: 0.3827
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 65		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0209	loss_val: 1.4681	loss_test: 1.2820	accuracy_train: 0.5833	accuracy_val: 0.3889	accuracy_test: 0.4783
[server]	loss_train: 1.1291	loss_val: 1.3694	loss_test: 1.3244	accuracy_train: 0.6078	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0780	loss_val: 1.4674	loss_test: 1.4187	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.5200
[server]	loss_train: 1.0420	loss_val: 1.3441	loss_test: 1.2667	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 1.0261	loss_val: 1.4177	loss_test: 1.3174	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0917	loss_val: 1.2321	loss_test: 1.4753	accuracy_train: 0.5965	accuracy_val: 0.6000	accuracy_test: 0.3077
[server]	loss_train: 1.0337	loss_val: 1.3539	loss_test: 1.3802	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0646	loss_val: 1.4849	loss_test: 1.4644	accuracy_train: 0.6800	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0873	loss_val: 1.2936	loss_test: 1.2373	accuracy_train: 0.6481	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1043	loss_val: 1.3434	loss_test: 1.3478	accuracy_train: 0.5918	accuracy_val: 0.3714	accuracy_test: 0.2609
[server]	loss_train: 1.1128	loss_val: 1.5555	loss_test: 1.2077	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0720	loss_val: 1.6292	loss_test: 1.4493	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1161	loss_val: 1.2896	loss_test: 1.2624	accuracy_train: 0.5833	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.2034	loss_val: 1.2748	loss_test: 1.4055	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 0.9724	loss_val: 1.3650	loss_test: 1.3768	accuracy_train: 0.7174	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9981	loss_val: 1.3996	loss_test: 1.5138	accuracy_train: 0.7400	accuracy_val: 0.3714	accuracy_test: 0.2800
[server]	loss_train: 1.0650	loss_val: 1.3488	loss_test: 1.4760	accuracy_train: 0.5806	accuracy_val: 0.5000	accuracy_test: 0.3448
[server]	loss_train: 1.0564	loss_val: 1.4196	loss_test: 1.4700	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1131	loss_val: 1.4187	loss_test: 1.4497	accuracy_train: 0.6825	accuracy_val: 0.3636	accuracy_test: 0.3448
[server]	loss_train: 1.0591	loss_val: 1.4175	loss_test: 1.4659	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 65	curr_val_accuracy: 0.4121	curr_test_accuracy: 0.3868
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 66		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0181	loss_val: 1.4694	loss_test: 1.2814	accuracy_train: 0.5833	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1275	loss_val: 1.3704	loss_test: 1.3242	accuracy_train: 0.6078	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0754	loss_val: 1.4679	loss_test: 1.4192	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.5200
[server]	loss_train: 1.0397	loss_val: 1.3435	loss_test: 1.2660	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 1.0228	loss_val: 1.4196	loss_test: 1.3164	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0890	loss_val: 1.2320	loss_test: 1.4760	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0314	loss_val: 1.3550	loss_test: 1.3810	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0623	loss_val: 1.4860	loss_test: 1.4637	accuracy_train: 0.6800	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0846	loss_val: 1.2936	loss_test: 1.2366	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1024	loss_val: 1.3432	loss_test: 1.3475	accuracy_train: 0.5918	accuracy_val: 0.3714	accuracy_test: 0.2609
[server]	loss_train: 1.1113	loss_val: 1.5582	loss_test: 1.2061	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0697	loss_val: 1.6314	loss_test: 1.4508	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1134	loss_val: 1.2881	loss_test: 1.2617	accuracy_train: 0.5833	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.2016	loss_val: 1.2738	loss_test: 1.4066	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 0.9689	loss_val: 1.3655	loss_test: 1.3763	accuracy_train: 0.7174	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9951	loss_val: 1.3996	loss_test: 1.5158	accuracy_train: 0.7600	accuracy_val: 0.3714	accuracy_test: 0.2800
[server]	loss_train: 1.0628	loss_val: 1.3489	loss_test: 1.4770	accuracy_train: 0.5806	accuracy_val: 0.5000	accuracy_test: 0.3448
[server]	loss_train: 1.0539	loss_val: 1.4205	loss_test: 1.4708	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1114	loss_val: 1.4193	loss_test: 1.4503	accuracy_train: 0.6825	accuracy_val: 0.3636	accuracy_test: 0.3448
[server]	loss_train: 1.0573	loss_val: 1.4185	loss_test: 1.4668	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 66	curr_val_accuracy: 0.4094	curr_test_accuracy: 0.3889
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 67		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0154	loss_val: 1.4707	loss_test: 1.2808	accuracy_train: 0.5833	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1260	loss_val: 1.3714	loss_test: 1.3241	accuracy_train: 0.6078	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0729	loss_val: 1.4683	loss_test: 1.4197	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.5200
[server]	loss_train: 1.0375	loss_val: 1.3430	loss_test: 1.2654	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 1.0195	loss_val: 1.4215	loss_test: 1.3156	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0864	loss_val: 1.2321	loss_test: 1.4767	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0293	loss_val: 1.3561	loss_test: 1.3817	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0600	loss_val: 1.4871	loss_test: 1.4630	accuracy_train: 0.6800	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0819	loss_val: 1.2935	loss_test: 1.2360	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.1005	loss_val: 1.3430	loss_test: 1.3472	accuracy_train: 0.5918	accuracy_val: 0.3429	accuracy_test: 0.2609
[server]	loss_train: 1.1097	loss_val: 1.5609	loss_test: 1.2046	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0674	loss_val: 1.6337	loss_test: 1.4523	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1108	loss_val: 1.2867	loss_test: 1.2611	accuracy_train: 0.5833	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1999	loss_val: 1.2729	loss_test: 1.4078	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 0.9654	loss_val: 1.3660	loss_test: 1.3758	accuracy_train: 0.7174	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9922	loss_val: 1.3996	loss_test: 1.5178	accuracy_train: 0.7600	accuracy_val: 0.3714	accuracy_test: 0.2800
[server]	loss_train: 1.0607	loss_val: 1.3490	loss_test: 1.4779	accuracy_train: 0.5806	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0515	loss_val: 1.4214	loss_test: 1.4716	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1097	loss_val: 1.4199	loss_test: 1.4510	accuracy_train: 0.6825	accuracy_val: 0.3636	accuracy_test: 0.3448
[server]	loss_train: 1.0555	loss_val: 1.4194	loss_test: 1.4677	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 67	curr_val_accuracy: 0.4067	curr_test_accuracy: 0.3889
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 68		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0128	loss_val: 1.4719	loss_test: 1.2802	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1246	loss_val: 1.3724	loss_test: 1.3239	accuracy_train: 0.6078	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0704	loss_val: 1.4688	loss_test: 1.4202	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.5200
[server]	loss_train: 1.0354	loss_val: 1.3425	loss_test: 1.2648	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 1.0164	loss_val: 1.4234	loss_test: 1.3147	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0838	loss_val: 1.2321	loss_test: 1.4774	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0272	loss_val: 1.3572	loss_test: 1.3825	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0579	loss_val: 1.4881	loss_test: 1.4623	accuracy_train: 0.6800	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0793	loss_val: 1.2935	loss_test: 1.2355	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0987	loss_val: 1.3428	loss_test: 1.3469	accuracy_train: 0.5918	accuracy_val: 0.3714	accuracy_test: 0.2609
[server]	loss_train: 1.1083	loss_val: 1.5637	loss_test: 1.2030	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0653	loss_val: 1.6360	loss_test: 1.4539	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1083	loss_val: 1.2854	loss_test: 1.2606	accuracy_train: 0.5833	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1982	loss_val: 1.2720	loss_test: 1.4089	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 0.9621	loss_val: 1.3665	loss_test: 1.3754	accuracy_train: 0.7174	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9895	loss_val: 1.3995	loss_test: 1.5198	accuracy_train: 0.7600	accuracy_val: 0.3714	accuracy_test: 0.2800
[server]	loss_train: 1.0586	loss_val: 1.3491	loss_test: 1.4788	accuracy_train: 0.5806	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0491	loss_val: 1.4223	loss_test: 1.4724	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1081	loss_val: 1.4205	loss_test: 1.4516	accuracy_train: 0.6667	accuracy_val: 0.3636	accuracy_test: 0.3448
[server]	loss_train: 1.0538	loss_val: 1.4204	loss_test: 1.4686	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 68	curr_val_accuracy: 0.4081	curr_test_accuracy: 0.3889
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 69		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0103	loss_val: 1.4732	loss_test: 1.2797	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1232	loss_val: 1.3734	loss_test: 1.3238	accuracy_train: 0.6078	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0680	loss_val: 1.4694	loss_test: 1.4208	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.5200
[server]	loss_train: 1.0334	loss_val: 1.3421	loss_test: 1.2643	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 1.0133	loss_val: 1.4254	loss_test: 1.3139	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0814	loss_val: 1.2322	loss_test: 1.4781	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0252	loss_val: 1.3584	loss_test: 1.3833	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0558	loss_val: 1.4892	loss_test: 1.4617	accuracy_train: 0.6800	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0768	loss_val: 1.2935	loss_test: 1.2350	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0969	loss_val: 1.3427	loss_test: 1.3467	accuracy_train: 0.5918	accuracy_val: 0.3714	accuracy_test: 0.2609
[server]	loss_train: 1.1069	loss_val: 1.5664	loss_test: 1.2015	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.3846
[server]	loss_train: 1.0631	loss_val: 1.6383	loss_test: 1.4554	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1058	loss_val: 1.2840	loss_test: 1.2601	accuracy_train: 0.5833	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1966	loss_val: 1.2711	loss_test: 1.4099	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 0.9588	loss_val: 1.3670	loss_test: 1.3750	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9867	loss_val: 1.3995	loss_test: 1.5218	accuracy_train: 0.7600	accuracy_val: 0.3714	accuracy_test: 0.2800
[server]	loss_train: 1.0567	loss_val: 1.3493	loss_test: 1.4797	accuracy_train: 0.5806	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0468	loss_val: 1.4232	loss_test: 1.4731	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1066	loss_val: 1.4210	loss_test: 1.4522	accuracy_train: 0.6667	accuracy_val: 0.3636	accuracy_test: 0.3448
[server]	loss_train: 1.0521	loss_val: 1.4213	loss_test: 1.4694	accuracy_train: 0.6724	accuracy_val: 0.3590	accuracy_test: 0.3214
curr_round: 69	curr_val_accuracy: 0.4095	curr_test_accuracy: 0.3868
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 70		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0078	loss_val: 1.4744	loss_test: 1.2791	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1219	loss_val: 1.3744	loss_test: 1.3238	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0657	loss_val: 1.4699	loss_test: 1.4214	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.5200
[server]	loss_train: 1.0314	loss_val: 1.3417	loss_test: 1.2639	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 1.0103	loss_val: 1.4273	loss_test: 1.3131	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0789	loss_val: 1.2324	loss_test: 1.4788	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0233	loss_val: 1.3594	loss_test: 1.3841	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0537	loss_val: 1.4902	loss_test: 1.4611	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0743	loss_val: 1.2936	loss_test: 1.2345	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0951	loss_val: 1.3425	loss_test: 1.3465	accuracy_train: 0.5918	accuracy_val: 0.3714	accuracy_test: 0.2609
[server]	loss_train: 1.1056	loss_val: 1.5692	loss_test: 1.2001	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.3846
[server]	loss_train: 1.0611	loss_val: 1.6406	loss_test: 1.4570	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1034	loss_val: 1.2828	loss_test: 1.2597	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1950	loss_val: 1.2703	loss_test: 1.4110	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 0.9556	loss_val: 1.3676	loss_test: 1.3747	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9841	loss_val: 1.3995	loss_test: 1.5237	accuracy_train: 0.7600	accuracy_val: 0.3714	accuracy_test: 0.2800
[server]	loss_train: 1.0547	loss_val: 1.3494	loss_test: 1.4806	accuracy_train: 0.5806	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0445	loss_val: 1.4241	loss_test: 1.4739	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1051	loss_val: 1.4217	loss_test: 1.4529	accuracy_train: 0.6667	accuracy_val: 0.3636	accuracy_test: 0.3448
[server]	loss_train: 1.0505	loss_val: 1.4222	loss_test: 1.4704	accuracy_train: 0.6724	accuracy_val: 0.3590	accuracy_test: 0.3214
curr_round: 70	curr_val_accuracy: 0.4095	curr_test_accuracy: 0.3868
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 71		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0054	loss_val: 1.4757	loss_test: 1.2787	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1207	loss_val: 1.3754	loss_test: 1.3237	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0634	loss_val: 1.4706	loss_test: 1.4220	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.5200
[server]	loss_train: 1.0295	loss_val: 1.3414	loss_test: 1.2635	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 1.0074	loss_val: 1.4293	loss_test: 1.3124	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0766	loss_val: 1.2326	loss_test: 1.4794	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0214	loss_val: 1.3606	loss_test: 1.3849	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0517	loss_val: 1.4912	loss_test: 1.4605	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0719	loss_val: 1.2936	loss_test: 1.2341	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0935	loss_val: 1.3424	loss_test: 1.3463	accuracy_train: 0.5918	accuracy_val: 0.3714	accuracy_test: 0.2609
[server]	loss_train: 1.1043	loss_val: 1.5718	loss_test: 1.1987	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.3846
[server]	loss_train: 1.0591	loss_val: 1.6429	loss_test: 1.4585	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.1011	loss_val: 1.2815	loss_test: 1.2593	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1935	loss_val: 1.2695	loss_test: 1.4122	accuracy_train: 0.4921	accuracy_val: 0.5000	accuracy_test: 0.2857
[server]	loss_train: 0.9525	loss_val: 1.3681	loss_test: 1.3744	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9815	loss_val: 1.3995	loss_test: 1.5256	accuracy_train: 0.7600	accuracy_val: 0.3714	accuracy_test: 0.2800
[server]	loss_train: 1.0529	loss_val: 1.3497	loss_test: 1.4816	accuracy_train: 0.5645	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0423	loss_val: 1.4250	loss_test: 1.4746	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1037	loss_val: 1.4224	loss_test: 1.4535	accuracy_train: 0.6667	accuracy_val: 0.3636	accuracy_test: 0.3448
[server]	loss_train: 1.0489	loss_val: 1.4231	loss_test: 1.4712	accuracy_train: 0.6724	accuracy_val: 0.3590	accuracy_test: 0.3214
curr_round: 71	curr_val_accuracy: 0.4108	curr_test_accuracy: 0.3868
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 72		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0031	loss_val: 1.4770	loss_test: 1.2783	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1195	loss_val: 1.3764	loss_test: 1.3236	accuracy_train: 0.5882	accuracy_val: 0.4167	accuracy_test: 0.4167
[server]	loss_train: 1.0613	loss_val: 1.4711	loss_test: 1.4227	accuracy_train: 0.5660	accuracy_val: 0.2308	accuracy_test: 0.5200
[server]	loss_train: 1.0277	loss_val: 1.3410	loss_test: 1.2631	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 1.0046	loss_val: 1.4313	loss_test: 1.3117	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0743	loss_val: 1.2329	loss_test: 1.4800	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0196	loss_val: 1.3618	loss_test: 1.3858	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0498	loss_val: 1.4922	loss_test: 1.4599	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0696	loss_val: 1.2937	loss_test: 1.2337	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0918	loss_val: 1.3423	loss_test: 1.3462	accuracy_train: 0.5918	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.1030	loss_val: 1.5744	loss_test: 1.1974	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.3846
[server]	loss_train: 1.0571	loss_val: 1.6451	loss_test: 1.4600	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0988	loss_val: 1.2803	loss_test: 1.2590	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1920	loss_val: 1.2689	loss_test: 1.4134	accuracy_train: 0.4921	accuracy_val: 0.5000	accuracy_test: 0.2857
[server]	loss_train: 0.9496	loss_val: 1.3687	loss_test: 1.3741	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9790	loss_val: 1.3995	loss_test: 1.5276	accuracy_train: 0.7600	accuracy_val: 0.4000	accuracy_test: 0.2800
[server]	loss_train: 1.0511	loss_val: 1.3499	loss_test: 1.4825	accuracy_train: 0.5645	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0402	loss_val: 1.4258	loss_test: 1.4754	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1023	loss_val: 1.4230	loss_test: 1.4542	accuracy_train: 0.6667	accuracy_val: 0.3636	accuracy_test: 0.3448
[server]	loss_train: 1.0473	loss_val: 1.4239	loss_test: 1.4720	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 72	curr_val_accuracy: 0.4122	curr_test_accuracy: 0.3868
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 73		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0008	loss_val: 1.4783	loss_test: 1.2779	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1183	loss_val: 1.3774	loss_test: 1.3235	accuracy_train: 0.5686	accuracy_val: 0.4167	accuracy_test: 0.3750
[server]	loss_train: 1.0592	loss_val: 1.4718	loss_test: 1.4234	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0260	loss_val: 1.3408	loss_test: 1.2628	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 1.0018	loss_val: 1.4332	loss_test: 1.3110	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0721	loss_val: 1.2332	loss_test: 1.4806	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0178	loss_val: 1.3630	loss_test: 1.3867	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0479	loss_val: 1.4932	loss_test: 1.4593	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0673	loss_val: 1.2938	loss_test: 1.2334	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0902	loss_val: 1.3421	loss_test: 1.3460	accuracy_train: 0.5918	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.1018	loss_val: 1.5770	loss_test: 1.1961	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.3846
[server]	loss_train: 1.0552	loss_val: 1.6474	loss_test: 1.4616	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0965	loss_val: 1.2792	loss_test: 1.2587	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1905	loss_val: 1.2682	loss_test: 1.4145	accuracy_train: 0.4921	accuracy_val: 0.5000	accuracy_test: 0.2857
[server]	loss_train: 0.9467	loss_val: 1.3692	loss_test: 1.3739	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9766	loss_val: 1.3996	loss_test: 1.5295	accuracy_train: 0.7600	accuracy_val: 0.4000	accuracy_test: 0.2800
[server]	loss_train: 1.0493	loss_val: 1.3501	loss_test: 1.4834	accuracy_train: 0.5645	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0382	loss_val: 1.4266	loss_test: 1.4762	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.1010	loss_val: 1.4237	loss_test: 1.4549	accuracy_train: 0.6667	accuracy_val: 0.3636	accuracy_test: 0.3448
[server]	loss_train: 1.0458	loss_val: 1.4248	loss_test: 1.4729	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 73	curr_val_accuracy: 0.4122	curr_test_accuracy: 0.3827
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 74		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9986	loss_val: 1.4796	loss_test: 1.2776	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1171	loss_val: 1.3784	loss_test: 1.3235	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0571	loss_val: 1.4724	loss_test: 1.4241	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0243	loss_val: 1.3405	loss_test: 1.2625	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9991	loss_val: 1.4352	loss_test: 1.3103	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0700	loss_val: 1.2336	loss_test: 1.4812	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0161	loss_val: 1.3641	loss_test: 1.3875	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0461	loss_val: 1.4942	loss_test: 1.4588	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0650	loss_val: 1.2939	loss_test: 1.2331	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0887	loss_val: 1.3421	loss_test: 1.3460	accuracy_train: 0.5918	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.1006	loss_val: 1.5796	loss_test: 1.1949	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0533	loss_val: 1.6497	loss_test: 1.4631	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0943	loss_val: 1.2781	loss_test: 1.2584	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1891	loss_val: 1.2676	loss_test: 1.4156	accuracy_train: 0.4921	accuracy_val: 0.4773	accuracy_test: 0.2857
[server]	loss_train: 0.9438	loss_val: 1.3698	loss_test: 1.3738	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9742	loss_val: 1.3996	loss_test: 1.5314	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0476	loss_val: 1.3504	loss_test: 1.4844	accuracy_train: 0.5645	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0361	loss_val: 1.4275	loss_test: 1.4769	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.0997	loss_val: 1.4244	loss_test: 1.4555	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.0444	loss_val: 1.4257	loss_test: 1.4738	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 74	curr_val_accuracy: 0.4095	curr_test_accuracy: 0.3848
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 75		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9965	loss_val: 1.4808	loss_test: 1.2773	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1160	loss_val: 1.3794	loss_test: 1.3234	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0551	loss_val: 1.4731	loss_test: 1.4248	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0226	loss_val: 1.3403	loss_test: 1.2623	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9964	loss_val: 1.4371	loss_test: 1.3097	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0679	loss_val: 1.2339	loss_test: 1.4818	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0145	loss_val: 1.3652	loss_test: 1.3884	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0443	loss_val: 1.4951	loss_test: 1.4583	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0628	loss_val: 1.2940	loss_test: 1.2328	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0872	loss_val: 1.3420	loss_test: 1.3459	accuracy_train: 0.5918	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0995	loss_val: 1.5823	loss_test: 1.1937	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0515	loss_val: 1.6520	loss_test: 1.4646	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0921	loss_val: 1.2770	loss_test: 1.2582	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1877	loss_val: 1.2670	loss_test: 1.4168	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.2857
[server]	loss_train: 0.9411	loss_val: 1.3704	loss_test: 1.3736	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9720	loss_val: 1.3997	loss_test: 1.5333	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0459	loss_val: 1.3506	loss_test: 1.4853	accuracy_train: 0.5645	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0341	loss_val: 1.4284	loss_test: 1.4777	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.0984	loss_val: 1.4252	loss_test: 1.4562	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.0431	loss_val: 1.4266	loss_test: 1.4747	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 75	curr_val_accuracy: 0.4081	curr_test_accuracy: 0.3848
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 76		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9944	loss_val: 1.4821	loss_test: 1.2770	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1150	loss_val: 1.3804	loss_test: 1.3234	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0532	loss_val: 1.4738	loss_test: 1.4255	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0210	loss_val: 1.3401	loss_test: 1.2621	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9939	loss_val: 1.4390	loss_test: 1.3091	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0658	loss_val: 1.2343	loss_test: 1.4823	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0129	loss_val: 1.3664	loss_test: 1.3893	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0426	loss_val: 1.4961	loss_test: 1.4578	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0606	loss_val: 1.2942	loss_test: 1.2326	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0857	loss_val: 1.3419	loss_test: 1.3459	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0984	loss_val: 1.5849	loss_test: 1.1926	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0498	loss_val: 1.6542	loss_test: 1.4662	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0900	loss_val: 1.2760	loss_test: 1.2580	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4583
[server]	loss_train: 1.1864	loss_val: 1.2664	loss_test: 1.4179	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.2857
[server]	loss_train: 0.9384	loss_val: 1.3710	loss_test: 1.3735	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9697	loss_val: 1.3997	loss_test: 1.5352	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0442	loss_val: 1.3509	loss_test: 1.4862	accuracy_train: 0.5645	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0322	loss_val: 1.4292	loss_test: 1.4784	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.4286
[server]	loss_train: 1.0973	loss_val: 1.4259	loss_test: 1.4568	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.0417	loss_val: 1.4275	loss_test: 1.4755	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 76	curr_val_accuracy: 0.4081	curr_test_accuracy: 0.3868
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 77		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9924	loss_val: 1.4834	loss_test: 1.2768	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1139	loss_val: 1.3815	loss_test: 1.3234	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0513	loss_val: 1.4745	loss_test: 1.4262	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0195	loss_val: 1.3400	loss_test: 1.2619	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9914	loss_val: 1.4410	loss_test: 1.3085	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0639	loss_val: 1.2348	loss_test: 1.4828	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0114	loss_val: 1.3676	loss_test: 1.3902	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0409	loss_val: 1.4971	loss_test: 1.4573	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0585	loss_val: 1.2943	loss_test: 1.2324	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0843	loss_val: 1.3418	loss_test: 1.3459	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0973	loss_val: 1.5874	loss_test: 1.1915	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0480	loss_val: 1.6565	loss_test: 1.4677	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0880	loss_val: 1.2749	loss_test: 1.2579	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1851	loss_val: 1.2659	loss_test: 1.4191	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.2857
[server]	loss_train: 0.9358	loss_val: 1.3715	loss_test: 1.3734	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9675	loss_val: 1.3998	loss_test: 1.5370	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0427	loss_val: 1.3512	loss_test: 1.4871	accuracy_train: 0.5645	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0303	loss_val: 1.4301	loss_test: 1.4792	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0961	loss_val: 1.4267	loss_test: 1.4575	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.0404	loss_val: 1.4283	loss_test: 1.4762	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 77	curr_val_accuracy: 0.4081	curr_test_accuracy: 0.3827
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 78		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9904	loss_val: 1.4847	loss_test: 1.2766	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1129	loss_val: 1.3825	loss_test: 1.3234	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0494	loss_val: 1.4752	loss_test: 1.4270	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0180	loss_val: 1.3399	loss_test: 1.2617	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9890	loss_val: 1.4429	loss_test: 1.3080	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0619	loss_val: 1.2353	loss_test: 1.4834	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0099	loss_val: 1.3688	loss_test: 1.3911	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0393	loss_val: 1.4980	loss_test: 1.4568	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0564	loss_val: 1.2944	loss_test: 1.2322	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0829	loss_val: 1.3417	loss_test: 1.3458	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0963	loss_val: 1.5898	loss_test: 1.1904	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0463	loss_val: 1.6587	loss_test: 1.4692	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0860	loss_val: 1.2740	loss_test: 1.2578	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1838	loss_val: 1.2654	loss_test: 1.4203	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.2857
[server]	loss_train: 0.9333	loss_val: 1.3721	loss_test: 1.3734	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9654	loss_val: 1.3999	loss_test: 1.5389	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0411	loss_val: 1.3515	loss_test: 1.4881	accuracy_train: 0.5806	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0285	loss_val: 1.4309	loss_test: 1.4800	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0950	loss_val: 1.4275	loss_test: 1.4582	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.0391	loss_val: 1.4291	loss_test: 1.4770	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 78	curr_val_accuracy: 0.4081	curr_test_accuracy: 0.3827
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 79		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9885	loss_val: 1.4859	loss_test: 1.2764	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1120	loss_val: 1.3835	loss_test: 1.3234	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0476	loss_val: 1.4759	loss_test: 1.4277	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0166	loss_val: 1.3398	loss_test: 1.2616	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9866	loss_val: 1.4449	loss_test: 1.3074	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0600	loss_val: 1.2358	loss_test: 1.4839	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0084	loss_val: 1.3699	loss_test: 1.3920	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3182
[server]	loss_train: 1.0377	loss_val: 1.4989	loss_test: 1.4564	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0544	loss_val: 1.2946	loss_test: 1.2320	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0815	loss_val: 1.3416	loss_test: 1.3459	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0953	loss_val: 1.5924	loss_test: 1.1895	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0447	loss_val: 1.6609	loss_test: 1.4707	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0840	loss_val: 1.2730	loss_test: 1.2578	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1825	loss_val: 1.2649	loss_test: 1.4215	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.2857
[server]	loss_train: 0.9308	loss_val: 1.3727	loss_test: 1.3733	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9634	loss_val: 1.4001	loss_test: 1.5407	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0396	loss_val: 1.3518	loss_test: 1.4890	accuracy_train: 0.5806	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0267	loss_val: 1.4317	loss_test: 1.4807	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0939	loss_val: 1.4282	loss_test: 1.4588	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.0379	loss_val: 1.4300	loss_test: 1.4779	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 79	curr_val_accuracy: 0.4081	curr_test_accuracy: 0.3827
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 80		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9866	loss_val: 1.4872	loss_test: 1.2762	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1111	loss_val: 1.3845	loss_test: 1.3234	accuracy_train: 0.5294	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0459	loss_val: 1.4767	loss_test: 1.4285	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0152	loss_val: 1.3397	loss_test: 1.2615	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9842	loss_val: 1.4467	loss_test: 1.3069	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0582	loss_val: 1.2364	loss_test: 1.4845	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0070	loss_val: 1.3711	loss_test: 1.3930	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0361	loss_val: 1.4999	loss_test: 1.4560	accuracy_train: 0.6800	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0524	loss_val: 1.2947	loss_test: 1.2319	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0802	loss_val: 1.3416	loss_test: 1.3460	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0943	loss_val: 1.5949	loss_test: 1.1885	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0431	loss_val: 1.6632	loss_test: 1.4722	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0821	loss_val: 1.2721	loss_test: 1.2578	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1813	loss_val: 1.2645	loss_test: 1.4226	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9284	loss_val: 1.3733	loss_test: 1.3733	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9614	loss_val: 1.4002	loss_test: 1.5426	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0381	loss_val: 1.3522	loss_test: 1.4899	accuracy_train: 0.5806	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0249	loss_val: 1.4326	loss_test: 1.4815	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0928	loss_val: 1.4290	loss_test: 1.4595	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.0366	loss_val: 1.4308	loss_test: 1.4787	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 80	curr_val_accuracy: 0.4081	curr_test_accuracy: 0.3869
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 81		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9849	loss_val: 1.4884	loss_test: 1.2761	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1101	loss_val: 1.3856	loss_test: 1.3234	accuracy_train: 0.5294	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0442	loss_val: 1.4775	loss_test: 1.4292	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0139	loss_val: 1.3397	loss_test: 1.2614	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9820	loss_val: 1.4486	loss_test: 1.3064	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0564	loss_val: 1.2369	loss_test: 1.4849	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0056	loss_val: 1.3723	loss_test: 1.3939	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0345	loss_val: 1.5008	loss_test: 1.4556	accuracy_train: 0.6800	accuracy_val: 0.4167	accuracy_test: 0.3478
[server]	loss_train: 1.0505	loss_val: 1.2949	loss_test: 1.2318	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0789	loss_val: 1.3416	loss_test: 1.3461	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0934	loss_val: 1.5973	loss_test: 1.1876	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0415	loss_val: 1.6654	loss_test: 1.4737	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0802	loss_val: 1.2712	loss_test: 1.2578	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1802	loss_val: 1.2641	loss_test: 1.4238	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9261	loss_val: 1.3739	loss_test: 1.3734	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9594	loss_val: 1.4003	loss_test: 1.5444	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0367	loss_val: 1.3526	loss_test: 1.4908	accuracy_train: 0.5968	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0232	loss_val: 1.4334	loss_test: 1.4822	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0918	loss_val: 1.4298	loss_test: 1.4602	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.0355	loss_val: 1.4316	loss_test: 1.4794	accuracy_train: 0.6724	accuracy_val: 0.3333	accuracy_test: 0.3214
curr_round: 81	curr_val_accuracy: 0.4081	curr_test_accuracy: 0.3890
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 82		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9831	loss_val: 1.4897	loss_test: 1.2760	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1093	loss_val: 1.3866	loss_test: 1.3235	accuracy_train: 0.5294	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0425	loss_val: 1.4782	loss_test: 1.4300	accuracy_train: 0.5472	accuracy_val: 0.2308	accuracy_test: 0.4800
[server]	loss_train: 1.0126	loss_val: 1.3396	loss_test: 1.2614	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9798	loss_val: 1.4505	loss_test: 1.3059	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0546	loss_val: 1.2375	loss_test: 1.4855	accuracy_train: 0.6140	accuracy_val: 0.5750	accuracy_test: 0.3462
[server]	loss_train: 1.0043	loss_val: 1.3735	loss_test: 1.3949	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0330	loss_val: 1.5017	loss_test: 1.4552	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3478
[server]	loss_train: 1.0486	loss_val: 1.2951	loss_test: 1.2318	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0776	loss_val: 1.3415	loss_test: 1.3462	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0925	loss_val: 1.5998	loss_test: 1.1867	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0399	loss_val: 1.6676	loss_test: 1.4752	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0784	loss_val: 1.2704	loss_test: 1.2578	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1790	loss_val: 1.2638	loss_test: 1.4250	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9238	loss_val: 1.3745	loss_test: 1.3734	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9575	loss_val: 1.4004	loss_test: 1.5462	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0353	loss_val: 1.3529	loss_test: 1.4917	accuracy_train: 0.5968	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0215	loss_val: 1.4343	loss_test: 1.4829	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0908	loss_val: 1.4306	loss_test: 1.4609	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.0343	loss_val: 1.4324	loss_test: 1.4802	accuracy_train: 0.6724	accuracy_val: 0.3590	accuracy_test: 0.3214
curr_round: 82	curr_val_accuracy: 0.4095	curr_test_accuracy: 0.3890
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 83		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9814	loss_val: 1.4910	loss_test: 1.2760	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1084	loss_val: 1.3876	loss_test: 1.3235	accuracy_train: 0.5294	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0409	loss_val: 1.4790	loss_test: 1.4308	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.0114	loss_val: 1.3396	loss_test: 1.2614	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9776	loss_val: 1.4524	loss_test: 1.3055	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0529	loss_val: 1.2381	loss_test: 1.4860	accuracy_train: 0.6140	accuracy_val: 0.5500	accuracy_test: 0.3462
[server]	loss_train: 1.0030	loss_val: 1.3746	loss_test: 1.3959	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0316	loss_val: 1.5026	loss_test: 1.4549	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3478
[server]	loss_train: 1.0467	loss_val: 1.2952	loss_test: 1.2317	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0764	loss_val: 1.3415	loss_test: 1.3464	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0917	loss_val: 1.6022	loss_test: 1.1859	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0384	loss_val: 1.6698	loss_test: 1.4767	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0766	loss_val: 1.2695	loss_test: 1.2579	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1779	loss_val: 1.2634	loss_test: 1.4262	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9216	loss_val: 1.3751	loss_test: 1.3735	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9556	loss_val: 1.4006	loss_test: 1.5480	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0340	loss_val: 1.3532	loss_test: 1.4925	accuracy_train: 0.5968	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0199	loss_val: 1.4351	loss_test: 1.4837	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0899	loss_val: 1.4315	loss_test: 1.4616	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.0332	loss_val: 1.4332	loss_test: 1.4810	accuracy_train: 0.6724	accuracy_val: 0.3590	accuracy_test: 0.3214
curr_round: 83	curr_val_accuracy: 0.4095	curr_test_accuracy: 0.3890
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 84		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9797	loss_val: 1.4923	loss_test: 1.2759	accuracy_train: 0.6042	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1076	loss_val: 1.3886	loss_test: 1.3235	accuracy_train: 0.5294	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0393	loss_val: 1.4798	loss_test: 1.4317	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.0101	loss_val: 1.3397	loss_test: 1.2614	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9755	loss_val: 1.4542	loss_test: 1.3050	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0513	loss_val: 1.2387	loss_test: 1.4864	accuracy_train: 0.6140	accuracy_val: 0.5500	accuracy_test: 0.3462
[server]	loss_train: 1.0018	loss_val: 1.3758	loss_test: 1.3969	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0302	loss_val: 1.5035	loss_test: 1.4546	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3478
[server]	loss_train: 1.0449	loss_val: 1.2954	loss_test: 1.2317	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0752	loss_val: 1.3415	loss_test: 1.3465	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0908	loss_val: 1.6046	loss_test: 1.1851	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0369	loss_val: 1.6720	loss_test: 1.4782	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0748	loss_val: 1.2687	loss_test: 1.2579	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1768	loss_val: 1.2631	loss_test: 1.4274	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9194	loss_val: 1.3756	loss_test: 1.3736	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9538	loss_val: 1.4007	loss_test: 1.5497	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0326	loss_val: 1.3536	loss_test: 1.4935	accuracy_train: 0.5968	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0183	loss_val: 1.4360	loss_test: 1.4844	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0889	loss_val: 1.4323	loss_test: 1.4623	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.0322	loss_val: 1.4340	loss_test: 1.4817	accuracy_train: 0.6724	accuracy_val: 0.3590	accuracy_test: 0.3214
curr_round: 84	curr_val_accuracy: 0.4095	curr_test_accuracy: 0.3890
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 85		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9781	loss_val: 1.4935	loss_test: 1.2759	accuracy_train: 0.6250	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1068	loss_val: 1.3895	loss_test: 1.3236	accuracy_train: 0.5294	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0378	loss_val: 1.4806	loss_test: 1.4325	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.0090	loss_val: 1.3397	loss_test: 1.2614	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9734	loss_val: 1.4560	loss_test: 1.3045	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0496	loss_val: 1.2394	loss_test: 1.4869	accuracy_train: 0.6140	accuracy_val: 0.5500	accuracy_test: 0.3462
[server]	loss_train: 1.0006	loss_val: 1.3769	loss_test: 1.3979	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0288	loss_val: 1.5044	loss_test: 1.4542	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3478
[server]	loss_train: 1.0432	loss_val: 1.2955	loss_test: 1.2316	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0740	loss_val: 1.3415	loss_test: 1.3467	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0900	loss_val: 1.6071	loss_test: 1.1843	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0355	loss_val: 1.6741	loss_test: 1.4797	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0731	loss_val: 1.2680	loss_test: 1.2580	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1757	loss_val: 1.2628	loss_test: 1.4286	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9173	loss_val: 1.3762	loss_test: 1.3737	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9520	loss_val: 1.4009	loss_test: 1.5515	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0313	loss_val: 1.3540	loss_test: 1.4944	accuracy_train: 0.5968	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0168	loss_val: 1.4369	loss_test: 1.4851	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0880	loss_val: 1.4331	loss_test: 1.4629	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.0311	loss_val: 1.4348	loss_test: 1.4825	accuracy_train: 0.6724	accuracy_val: 0.3590	accuracy_test: 0.3214
curr_round: 85	curr_val_accuracy: 0.4095	curr_test_accuracy: 0.3890
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 86		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9765	loss_val: 1.4947	loss_test: 1.2758	accuracy_train: 0.6250	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1060	loss_val: 1.3905	loss_test: 1.3236	accuracy_train: 0.5294	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0362	loss_val: 1.4814	loss_test: 1.4333	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.0078	loss_val: 1.3397	loss_test: 1.2614	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9713	loss_val: 1.4578	loss_test: 1.3040	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0480	loss_val: 1.2400	loss_test: 1.4874	accuracy_train: 0.6140	accuracy_val: 0.5500	accuracy_test: 0.3462
[server]	loss_train: 0.9994	loss_val: 1.3781	loss_test: 1.3988	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0274	loss_val: 1.5053	loss_test: 1.4540	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3478
[server]	loss_train: 1.0414	loss_val: 1.2957	loss_test: 1.2316	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0729	loss_val: 1.3415	loss_test: 1.3469	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0892	loss_val: 1.6094	loss_test: 1.1835	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0340	loss_val: 1.6763	loss_test: 1.4812	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0714	loss_val: 1.2672	loss_test: 1.2582	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4167
[server]	loss_train: 1.1747	loss_val: 1.2625	loss_test: 1.4297	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9152	loss_val: 1.3768	loss_test: 1.3738	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9503	loss_val: 1.4010	loss_test: 1.5533	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0301	loss_val: 1.3544	loss_test: 1.4953	accuracy_train: 0.5968	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0153	loss_val: 1.4378	loss_test: 1.4858	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0871	loss_val: 1.4339	loss_test: 1.4636	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0302	loss_val: 1.4356	loss_test: 1.4833	accuracy_train: 0.6724	accuracy_val: 0.4103	accuracy_test: 0.3929
curr_round: 86	curr_val_accuracy: 0.4123	curr_test_accuracy: 0.3950
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 87		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9750	loss_val: 1.4960	loss_test: 1.2758	accuracy_train: 0.6458	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1052	loss_val: 1.3915	loss_test: 1.3237	accuracy_train: 0.5294	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0348	loss_val: 1.4822	loss_test: 1.4341	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.0067	loss_val: 1.3398	loss_test: 1.2615	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9694	loss_val: 1.4596	loss_test: 1.3036	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0464	loss_val: 1.2406	loss_test: 1.4878	accuracy_train: 0.6140	accuracy_val: 0.5500	accuracy_test: 0.3462
[server]	loss_train: 0.9982	loss_val: 1.3793	loss_test: 1.3998	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0261	loss_val: 1.5062	loss_test: 1.4537	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0397	loss_val: 1.2958	loss_test: 1.2316	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0718	loss_val: 1.3415	loss_test: 1.3471	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0885	loss_val: 1.6118	loss_test: 1.1828	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0326	loss_val: 1.6784	loss_test: 1.4827	accuracy_train: 0.6744	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0697	loss_val: 1.2665	loss_test: 1.2583	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4583
[server]	loss_train: 1.1737	loss_val: 1.2623	loss_test: 1.4309	accuracy_train: 0.5079	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9132	loss_val: 1.3774	loss_test: 1.3739	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9486	loss_val: 1.4012	loss_test: 1.5550	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0288	loss_val: 1.3548	loss_test: 1.4962	accuracy_train: 0.5968	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0138	loss_val: 1.4387	loss_test: 1.4865	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0863	loss_val: 1.4347	loss_test: 1.4643	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0292	loss_val: 1.4364	loss_test: 1.4840	accuracy_train: 0.6724	accuracy_val: 0.3846	accuracy_test: 0.3929
curr_round: 87	curr_val_accuracy: 0.4109	curr_test_accuracy: 0.3948
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 88		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9735	loss_val: 1.4972	loss_test: 1.2759	accuracy_train: 0.6458	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1045	loss_val: 1.3925	loss_test: 1.3238	accuracy_train: 0.5294	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0333	loss_val: 1.4831	loss_test: 1.4349	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.0056	loss_val: 1.3399	loss_test: 1.2615	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9675	loss_val: 1.4614	loss_test: 1.3032	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0449	loss_val: 1.2413	loss_test: 1.4883	accuracy_train: 0.6140	accuracy_val: 0.5500	accuracy_test: 0.3462
[server]	loss_train: 0.9971	loss_val: 1.3804	loss_test: 1.4009	accuracy_train: 0.5745	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0248	loss_val: 1.5070	loss_test: 1.4535	accuracy_train: 0.6600	accuracy_val: 0.4167	accuracy_test: 0.3043
[server]	loss_train: 1.0380	loss_val: 1.2960	loss_test: 1.2317	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0707	loss_val: 1.3415	loss_test: 1.3473	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0877	loss_val: 1.6141	loss_test: 1.1821	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0313	loss_val: 1.6805	loss_test: 1.4841	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0681	loss_val: 1.2657	loss_test: 1.2585	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4583
[server]	loss_train: 1.1727	loss_val: 1.2621	loss_test: 1.4321	accuracy_train: 0.5079	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9112	loss_val: 1.3780	loss_test: 1.3741	accuracy_train: 0.7391	accuracy_val: 0.5152	accuracy_test: 0.5000
[server]	loss_train: 0.9469	loss_val: 1.4014	loss_test: 1.5567	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0276	loss_val: 1.3552	loss_test: 1.4971	accuracy_train: 0.5968	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0123	loss_val: 1.4396	loss_test: 1.4872	accuracy_train: 0.6000	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0855	loss_val: 1.4356	loss_test: 1.4650	accuracy_train: 0.6825	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0283	loss_val: 1.4372	loss_test: 1.4848	accuracy_train: 0.6724	accuracy_val: 0.3846	accuracy_test: 0.3929
curr_round: 88	curr_val_accuracy: 0.4109	curr_test_accuracy: 0.3948
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 89		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9721	loss_val: 1.4985	loss_test: 1.2759	accuracy_train: 0.6458	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1038	loss_val: 1.3934	loss_test: 1.3238	accuracy_train: 0.5294	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0319	loss_val: 1.4839	loss_test: 1.4358	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.0046	loss_val: 1.3400	loss_test: 1.2616	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9656	loss_val: 1.4632	loss_test: 1.3029	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0435	loss_val: 1.2420	loss_test: 1.4887	accuracy_train: 0.6140	accuracy_val: 0.5250	accuracy_test: 0.3462
[server]	loss_train: 0.9960	loss_val: 1.3816	loss_test: 1.4019	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0235	loss_val: 1.5079	loss_test: 1.4533	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.0364	loss_val: 1.2962	loss_test: 1.2317	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5385
[server]	loss_train: 1.0696	loss_val: 1.3415	loss_test: 1.3476	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0870	loss_val: 1.6165	loss_test: 1.1814	accuracy_train: 0.6140	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0299	loss_val: 1.6826	loss_test: 1.4856	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0665	loss_val: 1.2650	loss_test: 1.2586	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4583
[server]	loss_train: 1.1717	loss_val: 1.2619	loss_test: 1.4333	accuracy_train: 0.5079	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9093	loss_val: 1.3786	loss_test: 1.3742	accuracy_train: 0.7391	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 0.9453	loss_val: 1.4016	loss_test: 1.5584	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0265	loss_val: 1.3556	loss_test: 1.4980	accuracy_train: 0.6129	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0109	loss_val: 1.4406	loss_test: 1.4879	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0847	loss_val: 1.4364	loss_test: 1.4657	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0274	loss_val: 1.4379	loss_test: 1.4855	accuracy_train: 0.6724	accuracy_val: 0.3846	accuracy_test: 0.3929
curr_round: 89	curr_val_accuracy: 0.4069	curr_test_accuracy: 0.3948
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 90		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9707	loss_val: 1.4998	loss_test: 1.2760	accuracy_train: 0.6458	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1031	loss_val: 1.3944	loss_test: 1.3239	accuracy_train: 0.5294	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0305	loss_val: 1.4847	loss_test: 1.4366	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.0036	loss_val: 1.3401	loss_test: 1.2618	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9637	loss_val: 1.4649	loss_test: 1.3025	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0420	loss_val: 1.2426	loss_test: 1.4891	accuracy_train: 0.6140	accuracy_val: 0.5250	accuracy_test: 0.3462
[server]	loss_train: 0.9950	loss_val: 1.3827	loss_test: 1.4029	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0223	loss_val: 1.5087	loss_test: 1.4532	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.0348	loss_val: 1.2964	loss_test: 1.2318	accuracy_train: 0.6667	accuracy_val: 0.4474	accuracy_test: 0.5000
[server]	loss_train: 1.0686	loss_val: 1.3415	loss_test: 1.3479	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0864	loss_val: 1.6188	loss_test: 1.1808	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0286	loss_val: 1.6848	loss_test: 1.4870	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0649	loss_val: 1.2644	loss_test: 1.2589	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4583
[server]	loss_train: 1.1708	loss_val: 1.2617	loss_test: 1.4344	accuracy_train: 0.5079	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9075	loss_val: 1.3792	loss_test: 1.3744	accuracy_train: 0.7391	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 0.9437	loss_val: 1.4018	loss_test: 1.5600	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0253	loss_val: 1.3560	loss_test: 1.4989	accuracy_train: 0.6129	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0096	loss_val: 1.4416	loss_test: 1.4886	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0839	loss_val: 1.4372	loss_test: 1.4664	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0265	loss_val: 1.4387	loss_test: 1.4862	accuracy_train: 0.6724	accuracy_val: 0.3846	accuracy_test: 0.3929
curr_round: 90	curr_val_accuracy: 0.4069	curr_test_accuracy: 0.3928
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 91		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9693	loss_val: 1.5010	loss_test: 1.2761	accuracy_train: 0.6458	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1024	loss_val: 1.3953	loss_test: 1.3240	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0292	loss_val: 1.4856	loss_test: 1.4375	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.0026	loss_val: 1.3402	loss_test: 1.2619	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9619	loss_val: 1.4666	loss_test: 1.3022	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5000
[server]	loss_train: 1.0406	loss_val: 1.2433	loss_test: 1.4896	accuracy_train: 0.6140	accuracy_val: 0.5250	accuracy_test: 0.3462
[server]	loss_train: 0.9939	loss_val: 1.3838	loss_test: 1.4039	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0211	loss_val: 1.5096	loss_test: 1.4530	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.0332	loss_val: 1.2965	loss_test: 1.2319	accuracy_train: 0.6667	accuracy_val: 0.4737	accuracy_test: 0.5000
[server]	loss_train: 1.0676	loss_val: 1.3415	loss_test: 1.3481	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0857	loss_val: 1.6210	loss_test: 1.1801	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0273	loss_val: 1.6869	loss_test: 1.4885	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0634	loss_val: 1.2637	loss_test: 1.2591	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4583
[server]	loss_train: 1.1699	loss_val: 1.2615	loss_test: 1.4356	accuracy_train: 0.5079	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9056	loss_val: 1.3797	loss_test: 1.3746	accuracy_train: 0.7391	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 0.9421	loss_val: 1.4020	loss_test: 1.5617	accuracy_train: 0.7600	accuracy_val: 0.4286	accuracy_test: 0.2800
[server]	loss_train: 1.0242	loss_val: 1.3564	loss_test: 1.4998	accuracy_train: 0.6129	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0082	loss_val: 1.4425	loss_test: 1.4893	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0831	loss_val: 1.4381	loss_test: 1.4671	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3793
[server]	loss_train: 1.0256	loss_val: 1.4395	loss_test: 1.4869	accuracy_train: 0.6897	accuracy_val: 0.3846	accuracy_test: 0.3929
curr_round: 91	curr_val_accuracy: 0.4083	curr_test_accuracy: 0.3928
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 92		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9679	loss_val: 1.5023	loss_test: 1.2762	accuracy_train: 0.6458	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1017	loss_val: 1.3963	loss_test: 1.3241	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0279	loss_val: 1.4864	loss_test: 1.4383	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.0016	loss_val: 1.3403	loss_test: 1.2620	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9601	loss_val: 1.4683	loss_test: 1.3018	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5417
[server]	loss_train: 1.0392	loss_val: 1.2440	loss_test: 1.4900	accuracy_train: 0.6140	accuracy_val: 0.5250	accuracy_test: 0.3462
[server]	loss_train: 0.9930	loss_val: 1.3850	loss_test: 1.4049	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0199	loss_val: 1.5105	loss_test: 1.4528	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.0316	loss_val: 1.2967	loss_test: 1.2320	accuracy_train: 0.6667	accuracy_val: 0.4737	accuracy_test: 0.5000
[server]	loss_train: 1.0666	loss_val: 1.3415	loss_test: 1.3484	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0850	loss_val: 1.6232	loss_test: 1.1796	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0260	loss_val: 1.6889	loss_test: 1.4899	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0619	loss_val: 1.2631	loss_test: 1.2593	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4583
[server]	loss_train: 1.1690	loss_val: 1.2613	loss_test: 1.4368	accuracy_train: 0.5079	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9038	loss_val: 1.3803	loss_test: 1.3748	accuracy_train: 0.7391	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 0.9406	loss_val: 1.4022	loss_test: 1.5634	accuracy_train: 0.7600	accuracy_val: 0.4000	accuracy_test: 0.2800
[server]	loss_train: 1.0231	loss_val: 1.3569	loss_test: 1.5007	accuracy_train: 0.6129	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0069	loss_val: 1.4434	loss_test: 1.4900	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0823	loss_val: 1.4390	loss_test: 1.4678	accuracy_train: 0.6667	accuracy_val: 0.3409	accuracy_test: 0.3448
[server]	loss_train: 1.0248	loss_val: 1.4402	loss_test: 1.4876	accuracy_train: 0.6897	accuracy_val: 0.3846	accuracy_test: 0.3929
curr_round: 92	curr_val_accuracy: 0.4069	curr_test_accuracy: 0.3929
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 93		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9666	loss_val: 1.5035	loss_test: 1.2763	accuracy_train: 0.6458	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1010	loss_val: 1.3972	loss_test: 1.3242	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0266	loss_val: 1.4873	loss_test: 1.4392	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 1.0007	loss_val: 1.3405	loss_test: 1.2622	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9584	loss_val: 1.4700	loss_test: 1.3015	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5417
[server]	loss_train: 1.0378	loss_val: 1.2447	loss_test: 1.4904	accuracy_train: 0.6140	accuracy_val: 0.5250	accuracy_test: 0.3462
[server]	loss_train: 0.9920	loss_val: 1.3861	loss_test: 1.4059	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0187	loss_val: 1.5113	loss_test: 1.4527	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.0301	loss_val: 1.2969	loss_test: 1.2321	accuracy_train: 0.6667	accuracy_val: 0.4737	accuracy_test: 0.5000
[server]	loss_train: 1.0656	loss_val: 1.3415	loss_test: 1.3487	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0844	loss_val: 1.6254	loss_test: 1.1790	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0247	loss_val: 1.6910	loss_test: 1.4913	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0604	loss_val: 1.2624	loss_test: 1.2595	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4583
[server]	loss_train: 1.1681	loss_val: 1.2612	loss_test: 1.4379	accuracy_train: 0.5079	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9020	loss_val: 1.3809	loss_test: 1.3750	accuracy_train: 0.7391	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 0.9391	loss_val: 1.4024	loss_test: 1.5650	accuracy_train: 0.7600	accuracy_val: 0.4000	accuracy_test: 0.2800
[server]	loss_train: 1.0221	loss_val: 1.3573	loss_test: 1.5016	accuracy_train: 0.6129	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0056	loss_val: 1.4444	loss_test: 1.4907	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0816	loss_val: 1.4398	loss_test: 1.4685	accuracy_train: 0.6667	accuracy_val: 0.3182	accuracy_test: 0.3448
[server]	loss_train: 1.0240	loss_val: 1.4410	loss_test: 1.4883	accuracy_train: 0.6897	accuracy_val: 0.3846	accuracy_test: 0.3929
curr_round: 93	curr_val_accuracy: 0.4055	curr_test_accuracy: 0.3929
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 94		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9654	loss_val: 1.5048	loss_test: 1.2764	accuracy_train: 0.6458	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.1003	loss_val: 1.3981	loss_test: 1.3243	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0253	loss_val: 1.4881	loss_test: 1.4400	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 0.9998	loss_val: 1.3406	loss_test: 1.2623	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9567	loss_val: 1.4717	loss_test: 1.3012	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5417
[server]	loss_train: 1.0365	loss_val: 1.2454	loss_test: 1.4909	accuracy_train: 0.6140	accuracy_val: 0.5250	accuracy_test: 0.3462
[server]	loss_train: 0.9910	loss_val: 1.3873	loss_test: 1.4070	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0175	loss_val: 1.5122	loss_test: 1.4525	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.0286	loss_val: 1.2971	loss_test: 1.2322	accuracy_train: 0.6667	accuracy_val: 0.4737	accuracy_test: 0.5000
[server]	loss_train: 1.0646	loss_val: 1.3416	loss_test: 1.3490	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0838	loss_val: 1.6277	loss_test: 1.1785	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0234	loss_val: 1.6930	loss_test: 1.4928	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0590	loss_val: 1.2619	loss_test: 1.2598	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4583
[server]	loss_train: 1.1673	loss_val: 1.2611	loss_test: 1.4390	accuracy_train: 0.5079	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.9003	loss_val: 1.3815	loss_test: 1.3752	accuracy_train: 0.7391	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 0.9377	loss_val: 1.4027	loss_test: 1.5666	accuracy_train: 0.7400	accuracy_val: 0.4000	accuracy_test: 0.2800
[server]	loss_train: 1.0210	loss_val: 1.3577	loss_test: 1.5025	accuracy_train: 0.6129	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0044	loss_val: 1.4454	loss_test: 1.4914	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0809	loss_val: 1.4407	loss_test: 1.4692	accuracy_train: 0.6508	accuracy_val: 0.2955	accuracy_test: 0.3448
[server]	loss_train: 1.0232	loss_val: 1.4418	loss_test: 1.4889	accuracy_train: 0.6897	accuracy_val: 0.3846	accuracy_test: 0.3929
curr_round: 94	curr_val_accuracy: 0.4042	curr_test_accuracy: 0.3929
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 95		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9641	loss_val: 1.5060	loss_test: 1.2766	accuracy_train: 0.6458	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.0997	loss_val: 1.3991	loss_test: 1.3244	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3750
[server]	loss_train: 1.0241	loss_val: 1.4890	loss_test: 1.4408	accuracy_train: 0.5472	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 0.9989	loss_val: 1.3407	loss_test: 1.2625	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9551	loss_val: 1.4733	loss_test: 1.3009	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5417
[server]	loss_train: 1.0352	loss_val: 1.2461	loss_test: 1.4913	accuracy_train: 0.6140	accuracy_val: 0.5250	accuracy_test: 0.3462
[server]	loss_train: 0.9901	loss_val: 1.3884	loss_test: 1.4080	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0164	loss_val: 1.5131	loss_test: 1.4525	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.0272	loss_val: 1.2973	loss_test: 1.2324	accuracy_train: 0.6667	accuracy_val: 0.4737	accuracy_test: 0.5000
[server]	loss_train: 1.0637	loss_val: 1.3416	loss_test: 1.3493	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0832	loss_val: 1.6299	loss_test: 1.1779	accuracy_train: 0.5965	accuracy_val: 0.3077	accuracy_test: 0.4231
[server]	loss_train: 1.0222	loss_val: 1.6950	loss_test: 1.4942	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0575	loss_val: 1.2613	loss_test: 1.2601	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4583
[server]	loss_train: 1.1665	loss_val: 1.2610	loss_test: 1.4402	accuracy_train: 0.5079	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.8987	loss_val: 1.3820	loss_test: 1.3754	accuracy_train: 0.7391	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 0.9362	loss_val: 1.4029	loss_test: 1.5682	accuracy_train: 0.7400	accuracy_val: 0.4000	accuracy_test: 0.2400
[server]	loss_train: 1.0200	loss_val: 1.3582	loss_test: 1.5034	accuracy_train: 0.6129	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0032	loss_val: 1.4464	loss_test: 1.4920	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0802	loss_val: 1.4416	loss_test: 1.4700	accuracy_train: 0.6508	accuracy_val: 0.2955	accuracy_test: 0.3448
[server]	loss_train: 1.0224	loss_val: 1.4426	loss_test: 1.4897	accuracy_train: 0.6897	accuracy_val: 0.3846	accuracy_test: 0.3929
curr_round: 95	curr_val_accuracy: 0.4042	curr_test_accuracy: 0.3909
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 96		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9629	loss_val: 1.5072	loss_test: 1.2767	accuracy_train: 0.6458	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.0991	loss_val: 1.4000	loss_test: 1.3245	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3333
[server]	loss_train: 1.0228	loss_val: 1.4898	loss_test: 1.4417	accuracy_train: 0.5660	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 0.9981	loss_val: 1.3409	loss_test: 1.2627	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9534	loss_val: 1.4750	loss_test: 1.3006	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5417
[server]	loss_train: 1.0339	loss_val: 1.2468	loss_test: 1.4918	accuracy_train: 0.6140	accuracy_val: 0.5250	accuracy_test: 0.3462
[server]	loss_train: 0.9892	loss_val: 1.3896	loss_test: 1.4091	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0153	loss_val: 1.5139	loss_test: 1.4524	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.0258	loss_val: 1.2975	loss_test: 1.2325	accuracy_train: 0.6667	accuracy_val: 0.4737	accuracy_test: 0.5000
[server]	loss_train: 1.0628	loss_val: 1.3416	loss_test: 1.3497	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0826	loss_val: 1.6321	loss_test: 1.1775	accuracy_train: 0.5614	accuracy_val: 0.2821	accuracy_test: 0.3846
[server]	loss_train: 1.0210	loss_val: 1.6970	loss_test: 1.4956	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0561	loss_val: 1.2607	loss_test: 1.2604	accuracy_train: 0.6042	accuracy_val: 0.5143	accuracy_test: 0.4583
[server]	loss_train: 1.1657	loss_val: 1.2609	loss_test: 1.4414	accuracy_train: 0.5079	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.8971	loss_val: 1.3825	loss_test: 1.3756	accuracy_train: 0.7391	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 0.9348	loss_val: 1.4032	loss_test: 1.5698	accuracy_train: 0.7400	accuracy_val: 0.4000	accuracy_test: 0.2400
[server]	loss_train: 1.0190	loss_val: 1.3586	loss_test: 1.5042	accuracy_train: 0.6129	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0020	loss_val: 1.4474	loss_test: 1.4927	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0795	loss_val: 1.4424	loss_test: 1.4707	accuracy_train: 0.6508	accuracy_val: 0.2955	accuracy_test: 0.3448
[server]	loss_train: 1.0217	loss_val: 1.4433	loss_test: 1.4905	accuracy_train: 0.6897	accuracy_val: 0.4103	accuracy_test: 0.3929
curr_round: 96	curr_val_accuracy: 0.4042	curr_test_accuracy: 0.3868
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 97		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9618	loss_val: 1.5084	loss_test: 1.2769	accuracy_train: 0.6458	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.0985	loss_val: 1.4008	loss_test: 1.3246	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3333
[server]	loss_train: 1.0216	loss_val: 1.4907	loss_test: 1.4426	accuracy_train: 0.5660	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 0.9972	loss_val: 1.3411	loss_test: 1.2629	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9518	loss_val: 1.4766	loss_test: 1.3003	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5417
[server]	loss_train: 1.0326	loss_val: 1.2475	loss_test: 1.4922	accuracy_train: 0.6140	accuracy_val: 0.5250	accuracy_test: 0.3462
[server]	loss_train: 0.9883	loss_val: 1.3907	loss_test: 1.4101	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0143	loss_val: 1.5147	loss_test: 1.4523	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.0243	loss_val: 1.2977	loss_test: 1.2327	accuracy_train: 0.6667	accuracy_val: 0.4737	accuracy_test: 0.5000
[server]	loss_train: 1.0619	loss_val: 1.3417	loss_test: 1.3500	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.2609
[server]	loss_train: 1.0821	loss_val: 1.6342	loss_test: 1.1770	accuracy_train: 0.5614	accuracy_val: 0.2821	accuracy_test: 0.3846
[server]	loss_train: 1.0199	loss_val: 1.6990	loss_test: 1.4970	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0548	loss_val: 1.2601	loss_test: 1.2607	accuracy_train: 0.6042	accuracy_val: 0.5429	accuracy_test: 0.4583
[server]	loss_train: 1.1648	loss_val: 1.2607	loss_test: 1.4425	accuracy_train: 0.5079	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.8954	loss_val: 1.3831	loss_test: 1.3759	accuracy_train: 0.7391	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 0.9334	loss_val: 1.4035	loss_test: 1.5714	accuracy_train: 0.7400	accuracy_val: 0.4000	accuracy_test: 0.2400
[server]	loss_train: 1.0180	loss_val: 1.3591	loss_test: 1.5051	accuracy_train: 0.6290	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 1.0008	loss_val: 1.4484	loss_test: 1.4933	accuracy_train: 0.6222	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0789	loss_val: 1.4433	loss_test: 1.4713	accuracy_train: 0.6508	accuracy_val: 0.2955	accuracy_test: 0.3793
[server]	loss_train: 1.0210	loss_val: 1.4440	loss_test: 1.4911	accuracy_train: 0.6897	accuracy_val: 0.4103	accuracy_test: 0.3929
curr_round: 97	curr_val_accuracy: 0.4055	curr_test_accuracy: 0.3889
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 98		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9606	loss_val: 1.5096	loss_test: 1.2771	accuracy_train: 0.6458	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.0979	loss_val: 1.4017	loss_test: 1.3247	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3333
[server]	loss_train: 1.0205	loss_val: 1.4915	loss_test: 1.4434	accuracy_train: 0.5660	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 0.9964	loss_val: 1.3413	loss_test: 1.2631	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9503	loss_val: 1.4782	loss_test: 1.3000	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5417
[server]	loss_train: 1.0314	loss_val: 1.2482	loss_test: 1.4926	accuracy_train: 0.6140	accuracy_val: 0.5250	accuracy_test: 0.3462
[server]	loss_train: 0.9874	loss_val: 1.3918	loss_test: 1.4110	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0132	loss_val: 1.5155	loss_test: 1.4523	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.0229	loss_val: 1.2979	loss_test: 1.2328	accuracy_train: 0.6667	accuracy_val: 0.4737	accuracy_test: 0.5000
[server]	loss_train: 1.0610	loss_val: 1.3417	loss_test: 1.3503	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.3043
[server]	loss_train: 1.0815	loss_val: 1.6363	loss_test: 1.1765	accuracy_train: 0.5614	accuracy_val: 0.2821	accuracy_test: 0.3846
[server]	loss_train: 1.0187	loss_val: 1.7010	loss_test: 1.4984	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0534	loss_val: 1.2596	loss_test: 1.2610	accuracy_train: 0.6042	accuracy_val: 0.5714	accuracy_test: 0.4583
[server]	loss_train: 1.1640	loss_val: 1.2607	loss_test: 1.4436	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.8939	loss_val: 1.3837	loss_test: 1.3761	accuracy_train: 0.7391	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 0.9320	loss_val: 1.4037	loss_test: 1.5729	accuracy_train: 0.7400	accuracy_val: 0.4000	accuracy_test: 0.2400
[server]	loss_train: 1.0171	loss_val: 1.3595	loss_test: 1.5059	accuracy_train: 0.6290	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 0.9996	loss_val: 1.4494	loss_test: 1.4940	accuracy_train: 0.6444	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0782	loss_val: 1.4441	loss_test: 1.4720	accuracy_train: 0.6508	accuracy_val: 0.2955	accuracy_test: 0.3793
[server]	loss_train: 1.0202	loss_val: 1.4448	loss_test: 1.4917	accuracy_train: 0.6724	accuracy_val: 0.4103	accuracy_test: 0.3929
curr_round: 98	curr_val_accuracy: 0.4069	curr_test_accuracy: 0.3909
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
round # 99		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9595	loss_val: 1.5109	loss_test: 1.2773	accuracy_train: 0.6458	accuracy_val: 0.3611	accuracy_test: 0.4783
[server]	loss_train: 1.0973	loss_val: 1.4026	loss_test: 1.3249	accuracy_train: 0.5490	accuracy_val: 0.3889	accuracy_test: 0.3333
[server]	loss_train: 1.0193	loss_val: 1.4924	loss_test: 1.4443	accuracy_train: 0.5660	accuracy_val: 0.2564	accuracy_test: 0.4800
[server]	loss_train: 0.9956	loss_val: 1.3415	loss_test: 1.2633	accuracy_train: 0.6600	accuracy_val: 0.3824	accuracy_test: 0.4783
[server]	loss_train: 0.9487	loss_val: 1.4797	loss_test: 1.2998	accuracy_train: 0.6923	accuracy_val: 0.5135	accuracy_test: 0.5417
[server]	loss_train: 1.0302	loss_val: 1.2489	loss_test: 1.4930	accuracy_train: 0.6140	accuracy_val: 0.5250	accuracy_test: 0.3077
[server]	loss_train: 0.9866	loss_val: 1.3929	loss_test: 1.4121	accuracy_train: 0.5957	accuracy_val: 0.4242	accuracy_test: 0.3636
[server]	loss_train: 1.0122	loss_val: 1.5164	loss_test: 1.4523	accuracy_train: 0.6600	accuracy_val: 0.3889	accuracy_test: 0.3043
[server]	loss_train: 1.0216	loss_val: 1.2981	loss_test: 1.2330	accuracy_train: 0.6667	accuracy_val: 0.4737	accuracy_test: 0.5000
[server]	loss_train: 1.0601	loss_val: 1.3418	loss_test: 1.3507	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.3043
[server]	loss_train: 1.0810	loss_val: 1.6384	loss_test: 1.1761	accuracy_train: 0.5614	accuracy_val: 0.2821	accuracy_test: 0.3846
[server]	loss_train: 1.0176	loss_val: 1.7029	loss_test: 1.4999	accuracy_train: 0.6977	accuracy_val: 0.2581	accuracy_test: 0.3000
[server]	loss_train: 1.0521	loss_val: 1.2591	loss_test: 1.2613	accuracy_train: 0.6042	accuracy_val: 0.5714	accuracy_test: 0.4583
[server]	loss_train: 1.1633	loss_val: 1.2606	loss_test: 1.4447	accuracy_train: 0.4921	accuracy_val: 0.4545	accuracy_test: 0.3214
[server]	loss_train: 0.8924	loss_val: 1.3842	loss_test: 1.3763	accuracy_train: 0.7391	accuracy_val: 0.4848	accuracy_test: 0.5000
[server]	loss_train: 0.9307	loss_val: 1.4040	loss_test: 1.5745	accuracy_train: 0.7400	accuracy_val: 0.4000	accuracy_test: 0.2400
[server]	loss_train: 1.0161	loss_val: 1.3600	loss_test: 1.5068	accuracy_train: 0.6290	accuracy_val: 0.4773	accuracy_test: 0.3448
[server]	loss_train: 0.9985	loss_val: 1.4504	loss_test: 1.4946	accuracy_train: 0.6444	accuracy_val: 0.3750	accuracy_test: 0.3810
[server]	loss_train: 1.0776	loss_val: 1.4449	loss_test: 1.4728	accuracy_train: 0.6508	accuracy_val: 0.2955	accuracy_test: 0.3793
[server]	loss_train: 1.0195	loss_val: 1.4455	loss_test: 1.4923	accuracy_train: 0.6724	accuracy_val: 0.4103	accuracy_test: 0.3929
curr_round: 99	curr_val_accuracy: 0.4069	curr_test_accuracy: 0.3889
best_round: 27	best_val_accuracy: 0.4149	best_test_accuracy: 0.3949
--------------------------------------------------
