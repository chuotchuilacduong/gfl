G:\conda\envs\gfl\Lib\site-packages\torch_geometric\data\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[client 0]	loss_train: 1.9700	loss_val: 1.9678	loss_test: 1.9869	accuracy_train: 0.1818	accuracy_val: 0.1356	accuracy_test: 0.1083
[client 1]	loss_train: 1.9502	loss_val: 1.9633	loss_test: 1.9571	accuracy_train: 0.1282	accuracy_val: 0.2045	accuracy_test: 0.1778
[client 2]	loss_train: 1.9672	loss_val: 1.9455	loss_test: 1.9476	accuracy_train: 0.2453	accuracy_val: 0.1560	accuracy_test: 0.1930
[client 3]	loss_train: 1.9546	loss_val: 1.9522	loss_test: 1.9572	accuracy_train: 0.1458	accuracy_val: 0.2574	accuracy_test: 0.1635
[client 4]	loss_train: 1.9316	loss_val: 1.9112	loss_test: 1.9351	accuracy_train: 0.0943	accuracy_val: 0.2523	accuracy_test: 0.0948
[client 5]	loss_train: 1.9640	loss_val: 1.9530	loss_test: 1.9518	accuracy_train: 0.0566	accuracy_val: 0.1043	accuracy_test: 0.1293
[client 6]	loss_train: 1.9386	loss_val: 1.9686	loss_test: 1.9661	accuracy_train: 0.1818	accuracy_val: 0.1207	accuracy_test: 0.1271
[client 7]	loss_train: 1.9816	loss_val: 1.9653	loss_test: 1.9640	accuracy_train: 0.0000	accuracy_val: 0.0885	accuracy_test: 0.1130
[client 8]	loss_train: 1.9516	loss_val: 1.9312	loss_test: 1.9311	accuracy_train: 0.0962	accuracy_val: 0.2037	accuracy_test: 0.1786
[client 9]	loss_train: 1.9675	loss_val: 1.9457	loss_test: 1.9489	accuracy_train: 0.0408	accuracy_val: 0.1238	accuracy_test: 0.1296
curr_round: 0	curr_val_accuracy: 0.1626	curr_test_accuracy: 0.1401
best_round: 0	best_val_accuracy: 0.1626	best_test_accuracy: 0.1401
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[client 0]	loss_train: 1.9700	loss_val: 1.9678	loss_test: 1.9869	accuracy_train: 0.1818	accuracy_val: 0.1356	accuracy_test: 0.1083
[client 1]	loss_train: 1.9502	loss_val: 1.9633	loss_test: 1.9571	accuracy_train: 0.1282	accuracy_val: 0.2045	accuracy_test: 0.1778
[client 2]	loss_train: 1.9672	loss_val: 1.9455	loss_test: 1.9476	accuracy_train: 0.2453	accuracy_val: 0.1560	accuracy_test: 0.1930
[client 3]	loss_train: 1.9546	loss_val: 1.9522	loss_test: 1.9572	accuracy_train: 0.1458	accuracy_val: 0.2574	accuracy_test: 0.1635
[client 4]	loss_train: 1.9316	loss_val: 1.9112	loss_test: 1.9351	accuracy_train: 0.0943	accuracy_val: 0.2523	accuracy_test: 0.0948
[client 5]	loss_train: 1.9640	loss_val: 1.9530	loss_test: 1.9518	accuracy_train: 0.0566	accuracy_val: 0.1043	accuracy_test: 0.1293
[client 6]	loss_train: 1.9386	loss_val: 1.9686	loss_test: 1.9661	accuracy_train: 0.1818	accuracy_val: 0.1207	accuracy_test: 0.1271
[client 7]	loss_train: 1.9816	loss_val: 1.9653	loss_test: 1.9640	accuracy_train: 0.0000	accuracy_val: 0.0885	accuracy_test: 0.1130
[client 8]	loss_train: 1.9516	loss_val: 1.9312	loss_test: 1.9311	accuracy_train: 0.0962	accuracy_val: 0.2037	accuracy_test: 0.1786
[client 9]	loss_train: 1.9675	loss_val: 1.9457	loss_test: 1.9489	accuracy_train: 0.0408	accuracy_val: 0.1238	accuracy_test: 0.1296
curr_round: 1	curr_val_accuracy: 0.1626	curr_test_accuracy: 0.1401
best_round: 0	best_val_accuracy: 0.1626	best_test_accuracy: 0.1401
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[client 0]	loss_train: 1.9700	loss_val: 1.9678	loss_test: 1.9869	accuracy_train: 0.1818	accuracy_val: 0.1356	accuracy_test: 0.1083
[client 1]	loss_train: 1.9502	loss_val: 1.9633	loss_test: 1.9571	accuracy_train: 0.1282	accuracy_val: 0.2045	accuracy_test: 0.1778
[client 2]	loss_train: 1.9672	loss_val: 1.9455	loss_test: 1.9476	accuracy_train: 0.2453	accuracy_val: 0.1560	accuracy_test: 0.1930
[client 3]	loss_train: 1.9546	loss_val: 1.9522	loss_test: 1.9572	accuracy_train: 0.1458	accuracy_val: 0.2574	accuracy_test: 0.1635
[client 4]	loss_train: 1.9316	loss_val: 1.9112	loss_test: 1.9351	accuracy_train: 0.0943	accuracy_val: 0.2523	accuracy_test: 0.0948
[client 5]	loss_train: 1.9640	loss_val: 1.9530	loss_test: 1.9518	accuracy_train: 0.0566	accuracy_val: 0.1043	accuracy_test: 0.1293
[client 6]	loss_train: 1.9386	loss_val: 1.9686	loss_test: 1.9661	accuracy_train: 0.1818	accuracy_val: 0.1207	accuracy_test: 0.1271
[client 7]	loss_train: 1.9816	loss_val: 1.9653	loss_test: 1.9640	accuracy_train: 0.0000	accuracy_val: 0.0885	accuracy_test: 0.1130
[client 8]	loss_train: 1.9516	loss_val: 1.9312	loss_test: 1.9311	accuracy_train: 0.0962	accuracy_val: 0.2037	accuracy_test: 0.1786
[client 9]	loss_train: 1.9675	loss_val: 1.9457	loss_test: 1.9489	accuracy_train: 0.0408	accuracy_val: 0.1238	accuracy_test: 0.1296
curr_round: 2	curr_val_accuracy: 0.1626	curr_test_accuracy: 0.1401
best_round: 0	best_val_accuracy: 0.1626	best_test_accuracy: 0.1401
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[client 0]	loss_train: 1.9700	loss_val: 1.9678	loss_test: 1.9869	accuracy_train: 0.1818	accuracy_val: 0.1356	accuracy_test: 0.1083
[client 1]	loss_train: 1.9502	loss_val: 1.9633	loss_test: 1.9571	accuracy_train: 0.1282	accuracy_val: 0.2045	accuracy_test: 0.1778
[client 2]	loss_train: 1.9672	loss_val: 1.9455	loss_test: 1.9476	accuracy_train: 0.2453	accuracy_val: 0.1560	accuracy_test: 0.1930
[client 3]	loss_train: 1.9546	loss_val: 1.9522	loss_test: 1.9572	accuracy_train: 0.1458	accuracy_val: 0.2574	accuracy_test: 0.1635
[client 4]	loss_train: 1.9316	loss_val: 1.9112	loss_test: 1.9351	accuracy_train: 0.0943	accuracy_val: 0.2523	accuracy_test: 0.0948
[client 5]	loss_train: 1.9640	loss_val: 1.9530	loss_test: 1.9518	accuracy_train: 0.0566	accuracy_val: 0.1043	accuracy_test: 0.1293
[client 6]	loss_train: 1.9386	loss_val: 1.9686	loss_test: 1.9661	accuracy_train: 0.1818	accuracy_val: 0.1207	accuracy_test: 0.1271
[client 7]	loss_train: 1.9816	loss_val: 1.9653	loss_test: 1.9640	accuracy_train: 0.0000	accuracy_val: 0.0885	accuracy_test: 0.1130
[client 8]	loss_train: 1.9516	loss_val: 1.9312	loss_test: 1.9311	accuracy_train: 0.0962	accuracy_val: 0.2037	accuracy_test: 0.1786
[client 9]	loss_train: 1.9675	loss_val: 1.9457	loss_test: 1.9489	accuracy_train: 0.0408	accuracy_val: 0.1238	accuracy_test: 0.1296
curr_round: 3	curr_val_accuracy: 0.1626	curr_test_accuracy: 0.1401
best_round: 0	best_val_accuracy: 0.1626	best_test_accuracy: 0.1401
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[client 0]	loss_train: 1.9700	loss_val: 1.9678	loss_test: 1.9869	accuracy_train: 0.1818	accuracy_val: 0.1356	accuracy_test: 0.1083
[client 1]	loss_train: 1.9502	loss_val: 1.9633	loss_test: 1.9571	accuracy_train: 0.1282	accuracy_val: 0.2045	accuracy_test: 0.1778
[client 2]	loss_train: 1.9672	loss_val: 1.9455	loss_test: 1.9476	accuracy_train: 0.2453	accuracy_val: 0.1560	accuracy_test: 0.1930
[client 3]	loss_train: 1.9546	loss_val: 1.9522	loss_test: 1.9572	accuracy_train: 0.1458	accuracy_val: 0.2574	accuracy_test: 0.1635
[client 4]	loss_train: 1.9316	loss_val: 1.9112	loss_test: 1.9351	accuracy_train: 0.0943	accuracy_val: 0.2523	accuracy_test: 0.0948
[client 5]	loss_train: 1.9640	loss_val: 1.9530	loss_test: 1.9518	accuracy_train: 0.0566	accuracy_val: 0.1043	accuracy_test: 0.1293
[client 6]	loss_train: 1.9386	loss_val: 1.9686	loss_test: 1.9661	accuracy_train: 0.1818	accuracy_val: 0.1207	accuracy_test: 0.1271
[client 7]	loss_train: 1.9816	loss_val: 1.9653	loss_test: 1.9640	accuracy_train: 0.0000	accuracy_val: 0.0885	accuracy_test: 0.1130
[client 8]	loss_train: 1.9516	loss_val: 1.9312	loss_test: 1.9311	accuracy_train: 0.0962	accuracy_val: 0.2037	accuracy_test: 0.1786
[client 9]	loss_train: 1.9675	loss_val: 1.9457	loss_test: 1.9489	accuracy_train: 0.0408	accuracy_val: 0.1238	accuracy_test: 0.1296
curr_round: 4	curr_val_accuracy: 0.1626	curr_test_accuracy: 0.1401
best_round: 0	best_val_accuracy: 0.1626	best_test_accuracy: 0.1401
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[client 0]	loss_train: 1.9700	loss_val: 1.9678	loss_test: 1.9869	accuracy_train: 0.1818	accuracy_val: 0.1356	accuracy_test: 0.1083
[client 1]	loss_train: 1.9502	loss_val: 1.9633	loss_test: 1.9571	accuracy_train: 0.1282	accuracy_val: 0.2045	accuracy_test: 0.1778
[client 2]	loss_train: 1.9672	loss_val: 1.9455	loss_test: 1.9476	accuracy_train: 0.2453	accuracy_val: 0.1560	accuracy_test: 0.1930
[client 3]	loss_train: 1.9546	loss_val: 1.9522	loss_test: 1.9572	accuracy_train: 0.1458	accuracy_val: 0.2574	accuracy_test: 0.1635
[client 4]	loss_train: 1.9316	loss_val: 1.9112	loss_test: 1.9351	accuracy_train: 0.0943	accuracy_val: 0.2523	accuracy_test: 0.0948
[client 5]	loss_train: 1.9640	loss_val: 1.9530	loss_test: 1.9518	accuracy_train: 0.0566	accuracy_val: 0.1043	accuracy_test: 0.1293
[client 6]	loss_train: 1.9386	loss_val: 1.9686	loss_test: 1.9661	accuracy_train: 0.1818	accuracy_val: 0.1207	accuracy_test: 0.1271
[client 7]	loss_train: 1.9816	loss_val: 1.9653	loss_test: 1.9640	accuracy_train: 0.0000	accuracy_val: 0.0885	accuracy_test: 0.1130
[client 8]	loss_train: 1.9516	loss_val: 1.9312	loss_test: 1.9311	accuracy_train: 0.0962	accuracy_val: 0.2037	accuracy_test: 0.1786
[client 9]	loss_train: 1.9675	loss_val: 1.9457	loss_test: 1.9489	accuracy_train: 0.0408	accuracy_val: 0.1238	accuracy_test: 0.1296
curr_round: 5	curr_val_accuracy: 0.1626	curr_test_accuracy: 0.1401
best_round: 0	best_val_accuracy: 0.1626	best_test_accuracy: 0.1401
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[client 0]	loss_train: 1.9700	loss_val: 1.9678	loss_test: 1.9869	accuracy_train: 0.1818	accuracy_val: 0.1356	accuracy_test: 0.1083
[client 1]	loss_train: 1.9502	loss_val: 1.9633	loss_test: 1.9571	accuracy_train: 0.1282	accuracy_val: 0.2045	accuracy_test: 0.1778
[client 2]	loss_train: 1.9672	loss_val: 1.9455	loss_test: 1.9476	accuracy_train: 0.2453	accuracy_val: 0.1560	accuracy_test: 0.1930
[client 3]	loss_train: 1.9546	loss_val: 1.9522	loss_test: 1.9572	accuracy_train: 0.1458	accuracy_val: 0.2574	accuracy_test: 0.1635
[client 4]	loss_train: 1.9316	loss_val: 1.9112	loss_test: 1.9351	accuracy_train: 0.0943	accuracy_val: 0.2523	accuracy_test: 0.0948
[client 5]	loss_train: 1.9640	loss_val: 1.9530	loss_test: 1.9518	accuracy_train: 0.0566	accuracy_val: 0.1043	accuracy_test: 0.1293
[client 6]	loss_train: 1.9386	loss_val: 1.9686	loss_test: 1.9661	accuracy_train: 0.1818	accuracy_val: 0.1207	accuracy_test: 0.1271
[client 7]	loss_train: 1.9816	loss_val: 1.9653	loss_test: 1.9640	accuracy_train: 0.0000	accuracy_val: 0.0885	accuracy_test: 0.1130
[client 8]	loss_train: 1.9516	loss_val: 1.9312	loss_test: 1.9311	accuracy_train: 0.0962	accuracy_val: 0.2037	accuracy_test: 0.1786
[client 9]	loss_train: 1.9675	loss_val: 1.9457	loss_test: 1.9489	accuracy_train: 0.0408	accuracy_val: 0.1238	accuracy_test: 0.1296
curr_round: 6	curr_val_accuracy: 0.1626	curr_test_accuracy: 0.1401
best_round: 0	best_val_accuracy: 0.1626	best_test_accuracy: 0.1401
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
[client 0]	loss_train: 1.9700	loss_val: 1.9678	loss_test: 1.9869	accuracy_train: 0.1818	accuracy_val: 0.1356	accuracy_test: 0.1083
[client 1]	loss_train: 1.9502	loss_val: 1.9633	loss_test: 1.9571	accuracy_train: 0.1282	accuracy_val: 0.2045	accuracy_test: 0.1778
[client 2]	loss_train: 1.9672	loss_val: 1.9455	loss_test: 1.9476	accuracy_train: 0.2453	accuracy_val: 0.1560	accuracy_test: 0.1930
[client 3]	loss_train: 1.9546	loss_val: 1.9522	loss_test: 1.9572	accuracy_train: 0.1458	accuracy_val: 0.2574	accuracy_test: 0.1635
[client 4]	loss_train: 1.9316	loss_val: 1.9112	loss_test: 1.9351	accuracy_train: 0.0943	accuracy_val: 0.2523	accuracy_test: 0.0948
[client 5]	loss_train: 1.9640	loss_val: 1.9530	loss_test: 1.9518	accuracy_train: 0.0566	accuracy_val: 0.1043	accuracy_test: 0.1293
[client 6]	loss_train: 1.9386	loss_val: 1.9686	loss_test: 1.9661	accuracy_train: 0.1818	accuracy_val: 0.1207	accuracy_test: 0.1271
[client 7]	loss_train: 1.9816	loss_val: 1.9653	loss_test: 1.9640	accuracy_train: 0.0000	accuracy_val: 0.0885	accuracy_test: 0.1130
[client 8]	loss_train: 1.9516	loss_val: 1.9312	loss_test: 1.9311	accuracy_train: 0.0962	accuracy_val: 0.2037	accuracy_test: 0.1786
[client 9]	loss_train: 1.9675	loss_val: 1.9457	loss_test: 1.9489	accuracy_train: 0.0408	accuracy_val: 0.1238	accuracy_test: 0.1296
curr_round: 7	curr_val_accuracy: 0.1626	curr_test_accuracy: 0.1401
best_round: 0	best_val_accuracy: 0.1626	best_test_accuracy: 0.1401
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Traceback (most recent call last):
  File "G:\Code\python\FedGM\main.py", line 32, in <module>
    trainer.train()
  File "G:\Code\python\FedGM\flcore\trainer.py", line 122, in train
    self.clients[client_id].execute()
  File "G:\Code\python\FedGM\flcore\fedlog\client.py", line 132, in execute
    self.train_model(current_round)
  File "G:\Code\python\FedGM\flcore\fedlog\client.py", line 452, in train_model
    syn_batch = Batch.from_data_list(syn_graph_list).to(self.device)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "G:\conda\envs\gfl\Lib\site-packages\torch_geometric\data\batch.py", line 97, in from_data_list
    batch, slice_dict, inc_dict = collate(
                                  ^^^^^^^^
  File "G:\conda\envs\gfl\Lib\site-packages\torch_geometric\data\collate.py", line 109, in collate
    value, slices, incs = _collate(attr, values, data_list, stores,
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "G:\conda\envs\gfl\Lib\site-packages\torch_geometric\data\collate.py", line 167, in _collate
    slices = cumsum(sizes)
             ^^^^^^^^^^^^^
  File "G:\conda\envs\gfl\Lib\site-packages\torch_geometric\utils\functions.py", line 24, in cumsum
    torch.cumsum(x, dim=dim, out=out.narrow(dim, 1, x.size(dim)))
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
