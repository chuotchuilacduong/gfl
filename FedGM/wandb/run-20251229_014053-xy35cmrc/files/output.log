G:\conda\envs\gfl\Lib\site-packages\torch_geometric\data\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
Associating local subgraph with global graph...: 100%|████████████████████████████| 170/170 [00:00<00:00, 10316.90it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 140/140 [00:00<00:00, 21307.11it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 174/174 [00:00<00:00, 26084.17it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████████| 96/96 [00:00<00:00, 21307.78it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 156/156 [00:00<00:00, 18407.46it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████████| 84/84 [00:00<00:00, 16815.65it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 126/126 [00:00<00:00, 21002.36it/s]
Associating local subgraph with global graph...: 100%|█████████████████████████████| 120/120 [00:00<00:00, 6003.51it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 136/136 [00:00<00:00, 24257.94it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 180/180 [00:00<00:00, 21467.05it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████████| 86/86 [00:00<00:00, 24741.76it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████████| 82/82 [00:00<00:00, 20355.88it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████████| 96/96 [00:00<00:00, 22299.01it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 112/112 [00:00<00:00, 13984.76it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 100/100 [00:00<00:00, 23515.95it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 142/142 [00:00<00:00, 23382.19it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 314/314 [00:00<00:00, 23403.97it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 150/150 [00:00<00:00, 15269.41it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████████| 82/82 [00:00<00:00, 15138.56it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 118/118 [00:00<00:00, 21455.17it/s]
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.2212	loss_train: 0.0817	loss_degree: 0.0243	loss_feat: 0.0000	loss_cls: 1.6096	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.2699	loss_train: 0.0810	loss_degree: 0.0238	loss_feat: 0.0000	loss_cls: 1.5961	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.4425	loss_train: 0.0803	loss_degree: 0.0232	loss_feat: 0.0000	loss_cls: 1.5833	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.1033	loss_train: 0.0818	loss_degree: 0.0226	loss_feat: 0.0000	loss_cls: 1.6139	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.3641	loss_train: 0.0809	loss_degree: 0.0213	loss_feat: 0.0000	loss_cls: 1.5966	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.4783	loss_train: 0.0800	loss_degree: 0.0205	loss_feat: 0.0000	loss_cls: 1.5800	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.2045	loss_train: 0.0821	loss_degree: 0.0351	loss_feat: 0.0000	loss_cls: 1.6074	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4273	loss_train: 0.0811	loss_degree: 0.0337	loss_feat: 0.0000	loss_cls: 1.5883	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4273	loss_train: 0.0801	loss_degree: 0.0328	loss_feat: 0.0000	loss_cls: 1.5701	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.3006	loss_train: 0.0811	loss_degree: 0.0211	loss_feat: 0.0000	loss_cls: 1.6007	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.3742	loss_train: 0.0801	loss_degree: 0.0204	loss_feat: 0.0000	loss_cls: 1.5823	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.3865	loss_train: 0.0792	loss_degree: 0.0200	loss_feat: 0.0000	loss_cls: 1.5650	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.2056	loss_train: 0.0818	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.6080	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.3738	loss_train: 0.0810	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.5928	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5234	loss_train: 0.0803	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.5784	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.2086	loss_train: 0.0808	loss_degree: 0.0066	loss_feat: 0.0000	loss_cls: 1.6097	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.2883	loss_train: 0.0801	loss_degree: 0.0062	loss_feat: 0.0000	loss_cls: 1.5956	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.3313	loss_train: 0.0794	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.5825	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.2263	loss_train: 0.0813	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.6102	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.3263	loss_train: 0.0805	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.5942	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.4632	loss_train: 0.0797	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.5789	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.1604	loss_train: 0.0814	loss_degree: 0.0138	loss_feat: 0.0000	loss_cls: 1.6142	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.2689	loss_train: 0.0807	loss_degree: 0.0135	loss_feat: 0.0000	loss_cls: 1.6003	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.4245	loss_train: 0.0800	loss_degree: 0.0134	loss_feat: 0.0000	loss_cls: 1.5872	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.2469	loss_train: 0.0811	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.6052	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.4012	loss_train: 0.0803	loss_degree: 0.0151	loss_feat: 0.0000	loss_cls: 1.5905	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.4753	loss_train: 0.0796	loss_degree: 0.0147	loss_feat: 0.0000	loss_cls: 1.5768	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.2442	loss_train: 0.0818	loss_degree: 0.0269	loss_feat: 0.0000	loss_cls: 1.6087	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3088	loss_train: 0.0811	loss_degree: 0.0261	loss_feat: 0.0000	loss_cls: 1.5950	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.2995	loss_train: 0.0804	loss_degree: 0.0256	loss_feat: 0.0000	loss_cls: 1.5821	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.2800	loss_train: 0.0805	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.6003	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.3533	loss_train: 0.0798	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.5862	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.4600	loss_train: 0.0791	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.5729	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.2000	loss_train: 0.0810	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.6079	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.2529	loss_train: 0.0802	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.5915	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4294	loss_train: 0.0794	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.5761	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.2703	loss_train: 0.0803	loss_degree: 0.0074	loss_feat: 0.0000	loss_cls: 1.5990	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.3243	loss_train: 0.0796	loss_degree: 0.0068	loss_feat: 0.0000	loss_cls: 1.5850	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.3514	loss_train: 0.0789	loss_degree: 0.0065	loss_feat: 0.0000	loss_cls: 1.5716	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.1143	loss_train: 0.0820	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.6227	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.2800	loss_train: 0.0810	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.6028	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.4114	loss_train: 0.0801	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.5840	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.2632	loss_train: 0.0810	loss_degree: 0.0131	loss_feat: 0.0000	loss_cls: 1.6063	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4158	loss_train: 0.0801	loss_degree: 0.0130	loss_feat: 0.0000	loss_cls: 1.5896	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4158	loss_train: 0.0793	loss_degree: 0.0126	loss_feat: 0.0000	loss_cls: 1.5738	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.2464	loss_train: 0.0814	loss_degree: 0.0217	loss_feat: 0.0000	loss_cls: 1.6071	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.3865	loss_train: 0.0808	loss_degree: 0.0213	loss_feat: 0.0000	loss_cls: 1.5941	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.3961	loss_train: 0.0801	loss_degree: 0.0207	loss_feat: 0.0000	loss_cls: 1.5819	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.2699	loss_train: 0.0810	loss_degree: 0.0191	loss_feat: 0.0000	loss_cls: 1.6011	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.3584	loss_train: 0.0802	loss_degree: 0.0186	loss_feat: 0.0000	loss_cls: 1.5862	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4115	loss_train: 0.0795	loss_degree: 0.0184	loss_feat: 0.0000	loss_cls: 1.5724	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.0983	loss_train: 0.0831	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.6187	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.2254	loss_train: 0.0824	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.6039	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.3468	loss_train: 0.0817	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.5900	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.2331	loss_train: 0.0812	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.6088	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.2393	loss_train: 0.0805	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.5951	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.2699	loss_train: 0.0799	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.5823	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.0852	loss_train: 0.0816	loss_degree: 0.0155	loss_feat: 0.0000	loss_cls: 1.6173	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.2332	loss_train: 0.0810	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.6051	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.4529	loss_train: 0.0804	loss_degree: 0.0150	loss_feat: 0.0000	loss_cls: 1.5934	loss_other: 0.0000
[server]	loss_train: 1.6140	loss_val: 1.6111	loss_test: 1.6117	accuracy_train: 0.2257	accuracy_val: 0.1681	accuracy_test: 0.2261
[server]	loss_train: 1.6009	loss_val: 1.6037	loss_test: 1.6027	accuracy_train: 0.2500	accuracy_val: 0.2500	accuracy_test: 0.3021
[server]	loss_train: 1.6078	loss_val: 1.6092	loss_test: 1.6088	accuracy_train: 0.1591	accuracy_val: 0.1101	accuracy_test: 0.1261
[server]	loss_train: 1.6190	loss_val: 1.6176	loss_test: 1.6183	accuracy_train: 0.1472	accuracy_val: 0.1098	accuracy_test: 0.1446
[server]	loss_train: 1.6042	loss_val: 1.6038	loss_test: 1.6045	accuracy_train: 0.1682	accuracy_val: 0.1667	accuracy_test: 0.2018
[server]	loss_train: 1.6047	loss_val: 1.5991	loss_test: 1.6060	accuracy_train: 0.1718	accuracy_val: 0.1975	accuracy_test: 0.1905
[server]	loss_train: 1.6052	loss_val: 1.6059	loss_test: 1.6067	accuracy_train: 0.1947	accuracy_val: 0.1789	accuracy_test: 0.1856
[server]	loss_train: 1.6051	loss_val: 1.6056	loss_test: 1.6046	accuracy_train: 0.1651	accuracy_val: 0.2243	accuracy_test: 0.1743
[server]	loss_train: 1.6007	loss_val: 1.6014	loss_test: 1.6013	accuracy_train: 0.2222	accuracy_val: 0.1829	accuracy_test: 0.2619
[server]	loss_train: 1.6064	loss_val: 1.6062	loss_test: 1.6082	accuracy_train: 0.1982	accuracy_val: 0.2037	accuracy_test: 0.1622
[server]	loss_train: 1.6028	loss_val: 1.6054	loss_test: 1.5998	accuracy_train: 0.2200	accuracy_val: 0.2162	accuracy_test: 0.2338
[server]	loss_train: 1.6070	loss_val: 1.6079	loss_test: 1.6103	accuracy_train: 0.1706	accuracy_val: 0.1744	accuracy_test: 0.1724
[server]	loss_train: 1.6013	loss_val: 1.6021	loss_test: 1.6027	accuracy_train: 0.2432	accuracy_val: 0.2568	accuracy_test: 0.1948
[server]	loss_train: 1.6044	loss_val: 1.6050	loss_test: 1.6052	accuracy_train: 0.2229	accuracy_val: 0.2584	accuracy_test: 0.1868
[server]	loss_train: 1.6097	loss_val: 1.6092	loss_test: 1.6086	accuracy_train: 0.1263	accuracy_val: 0.1489	accuracy_test: 0.1616
[server]	loss_train: 1.6057	loss_val: 1.6071	loss_test: 1.6056	accuracy_train: 0.2319	accuracy_val: 0.2353	accuracy_test: 0.1604
[server]	loss_train: 1.6101	loss_val: 1.6118	loss_test: 1.6077	accuracy_train: 0.2124	accuracy_val: 0.2212	accuracy_test: 0.2087
[server]	loss_train: 1.6001	loss_val: 1.5976	loss_test: 1.5967	accuracy_train: 0.2486	accuracy_val: 0.2471	accuracy_test: 0.2360
[server]	loss_train: 1.6033	loss_val: 1.6047	loss_test: 1.6066	accuracy_train: 0.1840	accuracy_val: 0.2346	accuracy_test: 0.1667
[server]	loss_train: 1.5996	loss_val: 1.5973	loss_test: 1.6011	accuracy_train: 0.2242	accuracy_val: 0.2523	accuracy_test: 0.1930
curr_round: 0	curr_val_accuracy: 0.2010	curr_test_accuracy: 0.1934
best_round: 0	best_val_accuracy: 0.2010	best_test_accuracy: 0.1934
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.5221	loss_train: 0.0797	loss_degree: 0.0229	loss_feat: 0.0000	loss_cls: 1.5711	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.5796	loss_train: 0.0791	loss_degree: 0.0226	loss_feat: 0.0000	loss_cls: 1.5592	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6018	loss_train: 0.0785	loss_degree: 0.0224	loss_feat: 0.0000	loss_cls: 1.5473	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.5054	loss_train: 0.0792	loss_degree: 0.0199	loss_feat: 0.0000	loss_cls: 1.5638	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.5489	loss_train: 0.0784	loss_degree: 0.0195	loss_feat: 0.0000	loss_cls: 1.5477	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.5707	loss_train: 0.0775	loss_degree: 0.0192	loss_feat: 0.0000	loss_cls: 1.5314	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0792	loss_degree: 0.0322	loss_feat: 0.0000	loss_cls: 1.5523	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4227	loss_train: 0.0783	loss_degree: 0.0317	loss_feat: 0.0000	loss_cls: 1.5346	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4227	loss_train: 0.0774	loss_degree: 0.0313	loss_feat: 0.0000	loss_cls: 1.5169	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4110	loss_train: 0.0784	loss_degree: 0.0196	loss_feat: 0.0000	loss_cls: 1.5482	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4172	loss_train: 0.0775	loss_degree: 0.0192	loss_feat: 0.0000	loss_cls: 1.5316	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4294	loss_train: 0.0767	loss_degree: 0.0190	loss_feat: 0.0000	loss_cls: 1.5148	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5514	loss_train: 0.0796	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.5647	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5514	loss_train: 0.0790	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.5512	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5374	loss_train: 0.0783	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.5378	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.3620	loss_train: 0.0788	loss_degree: 0.0060	loss_feat: 0.0000	loss_cls: 1.5699	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.3926	loss_train: 0.0782	loss_degree: 0.0059	loss_feat: 0.0000	loss_cls: 1.5576	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.4294	loss_train: 0.0776	loss_degree: 0.0058	loss_feat: 0.0000	loss_cls: 1.5454	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5421	loss_train: 0.0790	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.5641	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5316	loss_train: 0.0783	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.5495	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5421	loss_train: 0.0775	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.5348	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5472	loss_train: 0.0794	loss_degree: 0.0132	loss_feat: 0.0000	loss_cls: 1.5747	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.6038	loss_train: 0.0788	loss_degree: 0.0131	loss_feat: 0.0000	loss_cls: 1.5624	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.6415	loss_train: 0.0782	loss_degree: 0.0130	loss_feat: 0.0000	loss_cls: 1.5502	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.5062	loss_train: 0.0789	loss_degree: 0.0145	loss_feat: 0.0000	loss_cls: 1.5637	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.5309	loss_train: 0.0783	loss_degree: 0.0142	loss_feat: 0.0000	loss_cls: 1.5509	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.5494	loss_train: 0.0776	loss_degree: 0.0140	loss_feat: 0.0000	loss_cls: 1.5384	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.2995	loss_train: 0.0797	loss_degree: 0.0252	loss_feat: 0.0000	loss_cls: 1.5695	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3088	loss_train: 0.0791	loss_degree: 0.0248	loss_feat: 0.0000	loss_cls: 1.5571	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3134	loss_train: 0.0785	loss_degree: 0.0246	loss_feat: 0.0000	loss_cls: 1.5447	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.5200	loss_train: 0.0785	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.5601	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.5533	loss_train: 0.0779	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.5475	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.5800	loss_train: 0.0772	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.5349	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4882	loss_train: 0.0786	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.5612	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.5000	loss_train: 0.0779	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.5465	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4941	loss_train: 0.0772	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.5317	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.3986	loss_train: 0.0783	loss_degree: 0.0065	loss_feat: 0.0000	loss_cls: 1.5587	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.4595	loss_train: 0.0776	loss_degree: 0.0064	loss_feat: 0.0000	loss_cls: 1.5460	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.4797	loss_train: 0.0770	loss_degree: 0.0064	loss_feat: 0.0000	loss_cls: 1.5333	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.5086	loss_train: 0.0792	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.5659	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.5314	loss_train: 0.0782	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.5478	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.5429	loss_train: 0.0773	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.5297	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4105	loss_train: 0.0785	loss_degree: 0.0122	loss_feat: 0.0000	loss_cls: 1.5585	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4158	loss_train: 0.0778	loss_degree: 0.0119	loss_feat: 0.0000	loss_cls: 1.5433	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4158	loss_train: 0.0770	loss_degree: 0.0117	loss_feat: 0.0000	loss_cls: 1.5278	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.4106	loss_train: 0.0795	loss_degree: 0.0203	loss_feat: 0.0000	loss_cls: 1.5701	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.3865	loss_train: 0.0789	loss_degree: 0.0202	loss_feat: 0.0000	loss_cls: 1.5587	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.3816	loss_train: 0.0784	loss_degree: 0.0201	loss_feat: 0.0000	loss_cls: 1.5474	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4204	loss_train: 0.0789	loss_degree: 0.0181	loss_feat: 0.0000	loss_cls: 1.5593	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4292	loss_train: 0.0782	loss_degree: 0.0179	loss_feat: 0.0000	loss_cls: 1.5466	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4336	loss_train: 0.0776	loss_degree: 0.0177	loss_feat: 0.0000	loss_cls: 1.5342	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5087	loss_train: 0.0810	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.5768	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.6069	loss_train: 0.0804	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.5639	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5954	loss_train: 0.0797	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.5512	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.3252	loss_train: 0.0793	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.5700	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.3436	loss_train: 0.0787	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.5581	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.3742	loss_train: 0.0781	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.5463	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.5247	loss_train: 0.0799	loss_degree: 0.0148	loss_feat: 0.0000	loss_cls: 1.5822	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.5202	loss_train: 0.0793	loss_degree: 0.0147	loss_feat: 0.0000	loss_cls: 1.5712	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.5516	loss_train: 0.0787	loss_degree: 0.0147	loss_feat: 0.0000	loss_cls: 1.5603	loss_other: 0.0000
[server]	loss_train: 1.6140	loss_val: 1.6111	loss_test: 1.6117	accuracy_train: 0.2257	accuracy_val: 0.1681	accuracy_test: 0.2261
[server]	loss_train: 1.6009	loss_val: 1.6037	loss_test: 1.6027	accuracy_train: 0.2500	accuracy_val: 0.2500	accuracy_test: 0.3021
[server]	loss_train: 1.6078	loss_val: 1.6092	loss_test: 1.6088	accuracy_train: 0.1591	accuracy_val: 0.1101	accuracy_test: 0.1261
[server]	loss_train: 1.6190	loss_val: 1.6176	loss_test: 1.6183	accuracy_train: 0.1472	accuracy_val: 0.1098	accuracy_test: 0.1446
[server]	loss_train: 1.6042	loss_val: 1.6038	loss_test: 1.6045	accuracy_train: 0.1682	accuracy_val: 0.1667	accuracy_test: 0.2018
[server]	loss_train: 1.6047	loss_val: 1.5991	loss_test: 1.6060	accuracy_train: 0.1718	accuracy_val: 0.1975	accuracy_test: 0.1905
[server]	loss_train: 1.6052	loss_val: 1.6059	loss_test: 1.6067	accuracy_train: 0.1947	accuracy_val: 0.1789	accuracy_test: 0.1856
[server]	loss_train: 1.6051	loss_val: 1.6056	loss_test: 1.6046	accuracy_train: 0.1651	accuracy_val: 0.2243	accuracy_test: 0.1743
[server]	loss_train: 1.6007	loss_val: 1.6014	loss_test: 1.6013	accuracy_train: 0.2222	accuracy_val: 0.1829	accuracy_test: 0.2619
[server]	loss_train: 1.6064	loss_val: 1.6062	loss_test: 1.6082	accuracy_train: 0.1982	accuracy_val: 0.2037	accuracy_test: 0.1622
[server]	loss_train: 1.6028	loss_val: 1.6054	loss_test: 1.5998	accuracy_train: 0.2200	accuracy_val: 0.2162	accuracy_test: 0.2338
[server]	loss_train: 1.6070	loss_val: 1.6079	loss_test: 1.6103	accuracy_train: 0.1706	accuracy_val: 0.1744	accuracy_test: 0.1724
[server]	loss_train: 1.6013	loss_val: 1.6021	loss_test: 1.6027	accuracy_train: 0.2432	accuracy_val: 0.2568	accuracy_test: 0.1948
[server]	loss_train: 1.6044	loss_val: 1.6050	loss_test: 1.6052	accuracy_train: 0.2229	accuracy_val: 0.2584	accuracy_test: 0.1868
[server]	loss_train: 1.6097	loss_val: 1.6092	loss_test: 1.6086	accuracy_train: 0.1263	accuracy_val: 0.1489	accuracy_test: 0.1616
[server]	loss_train: 1.6057	loss_val: 1.6071	loss_test: 1.6056	accuracy_train: 0.2319	accuracy_val: 0.2353	accuracy_test: 0.1604
[server]	loss_train: 1.6101	loss_val: 1.6118	loss_test: 1.6077	accuracy_train: 0.2124	accuracy_val: 0.2212	accuracy_test: 0.2087
[server]	loss_train: 1.6001	loss_val: 1.5976	loss_test: 1.5967	accuracy_train: 0.2486	accuracy_val: 0.2471	accuracy_test: 0.2360
[server]	loss_train: 1.6033	loss_val: 1.6047	loss_test: 1.6066	accuracy_train: 0.1840	accuracy_val: 0.2346	accuracy_test: 0.1667
[server]	loss_train: 1.5996	loss_val: 1.5973	loss_test: 1.6011	accuracy_train: 0.2242	accuracy_val: 0.2523	accuracy_test: 0.1930
curr_round: 1	curr_val_accuracy: 0.2010	curr_test_accuracy: 0.1934
best_round: 0	best_val_accuracy: 0.2010	best_test_accuracy: 0.1934
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6018	loss_train: 0.0779	loss_degree: 0.0221	loss_feat: 0.0000	loss_cls: 1.5353	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6239	loss_train: 0.0773	loss_degree: 0.0220	loss_feat: 0.0000	loss_cls: 1.5231	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6195	loss_train: 0.0766	loss_degree: 0.0218	loss_feat: 0.0000	loss_cls: 1.5105	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.5707	loss_train: 0.0767	loss_degree: 0.0190	loss_feat: 0.0000	loss_cls: 1.5148	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.5870	loss_train: 0.0758	loss_degree: 0.0187	loss_feat: 0.0000	loss_cls: 1.4978	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.5815	loss_train: 0.0749	loss_degree: 0.0185	loss_feat: 0.0000	loss_cls: 1.4801	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0765	loss_degree: 0.0309	loss_feat: 0.0000	loss_cls: 1.4989	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0755	loss_degree: 0.0306	loss_feat: 0.0000	loss_cls: 1.4804	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0746	loss_degree: 0.0303	loss_feat: 0.0000	loss_cls: 1.4614	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4417	loss_train: 0.0758	loss_degree: 0.0187	loss_feat: 0.0000	loss_cls: 1.4977	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4356	loss_train: 0.0749	loss_degree: 0.0185	loss_feat: 0.0000	loss_cls: 1.4803	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4479	loss_train: 0.0740	loss_degree: 0.0183	loss_feat: 0.0000	loss_cls: 1.4625	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5701	loss_train: 0.0776	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.5243	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5654	loss_train: 0.0769	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.5104	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5654	loss_train: 0.0762	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.4962	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.4785	loss_train: 0.0769	loss_degree: 0.0058	loss_feat: 0.0000	loss_cls: 1.5331	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.5399	loss_train: 0.0763	loss_degree: 0.0057	loss_feat: 0.0000	loss_cls: 1.5204	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.5460	loss_train: 0.0757	loss_degree: 0.0057	loss_feat: 0.0000	loss_cls: 1.5074	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5789	loss_train: 0.0768	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.5199	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5684	loss_train: 0.0760	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.5046	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5842	loss_train: 0.0752	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.4889	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.6368	loss_train: 0.0775	loss_degree: 0.0130	loss_feat: 0.0000	loss_cls: 1.5380	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.6557	loss_train: 0.0769	loss_degree: 0.0129	loss_feat: 0.0000	loss_cls: 1.5254	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.6415	loss_train: 0.0763	loss_degree: 0.0129	loss_feat: 0.0000	loss_cls: 1.5126	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.5802	loss_train: 0.0770	loss_degree: 0.0139	loss_feat: 0.0000	loss_cls: 1.5257	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.6111	loss_train: 0.0763	loss_degree: 0.0137	loss_feat: 0.0000	loss_cls: 1.5129	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.6173	loss_train: 0.0757	loss_degree: 0.0136	loss_feat: 0.0000	loss_cls: 1.4997	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3180	loss_train: 0.0778	loss_degree: 0.0243	loss_feat: 0.0000	loss_cls: 1.5322	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3226	loss_train: 0.0772	loss_degree: 0.0241	loss_feat: 0.0000	loss_cls: 1.5194	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3226	loss_train: 0.0765	loss_degree: 0.0239	loss_feat: 0.0000	loss_cls: 1.5064	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.5867	loss_train: 0.0766	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.5222	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.6067	loss_train: 0.0760	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.5092	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.6000	loss_train: 0.0753	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.4958	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4824	loss_train: 0.0764	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.5167	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4706	loss_train: 0.0757	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.5013	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4529	loss_train: 0.0749	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.4853	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.4932	loss_train: 0.0763	loss_degree: 0.0063	loss_feat: 0.0000	loss_cls: 1.5204	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.5135	loss_train: 0.0757	loss_degree: 0.0062	loss_feat: 0.0000	loss_cls: 1.5072	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.5405	loss_train: 0.0750	loss_degree: 0.0062	loss_feat: 0.0000	loss_cls: 1.4935	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.5543	loss_train: 0.0764	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.5113	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.5714	loss_train: 0.0755	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.4926	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.5886	loss_train: 0.0745	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.4734	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4158	loss_train: 0.0762	loss_degree: 0.0115	loss_feat: 0.0000	loss_cls: 1.5121	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4158	loss_train: 0.0754	loss_degree: 0.0113	loss_feat: 0.0000	loss_cls: 1.4957	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4158	loss_train: 0.0745	loss_degree: 0.0111	loss_feat: 0.0000	loss_cls: 1.4788	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.3720	loss_train: 0.0778	loss_degree: 0.0200	loss_feat: 0.0000	loss_cls: 1.5361	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.3671	loss_train: 0.0772	loss_degree: 0.0199	loss_feat: 0.0000	loss_cls: 1.5246	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.3671	loss_train: 0.0766	loss_degree: 0.0198	loss_feat: 0.0000	loss_cls: 1.5128	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4425	loss_train: 0.0770	loss_degree: 0.0176	loss_feat: 0.0000	loss_cls: 1.5217	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4513	loss_train: 0.0763	loss_degree: 0.0175	loss_feat: 0.0000	loss_cls: 1.5092	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4558	loss_train: 0.0757	loss_degree: 0.0174	loss_feat: 0.0000	loss_cls: 1.4964	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5723	loss_train: 0.0791	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.5383	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5780	loss_train: 0.0784	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.5253	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5665	loss_train: 0.0778	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.5119	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4110	loss_train: 0.0775	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.5343	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4417	loss_train: 0.0769	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.5222	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4540	loss_train: 0.0762	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.5096	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.5605	loss_train: 0.0782	loss_degree: 0.0146	loss_feat: 0.0000	loss_cls: 1.5493	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.5785	loss_train: 0.0776	loss_degree: 0.0145	loss_feat: 0.0000	loss_cls: 1.5380	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6099	loss_train: 0.0770	loss_degree: 0.0145	loss_feat: 0.0000	loss_cls: 1.5264	loss_other: 0.0000
[server]	loss_train: 1.6140	loss_val: 1.6111	loss_test: 1.6117	accuracy_train: 0.2257	accuracy_val: 0.1681	accuracy_test: 0.2261
[server]	loss_train: 1.6009	loss_val: 1.6037	loss_test: 1.6027	accuracy_train: 0.2500	accuracy_val: 0.2500	accuracy_test: 0.3021
[server]	loss_train: 1.6078	loss_val: 1.6092	loss_test: 1.6088	accuracy_train: 0.1591	accuracy_val: 0.1101	accuracy_test: 0.1261
[server]	loss_train: 1.6190	loss_val: 1.6176	loss_test: 1.6183	accuracy_train: 0.1472	accuracy_val: 0.1098	accuracy_test: 0.1446
[server]	loss_train: 1.6042	loss_val: 1.6038	loss_test: 1.6045	accuracy_train: 0.1682	accuracy_val: 0.1667	accuracy_test: 0.2018
[server]	loss_train: 1.6047	loss_val: 1.5991	loss_test: 1.6060	accuracy_train: 0.1718	accuracy_val: 0.1975	accuracy_test: 0.1905
[server]	loss_train: 1.6052	loss_val: 1.6059	loss_test: 1.6067	accuracy_train: 0.1947	accuracy_val: 0.1789	accuracy_test: 0.1856
[server]	loss_train: 1.6051	loss_val: 1.6056	loss_test: 1.6046	accuracy_train: 0.1651	accuracy_val: 0.2243	accuracy_test: 0.1743
[server]	loss_train: 1.6007	loss_val: 1.6014	loss_test: 1.6013	accuracy_train: 0.2222	accuracy_val: 0.1829	accuracy_test: 0.2619
[server]	loss_train: 1.6064	loss_val: 1.6062	loss_test: 1.6082	accuracy_train: 0.1982	accuracy_val: 0.2037	accuracy_test: 0.1622
[server]	loss_train: 1.6028	loss_val: 1.6054	loss_test: 1.5998	accuracy_train: 0.2200	accuracy_val: 0.2162	accuracy_test: 0.2338
[server]	loss_train: 1.6070	loss_val: 1.6079	loss_test: 1.6103	accuracy_train: 0.1706	accuracy_val: 0.1744	accuracy_test: 0.1724
[server]	loss_train: 1.6013	loss_val: 1.6021	loss_test: 1.6027	accuracy_train: 0.2432	accuracy_val: 0.2568	accuracy_test: 0.1948
[server]	loss_train: 1.6044	loss_val: 1.6050	loss_test: 1.6052	accuracy_train: 0.2229	accuracy_val: 0.2584	accuracy_test: 0.1868
[server]	loss_train: 1.6097	loss_val: 1.6092	loss_test: 1.6086	accuracy_train: 0.1263	accuracy_val: 0.1489	accuracy_test: 0.1616
[server]	loss_train: 1.6057	loss_val: 1.6071	loss_test: 1.6056	accuracy_train: 0.2319	accuracy_val: 0.2353	accuracy_test: 0.1604
[server]	loss_train: 1.6101	loss_val: 1.6118	loss_test: 1.6077	accuracy_train: 0.2124	accuracy_val: 0.2212	accuracy_test: 0.2087
[server]	loss_train: 1.6001	loss_val: 1.5976	loss_test: 1.5967	accuracy_train: 0.2486	accuracy_val: 0.2471	accuracy_test: 0.2360
[server]	loss_train: 1.6033	loss_val: 1.6047	loss_test: 1.6066	accuracy_train: 0.1840	accuracy_val: 0.2346	accuracy_test: 0.1667
[server]	loss_train: 1.5996	loss_val: 1.5973	loss_test: 1.6011	accuracy_train: 0.2242	accuracy_val: 0.2523	accuracy_test: 0.1930
curr_round: 2	curr_val_accuracy: 0.2010	curr_test_accuracy: 0.1934
best_round: 0	best_val_accuracy: 0.2010	best_test_accuracy: 0.1934
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.5973	loss_train: 0.0760	loss_degree: 0.0217	loss_feat: 0.0000	loss_cls: 1.4975	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6062	loss_train: 0.0753	loss_degree: 0.0216	loss_feat: 0.0000	loss_cls: 1.4839	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.5973	loss_train: 0.0746	loss_degree: 0.0215	loss_feat: 0.0000	loss_cls: 1.4697	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.5924	loss_train: 0.0740	loss_degree: 0.0184	loss_feat: 0.0000	loss_cls: 1.4619	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.5978	loss_train: 0.0731	loss_degree: 0.0182	loss_feat: 0.0000	loss_cls: 1.4430	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6087	loss_train: 0.0721	loss_degree: 0.0181	loss_feat: 0.0000	loss_cls: 1.4236	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0736	loss_degree: 0.0300	loss_feat: 0.0000	loss_cls: 1.4419	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0726	loss_degree: 0.0297	loss_feat: 0.0000	loss_cls: 1.4219	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0716	loss_degree: 0.0294	loss_feat: 0.0000	loss_cls: 1.4017	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4479	loss_train: 0.0731	loss_degree: 0.0181	loss_feat: 0.0000	loss_cls: 1.4442	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4479	loss_train: 0.0722	loss_degree: 0.0179	loss_feat: 0.0000	loss_cls: 1.4257	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4479	loss_train: 0.0712	loss_degree: 0.0177	loss_feat: 0.0000	loss_cls: 1.4069	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5654	loss_train: 0.0755	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.4814	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5654	loss_train: 0.0747	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.4661	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5701	loss_train: 0.0739	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.4503	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.5828	loss_train: 0.0750	loss_degree: 0.0057	loss_feat: 0.0000	loss_cls: 1.4938	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6135	loss_train: 0.0743	loss_degree: 0.0056	loss_feat: 0.0000	loss_cls: 1.4797	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6258	loss_train: 0.0735	loss_degree: 0.0055	loss_feat: 0.0000	loss_cls: 1.4650	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5684	loss_train: 0.0744	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.4728	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5684	loss_train: 0.0736	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.4562	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5737	loss_train: 0.0727	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.4391	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.6226	loss_train: 0.0756	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.4993	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.6085	loss_train: 0.0749	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.4856	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.6179	loss_train: 0.0742	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.4714	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.6420	loss_train: 0.0750	loss_degree: 0.0135	loss_feat: 0.0000	loss_cls: 1.4860	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.6543	loss_train: 0.0743	loss_degree: 0.0135	loss_feat: 0.0000	loss_cls: 1.4719	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.6790	loss_train: 0.0735	loss_degree: 0.0134	loss_feat: 0.0000	loss_cls: 1.4572	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3226	loss_train: 0.0758	loss_degree: 0.0238	loss_feat: 0.0000	loss_cls: 1.4930	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3226	loss_train: 0.0751	loss_degree: 0.0236	loss_feat: 0.0000	loss_cls: 1.4793	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3318	loss_train: 0.0744	loss_degree: 0.0235	loss_feat: 0.0000	loss_cls: 1.4653	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.6133	loss_train: 0.0746	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.4819	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.6200	loss_train: 0.0739	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.4675	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.6200	loss_train: 0.0731	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.4527	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4353	loss_train: 0.0740	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.4686	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4235	loss_train: 0.0732	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.4514	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4235	loss_train: 0.0723	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.4336	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.5676	loss_train: 0.0743	loss_degree: 0.0062	loss_feat: 0.0000	loss_cls: 1.4794	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.5743	loss_train: 0.0735	loss_degree: 0.0062	loss_feat: 0.0000	loss_cls: 1.4646	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.5878	loss_train: 0.0728	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.4492	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6000	loss_train: 0.0736	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.4539	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6114	loss_train: 0.0726	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.4340	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6171	loss_train: 0.0716	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.4139	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4158	loss_train: 0.0736	loss_degree: 0.0110	loss_feat: 0.0000	loss_cls: 1.4611	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4211	loss_train: 0.0727	loss_degree: 0.0109	loss_feat: 0.0000	loss_cls: 1.4426	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4158	loss_train: 0.0717	loss_degree: 0.0108	loss_feat: 0.0000	loss_cls: 1.4235	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.3671	loss_train: 0.0760	loss_degree: 0.0197	loss_feat: 0.0000	loss_cls: 1.5006	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.3768	loss_train: 0.0754	loss_degree: 0.0196	loss_feat: 0.0000	loss_cls: 1.4880	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.3816	loss_train: 0.0747	loss_degree: 0.0196	loss_feat: 0.0000	loss_cls: 1.4749	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4558	loss_train: 0.0750	loss_degree: 0.0173	loss_feat: 0.0000	loss_cls: 1.4834	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4602	loss_train: 0.0744	loss_degree: 0.0172	loss_feat: 0.0000	loss_cls: 1.4702	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4646	loss_train: 0.0737	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.4567	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5665	loss_train: 0.0771	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.4981	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5607	loss_train: 0.0764	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.4839	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5607	loss_train: 0.0756	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.4692	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4663	loss_train: 0.0756	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.4965	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5031	loss_train: 0.0749	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.4830	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5399	loss_train: 0.0742	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.4689	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6188	loss_train: 0.0764	loss_degree: 0.0145	loss_feat: 0.0000	loss_cls: 1.5144	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6233	loss_train: 0.0758	loss_degree: 0.0144	loss_feat: 0.0000	loss_cls: 1.5019	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6368	loss_train: 0.0752	loss_degree: 0.0144	loss_feat: 0.0000	loss_cls: 1.4890	loss_other: 0.0000
[server]	loss_train: 1.6140	loss_val: 1.6111	loss_test: 1.6117	accuracy_train: 0.2257	accuracy_val: 0.1681	accuracy_test: 0.2261
[server]	loss_train: 1.6009	loss_val: 1.6037	loss_test: 1.6027	accuracy_train: 0.2500	accuracy_val: 0.2500	accuracy_test: 0.3021
[server]	loss_train: 1.6078	loss_val: 1.6092	loss_test: 1.6088	accuracy_train: 0.1591	accuracy_val: 0.1101	accuracy_test: 0.1261
[server]	loss_train: 1.6190	loss_val: 1.6176	loss_test: 1.6183	accuracy_train: 0.1472	accuracy_val: 0.1098	accuracy_test: 0.1446
[server]	loss_train: 1.6042	loss_val: 1.6038	loss_test: 1.6045	accuracy_train: 0.1682	accuracy_val: 0.1667	accuracy_test: 0.2018
[server]	loss_train: 1.6047	loss_val: 1.5991	loss_test: 1.6060	accuracy_train: 0.1718	accuracy_val: 0.1975	accuracy_test: 0.1905
[server]	loss_train: 1.6052	loss_val: 1.6059	loss_test: 1.6067	accuracy_train: 0.1947	accuracy_val: 0.1789	accuracy_test: 0.1856
[server]	loss_train: 1.6051	loss_val: 1.6056	loss_test: 1.6046	accuracy_train: 0.1651	accuracy_val: 0.2243	accuracy_test: 0.1743
[server]	loss_train: 1.6007	loss_val: 1.6014	loss_test: 1.6013	accuracy_train: 0.2222	accuracy_val: 0.1829	accuracy_test: 0.2619
[server]	loss_train: 1.6064	loss_val: 1.6062	loss_test: 1.6082	accuracy_train: 0.1982	accuracy_val: 0.2037	accuracy_test: 0.1622
[server]	loss_train: 1.6028	loss_val: 1.6054	loss_test: 1.5998	accuracy_train: 0.2200	accuracy_val: 0.2162	accuracy_test: 0.2338
[server]	loss_train: 1.6070	loss_val: 1.6079	loss_test: 1.6103	accuracy_train: 0.1706	accuracy_val: 0.1744	accuracy_test: 0.1724
[server]	loss_train: 1.6013	loss_val: 1.6021	loss_test: 1.6027	accuracy_train: 0.2432	accuracy_val: 0.2568	accuracy_test: 0.1948
[server]	loss_train: 1.6044	loss_val: 1.6050	loss_test: 1.6052	accuracy_train: 0.2229	accuracy_val: 0.2584	accuracy_test: 0.1868
[server]	loss_train: 1.6097	loss_val: 1.6092	loss_test: 1.6086	accuracy_train: 0.1263	accuracy_val: 0.1489	accuracy_test: 0.1616
[server]	loss_train: 1.6057	loss_val: 1.6071	loss_test: 1.6056	accuracy_train: 0.2319	accuracy_val: 0.2353	accuracy_test: 0.1604
[server]	loss_train: 1.6101	loss_val: 1.6118	loss_test: 1.6077	accuracy_train: 0.2124	accuracy_val: 0.2212	accuracy_test: 0.2087
[server]	loss_train: 1.6001	loss_val: 1.5976	loss_test: 1.5967	accuracy_train: 0.2486	accuracy_val: 0.2471	accuracy_test: 0.2360
[server]	loss_train: 1.6033	loss_val: 1.6047	loss_test: 1.6066	accuracy_train: 0.1840	accuracy_val: 0.2346	accuracy_test: 0.1667
[server]	loss_train: 1.5996	loss_val: 1.5973	loss_test: 1.6011	accuracy_train: 0.2242	accuracy_val: 0.2523	accuracy_test: 0.1930
curr_round: 3	curr_val_accuracy: 0.2010	curr_test_accuracy: 0.1934
best_round: 0	best_val_accuracy: 0.2010	best_test_accuracy: 0.1934
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.5885	loss_train: 0.0738	loss_degree: 0.0214	loss_feat: 0.0000	loss_cls: 1.4549	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.5841	loss_train: 0.0730	loss_degree: 0.0213	loss_feat: 0.0000	loss_cls: 1.4395	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.5841	loss_train: 0.0722	loss_degree: 0.0211	loss_feat: 0.0000	loss_cls: 1.4236	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6196	loss_train: 0.0711	loss_degree: 0.0179	loss_feat: 0.0000	loss_cls: 1.4036	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6250	loss_train: 0.0700	loss_degree: 0.0178	loss_feat: 0.0000	loss_cls: 1.3832	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6250	loss_train: 0.0690	loss_degree: 0.0177	loss_feat: 0.0000	loss_cls: 1.3624	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0705	loss_degree: 0.0292	loss_feat: 0.0000	loss_cls: 1.3814	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0695	loss_degree: 0.0289	loss_feat: 0.0000	loss_cls: 1.3612	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0685	loss_degree: 0.0285	loss_feat: 0.0000	loss_cls: 1.3414	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4479	loss_train: 0.0703	loss_degree: 0.0175	loss_feat: 0.0000	loss_cls: 1.3880	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4479	loss_train: 0.0693	loss_degree: 0.0173	loss_feat: 0.0000	loss_cls: 1.3691	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4601	loss_train: 0.0684	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.3503	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5701	loss_train: 0.0731	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.4340	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5701	loss_train: 0.0723	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.4173	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5701	loss_train: 0.0714	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.4001	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6319	loss_train: 0.0728	loss_degree: 0.0055	loss_feat: 0.0000	loss_cls: 1.4496	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6319	loss_train: 0.0719	loss_degree: 0.0054	loss_feat: 0.0000	loss_cls: 1.4335	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6503	loss_train: 0.0711	loss_degree: 0.0054	loss_feat: 0.0000	loss_cls: 1.4168	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5737	loss_train: 0.0719	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.4216	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5737	loss_train: 0.0710	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.4039	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5737	loss_train: 0.0701	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.3859	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.6132	loss_train: 0.0735	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.4567	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5991	loss_train: 0.0727	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.4416	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5991	loss_train: 0.0719	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.4261	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.6790	loss_train: 0.0728	loss_degree: 0.0134	loss_feat: 0.0000	loss_cls: 1.4420	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.6914	loss_train: 0.0720	loss_degree: 0.0133	loss_feat: 0.0000	loss_cls: 1.4262	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.6914	loss_train: 0.0712	loss_degree: 0.0133	loss_feat: 0.0000	loss_cls: 1.4098	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3364	loss_train: 0.0737	loss_degree: 0.0234	loss_feat: 0.0000	loss_cls: 1.4510	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3410	loss_train: 0.0730	loss_degree: 0.0232	loss_feat: 0.0000	loss_cls: 1.4365	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3502	loss_train: 0.0722	loss_degree: 0.0231	loss_feat: 0.0000	loss_cls: 1.4218	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.6333	loss_train: 0.0724	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.4373	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.6333	loss_train: 0.0716	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.4214	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.6467	loss_train: 0.0708	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.4051	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4176	loss_train: 0.0714	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.4153	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4176	loss_train: 0.0704	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.3966	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4176	loss_train: 0.0695	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.3777	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.5946	loss_train: 0.0720	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.4332	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.6149	loss_train: 0.0711	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.4164	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.6216	loss_train: 0.0703	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.3989	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6171	loss_train: 0.0705	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.3937	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6114	loss_train: 0.0695	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.3735	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6000	loss_train: 0.0685	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.3533	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4158	loss_train: 0.0707	loss_degree: 0.0107	loss_feat: 0.0000	loss_cls: 1.4039	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4158	loss_train: 0.0697	loss_degree: 0.0106	loss_feat: 0.0000	loss_cls: 1.3837	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4211	loss_train: 0.0687	loss_degree: 0.0106	loss_feat: 0.0000	loss_cls: 1.3633	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.3816	loss_train: 0.0740	loss_degree: 0.0196	loss_feat: 0.0000	loss_cls: 1.4614	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.3865	loss_train: 0.0734	loss_degree: 0.0196	loss_feat: 0.0000	loss_cls: 1.4474	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.3913	loss_train: 0.0726	loss_degree: 0.0196	loss_feat: 0.0000	loss_cls: 1.4331	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4646	loss_train: 0.0730	loss_degree: 0.0170	loss_feat: 0.0000	loss_cls: 1.4429	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4735	loss_train: 0.0723	loss_degree: 0.0170	loss_feat: 0.0000	loss_cls: 1.4287	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4823	loss_train: 0.0716	loss_degree: 0.0169	loss_feat: 0.0000	loss_cls: 1.4143	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5607	loss_train: 0.0749	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.4540	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5665	loss_train: 0.0741	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.4384	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5607	loss_train: 0.0733	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.4222	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5644	loss_train: 0.0735	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.4544	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5890	loss_train: 0.0727	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.4393	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5890	loss_train: 0.0720	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.4239	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6457	loss_train: 0.0745	loss_degree: 0.0144	loss_feat: 0.0000	loss_cls: 1.4755	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6592	loss_train: 0.0738	loss_degree: 0.0144	loss_feat: 0.0000	loss_cls: 1.4615	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6457	loss_train: 0.0731	loss_degree: 0.0144	loss_feat: 0.0000	loss_cls: 1.4471	loss_other: 0.0000
[server]	loss_train: 1.6140	loss_val: 1.6111	loss_test: 1.6117	accuracy_train: 0.2257	accuracy_val: 0.1681	accuracy_test: 0.2261
[server]	loss_train: 1.6009	loss_val: 1.6037	loss_test: 1.6027	accuracy_train: 0.2500	accuracy_val: 0.2500	accuracy_test: 0.3021
[server]	loss_train: 1.6078	loss_val: 1.6092	loss_test: 1.6088	accuracy_train: 0.1591	accuracy_val: 0.1101	accuracy_test: 0.1261
[server]	loss_train: 1.6190	loss_val: 1.6176	loss_test: 1.6183	accuracy_train: 0.1472	accuracy_val: 0.1098	accuracy_test: 0.1446
[server]	loss_train: 1.6042	loss_val: 1.6038	loss_test: 1.6045	accuracy_train: 0.1682	accuracy_val: 0.1667	accuracy_test: 0.2018
[server]	loss_train: 1.6047	loss_val: 1.5991	loss_test: 1.6060	accuracy_train: 0.1718	accuracy_val: 0.1975	accuracy_test: 0.1905
[server]	loss_train: 1.6052	loss_val: 1.6059	loss_test: 1.6067	accuracy_train: 0.1947	accuracy_val: 0.1789	accuracy_test: 0.1856
[server]	loss_train: 1.6051	loss_val: 1.6056	loss_test: 1.6046	accuracy_train: 0.1651	accuracy_val: 0.2243	accuracy_test: 0.1743
[server]	loss_train: 1.6007	loss_val: 1.6014	loss_test: 1.6013	accuracy_train: 0.2222	accuracy_val: 0.1829	accuracy_test: 0.2619
[server]	loss_train: 1.6064	loss_val: 1.6062	loss_test: 1.6082	accuracy_train: 0.1982	accuracy_val: 0.2037	accuracy_test: 0.1622
[server]	loss_train: 1.6028	loss_val: 1.6054	loss_test: 1.5998	accuracy_train: 0.2200	accuracy_val: 0.2162	accuracy_test: 0.2338
[server]	loss_train: 1.6070	loss_val: 1.6079	loss_test: 1.6103	accuracy_train: 0.1706	accuracy_val: 0.1744	accuracy_test: 0.1724
[server]	loss_train: 1.6013	loss_val: 1.6021	loss_test: 1.6027	accuracy_train: 0.2432	accuracy_val: 0.2568	accuracy_test: 0.1948
[server]	loss_train: 1.6044	loss_val: 1.6050	loss_test: 1.6052	accuracy_train: 0.2229	accuracy_val: 0.2584	accuracy_test: 0.1868
[server]	loss_train: 1.6097	loss_val: 1.6092	loss_test: 1.6086	accuracy_train: 0.1263	accuracy_val: 0.1489	accuracy_test: 0.1616
[server]	loss_train: 1.6057	loss_val: 1.6071	loss_test: 1.6056	accuracy_train: 0.2319	accuracy_val: 0.2353	accuracy_test: 0.1604
[server]	loss_train: 1.6101	loss_val: 1.6118	loss_test: 1.6077	accuracy_train: 0.2124	accuracy_val: 0.2212	accuracy_test: 0.2087
[server]	loss_train: 1.6001	loss_val: 1.5976	loss_test: 1.5967	accuracy_train: 0.2486	accuracy_val: 0.2471	accuracy_test: 0.2360
[server]	loss_train: 1.6033	loss_val: 1.6047	loss_test: 1.6066	accuracy_train: 0.1840	accuracy_val: 0.2346	accuracy_test: 0.1667
[server]	loss_train: 1.5996	loss_val: 1.5973	loss_test: 1.6011	accuracy_train: 0.2242	accuracy_val: 0.2523	accuracy_test: 0.1930
curr_round: 4	curr_val_accuracy: 0.2010	curr_test_accuracy: 0.1934
best_round: 0	best_val_accuracy: 0.2010	best_test_accuracy: 0.1934
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.5841	loss_train: 0.0714	loss_degree: 0.0210	loss_feat: 0.0000	loss_cls: 1.4072	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.5796	loss_train: 0.0706	loss_degree: 0.0210	loss_feat: 0.0000	loss_cls: 1.3904	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.5796	loss_train: 0.0697	loss_degree: 0.0209	loss_feat: 0.0000	loss_cls: 1.3731	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6250	loss_train: 0.0679	loss_degree: 0.0176	loss_feat: 0.0000	loss_cls: 1.3413	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6304	loss_train: 0.0669	loss_degree: 0.0174	loss_feat: 0.0000	loss_cls: 1.3202	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6304	loss_train: 0.0658	loss_degree: 0.0173	loss_feat: 0.0000	loss_cls: 1.2989	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0675	loss_degree: 0.0282	loss_feat: 0.0000	loss_cls: 1.3220	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0666	loss_degree: 0.0278	loss_feat: 0.0000	loss_cls: 1.3033	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0656	loss_degree: 0.0274	loss_feat: 0.0000	loss_cls: 1.2852	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4663	loss_train: 0.0674	loss_degree: 0.0168	loss_feat: 0.0000	loss_cls: 1.3316	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4663	loss_train: 0.0665	loss_degree: 0.0166	loss_feat: 0.0000	loss_cls: 1.3130	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4663	loss_train: 0.0655	loss_degree: 0.0163	loss_feat: 0.0000	loss_cls: 1.2946	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5748	loss_train: 0.0705	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.3827	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5748	loss_train: 0.0696	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.3649	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5748	loss_train: 0.0687	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.3468	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6503	loss_train: 0.0702	loss_degree: 0.0053	loss_feat: 0.0000	loss_cls: 1.3995	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6442	loss_train: 0.0693	loss_degree: 0.0053	loss_feat: 0.0000	loss_cls: 1.3816	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6442	loss_train: 0.0684	loss_degree: 0.0052	loss_feat: 0.0000	loss_cls: 1.3632	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5737	loss_train: 0.0692	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.3677	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5789	loss_train: 0.0683	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.3494	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5789	loss_train: 0.0673	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.3310	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5991	loss_train: 0.0711	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.4102	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5896	loss_train: 0.0703	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.3941	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5849	loss_train: 0.0695	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.3778	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.6975	loss_train: 0.0703	loss_degree: 0.0132	loss_feat: 0.0000	loss_cls: 1.3929	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.7099	loss_train: 0.0694	loss_degree: 0.0132	loss_feat: 0.0000	loss_cls: 1.3754	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.7037	loss_train: 0.0685	loss_degree: 0.0131	loss_feat: 0.0000	loss_cls: 1.3574	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3502	loss_train: 0.0715	loss_degree: 0.0230	loss_feat: 0.0000	loss_cls: 1.4068	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3641	loss_train: 0.0707	loss_degree: 0.0228	loss_feat: 0.0000	loss_cls: 1.3917	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3779	loss_train: 0.0700	loss_degree: 0.0227	loss_feat: 0.0000	loss_cls: 1.3764	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.6467	loss_train: 0.0699	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.3884	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.6600	loss_train: 0.0691	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.3712	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.6667	loss_train: 0.0682	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.3538	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4118	loss_train: 0.0685	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.3587	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4118	loss_train: 0.0676	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.3396	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4176	loss_train: 0.0666	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.3206	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.6216	loss_train: 0.0693	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.3808	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.6419	loss_train: 0.0684	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.3622	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.6419	loss_train: 0.0675	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.3429	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.5943	loss_train: 0.0675	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.3334	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.5943	loss_train: 0.0665	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.3136	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6000	loss_train: 0.0656	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.2942	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4263	loss_train: 0.0677	loss_degree: 0.0105	loss_feat: 0.0000	loss_cls: 1.3427	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4316	loss_train: 0.0666	loss_degree: 0.0104	loss_feat: 0.0000	loss_cls: 1.3222	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4368	loss_train: 0.0656	loss_degree: 0.0104	loss_feat: 0.0000	loss_cls: 1.3017	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.4058	loss_train: 0.0719	loss_degree: 0.0196	loss_feat: 0.0000	loss_cls: 1.4183	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.4106	loss_train: 0.0711	loss_degree: 0.0195	loss_feat: 0.0000	loss_cls: 1.4031	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.4155	loss_train: 0.0704	loss_degree: 0.0195	loss_feat: 0.0000	loss_cls: 1.3876	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4779	loss_train: 0.0708	loss_degree: 0.0168	loss_feat: 0.0000	loss_cls: 1.3996	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4823	loss_train: 0.0701	loss_degree: 0.0168	loss_feat: 0.0000	loss_cls: 1.3847	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.4912	loss_train: 0.0693	loss_degree: 0.0167	loss_feat: 0.0000	loss_cls: 1.3695	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5607	loss_train: 0.0725	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.4057	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5607	loss_train: 0.0716	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.3887	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5665	loss_train: 0.0707	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.3713	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5951	loss_train: 0.0712	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.4081	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.6012	loss_train: 0.0704	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.3919	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.6012	loss_train: 0.0695	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.3754	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6502	loss_train: 0.0723	loss_degree: 0.0144	loss_feat: 0.0000	loss_cls: 1.4321	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6592	loss_train: 0.0716	loss_degree: 0.0144	loss_feat: 0.0000	loss_cls: 1.4168	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6592	loss_train: 0.0708	loss_degree: 0.0144	loss_feat: 0.0000	loss_cls: 1.4010	loss_other: 0.0000
[server]	loss_train: 1.6140	loss_val: 1.6111	loss_test: 1.6117	accuracy_train: 0.2257	accuracy_val: 0.1681	accuracy_test: 0.2261
[server]	loss_train: 1.6009	loss_val: 1.6037	loss_test: 1.6027	accuracy_train: 0.2500	accuracy_val: 0.2500	accuracy_test: 0.3021
[server]	loss_train: 1.6078	loss_val: 1.6092	loss_test: 1.6088	accuracy_train: 0.1591	accuracy_val: 0.1101	accuracy_test: 0.1261
[server]	loss_train: 1.6190	loss_val: 1.6176	loss_test: 1.6183	accuracy_train: 0.1472	accuracy_val: 0.1098	accuracy_test: 0.1446
[server]	loss_train: 1.6042	loss_val: 1.6038	loss_test: 1.6045	accuracy_train: 0.1682	accuracy_val: 0.1667	accuracy_test: 0.2018
[server]	loss_train: 1.6047	loss_val: 1.5991	loss_test: 1.6060	accuracy_train: 0.1718	accuracy_val: 0.1975	accuracy_test: 0.1905
[server]	loss_train: 1.6052	loss_val: 1.6059	loss_test: 1.6067	accuracy_train: 0.1947	accuracy_val: 0.1789	accuracy_test: 0.1856
[server]	loss_train: 1.6051	loss_val: 1.6056	loss_test: 1.6046	accuracy_train: 0.1651	accuracy_val: 0.2243	accuracy_test: 0.1743
[server]	loss_train: 1.6007	loss_val: 1.6014	loss_test: 1.6013	accuracy_train: 0.2222	accuracy_val: 0.1829	accuracy_test: 0.2619
[server]	loss_train: 1.6064	loss_val: 1.6062	loss_test: 1.6082	accuracy_train: 0.1982	accuracy_val: 0.2037	accuracy_test: 0.1622
[server]	loss_train: 1.6028	loss_val: 1.6054	loss_test: 1.5998	accuracy_train: 0.2200	accuracy_val: 0.2162	accuracy_test: 0.2338
[server]	loss_train: 1.6070	loss_val: 1.6079	loss_test: 1.6103	accuracy_train: 0.1706	accuracy_val: 0.1744	accuracy_test: 0.1724
[server]	loss_train: 1.6013	loss_val: 1.6021	loss_test: 1.6027	accuracy_train: 0.2432	accuracy_val: 0.2568	accuracy_test: 0.1948
[server]	loss_train: 1.6044	loss_val: 1.6050	loss_test: 1.6052	accuracy_train: 0.2229	accuracy_val: 0.2584	accuracy_test: 0.1868
[server]	loss_train: 1.6097	loss_val: 1.6092	loss_test: 1.6086	accuracy_train: 0.1263	accuracy_val: 0.1489	accuracy_test: 0.1616
[server]	loss_train: 1.6057	loss_val: 1.6071	loss_test: 1.6056	accuracy_train: 0.2319	accuracy_val: 0.2353	accuracy_test: 0.1604
[server]	loss_train: 1.6101	loss_val: 1.6118	loss_test: 1.6077	accuracy_train: 0.2124	accuracy_val: 0.2212	accuracy_test: 0.2087
[server]	loss_train: 1.6001	loss_val: 1.5976	loss_test: 1.5967	accuracy_train: 0.2486	accuracy_val: 0.2471	accuracy_test: 0.2360
[server]	loss_train: 1.6033	loss_val: 1.6047	loss_test: 1.6066	accuracy_train: 0.1840	accuracy_val: 0.2346	accuracy_test: 0.1667
[server]	loss_train: 1.5996	loss_val: 1.5973	loss_test: 1.6011	accuracy_train: 0.2242	accuracy_val: 0.2523	accuracy_test: 0.1930
curr_round: 5	curr_val_accuracy: 0.2010	curr_test_accuracy: 0.1934
best_round: 0	best_val_accuracy: 0.2010	best_test_accuracy: 0.1934
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.5885	loss_train: 0.0688	loss_degree: 0.0208	loss_feat: 0.0000	loss_cls: 1.3555	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.5929	loss_train: 0.0679	loss_degree: 0.0207	loss_feat: 0.0000	loss_cls: 1.3375	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.5929	loss_train: 0.0670	loss_degree: 0.0206	loss_feat: 0.0000	loss_cls: 1.3192	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6304	loss_train: 0.0647	loss_degree: 0.0172	loss_feat: 0.0000	loss_cls: 1.2777	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6413	loss_train: 0.0637	loss_degree: 0.0170	loss_feat: 0.0000	loss_cls: 1.2566	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6413	loss_train: 0.0626	loss_degree: 0.0169	loss_feat: 0.0000	loss_cls: 1.2356	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0647	loss_degree: 0.0270	loss_feat: 0.0000	loss_cls: 1.2677	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0639	loss_degree: 0.0265	loss_feat: 0.0000	loss_cls: 1.2507	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0630	loss_degree: 0.0260	loss_feat: 0.0000	loss_cls: 1.2344	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4601	loss_train: 0.0646	loss_degree: 0.0161	loss_feat: 0.0000	loss_cls: 1.2763	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4785	loss_train: 0.0637	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.2582	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4908	loss_train: 0.0628	loss_degree: 0.0155	loss_feat: 0.0000	loss_cls: 1.2403	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5794	loss_train: 0.0678	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.3286	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5841	loss_train: 0.0669	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.3101	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5981	loss_train: 0.0660	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.2914	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6442	loss_train: 0.0675	loss_degree: 0.0052	loss_feat: 0.0000	loss_cls: 1.3443	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6442	loss_train: 0.0665	loss_degree: 0.0052	loss_feat: 0.0000	loss_cls: 1.3250	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6442	loss_train: 0.0655	loss_degree: 0.0052	loss_feat: 0.0000	loss_cls: 1.3052	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5737	loss_train: 0.0664	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.3126	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5737	loss_train: 0.0655	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.2942	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5737	loss_train: 0.0646	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.2757	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5755	loss_train: 0.0687	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.3614	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5755	loss_train: 0.0679	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.3448	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5802	loss_train: 0.0670	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.3282	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.7037	loss_train: 0.0676	loss_degree: 0.0131	loss_feat: 0.0000	loss_cls: 1.3389	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.6975	loss_train: 0.0666	loss_degree: 0.0131	loss_feat: 0.0000	loss_cls: 1.3199	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.7099	loss_train: 0.0657	loss_degree: 0.0130	loss_feat: 0.0000	loss_cls: 1.3005	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3825	loss_train: 0.0692	loss_degree: 0.0226	loss_feat: 0.0000	loss_cls: 1.3609	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3871	loss_train: 0.0684	loss_degree: 0.0224	loss_feat: 0.0000	loss_cls: 1.3453	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.3963	loss_train: 0.0676	loss_degree: 0.0223	loss_feat: 0.0000	loss_cls: 1.3294	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.6800	loss_train: 0.0673	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.3360	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.6933	loss_train: 0.0664	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.3179	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.7067	loss_train: 0.0655	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.2994	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4176	loss_train: 0.0657	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.3019	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4235	loss_train: 0.0648	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.2834	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4235	loss_train: 0.0638	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.2651	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.6486	loss_train: 0.0665	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.3232	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.6554	loss_train: 0.0655	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.3030	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.6689	loss_train: 0.0644	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.2824	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6000	loss_train: 0.0646	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.2750	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.5943	loss_train: 0.0637	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.2562	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6000	loss_train: 0.0627	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.2378	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4368	loss_train: 0.0646	loss_degree: 0.0103	loss_feat: 0.0000	loss_cls: 1.2815	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4368	loss_train: 0.0636	loss_degree: 0.0103	loss_feat: 0.0000	loss_cls: 1.2616	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4579	loss_train: 0.0626	loss_degree: 0.0102	loss_feat: 0.0000	loss_cls: 1.2421	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.4203	loss_train: 0.0696	loss_degree: 0.0195	loss_feat: 0.0000	loss_cls: 1.3717	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.4396	loss_train: 0.0687	loss_degree: 0.0195	loss_feat: 0.0000	loss_cls: 1.3554	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.4589	loss_train: 0.0679	loss_degree: 0.0195	loss_feat: 0.0000	loss_cls: 1.3388	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.5000	loss_train: 0.0685	loss_degree: 0.0166	loss_feat: 0.0000	loss_cls: 1.3540	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.5044	loss_train: 0.0677	loss_degree: 0.0166	loss_feat: 0.0000	loss_cls: 1.3383	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.5133	loss_train: 0.0669	loss_degree: 0.0165	loss_feat: 0.0000	loss_cls: 1.3223	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5723	loss_train: 0.0698	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.3536	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5780	loss_train: 0.0689	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.3355	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.5896	loss_train: 0.0680	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.3169	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.6196	loss_train: 0.0687	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.3587	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.6135	loss_train: 0.0678	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.3417	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.6319	loss_train: 0.0670	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.3244	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6592	loss_train: 0.0700	loss_degree: 0.0144	loss_feat: 0.0000	loss_cls: 1.3849	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6547	loss_train: 0.0691	loss_degree: 0.0144	loss_feat: 0.0000	loss_cls: 1.3685	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6592	loss_train: 0.0683	loss_degree: 0.0144	loss_feat: 0.0000	loss_cls: 1.3517	loss_other: 0.0000
[server]	loss_train: 1.6140	loss_val: 1.6111	loss_test: 1.6117	accuracy_train: 0.2257	accuracy_val: 0.1681	accuracy_test: 0.2261
[server]	loss_train: 1.6009	loss_val: 1.6037	loss_test: 1.6027	accuracy_train: 0.2500	accuracy_val: 0.2500	accuracy_test: 0.3021
[server]	loss_train: 1.6078	loss_val: 1.6092	loss_test: 1.6088	accuracy_train: 0.1591	accuracy_val: 0.1101	accuracy_test: 0.1261
[server]	loss_train: 1.6190	loss_val: 1.6176	loss_test: 1.6183	accuracy_train: 0.1472	accuracy_val: 0.1098	accuracy_test: 0.1446
[server]	loss_train: 1.6042	loss_val: 1.6038	loss_test: 1.6045	accuracy_train: 0.1682	accuracy_val: 0.1667	accuracy_test: 0.2018
[server]	loss_train: 1.6047	loss_val: 1.5991	loss_test: 1.6060	accuracy_train: 0.1718	accuracy_val: 0.1975	accuracy_test: 0.1905
[server]	loss_train: 1.6052	loss_val: 1.6059	loss_test: 1.6067	accuracy_train: 0.1947	accuracy_val: 0.1789	accuracy_test: 0.1856
[server]	loss_train: 1.6051	loss_val: 1.6056	loss_test: 1.6046	accuracy_train: 0.1651	accuracy_val: 0.2243	accuracy_test: 0.1743
[server]	loss_train: 1.6007	loss_val: 1.6014	loss_test: 1.6013	accuracy_train: 0.2222	accuracy_val: 0.1829	accuracy_test: 0.2619
[server]	loss_train: 1.6064	loss_val: 1.6062	loss_test: 1.6082	accuracy_train: 0.1982	accuracy_val: 0.2037	accuracy_test: 0.1622
[server]	loss_train: 1.6028	loss_val: 1.6054	loss_test: 1.5998	accuracy_train: 0.2200	accuracy_val: 0.2162	accuracy_test: 0.2338
[server]	loss_train: 1.6070	loss_val: 1.6079	loss_test: 1.6103	accuracy_train: 0.1706	accuracy_val: 0.1744	accuracy_test: 0.1724
[server]	loss_train: 1.6013	loss_val: 1.6021	loss_test: 1.6027	accuracy_train: 0.2432	accuracy_val: 0.2568	accuracy_test: 0.1948
[server]	loss_train: 1.6044	loss_val: 1.6050	loss_test: 1.6052	accuracy_train: 0.2229	accuracy_val: 0.2584	accuracy_test: 0.1868
[server]	loss_train: 1.6097	loss_val: 1.6092	loss_test: 1.6086	accuracy_train: 0.1263	accuracy_val: 0.1489	accuracy_test: 0.1616
[server]	loss_train: 1.6057	loss_val: 1.6071	loss_test: 1.6056	accuracy_train: 0.2319	accuracy_val: 0.2353	accuracy_test: 0.1604
[server]	loss_train: 1.6101	loss_val: 1.6118	loss_test: 1.6077	accuracy_train: 0.2124	accuracy_val: 0.2212	accuracy_test: 0.2087
[server]	loss_train: 1.6001	loss_val: 1.5976	loss_test: 1.5967	accuracy_train: 0.2486	accuracy_val: 0.2471	accuracy_test: 0.2360
[server]	loss_train: 1.6033	loss_val: 1.6047	loss_test: 1.6066	accuracy_train: 0.1840	accuracy_val: 0.2346	accuracy_test: 0.1667
[server]	loss_train: 1.5996	loss_val: 1.5973	loss_test: 1.6011	accuracy_train: 0.2242	accuracy_val: 0.2523	accuracy_test: 0.1930
curr_round: 6	curr_val_accuracy: 0.2010	curr_test_accuracy: 0.1934
best_round: 0	best_val_accuracy: 0.2010	best_test_accuracy: 0.1934
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6018	loss_train: 0.0661	loss_degree: 0.0205	loss_feat: 0.0000	loss_cls: 1.3007	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6018	loss_train: 0.0651	loss_degree: 0.0204	loss_feat: 0.0000	loss_cls: 1.2820	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6062	loss_train: 0.0642	loss_degree: 0.0203	loss_feat: 0.0000	loss_cls: 1.2631	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6522	loss_train: 0.0616	loss_degree: 0.0167	loss_feat: 0.0000	loss_cls: 1.2147	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6576	loss_train: 0.0605	loss_degree: 0.0165	loss_feat: 0.0000	loss_cls: 1.1939	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6630	loss_train: 0.0595	loss_degree: 0.0163	loss_feat: 0.0000	loss_cls: 1.1733	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0622	loss_degree: 0.0254	loss_feat: 0.0000	loss_cls: 1.2184	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0614	loss_degree: 0.0248	loss_feat: 0.0000	loss_cls: 1.2029	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4182	loss_train: 0.0606	loss_degree: 0.0241	loss_feat: 0.0000	loss_cls: 1.1877	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.4908	loss_train: 0.0619	loss_degree: 0.0152	loss_feat: 0.0000	loss_cls: 1.2224	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5031	loss_train: 0.0610	loss_degree: 0.0148	loss_feat: 0.0000	loss_cls: 1.2046	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5031	loss_train: 0.0601	loss_degree: 0.0145	loss_feat: 0.0000	loss_cls: 1.1870	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.5935	loss_train: 0.0650	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.2725	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.6075	loss_train: 0.0641	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.2535	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.6262	loss_train: 0.0631	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.2344	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6564	loss_train: 0.0645	loss_degree: 0.0051	loss_feat: 0.0000	loss_cls: 1.2852	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6626	loss_train: 0.0635	loss_degree: 0.0051	loss_feat: 0.0000	loss_cls: 1.2649	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6626	loss_train: 0.0625	loss_degree: 0.0051	loss_feat: 0.0000	loss_cls: 1.2445	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.5789	loss_train: 0.0636	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.2571	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.6000	loss_train: 0.0627	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.2386	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.6053	loss_train: 0.0618	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.2199	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5755	loss_train: 0.0662	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.3115	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5708	loss_train: 0.0654	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.2947	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5708	loss_train: 0.0645	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.2780	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.7222	loss_train: 0.0647	loss_degree: 0.0130	loss_feat: 0.0000	loss_cls: 1.2807	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.7346	loss_train: 0.0637	loss_degree: 0.0130	loss_feat: 0.0000	loss_cls: 1.2607	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.7469	loss_train: 0.0627	loss_degree: 0.0129	loss_feat: 0.0000	loss_cls: 1.2404	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.4147	loss_train: 0.0668	loss_degree: 0.0221	loss_feat: 0.0000	loss_cls: 1.3134	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.4194	loss_train: 0.0660	loss_degree: 0.0220	loss_feat: 0.0000	loss_cls: 1.2973	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.4332	loss_train: 0.0651	loss_degree: 0.0218	loss_feat: 0.0000	loss_cls: 1.2811	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.7067	loss_train: 0.0645	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.2806	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.7267	loss_train: 0.0636	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.2615	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.7467	loss_train: 0.0626	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.2422	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4353	loss_train: 0.0629	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.2471	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4412	loss_train: 0.0620	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.2292	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4588	loss_train: 0.0612	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.2115	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.6824	loss_train: 0.0634	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.2614	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.6959	loss_train: 0.0623	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.2400	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.7095	loss_train: 0.0612	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.2184	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6000	loss_train: 0.0618	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.2197	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6057	loss_train: 0.0609	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.2019	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6114	loss_train: 0.0601	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.1844	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4632	loss_train: 0.0617	loss_degree: 0.0102	loss_feat: 0.0000	loss_cls: 1.2229	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4632	loss_train: 0.0607	loss_degree: 0.0101	loss_feat: 0.0000	loss_cls: 1.2041	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4737	loss_train: 0.0598	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.1856	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.4686	loss_train: 0.0671	loss_degree: 0.0195	loss_feat: 0.0000	loss_cls: 1.3219	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.4831	loss_train: 0.0662	loss_degree: 0.0195	loss_feat: 0.0000	loss_cls: 1.3047	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.4976	loss_train: 0.0653	loss_degree: 0.0195	loss_feat: 0.0000	loss_cls: 1.2872	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.5310	loss_train: 0.0661	loss_degree: 0.0164	loss_feat: 0.0000	loss_cls: 1.3061	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.5354	loss_train: 0.0653	loss_degree: 0.0163	loss_feat: 0.0000	loss_cls: 1.2896	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.5398	loss_train: 0.0645	loss_degree: 0.0162	loss_feat: 0.0000	loss_cls: 1.2729	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.6012	loss_train: 0.0671	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.2981	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.6127	loss_train: 0.0661	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.2789	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.6185	loss_train: 0.0651	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.2593	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.6380	loss_train: 0.0661	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.3069	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.6442	loss_train: 0.0652	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.2892	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.6687	loss_train: 0.0643	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.2713	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6592	loss_train: 0.0675	loss_degree: 0.0145	loss_feat: 0.0000	loss_cls: 1.3347	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6726	loss_train: 0.0666	loss_degree: 0.0145	loss_feat: 0.0000	loss_cls: 1.3173	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6816	loss_train: 0.0657	loss_degree: 0.0145	loss_feat: 0.0000	loss_cls: 1.2998	loss_other: 0.0000
[server]	loss_train: 1.6140	loss_val: 1.6111	loss_test: 1.6117	accuracy_train: 0.2257	accuracy_val: 0.1681	accuracy_test: 0.2261
[server]	loss_train: 1.6009	loss_val: 1.6037	loss_test: 1.6027	accuracy_train: 0.2500	accuracy_val: 0.2500	accuracy_test: 0.3021
[server]	loss_train: 1.6078	loss_val: 1.6092	loss_test: 1.6088	accuracy_train: 0.1591	accuracy_val: 0.1101	accuracy_test: 0.1261
[server]	loss_train: 1.6190	loss_val: 1.6176	loss_test: 1.6183	accuracy_train: 0.1472	accuracy_val: 0.1098	accuracy_test: 0.1446
[server]	loss_train: 1.6042	loss_val: 1.6038	loss_test: 1.6045	accuracy_train: 0.1682	accuracy_val: 0.1667	accuracy_test: 0.2018
[server]	loss_train: 1.6047	loss_val: 1.5991	loss_test: 1.6060	accuracy_train: 0.1718	accuracy_val: 0.1975	accuracy_test: 0.1905
[server]	loss_train: 1.6052	loss_val: 1.6059	loss_test: 1.6067	accuracy_train: 0.1947	accuracy_val: 0.1789	accuracy_test: 0.1856
[server]	loss_train: 1.6051	loss_val: 1.6056	loss_test: 1.6046	accuracy_train: 0.1651	accuracy_val: 0.2243	accuracy_test: 0.1743
[server]	loss_train: 1.6007	loss_val: 1.6014	loss_test: 1.6013	accuracy_train: 0.2222	accuracy_val: 0.1829	accuracy_test: 0.2619
[server]	loss_train: 1.6064	loss_val: 1.6062	loss_test: 1.6082	accuracy_train: 0.1982	accuracy_val: 0.2037	accuracy_test: 0.1622
[server]	loss_train: 1.6028	loss_val: 1.6054	loss_test: 1.5998	accuracy_train: 0.2200	accuracy_val: 0.2162	accuracy_test: 0.2338
[server]	loss_train: 1.6070	loss_val: 1.6079	loss_test: 1.6103	accuracy_train: 0.1706	accuracy_val: 0.1744	accuracy_test: 0.1724
[server]	loss_train: 1.6013	loss_val: 1.6021	loss_test: 1.6027	accuracy_train: 0.2432	accuracy_val: 0.2568	accuracy_test: 0.1948
[server]	loss_train: 1.6044	loss_val: 1.6050	loss_test: 1.6052	accuracy_train: 0.2229	accuracy_val: 0.2584	accuracy_test: 0.1868
[server]	loss_train: 1.6097	loss_val: 1.6092	loss_test: 1.6086	accuracy_train: 0.1263	accuracy_val: 0.1489	accuracy_test: 0.1616
[server]	loss_train: 1.6057	loss_val: 1.6071	loss_test: 1.6056	accuracy_train: 0.2319	accuracy_val: 0.2353	accuracy_test: 0.1604
[server]	loss_train: 1.6101	loss_val: 1.6118	loss_test: 1.6077	accuracy_train: 0.2124	accuracy_val: 0.2212	accuracy_test: 0.2087
[server]	loss_train: 1.6001	loss_val: 1.5976	loss_test: 1.5967	accuracy_train: 0.2486	accuracy_val: 0.2471	accuracy_test: 0.2360
[server]	loss_train: 1.6033	loss_val: 1.6047	loss_test: 1.6066	accuracy_train: 0.1840	accuracy_val: 0.2346	accuracy_test: 0.1667
[server]	loss_train: 1.5996	loss_val: 1.5973	loss_test: 1.6011	accuracy_train: 0.2242	accuracy_val: 0.2523	accuracy_test: 0.1930
curr_round: 7	curr_val_accuracy: 0.2010	curr_test_accuracy: 0.1934
best_round: 0	best_val_accuracy: 0.2010	best_test_accuracy: 0.1934
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6106	loss_train: 0.0632	loss_degree: 0.0202	loss_feat: 0.0000	loss_cls: 1.2442	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6283	loss_train: 0.0623	loss_degree: 0.0201	loss_feat: 0.0000	loss_cls: 1.2251	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6372	loss_train: 0.0613	loss_degree: 0.0199	loss_feat: 0.0000	loss_cls: 1.2061	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6739	loss_train: 0.0585	loss_degree: 0.0161	loss_feat: 0.0000	loss_cls: 1.1529	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6739	loss_train: 0.0574	loss_degree: 0.0159	loss_feat: 0.0000	loss_cls: 1.1327	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.6848	loss_train: 0.0564	loss_degree: 0.0157	loss_feat: 0.0000	loss_cls: 1.1126	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4318	loss_train: 0.0598	loss_degree: 0.0234	loss_feat: 0.0000	loss_cls: 1.1728	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4409	loss_train: 0.0590	loss_degree: 0.0227	loss_feat: 0.0000	loss_cls: 1.1583	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4545	loss_train: 0.0583	loss_degree: 0.0219	loss_feat: 0.0000	loss_cls: 1.1441	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5153	loss_train: 0.0592	loss_degree: 0.0141	loss_feat: 0.0000	loss_cls: 1.1693	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5215	loss_train: 0.0583	loss_degree: 0.0137	loss_feat: 0.0000	loss_cls: 1.1518	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5337	loss_train: 0.0574	loss_degree: 0.0132	loss_feat: 0.0000	loss_cls: 1.1344	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.6308	loss_train: 0.0622	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.2152	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.6355	loss_train: 0.0612	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.1959	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.6449	loss_train: 0.0602	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.1767	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6687	loss_train: 0.0614	loss_degree: 0.0051	loss_feat: 0.0000	loss_cls: 1.2238	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6687	loss_train: 0.0604	loss_degree: 0.0051	loss_feat: 0.0000	loss_cls: 1.2031	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6687	loss_train: 0.0594	loss_degree: 0.0051	loss_feat: 0.0000	loss_cls: 1.1824	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.6105	loss_train: 0.0609	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.2013	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.6263	loss_train: 0.0599	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.1826	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.6474	loss_train: 0.0590	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.1639	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5755	loss_train: 0.0637	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.2612	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5802	loss_train: 0.0629	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.2445	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5802	loss_train: 0.0620	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.2278	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.7469	loss_train: 0.0616	loss_degree: 0.0129	loss_feat: 0.0000	loss_cls: 1.2200	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.7531	loss_train: 0.0606	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.1994	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.7531	loss_train: 0.0596	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.1788	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.4839	loss_train: 0.0643	loss_degree: 0.0216	loss_feat: 0.0000	loss_cls: 1.2647	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.5069	loss_train: 0.0635	loss_degree: 0.0215	loss_feat: 0.0000	loss_cls: 1.2483	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.5300	loss_train: 0.0627	loss_degree: 0.0212	loss_feat: 0.0000	loss_cls: 1.2318	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.7533	loss_train: 0.0616	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.2226	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.7467	loss_train: 0.0606	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.2028	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.7467	loss_train: 0.0596	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.1828	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4647	loss_train: 0.0603	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.1938	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.4882	loss_train: 0.0594	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.1762	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.5000	loss_train: 0.0585	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.1586	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.7095	loss_train: 0.0601	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.1967	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.7230	loss_train: 0.0590	loss_degree: 0.0061	loss_feat: 0.0000	loss_cls: 1.1748	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.7230	loss_train: 0.0580	loss_degree: 0.0062	loss_feat: 0.0000	loss_cls: 1.1529	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6114	loss_train: 0.0592	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.1671	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6171	loss_train: 0.0584	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.1501	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6286	loss_train: 0.0575	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.1334	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4842	loss_train: 0.0589	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.1675	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.4895	loss_train: 0.0580	loss_degree: 0.0099	loss_feat: 0.0000	loss_cls: 1.1497	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.5053	loss_train: 0.0571	loss_degree: 0.0099	loss_feat: 0.0000	loss_cls: 1.1322	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.5024	loss_train: 0.0645	loss_degree: 0.0195	loss_feat: 0.0000	loss_cls: 1.2695	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.5121	loss_train: 0.0636	loss_degree: 0.0195	loss_feat: 0.0000	loss_cls: 1.2516	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.5121	loss_train: 0.0627	loss_degree: 0.0196	loss_feat: 0.0000	loss_cls: 1.2336	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.5442	loss_train: 0.0636	loss_degree: 0.0161	loss_feat: 0.0000	loss_cls: 1.2561	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.5487	loss_train: 0.0628	loss_degree: 0.0161	loss_feat: 0.0000	loss_cls: 1.2391	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.5531	loss_train: 0.0619	loss_degree: 0.0160	loss_feat: 0.0000	loss_cls: 1.2220	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.6301	loss_train: 0.0641	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.2395	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.6301	loss_train: 0.0631	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.2194	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.6474	loss_train: 0.0621	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.1991	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.6810	loss_train: 0.0634	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.2532	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.6871	loss_train: 0.0625	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.2350	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.6933	loss_train: 0.0616	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.2166	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6861	loss_train: 0.0648	loss_degree: 0.0145	loss_feat: 0.0000	loss_cls: 1.2820	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6861	loss_train: 0.0639	loss_degree: 0.0145	loss_feat: 0.0000	loss_cls: 1.2640	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6861	loss_train: 0.0630	loss_degree: 0.0145	loss_feat: 0.0000	loss_cls: 1.2459	loss_other: 0.0000
[server]	loss_train: 1.6140	loss_val: 1.6111	loss_test: 1.6117	accuracy_train: 0.2257	accuracy_val: 0.1681	accuracy_test: 0.2261
[server]	loss_train: 1.6009	loss_val: 1.6037	loss_test: 1.6027	accuracy_train: 0.2500	accuracy_val: 0.2500	accuracy_test: 0.3021
[server]	loss_train: 1.6078	loss_val: 1.6092	loss_test: 1.6088	accuracy_train: 0.1591	accuracy_val: 0.1101	accuracy_test: 0.1261
[server]	loss_train: 1.6190	loss_val: 1.6176	loss_test: 1.6183	accuracy_train: 0.1472	accuracy_val: 0.1098	accuracy_test: 0.1446
[server]	loss_train: 1.6042	loss_val: 1.6038	loss_test: 1.6045	accuracy_train: 0.1682	accuracy_val: 0.1667	accuracy_test: 0.2018
[server]	loss_train: 1.6047	loss_val: 1.5991	loss_test: 1.6060	accuracy_train: 0.1718	accuracy_val: 0.1975	accuracy_test: 0.1905
[server]	loss_train: 1.6052	loss_val: 1.6059	loss_test: 1.6067	accuracy_train: 0.1947	accuracy_val: 0.1789	accuracy_test: 0.1856
[server]	loss_train: 1.6051	loss_val: 1.6056	loss_test: 1.6046	accuracy_train: 0.1651	accuracy_val: 0.2243	accuracy_test: 0.1743
[server]	loss_train: 1.6007	loss_val: 1.6014	loss_test: 1.6013	accuracy_train: 0.2222	accuracy_val: 0.1829	accuracy_test: 0.2619
[server]	loss_train: 1.6064	loss_val: 1.6062	loss_test: 1.6082	accuracy_train: 0.1982	accuracy_val: 0.2037	accuracy_test: 0.1622
[server]	loss_train: 1.6028	loss_val: 1.6054	loss_test: 1.5998	accuracy_train: 0.2200	accuracy_val: 0.2162	accuracy_test: 0.2338
[server]	loss_train: 1.6070	loss_val: 1.6079	loss_test: 1.6103	accuracy_train: 0.1706	accuracy_val: 0.1744	accuracy_test: 0.1724
[server]	loss_train: 1.6013	loss_val: 1.6021	loss_test: 1.6027	accuracy_train: 0.2432	accuracy_val: 0.2568	accuracy_test: 0.1948
[server]	loss_train: 1.6044	loss_val: 1.6050	loss_test: 1.6052	accuracy_train: 0.2229	accuracy_val: 0.2584	accuracy_test: 0.1868
[server]	loss_train: 1.6097	loss_val: 1.6092	loss_test: 1.6086	accuracy_train: 0.1263	accuracy_val: 0.1489	accuracy_test: 0.1616
[server]	loss_train: 1.6057	loss_val: 1.6071	loss_test: 1.6056	accuracy_train: 0.2319	accuracy_val: 0.2353	accuracy_test: 0.1604
[server]	loss_train: 1.6101	loss_val: 1.6118	loss_test: 1.6077	accuracy_train: 0.2124	accuracy_val: 0.2212	accuracy_test: 0.2087
[server]	loss_train: 1.6001	loss_val: 1.5976	loss_test: 1.5967	accuracy_train: 0.2486	accuracy_val: 0.2471	accuracy_test: 0.2360
[server]	loss_train: 1.6033	loss_val: 1.6047	loss_test: 1.6066	accuracy_train: 0.1840	accuracy_val: 0.2346	accuracy_test: 0.1667
[server]	loss_train: 1.5996	loss_val: 1.5973	loss_test: 1.6011	accuracy_train: 0.2242	accuracy_val: 0.2523	accuracy_test: 0.1930
curr_round: 8	curr_val_accuracy: 0.2010	curr_test_accuracy: 0.1934
best_round: 0	best_val_accuracy: 0.2010	best_test_accuracy: 0.1934
--------------------------------------------------
round # 9		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6460	loss_train: 0.0603	loss_degree: 0.0198	loss_feat: 0.0000	loss_cls: 1.1871	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6504	loss_train: 0.0594	loss_degree: 0.0196	loss_feat: 0.0000	loss_cls: 1.1681	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.9690	acc_cls: 0.6504	loss_train: 0.0584	loss_degree: 0.0195	loss_feat: 0.0000	loss_cls: 1.1493	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.7011	loss_train: 0.0554	loss_degree: 0.0155	loss_feat: 0.0000	loss_cls: 1.0927	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.7228	loss_train: 0.0544	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.0731	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.9674	acc_cls: 0.7283	loss_train: 0.0534	loss_degree: 0.0150	loss_feat: 0.0000	loss_cls: 1.0537	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4545	loss_train: 0.0576	loss_degree: 0.0210	loss_feat: 0.0000	loss_cls: 1.1302	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4682	loss_train: 0.0568	loss_degree: 0.0201	loss_feat: 0.0000	loss_cls: 1.1166	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.9273	acc_cls: 0.4727	loss_train: 0.0561	loss_degree: 0.0192	loss_feat: 0.0000	loss_cls: 1.1032	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5399	loss_train: 0.0565	loss_degree: 0.0127	loss_feat: 0.0000	loss_cls: 1.1171	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5399	loss_train: 0.0556	loss_degree: 0.0122	loss_feat: 0.0000	loss_cls: 1.0999	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.5399	loss_train: 0.0547	loss_degree: 0.0117	loss_feat: 0.0000	loss_cls: 1.0829	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.6542	loss_train: 0.0593	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.1574	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.6869	loss_train: 0.0583	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.1383	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.9533	acc_cls: 0.6916	loss_train: 0.0574	loss_degree: 0.0280	loss_feat: 0.0000	loss_cls: 1.1192	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6748	loss_train: 0.0583	loss_degree: 0.0051	loss_feat: 0.0000	loss_cls: 1.1617	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6871	loss_train: 0.0573	loss_degree: 0.0051	loss_feat: 0.0000	loss_cls: 1.1410	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.9877	acc_cls: 0.6994	loss_train: 0.0563	loss_degree: 0.0051	loss_feat: 0.0000	loss_cls: 1.1205	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.6579	loss_train: 0.0581	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.1453	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.6737	loss_train: 0.0571	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.1267	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.9684	acc_cls: 0.6789	loss_train: 0.0562	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.1083	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.5991	loss_train: 0.0612	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.2111	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.6085	loss_train: 0.0604	loss_degree: 0.0128	loss_feat: 0.0000	loss_cls: 1.1944	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.9717	acc_cls: 0.6085	loss_train: 0.0595	loss_degree: 0.0129	loss_feat: 0.0000	loss_cls: 1.1778	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.7531	loss_train: 0.0585	loss_degree: 0.0127	loss_feat: 0.0000	loss_cls: 1.1581	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.7531	loss_train: 0.0575	loss_degree: 0.0127	loss_feat: 0.0000	loss_cls: 1.1376	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.9691	acc_cls: 0.7654	loss_train: 0.0565	loss_degree: 0.0126	loss_feat: 0.0000	loss_cls: 1.1172	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.5346	loss_train: 0.0618	loss_degree: 0.0210	loss_feat: 0.0000	loss_cls: 1.2153	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.5760	loss_train: 0.0610	loss_degree: 0.0208	loss_feat: 0.0000	loss_cls: 1.1987	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.9447	acc_cls: 0.6037	loss_train: 0.0601	loss_degree: 0.0206	loss_feat: 0.0000	loss_cls: 1.1822	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.7533	loss_train: 0.0586	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.1626	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.7533	loss_train: 0.0576	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.1424	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.9800	acc_cls: 0.7667	loss_train: 0.0566	loss_degree: 0.0100	loss_feat: 0.0000	loss_cls: 1.1221	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.5235	loss_train: 0.0576	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.1410	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.5294	loss_train: 0.0568	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.1234	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.9765	acc_cls: 0.5529	loss_train: 0.0559	loss_degree: 0.0118	loss_feat: 0.0000	loss_cls: 1.1057	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.7297	loss_train: 0.0569	loss_degree: 0.0062	loss_feat: 0.0000	loss_cls: 1.1310	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.7297	loss_train: 0.0558	loss_degree: 0.0062	loss_feat: 0.0000	loss_cls: 1.1093	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.9865	acc_cls: 0.7297	loss_train: 0.0547	loss_degree: 0.0062	loss_feat: 0.0000	loss_cls: 1.0876	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6286	loss_train: 0.0567	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.1169	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6400	loss_train: 0.0559	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.1007	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.9657	acc_cls: 0.6571	loss_train: 0.0551	loss_degree: 0.0171	loss_feat: 0.0000	loss_cls: 1.0847	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.5263	loss_train: 0.0562	loss_degree: 0.0098	loss_feat: 0.0000	loss_cls: 1.1148	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.5263	loss_train: 0.0554	loss_degree: 0.0097	loss_feat: 0.0000	loss_cls: 1.0977	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.9737	acc_cls: 0.5421	loss_train: 0.0545	loss_degree: 0.0097	loss_feat: 0.0000	loss_cls: 1.0808	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.5266	loss_train: 0.0618	loss_degree: 0.0196	loss_feat: 0.0000	loss_cls: 1.2155	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.5411	loss_train: 0.0608	loss_degree: 0.0196	loss_feat: 0.0000	loss_cls: 1.1973	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.9565	acc_cls: 0.5556	loss_train: 0.0599	loss_degree: 0.0196	loss_feat: 0.0000	loss_cls: 1.1790	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.5619	loss_train: 0.0610	loss_degree: 0.0158	loss_feat: 0.0000	loss_cls: 1.2048	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.5619	loss_train: 0.0602	loss_degree: 0.0157	loss_feat: 0.0000	loss_cls: 1.1876	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.9602	acc_cls: 0.5708	loss_train: 0.0593	loss_degree: 0.0156	loss_feat: 0.0000	loss_cls: 1.1704	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.6647	loss_train: 0.0611	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.1787	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.6647	loss_train: 0.0601	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.1581	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.9364	acc_cls: 0.6821	loss_train: 0.0590	loss_degree: 0.0434	loss_feat: 0.0000	loss_cls: 1.1374	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.6933	loss_train: 0.0607	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.1981	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.7055	loss_train: 0.0597	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.1794	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.9693	acc_cls: 0.7055	loss_train: 0.0588	loss_degree: 0.0153	loss_feat: 0.0000	loss_cls: 1.1606	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6951	loss_train: 0.0621	loss_degree: 0.0145	loss_feat: 0.0000	loss_cls: 1.2277	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.6951	loss_train: 0.0612	loss_degree: 0.0146	loss_feat: 0.0000	loss_cls: 1.2095	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.9686	acc_cls: 0.7130	loss_train: 0.0603	loss_degree: 0.0146	loss_feat: 0.0000	loss_cls: 1.1912	loss_other: 0.0000
[server]	loss_train: 1.5976	loss_val: 1.6059	loss_test: 1.5927	accuracy_train: 0.2301	accuracy_val: 0.2301	accuracy_test: 0.2261
[server]	loss_train: 1.5440	loss_val: 1.5473	loss_test: 1.5551	accuracy_train: 0.2174	accuracy_val: 0.2174	accuracy_test: 0.2188
[server]	loss_train: 1.4923	loss_val: 1.5083	loss_test: 1.4911	accuracy_train: 0.4136	accuracy_val: 0.4128	accuracy_test: 0.4144
[server]	loss_train: 1.5401	loss_val: 1.5506	loss_test: 1.5581	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.5369	loss_val: 1.5365	loss_test: 1.5428	accuracy_train: 0.2430	accuracy_val: 0.2407	accuracy_test: 0.2385
[server]	loss_train: 1.5558	loss_val: 1.5482	loss_test: 1.5466	accuracy_train: 0.2454	accuracy_val: 0.2469	accuracy_test: 0.2500
[server]	loss_train: 1.5334	loss_val: 1.5356	loss_test: 1.5195	accuracy_train: 0.2579	accuracy_val: 0.2526	accuracy_test: 0.2577
[server]	loss_train: 1.5396	loss_val: 1.5436	loss_test: 1.5573	accuracy_train: 0.2123	accuracy_val: 0.2150	accuracy_test: 0.2110
[server]	loss_train: 1.5803	loss_val: 1.5658	loss_test: 1.5827	accuracy_train: 0.1790	accuracy_val: 0.1829	accuracy_test: 0.1786
[server]	loss_train: 1.5386	loss_val: 1.5334	loss_test: 1.5367	accuracy_train: 0.2995	accuracy_val: 0.3056	accuracy_test: 0.2973
[server]	loss_train: 1.5668	loss_val: 1.5677	loss_test: 1.5878	accuracy_train: 0.2067	accuracy_val: 0.2162	accuracy_test: 0.2078
[server]	loss_train: 1.5470	loss_val: 1.5594	loss_test: 1.5303	accuracy_train: 0.3529	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.5479	loss_val: 1.5626	loss_test: 1.5575	accuracy_train: 0.2027	accuracy_val: 0.2027	accuracy_test: 0.1948
[server]	loss_train: 1.5260	loss_val: 1.5208	loss_test: 1.5380	accuracy_train: 0.3600	accuracy_val: 0.3596	accuracy_test: 0.3516
[server]	loss_train: 1.5121	loss_val: 1.5338	loss_test: 1.5411	accuracy_train: 0.3684	accuracy_val: 0.3723	accuracy_test: 0.3636
[server]	loss_train: 1.5698	loss_val: 1.5607	loss_test: 1.5748	accuracy_train: 0.1594	accuracy_val: 0.1569	accuracy_test: 0.1604
[server]	loss_train: 1.5593	loss_val: 1.5586	loss_test: 1.5540	accuracy_train: 0.2080	accuracy_val: 0.2124	accuracy_test: 0.2087
[server]	loss_train: 1.5710	loss_val: 1.5736	loss_test: 1.5654	accuracy_train: 0.2254	accuracy_val: 0.2235	accuracy_test: 0.2247
[server]	loss_train: 1.5704	loss_val: 1.5863	loss_test: 1.5771	accuracy_train: 0.2270	accuracy_val: 0.2222	accuracy_test: 0.2262
[server]	loss_train: 1.5657	loss_val: 1.5718	loss_test: 1.5681	accuracy_train: 0.2242	accuracy_val: 0.2252	accuracy_test: 0.2281
curr_round: 9	curr_val_accuracy: 0.2592	curr_test_accuracy: 0.2576
best_round: 9	best_val_accuracy: 0.2592	best_test_accuracy: 0.2576
--------------------------------------------------
round # 10		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5961	loss_val: 1.6058	loss_test: 1.5928	accuracy_train: 0.2301	accuracy_val: 0.2301	accuracy_test: 0.2261
[server]	loss_train: 1.5352	loss_val: 1.5392	loss_test: 1.5495	accuracy_train: 0.2174	accuracy_val: 0.2174	accuracy_test: 0.2188
[server]	loss_train: 1.4786	loss_val: 1.4978	loss_test: 1.4809	accuracy_train: 0.4136	accuracy_val: 0.4128	accuracy_test: 0.4144
[server]	loss_train: 1.5336	loss_val: 1.5433	loss_test: 1.5540	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.5255	loss_val: 1.5267	loss_test: 1.5345	accuracy_train: 0.2430	accuracy_val: 0.2407	accuracy_test: 0.2385
[server]	loss_train: 1.5467	loss_val: 1.5392	loss_test: 1.5367	accuracy_train: 0.2454	accuracy_val: 0.2469	accuracy_test: 0.2500
[server]	loss_train: 1.5224	loss_val: 1.5260	loss_test: 1.5098	accuracy_train: 0.2579	accuracy_val: 0.2526	accuracy_test: 0.2577
[server]	loss_train: 1.5289	loss_val: 1.5350	loss_test: 1.5481	accuracy_train: 0.2123	accuracy_val: 0.2150	accuracy_test: 0.2110
[server]	loss_train: 1.5749	loss_val: 1.5599	loss_test: 1.5793	accuracy_train: 0.1790	accuracy_val: 0.1829	accuracy_test: 0.1786
[server]	loss_train: 1.5287	loss_val: 1.5242	loss_test: 1.5270	accuracy_train: 0.2995	accuracy_val: 0.3056	accuracy_test: 0.2973
[server]	loss_train: 1.5607	loss_val: 1.5620	loss_test: 1.5832	accuracy_train: 0.2067	accuracy_val: 0.2162	accuracy_test: 0.2078
[server]	loss_train: 1.5392	loss_val: 1.5543	loss_test: 1.5225	accuracy_train: 0.3529	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.5380	loss_val: 1.5564	loss_test: 1.5498	accuracy_train: 0.2027	accuracy_val: 0.2027	accuracy_test: 0.1948
[server]	loss_train: 1.5169	loss_val: 1.5122	loss_test: 1.5316	accuracy_train: 0.3600	accuracy_val: 0.3596	accuracy_test: 0.3516
[server]	loss_train: 1.4984	loss_val: 1.5236	loss_test: 1.5343	accuracy_train: 0.3684	accuracy_val: 0.3723	accuracy_test: 0.3636
[server]	loss_train: 1.5630	loss_val: 1.5544	loss_test: 1.5676	accuracy_train: 0.1594	accuracy_val: 0.1569	accuracy_test: 0.1604
[server]	loss_train: 1.5517	loss_val: 1.5526	loss_test: 1.5463	accuracy_train: 0.2080	accuracy_val: 0.2124	accuracy_test: 0.2087
[server]	loss_train: 1.5651	loss_val: 1.5677	loss_test: 1.5603	accuracy_train: 0.2254	accuracy_val: 0.2235	accuracy_test: 0.2247
[server]	loss_train: 1.5645	loss_val: 1.5814	loss_test: 1.5714	accuracy_train: 0.2270	accuracy_val: 0.2222	accuracy_test: 0.2262
[server]	loss_train: 1.5585	loss_val: 1.5656	loss_test: 1.5618	accuracy_train: 0.2242	accuracy_val: 0.2252	accuracy_test: 0.2281
curr_round: 10	curr_val_accuracy: 0.2592	curr_test_accuracy: 0.2576
best_round: 9	best_val_accuracy: 0.2592	best_test_accuracy: 0.2576
--------------------------------------------------
round # 11		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5940	loss_val: 1.6054	loss_test: 1.5932	accuracy_train: 0.2301	accuracy_val: 0.2301	accuracy_test: 0.2261
[server]	loss_train: 1.5245	loss_val: 1.5294	loss_test: 1.5436	accuracy_train: 0.2174	accuracy_val: 0.2174	accuracy_test: 0.2188
[server]	loss_train: 1.4617	loss_val: 1.4853	loss_test: 1.4696	accuracy_train: 0.4136	accuracy_val: 0.4128	accuracy_test: 0.4144
[server]	loss_train: 1.5262	loss_val: 1.5341	loss_test: 1.5492	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.5113	loss_val: 1.5150	loss_test: 1.5249	accuracy_train: 0.2430	accuracy_val: 0.2407	accuracy_test: 0.2385
[server]	loss_train: 1.5348	loss_val: 1.5280	loss_test: 1.5242	accuracy_train: 0.2454	accuracy_val: 0.2469	accuracy_test: 0.2500
[server]	loss_train: 1.5088	loss_val: 1.5141	loss_test: 1.4985	accuracy_train: 0.2579	accuracy_val: 0.2526	accuracy_test: 0.2577
[server]	loss_train: 1.5158	loss_val: 1.5246	loss_test: 1.5363	accuracy_train: 0.2123	accuracy_val: 0.2150	accuracy_test: 0.2110
[server]	loss_train: 1.5678	loss_val: 1.5526	loss_test: 1.5749	accuracy_train: 0.1790	accuracy_val: 0.1829	accuracy_test: 0.1786
[server]	loss_train: 1.5163	loss_val: 1.5128	loss_test: 1.5150	accuracy_train: 0.2995	accuracy_val: 0.3056	accuracy_test: 0.2973
[server]	loss_train: 1.5530	loss_val: 1.5552	loss_test: 1.5772	accuracy_train: 0.2067	accuracy_val: 0.2162	accuracy_test: 0.2078
[server]	loss_train: 1.5297	loss_val: 1.5481	loss_test: 1.5134	accuracy_train: 0.3529	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.5256	loss_val: 1.5489	loss_test: 1.5402	accuracy_train: 0.2027	accuracy_val: 0.2027	accuracy_test: 0.1948
[server]	loss_train: 1.5061	loss_val: 1.5023	loss_test: 1.5246	accuracy_train: 0.3600	accuracy_val: 0.3596	accuracy_test: 0.3516
[server]	loss_train: 1.4810	loss_val: 1.5110	loss_test: 1.5262	accuracy_train: 0.3684	accuracy_val: 0.3723	accuracy_test: 0.3636
[server]	loss_train: 1.5542	loss_val: 1.5469	loss_test: 1.5584	accuracy_train: 0.1594	accuracy_val: 0.1569	accuracy_test: 0.1604
[server]	loss_train: 1.5421	loss_val: 1.5456	loss_test: 1.5369	accuracy_train: 0.2080	accuracy_val: 0.2124	accuracy_test: 0.2087
[server]	loss_train: 1.5578	loss_val: 1.5600	loss_test: 1.5542	accuracy_train: 0.2254	accuracy_val: 0.2235	accuracy_test: 0.2247
[server]	loss_train: 1.5572	loss_val: 1.5748	loss_test: 1.5640	accuracy_train: 0.2270	accuracy_val: 0.2222	accuracy_test: 0.2262
[server]	loss_train: 1.5494	loss_val: 1.5579	loss_test: 1.5539	accuracy_train: 0.2242	accuracy_val: 0.2252	accuracy_test: 0.2281
curr_round: 11	curr_val_accuracy: 0.2592	curr_test_accuracy: 0.2576
best_round: 9	best_val_accuracy: 0.2592	best_test_accuracy: 0.2576
--------------------------------------------------
round # 12		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5910	loss_val: 1.6036	loss_test: 1.5934	accuracy_train: 0.2301	accuracy_val: 0.2301	accuracy_test: 0.2261
[server]	loss_train: 1.5140	loss_val: 1.5197	loss_test: 1.5392	accuracy_train: 0.2174	accuracy_val: 0.2174	accuracy_test: 0.2188
[server]	loss_train: 1.4451	loss_val: 1.4734	loss_test: 1.4596	accuracy_train: 0.4182	accuracy_val: 0.4128	accuracy_test: 0.4144
[server]	loss_train: 1.5196	loss_val: 1.5242	loss_test: 1.5444	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.4973	loss_val: 1.5042	loss_test: 1.5165	accuracy_train: 0.2430	accuracy_val: 0.2407	accuracy_test: 0.2385
[server]	loss_train: 1.5220	loss_val: 1.5164	loss_test: 1.5111	accuracy_train: 0.2454	accuracy_val: 0.2469	accuracy_test: 0.2500
[server]	loss_train: 1.4957	loss_val: 1.5021	loss_test: 1.4888	accuracy_train: 0.2579	accuracy_val: 0.2526	accuracy_test: 0.2577
[server]	loss_train: 1.5032	loss_val: 1.5151	loss_test: 1.5244	accuracy_train: 0.2123	accuracy_val: 0.2150	accuracy_test: 0.2110
[server]	loss_train: 1.5599	loss_val: 1.5454	loss_test: 1.5697	accuracy_train: 0.1790	accuracy_val: 0.1829	accuracy_test: 0.1786
[server]	loss_train: 1.5036	loss_val: 1.5012	loss_test: 1.5028	accuracy_train: 0.2995	accuracy_val: 0.3056	accuracy_test: 0.2973
[server]	loss_train: 1.5449	loss_val: 1.5483	loss_test: 1.5700	accuracy_train: 0.2067	accuracy_val: 0.2162	accuracy_test: 0.2078
[server]	loss_train: 1.5196	loss_val: 1.5411	loss_test: 1.5045	accuracy_train: 0.3588	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.5131	loss_val: 1.5414	loss_test: 1.5308	accuracy_train: 0.2027	accuracy_val: 0.2027	accuracy_test: 0.1948
[server]	loss_train: 1.4955	loss_val: 1.4927	loss_test: 1.5179	accuracy_train: 0.3600	accuracy_val: 0.3596	accuracy_test: 0.3516
[server]	loss_train: 1.4634	loss_val: 1.4982	loss_test: 1.5178	accuracy_train: 0.3684	accuracy_val: 0.3723	accuracy_test: 0.3636
[server]	loss_train: 1.5453	loss_val: 1.5402	loss_test: 1.5485	accuracy_train: 0.1594	accuracy_val: 0.1569	accuracy_test: 0.1604
[server]	loss_train: 1.5324	loss_val: 1.5391	loss_test: 1.5276	accuracy_train: 0.2124	accuracy_val: 0.2124	accuracy_test: 0.2087
[server]	loss_train: 1.5497	loss_val: 1.5508	loss_test: 1.5479	accuracy_train: 0.2254	accuracy_val: 0.2235	accuracy_test: 0.2247
[server]	loss_train: 1.5497	loss_val: 1.5666	loss_test: 1.5559	accuracy_train: 0.2270	accuracy_val: 0.2222	accuracy_test: 0.2262
[server]	loss_train: 1.5396	loss_val: 1.5498	loss_test: 1.5456	accuracy_train: 0.2242	accuracy_val: 0.2252	accuracy_test: 0.2281
curr_round: 12	curr_val_accuracy: 0.2592	curr_test_accuracy: 0.2576
best_round: 9	best_val_accuracy: 0.2592	best_test_accuracy: 0.2576
--------------------------------------------------
round # 13		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5860	loss_val: 1.5989	loss_test: 1.5924	accuracy_train: 0.2257	accuracy_val: 0.2301	accuracy_test: 0.2261
[server]	loss_train: 1.5040	loss_val: 1.5105	loss_test: 1.5360	accuracy_train: 0.2228	accuracy_val: 0.2283	accuracy_test: 0.2188
[server]	loss_train: 1.4302	loss_val: 1.4629	loss_test: 1.4517	accuracy_train: 0.4227	accuracy_val: 0.4037	accuracy_test: 0.4054
[server]	loss_train: 1.5140	loss_val: 1.5143	loss_test: 1.5394	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3373
[server]	loss_train: 1.4844	loss_val: 1.4953	loss_test: 1.5102	accuracy_train: 0.2477	accuracy_val: 0.2315	accuracy_test: 0.2294
[server]	loss_train: 1.5091	loss_val: 1.5049	loss_test: 1.4982	accuracy_train: 0.2393	accuracy_val: 0.2469	accuracy_test: 0.2500
[server]	loss_train: 1.4839	loss_val: 1.4909	loss_test: 1.4815	accuracy_train: 0.2579	accuracy_val: 0.2526	accuracy_test: 0.2680
[server]	loss_train: 1.4920	loss_val: 1.5069	loss_test: 1.5129	accuracy_train: 0.2217	accuracy_val: 0.2056	accuracy_test: 0.2385
[server]	loss_train: 1.5507	loss_val: 1.5380	loss_test: 1.5628	accuracy_train: 0.1852	accuracy_val: 0.1951	accuracy_test: 0.1786
[server]	loss_train: 1.4911	loss_val: 1.4900	loss_test: 1.4914	accuracy_train: 0.2995	accuracy_val: 0.3056	accuracy_test: 0.3063
[server]	loss_train: 1.5363	loss_val: 1.5411	loss_test: 1.5614	accuracy_train: 0.2133	accuracy_val: 0.2027	accuracy_test: 0.1948
[server]	loss_train: 1.5094	loss_val: 1.5331	loss_test: 1.4959	accuracy_train: 0.3588	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.5012	loss_val: 1.5336	loss_test: 1.5220	accuracy_train: 0.2095	accuracy_val: 0.2162	accuracy_test: 0.1948
[server]	loss_train: 1.4855	loss_val: 1.4838	loss_test: 1.5115	accuracy_train: 0.3714	accuracy_val: 0.3596	accuracy_test: 0.3297
[server]	loss_train: 1.4471	loss_val: 1.4858	loss_test: 1.5096	accuracy_train: 0.3737	accuracy_val: 0.3723	accuracy_test: 0.3838
[server]	loss_train: 1.5362	loss_val: 1.5346	loss_test: 1.5384	accuracy_train: 0.1594	accuracy_val: 0.1569	accuracy_test: 0.1604
[server]	loss_train: 1.5230	loss_val: 1.5334	loss_test: 1.5192	accuracy_train: 0.2124	accuracy_val: 0.2212	accuracy_test: 0.2087
[server]	loss_train: 1.5405	loss_val: 1.5400	loss_test: 1.5410	accuracy_train: 0.2312	accuracy_val: 0.2235	accuracy_test: 0.2247
[server]	loss_train: 1.5420	loss_val: 1.5563	loss_test: 1.5470	accuracy_train: 0.2393	accuracy_val: 0.2469	accuracy_test: 0.2262
[server]	loss_train: 1.5296	loss_val: 1.5414	loss_test: 1.5368	accuracy_train: 0.2197	accuracy_val: 0.2252	accuracy_test: 0.2281
curr_round: 13	curr_val_accuracy: 0.2603	curr_test_accuracy: 0.2591
best_round: 13	best_val_accuracy: 0.2603	best_test_accuracy: 0.2591
--------------------------------------------------
round # 14		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5782	loss_val: 1.5908	loss_test: 1.5893	accuracy_train: 0.2389	accuracy_val: 0.2301	accuracy_test: 0.2261
[server]	loss_train: 1.4940	loss_val: 1.5014	loss_test: 1.5332	accuracy_train: 0.2228	accuracy_val: 0.2391	accuracy_test: 0.2188
[server]	loss_train: 1.4170	loss_val: 1.4538	loss_test: 1.4450	accuracy_train: 0.4227	accuracy_val: 0.3945	accuracy_test: 0.4054
[server]	loss_train: 1.5088	loss_val: 1.5043	loss_test: 1.5336	accuracy_train: 0.3313	accuracy_val: 0.3415	accuracy_test: 0.3494
[server]	loss_train: 1.4727	loss_val: 1.4882	loss_test: 1.5055	accuracy_train: 0.2523	accuracy_val: 0.2407	accuracy_test: 0.2294
[server]	loss_train: 1.4961	loss_val: 1.4938	loss_test: 1.4854	accuracy_train: 0.2699	accuracy_val: 0.2469	accuracy_test: 0.2500
[server]	loss_train: 1.4732	loss_val: 1.4804	loss_test: 1.4764	accuracy_train: 0.2632	accuracy_val: 0.2632	accuracy_test: 0.2680
[server]	loss_train: 1.4820	loss_val: 1.4999	loss_test: 1.5018	accuracy_train: 0.2311	accuracy_val: 0.2056	accuracy_test: 0.2385
[server]	loss_train: 1.5404	loss_val: 1.5301	loss_test: 1.5540	accuracy_train: 0.1975	accuracy_val: 0.1951	accuracy_test: 0.1905
[server]	loss_train: 1.4790	loss_val: 1.4792	loss_test: 1.4807	accuracy_train: 0.2949	accuracy_val: 0.3056	accuracy_test: 0.3243
[server]	loss_train: 1.5268	loss_val: 1.5332	loss_test: 1.5517	accuracy_train: 0.2200	accuracy_val: 0.2162	accuracy_test: 0.1818
[server]	loss_train: 1.4989	loss_val: 1.5237	loss_test: 1.4871	accuracy_train: 0.3706	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.4899	loss_val: 1.5249	loss_test: 1.5134	accuracy_train: 0.2162	accuracy_val: 0.2162	accuracy_test: 0.1948
[server]	loss_train: 1.4756	loss_val: 1.4750	loss_test: 1.5050	accuracy_train: 0.3714	accuracy_val: 0.3596	accuracy_test: 0.3297
[server]	loss_train: 1.4324	loss_val: 1.4740	loss_test: 1.5016	accuracy_train: 0.3895	accuracy_val: 0.3723	accuracy_test: 0.3838
[server]	loss_train: 1.5270	loss_val: 1.5296	loss_test: 1.5279	accuracy_train: 0.1546	accuracy_val: 0.1569	accuracy_test: 0.1604
[server]	loss_train: 1.5135	loss_val: 1.5278	loss_test: 1.5115	accuracy_train: 0.2301	accuracy_val: 0.2124	accuracy_test: 0.2261
[server]	loss_train: 1.5301	loss_val: 1.5280	loss_test: 1.5328	accuracy_train: 0.2428	accuracy_val: 0.2235	accuracy_test: 0.2247
[server]	loss_train: 1.5338	loss_val: 1.5443	loss_test: 1.5375	accuracy_train: 0.2454	accuracy_val: 0.2469	accuracy_test: 0.2262
[server]	loss_train: 1.5191	loss_val: 1.5326	loss_test: 1.5276	accuracy_train: 0.2287	accuracy_val: 0.2252	accuracy_test: 0.2281
curr_round: 14	curr_val_accuracy: 0.2619	curr_test_accuracy: 0.2617
best_round: 14	best_val_accuracy: 0.2619	best_test_accuracy: 0.2617
--------------------------------------------------
round # 15		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5679	loss_val: 1.5799	loss_test: 1.5845	accuracy_train: 0.2434	accuracy_val: 0.2301	accuracy_test: 0.2261
[server]	loss_train: 1.4840	loss_val: 1.4918	loss_test: 1.5300	accuracy_train: 0.2609	accuracy_val: 0.2500	accuracy_test: 0.1979
[server]	loss_train: 1.4052	loss_val: 1.4457	loss_test: 1.4386	accuracy_train: 0.4364	accuracy_val: 0.3761	accuracy_test: 0.3964
[server]	loss_train: 1.5033	loss_val: 1.4944	loss_test: 1.5271	accuracy_train: 0.3497	accuracy_val: 0.3537	accuracy_test: 0.3735
[server]	loss_train: 1.4620	loss_val: 1.4824	loss_test: 1.5017	accuracy_train: 0.2710	accuracy_val: 0.2315	accuracy_test: 0.2477
[server]	loss_train: 1.4833	loss_val: 1.4834	loss_test: 1.4727	accuracy_train: 0.2822	accuracy_val: 0.2469	accuracy_test: 0.2619
[server]	loss_train: 1.4633	loss_val: 1.4707	loss_test: 1.4729	accuracy_train: 0.2684	accuracy_val: 0.2526	accuracy_test: 0.2887
[server]	loss_train: 1.4728	loss_val: 1.4936	loss_test: 1.4909	accuracy_train: 0.2500	accuracy_val: 0.2243	accuracy_test: 0.2385
[server]	loss_train: 1.5293	loss_val: 1.5215	loss_test: 1.5434	accuracy_train: 0.2037	accuracy_val: 0.2195	accuracy_test: 0.2024
[server]	loss_train: 1.4669	loss_val: 1.4688	loss_test: 1.4705	accuracy_train: 0.2995	accuracy_val: 0.3333	accuracy_test: 0.3243
[server]	loss_train: 1.5162	loss_val: 1.5245	loss_test: 1.5415	accuracy_train: 0.2267	accuracy_val: 0.2432	accuracy_test: 0.1818
[server]	loss_train: 1.4885	loss_val: 1.5128	loss_test: 1.4775	accuracy_train: 0.3706	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.4790	loss_val: 1.5151	loss_test: 1.5047	accuracy_train: 0.2365	accuracy_val: 0.2432	accuracy_test: 0.1948
[server]	loss_train: 1.4655	loss_val: 1.4660	loss_test: 1.4982	accuracy_train: 0.3771	accuracy_val: 0.3483	accuracy_test: 0.3187
[server]	loss_train: 1.4190	loss_val: 1.4626	loss_test: 1.4939	accuracy_train: 0.3947	accuracy_val: 0.3830	accuracy_test: 0.3737
[server]	loss_train: 1.5177	loss_val: 1.5247	loss_test: 1.5174	accuracy_train: 0.1594	accuracy_val: 0.1765	accuracy_test: 0.1604
[server]	loss_train: 1.5040	loss_val: 1.5219	loss_test: 1.5043	accuracy_train: 0.2301	accuracy_val: 0.2743	accuracy_test: 0.2522
[server]	loss_train: 1.5186	loss_val: 1.5156	loss_test: 1.5234	accuracy_train: 0.2543	accuracy_val: 0.2235	accuracy_test: 0.2247
[server]	loss_train: 1.5253	loss_val: 1.5315	loss_test: 1.5281	accuracy_train: 0.2638	accuracy_val: 0.2469	accuracy_test: 0.2262
[server]	loss_train: 1.5083	loss_val: 1.5234	loss_test: 1.5179	accuracy_train: 0.2287	accuracy_val: 0.2342	accuracy_test: 0.2281
curr_round: 15	curr_val_accuracy: 0.2719	curr_test_accuracy: 0.2648
best_round: 15	best_val_accuracy: 0.2719	best_test_accuracy: 0.2648
--------------------------------------------------
round # 16		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5558	loss_val: 1.5674	loss_test: 1.5783	accuracy_train: 0.2389	accuracy_val: 0.2566	accuracy_test: 0.2348
[server]	loss_train: 1.4737	loss_val: 1.4819	loss_test: 1.5257	accuracy_train: 0.3043	accuracy_val: 0.2609	accuracy_test: 0.1875
[server]	loss_train: 1.3941	loss_val: 1.4383	loss_test: 1.4315	accuracy_train: 0.4227	accuracy_val: 0.3578	accuracy_test: 0.3784
[server]	loss_train: 1.4973	loss_val: 1.4847	loss_test: 1.5199	accuracy_train: 0.3558	accuracy_val: 0.3780	accuracy_test: 0.3614
[server]	loss_train: 1.4522	loss_val: 1.4775	loss_test: 1.4983	accuracy_train: 0.2944	accuracy_val: 0.2778	accuracy_test: 0.2477
[server]	loss_train: 1.4710	loss_val: 1.4741	loss_test: 1.4602	accuracy_train: 0.2883	accuracy_val: 0.2716	accuracy_test: 0.2857
[server]	loss_train: 1.4538	loss_val: 1.4615	loss_test: 1.4703	accuracy_train: 0.3263	accuracy_val: 0.3158	accuracy_test: 0.2887
[server]	loss_train: 1.4639	loss_val: 1.4874	loss_test: 1.4801	accuracy_train: 0.2642	accuracy_val: 0.2150	accuracy_test: 0.2294
[server]	loss_train: 1.5178	loss_val: 1.5124	loss_test: 1.5313	accuracy_train: 0.2284	accuracy_val: 0.2073	accuracy_test: 0.2024
[server]	loss_train: 1.4550	loss_val: 1.4588	loss_test: 1.4609	accuracy_train: 0.3226	accuracy_val: 0.3426	accuracy_test: 0.3063
[server]	loss_train: 1.5049	loss_val: 1.5152	loss_test: 1.5318	accuracy_train: 0.2333	accuracy_val: 0.2432	accuracy_test: 0.1948
[server]	loss_train: 1.4784	loss_val: 1.5010	loss_test: 1.4667	accuracy_train: 0.3882	accuracy_val: 0.3372	accuracy_test: 0.3678
[server]	loss_train: 1.4684	loss_val: 1.5043	loss_test: 1.4957	accuracy_train: 0.2838	accuracy_val: 0.2568	accuracy_test: 0.2208
[server]	loss_train: 1.4549	loss_val: 1.4562	loss_test: 1.4910	accuracy_train: 0.3829	accuracy_val: 0.3371	accuracy_test: 0.2857
[server]	loss_train: 1.4066	loss_val: 1.4517	loss_test: 1.4865	accuracy_train: 0.4211	accuracy_val: 0.3830	accuracy_test: 0.3737
[server]	loss_train: 1.5084	loss_val: 1.5199	loss_test: 1.5070	accuracy_train: 0.1932	accuracy_val: 0.2059	accuracy_test: 0.1792
[server]	loss_train: 1.4944	loss_val: 1.5156	loss_test: 1.4975	accuracy_train: 0.2788	accuracy_val: 0.2743	accuracy_test: 0.2609
[server]	loss_train: 1.5067	loss_val: 1.5038	loss_test: 1.5132	accuracy_train: 0.2659	accuracy_val: 0.2353	accuracy_test: 0.2247
[server]	loss_train: 1.5167	loss_val: 1.5188	loss_test: 1.5190	accuracy_train: 0.2638	accuracy_val: 0.2469	accuracy_test: 0.2500
[server]	loss_train: 1.4974	loss_val: 1.5141	loss_test: 1.5080	accuracy_train: 0.2422	accuracy_val: 0.2432	accuracy_test: 0.2456
curr_round: 16	curr_val_accuracy: 0.2826	curr_test_accuracy: 0.2669
best_round: 16	best_val_accuracy: 0.2826	best_test_accuracy: 0.2669
--------------------------------------------------
round # 17		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5429	loss_val: 1.5548	loss_test: 1.5714	accuracy_train: 0.2611	accuracy_val: 0.2920	accuracy_test: 0.2609
[server]	loss_train: 1.4634	loss_val: 1.4718	loss_test: 1.5203	accuracy_train: 0.3207	accuracy_val: 0.3043	accuracy_test: 0.1979
[server]	loss_train: 1.3833	loss_val: 1.4313	loss_test: 1.4232	accuracy_train: 0.4409	accuracy_val: 0.3303	accuracy_test: 0.3964
[server]	loss_train: 1.4910	loss_val: 1.4754	loss_test: 1.5123	accuracy_train: 0.3436	accuracy_val: 0.4024	accuracy_test: 0.3735
[server]	loss_train: 1.4430	loss_val: 1.4729	loss_test: 1.4949	accuracy_train: 0.3271	accuracy_val: 0.2870	accuracy_test: 0.2752
[server]	loss_train: 1.4593	loss_val: 1.4660	loss_test: 1.4479	accuracy_train: 0.3190	accuracy_val: 0.2963	accuracy_test: 0.2619
[server]	loss_train: 1.4444	loss_val: 1.4526	loss_test: 1.4682	accuracy_train: 0.3579	accuracy_val: 0.3053	accuracy_test: 0.3402
[server]	loss_train: 1.4550	loss_val: 1.4812	loss_test: 1.4695	accuracy_train: 0.2877	accuracy_val: 0.2710	accuracy_test: 0.2477
[server]	loss_train: 1.5062	loss_val: 1.5030	loss_test: 1.5183	accuracy_train: 0.2840	accuracy_val: 0.2195	accuracy_test: 0.2143
[server]	loss_train: 1.4433	loss_val: 1.4490	loss_test: 1.4518	accuracy_train: 0.3502	accuracy_val: 0.3519	accuracy_test: 0.3063
[server]	loss_train: 1.4932	loss_val: 1.5059	loss_test: 1.5234	accuracy_train: 0.2867	accuracy_val: 0.2432	accuracy_test: 0.2338
[server]	loss_train: 1.4690	loss_val: 1.4890	loss_test: 1.4550	accuracy_train: 0.3706	accuracy_val: 0.3023	accuracy_test: 0.3678
[server]	loss_train: 1.4581	loss_val: 1.4930	loss_test: 1.4865	accuracy_train: 0.3311	accuracy_val: 0.3108	accuracy_test: 0.2338
[server]	loss_train: 1.4437	loss_val: 1.4459	loss_test: 1.4840	accuracy_train: 0.3657	accuracy_val: 0.3258	accuracy_test: 0.2857
[server]	loss_train: 1.3950	loss_val: 1.4415	loss_test: 1.4795	accuracy_train: 0.4263	accuracy_val: 0.3723	accuracy_test: 0.3434
[server]	loss_train: 1.4993	loss_val: 1.5150	loss_test: 1.4971	accuracy_train: 0.2464	accuracy_val: 0.2451	accuracy_test: 0.1981
[server]	loss_train: 1.4848	loss_val: 1.5089	loss_test: 1.4909	accuracy_train: 0.2920	accuracy_val: 0.3097	accuracy_test: 0.2957
[server]	loss_train: 1.4947	loss_val: 1.4932	loss_test: 1.5025	accuracy_train: 0.2659	accuracy_val: 0.2000	accuracy_test: 0.2247
[server]	loss_train: 1.5082	loss_val: 1.5071	loss_test: 1.5107	accuracy_train: 0.2638	accuracy_val: 0.2469	accuracy_test: 0.2857
[server]	loss_train: 1.4866	loss_val: 1.5048	loss_test: 1.4980	accuracy_train: 0.2646	accuracy_val: 0.2613	accuracy_test: 0.2368
curr_round: 17	curr_val_accuracy: 0.2947	curr_test_accuracy: 0.2799
best_round: 17	best_val_accuracy: 0.2947	best_test_accuracy: 0.2799
--------------------------------------------------
round # 18		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5303	loss_val: 1.5431	loss_test: 1.5646	accuracy_train: 0.2655	accuracy_val: 0.2832	accuracy_test: 0.2522
[server]	loss_train: 1.4531	loss_val: 1.4619	loss_test: 1.5141	accuracy_train: 0.3424	accuracy_val: 0.3152	accuracy_test: 0.2188
[server]	loss_train: 1.3725	loss_val: 1.4244	loss_test: 1.4137	accuracy_train: 0.4364	accuracy_val: 0.3028	accuracy_test: 0.3784
[server]	loss_train: 1.4845	loss_val: 1.4665	loss_test: 1.5047	accuracy_train: 0.3252	accuracy_val: 0.3659	accuracy_test: 0.3735
[server]	loss_train: 1.4341	loss_val: 1.4684	loss_test: 1.4913	accuracy_train: 0.3551	accuracy_val: 0.3056	accuracy_test: 0.2569
[server]	loss_train: 1.4483	loss_val: 1.4592	loss_test: 1.4359	accuracy_train: 0.3374	accuracy_val: 0.2963	accuracy_test: 0.2738
[server]	loss_train: 1.4349	loss_val: 1.4437	loss_test: 1.4660	accuracy_train: 0.3947	accuracy_val: 0.3263	accuracy_test: 0.3299
[server]	loss_train: 1.4463	loss_val: 1.4748	loss_test: 1.4590	accuracy_train: 0.3160	accuracy_val: 0.2617	accuracy_test: 0.2752
[server]	loss_train: 1.4948	loss_val: 1.4939	loss_test: 1.5049	accuracy_train: 0.3148	accuracy_val: 0.2195	accuracy_test: 0.2381
[server]	loss_train: 1.4320	loss_val: 1.4396	loss_test: 1.4433	accuracy_train: 0.3641	accuracy_val: 0.3611	accuracy_test: 0.3153
[server]	loss_train: 1.4815	loss_val: 1.4968	loss_test: 1.5165	accuracy_train: 0.3267	accuracy_val: 0.2568	accuracy_test: 0.2338
[server]	loss_train: 1.4606	loss_val: 1.4774	loss_test: 1.4427	accuracy_train: 0.3647	accuracy_val: 0.3023	accuracy_test: 0.3678
[server]	loss_train: 1.4478	loss_val: 1.4815	loss_test: 1.4773	accuracy_train: 0.3446	accuracy_val: 0.3243	accuracy_test: 0.2857
[server]	loss_train: 1.4323	loss_val: 1.4351	loss_test: 1.4778	accuracy_train: 0.3543	accuracy_val: 0.2921	accuracy_test: 0.2857
[server]	loss_train: 1.3839	loss_val: 1.4320	loss_test: 1.4730	accuracy_train: 0.4263	accuracy_val: 0.3617	accuracy_test: 0.3434
[server]	loss_train: 1.4907	loss_val: 1.5103	loss_test: 1.4880	accuracy_train: 0.2319	accuracy_val: 0.2647	accuracy_test: 0.2264
[server]	loss_train: 1.4754	loss_val: 1.5020	loss_test: 1.4846	accuracy_train: 0.3009	accuracy_val: 0.3274	accuracy_test: 0.2870
[server]	loss_train: 1.4833	loss_val: 1.4840	loss_test: 1.4920	accuracy_train: 0.2717	accuracy_val: 0.2353	accuracy_test: 0.2472
[server]	loss_train: 1.5001	loss_val: 1.4969	loss_test: 1.5034	accuracy_train: 0.2638	accuracy_val: 0.2716	accuracy_test: 0.2738
[server]	loss_train: 1.4762	loss_val: 1.4962	loss_test: 1.4882	accuracy_train: 0.2780	accuracy_val: 0.2523	accuracy_test: 0.2456
curr_round: 18	curr_val_accuracy: 0.2969	curr_test_accuracy: 0.2855
best_round: 18	best_val_accuracy: 0.2969	best_test_accuracy: 0.2855
--------------------------------------------------
round # 19		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5188	loss_val: 1.5333	loss_test: 1.5583	accuracy_train: 0.2920	accuracy_val: 0.2566	accuracy_test: 0.2522
[server]	loss_train: 1.4431	loss_val: 1.4522	loss_test: 1.5074	accuracy_train: 0.3478	accuracy_val: 0.3261	accuracy_test: 0.2083
[server]	loss_train: 1.3614	loss_val: 1.4176	loss_test: 1.4032	accuracy_train: 0.4318	accuracy_val: 0.3303	accuracy_test: 0.3964
[server]	loss_train: 1.4782	loss_val: 1.4582	loss_test: 1.4972	accuracy_train: 0.3558	accuracy_val: 0.3902	accuracy_test: 0.3855
[server]	loss_train: 1.4255	loss_val: 1.4640	loss_test: 1.4875	accuracy_train: 0.3505	accuracy_val: 0.3333	accuracy_test: 0.2661
[server]	loss_train: 1.4381	loss_val: 1.4537	loss_test: 1.4246	accuracy_train: 0.3681	accuracy_val: 0.3210	accuracy_test: 0.3214
[server]	loss_train: 1.4253	loss_val: 1.4348	loss_test: 1.4637	accuracy_train: 0.4105	accuracy_val: 0.3579	accuracy_test: 0.3299
[server]	loss_train: 1.4376	loss_val: 1.4684	loss_test: 1.4489	accuracy_train: 0.3160	accuracy_val: 0.2897	accuracy_test: 0.2752
[server]	loss_train: 1.4838	loss_val: 1.4852	loss_test: 1.4916	accuracy_train: 0.3210	accuracy_val: 0.2073	accuracy_test: 0.2500
[server]	loss_train: 1.4212	loss_val: 1.4307	loss_test: 1.4353	accuracy_train: 0.3687	accuracy_val: 0.3704	accuracy_test: 0.3153
[server]	loss_train: 1.4704	loss_val: 1.4885	loss_test: 1.5110	accuracy_train: 0.3267	accuracy_val: 0.2838	accuracy_test: 0.2338
[server]	loss_train: 1.4531	loss_val: 1.4668	loss_test: 1.4305	accuracy_train: 0.3647	accuracy_val: 0.2791	accuracy_test: 0.3678
[server]	loss_train: 1.4375	loss_val: 1.4703	loss_test: 1.4684	accuracy_train: 0.3446	accuracy_val: 0.3378	accuracy_test: 0.2727
[server]	loss_train: 1.4209	loss_val: 1.4243	loss_test: 1.4724	accuracy_train: 0.3429	accuracy_val: 0.3146	accuracy_test: 0.2637
[server]	loss_train: 1.3731	loss_val: 1.4232	loss_test: 1.4669	accuracy_train: 0.4263	accuracy_val: 0.3511	accuracy_test: 0.3232
[server]	loss_train: 1.4826	loss_val: 1.5059	loss_test: 1.4798	accuracy_train: 0.2657	accuracy_val: 0.2745	accuracy_test: 0.2453
[server]	loss_train: 1.4663	loss_val: 1.4954	loss_test: 1.4787	accuracy_train: 0.3186	accuracy_val: 0.3540	accuracy_test: 0.3130
[server]	loss_train: 1.4727	loss_val: 1.4764	loss_test: 1.4819	accuracy_train: 0.2659	accuracy_val: 0.2824	accuracy_test: 0.2697
[server]	loss_train: 1.4924	loss_val: 1.4885	loss_test: 1.4970	accuracy_train: 0.2515	accuracy_val: 0.2963	accuracy_test: 0.3095
[server]	loss_train: 1.4662	loss_val: 1.4882	loss_test: 1.4787	accuracy_train: 0.2870	accuracy_val: 0.2432	accuracy_test: 0.2895
curr_round: 19	curr_val_accuracy: 0.3102	curr_test_accuracy: 0.2948
best_round: 19	best_val_accuracy: 0.3102	best_test_accuracy: 0.2948
--------------------------------------------------
round # 20		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5087	loss_val: 1.5253	loss_test: 1.5529	accuracy_train: 0.3097	accuracy_val: 0.2743	accuracy_test: 0.2522
[server]	loss_train: 1.4335	loss_val: 1.4430	loss_test: 1.5005	accuracy_train: 0.3587	accuracy_val: 0.3370	accuracy_test: 0.2083
[server]	loss_train: 1.3505	loss_val: 1.4110	loss_test: 1.3928	accuracy_train: 0.4364	accuracy_val: 0.3303	accuracy_test: 0.3874
[server]	loss_train: 1.4725	loss_val: 1.4510	loss_test: 1.4902	accuracy_train: 0.3497	accuracy_val: 0.3659	accuracy_test: 0.4096
[server]	loss_train: 1.4169	loss_val: 1.4597	loss_test: 1.4837	accuracy_train: 0.3598	accuracy_val: 0.3333	accuracy_test: 0.2569
[server]	loss_train: 1.4287	loss_val: 1.4494	loss_test: 1.4139	accuracy_train: 0.3681	accuracy_val: 0.2963	accuracy_test: 0.3333
[server]	loss_train: 1.4158	loss_val: 1.4260	loss_test: 1.4613	accuracy_train: 0.4263	accuracy_val: 0.3895	accuracy_test: 0.3505
[server]	loss_train: 1.4291	loss_val: 1.4621	loss_test: 1.4394	accuracy_train: 0.3396	accuracy_val: 0.2991	accuracy_test: 0.2844
[server]	loss_train: 1.4733	loss_val: 1.4772	loss_test: 1.4789	accuracy_train: 0.3457	accuracy_val: 0.2073	accuracy_test: 0.2500
[server]	loss_train: 1.4109	loss_val: 1.4222	loss_test: 1.4281	accuracy_train: 0.3733	accuracy_val: 0.3796	accuracy_test: 0.3063
[server]	loss_train: 1.4600	loss_val: 1.4812	loss_test: 1.5067	accuracy_train: 0.3400	accuracy_val: 0.2838	accuracy_test: 0.2468
[server]	loss_train: 1.4466	loss_val: 1.4574	loss_test: 1.4190	accuracy_train: 0.3529	accuracy_val: 0.2907	accuracy_test: 0.3678
[server]	loss_train: 1.4273	loss_val: 1.4597	loss_test: 1.4599	accuracy_train: 0.3784	accuracy_val: 0.3378	accuracy_test: 0.2727
[server]	loss_train: 1.4097	loss_val: 1.4142	loss_test: 1.4682	accuracy_train: 0.3543	accuracy_val: 0.3146	accuracy_test: 0.2857
[server]	loss_train: 1.3627	loss_val: 1.4153	loss_test: 1.4614	accuracy_train: 0.4368	accuracy_val: 0.3511	accuracy_test: 0.3232
[server]	loss_train: 1.4753	loss_val: 1.5021	loss_test: 1.4725	accuracy_train: 0.2850	accuracy_val: 0.3333	accuracy_test: 0.2642
[server]	loss_train: 1.4578	loss_val: 1.4889	loss_test: 1.4730	accuracy_train: 0.3274	accuracy_val: 0.3451	accuracy_test: 0.3304
[server]	loss_train: 1.4629	loss_val: 1.4701	loss_test: 1.4724	accuracy_train: 0.2659	accuracy_val: 0.2941	accuracy_test: 0.2697
[server]	loss_train: 1.4852	loss_val: 1.4819	loss_test: 1.4914	accuracy_train: 0.2699	accuracy_val: 0.2840	accuracy_test: 0.3333
[server]	loss_train: 1.4566	loss_val: 1.4811	loss_test: 1.4696	accuracy_train: 0.3094	accuracy_val: 0.2613	accuracy_test: 0.2982
curr_round: 20	curr_val_accuracy: 0.3166	curr_test_accuracy: 0.3015
best_round: 20	best_val_accuracy: 0.3166	best_test_accuracy: 0.3015
--------------------------------------------------
round # 21		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4997	loss_val: 1.5190	loss_test: 1.5486	accuracy_train: 0.3053	accuracy_val: 0.2655	accuracy_test: 0.2522
[server]	loss_train: 1.4241	loss_val: 1.4342	loss_test: 1.4937	accuracy_train: 0.3641	accuracy_val: 0.3478	accuracy_test: 0.1979
[server]	loss_train: 1.3403	loss_val: 1.4050	loss_test: 1.3836	accuracy_train: 0.4500	accuracy_val: 0.3211	accuracy_test: 0.3784
[server]	loss_train: 1.4677	loss_val: 1.4450	loss_test: 1.4841	accuracy_train: 0.3252	accuracy_val: 0.3902	accuracy_test: 0.4096
[server]	loss_train: 1.4083	loss_val: 1.4554	loss_test: 1.4798	accuracy_train: 0.3738	accuracy_val: 0.3426	accuracy_test: 0.2752
[server]	loss_train: 1.4198	loss_val: 1.4461	loss_test: 1.4040	accuracy_train: 0.3804	accuracy_val: 0.3086	accuracy_test: 0.3333
[server]	loss_train: 1.4065	loss_val: 1.4174	loss_test: 1.4589	accuracy_train: 0.4263	accuracy_val: 0.3895	accuracy_test: 0.3608
[server]	loss_train: 1.4208	loss_val: 1.4562	loss_test: 1.4304	accuracy_train: 0.3491	accuracy_val: 0.3364	accuracy_test: 0.2844
[server]	loss_train: 1.4632	loss_val: 1.4697	loss_test: 1.4670	accuracy_train: 0.3519	accuracy_val: 0.2073	accuracy_test: 0.2619
[server]	loss_train: 1.4015	loss_val: 1.4145	loss_test: 1.4218	accuracy_train: 0.3594	accuracy_val: 0.3704	accuracy_test: 0.3063
[server]	loss_train: 1.4504	loss_val: 1.4749	loss_test: 1.5028	accuracy_train: 0.3600	accuracy_val: 0.2973	accuracy_test: 0.2338
[server]	loss_train: 1.4412	loss_val: 1.4494	loss_test: 1.4088	accuracy_train: 0.3412	accuracy_val: 0.2791	accuracy_test: 0.3678
[server]	loss_train: 1.4172	loss_val: 1.4497	loss_test: 1.4519	accuracy_train: 0.3919	accuracy_val: 0.3378	accuracy_test: 0.2857
[server]	loss_train: 1.3994	loss_val: 1.4052	loss_test: 1.4653	accuracy_train: 0.3543	accuracy_val: 0.3034	accuracy_test: 0.2747
[server]	loss_train: 1.3531	loss_val: 1.4085	loss_test: 1.4565	accuracy_train: 0.4368	accuracy_val: 0.3404	accuracy_test: 0.3434
[server]	loss_train: 1.4684	loss_val: 1.4987	loss_test: 1.4658	accuracy_train: 0.2899	accuracy_val: 0.3333	accuracy_test: 0.2925
[server]	loss_train: 1.4499	loss_val: 1.4828	loss_test: 1.4677	accuracy_train: 0.3363	accuracy_val: 0.3540	accuracy_test: 0.3217
[server]	loss_train: 1.4538	loss_val: 1.4648	loss_test: 1.4634	accuracy_train: 0.2717	accuracy_val: 0.3294	accuracy_test: 0.2697
[server]	loss_train: 1.4782	loss_val: 1.4764	loss_test: 1.4863	accuracy_train: 0.2822	accuracy_val: 0.2716	accuracy_test: 0.3214
[server]	loss_train: 1.4474	loss_val: 1.4746	loss_test: 1.4608	accuracy_train: 0.3094	accuracy_val: 0.2793	accuracy_test: 0.2982
curr_round: 21	curr_val_accuracy: 0.3213	curr_test_accuracy: 0.3036
best_round: 21	best_val_accuracy: 0.3213	best_test_accuracy: 0.3036
--------------------------------------------------
round # 22		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4916	loss_val: 1.5137	loss_test: 1.5453	accuracy_train: 0.3097	accuracy_val: 0.2920	accuracy_test: 0.2696
[server]	loss_train: 1.4151	loss_val: 1.4257	loss_test: 1.4870	accuracy_train: 0.3804	accuracy_val: 0.3370	accuracy_test: 0.2188
[server]	loss_train: 1.3314	loss_val: 1.3999	loss_test: 1.3765	accuracy_train: 0.4455	accuracy_val: 0.3211	accuracy_test: 0.3694
[server]	loss_train: 1.4641	loss_val: 1.4406	loss_test: 1.4791	accuracy_train: 0.3374	accuracy_val: 0.3780	accuracy_test: 0.3855
[server]	loss_train: 1.3997	loss_val: 1.4513	loss_test: 1.4761	accuracy_train: 0.3832	accuracy_val: 0.3333	accuracy_test: 0.2752
[server]	loss_train: 1.4113	loss_val: 1.4434	loss_test: 1.3948	accuracy_train: 0.3865	accuracy_val: 0.2593	accuracy_test: 0.3333
[server]	loss_train: 1.3975	loss_val: 1.4093	loss_test: 1.4567	accuracy_train: 0.4211	accuracy_val: 0.3789	accuracy_test: 0.3711
[server]	loss_train: 1.4129	loss_val: 1.4507	loss_test: 1.4219	accuracy_train: 0.3632	accuracy_val: 0.3178	accuracy_test: 0.3028
[server]	loss_train: 1.4536	loss_val: 1.4627	loss_test: 1.4558	accuracy_train: 0.3519	accuracy_val: 0.2195	accuracy_test: 0.2738
[server]	loss_train: 1.3928	loss_val: 1.4076	loss_test: 1.4162	accuracy_train: 0.3687	accuracy_val: 0.3704	accuracy_test: 0.2973
[server]	loss_train: 1.4416	loss_val: 1.4693	loss_test: 1.4987	accuracy_train: 0.3667	accuracy_val: 0.2973	accuracy_test: 0.2468
[server]	loss_train: 1.4366	loss_val: 1.4428	loss_test: 1.4005	accuracy_train: 0.3412	accuracy_val: 0.2674	accuracy_test: 0.3448
[server]	loss_train: 1.4071	loss_val: 1.4403	loss_test: 1.4445	accuracy_train: 0.3986	accuracy_val: 0.3514	accuracy_test: 0.2987
[server]	loss_train: 1.3902	loss_val: 1.3977	loss_test: 1.4637	accuracy_train: 0.3714	accuracy_val: 0.3258	accuracy_test: 0.2747
[server]	loss_train: 1.3445	loss_val: 1.4027	loss_test: 1.4525	accuracy_train: 0.4474	accuracy_val: 0.3617	accuracy_test: 0.3131
[server]	loss_train: 1.4619	loss_val: 1.4958	loss_test: 1.4593	accuracy_train: 0.3043	accuracy_val: 0.2941	accuracy_test: 0.3208
[server]	loss_train: 1.4425	loss_val: 1.4770	loss_test: 1.4629	accuracy_train: 0.3584	accuracy_val: 0.3451	accuracy_test: 0.3217
[server]	loss_train: 1.4450	loss_val: 1.4599	loss_test: 1.4548	accuracy_train: 0.2948	accuracy_val: 0.3176	accuracy_test: 0.2921
[server]	loss_train: 1.4713	loss_val: 1.4715	loss_test: 1.4813	accuracy_train: 0.2699	accuracy_val: 0.2716	accuracy_test: 0.3214
[server]	loss_train: 1.4383	loss_val: 1.4687	loss_test: 1.4522	accuracy_train: 0.3049	accuracy_val: 0.3063	accuracy_test: 0.2807
curr_round: 22	curr_val_accuracy: 0.3187	curr_test_accuracy: 0.3056
best_round: 21	best_val_accuracy: 0.3213	best_test_accuracy: 0.3036
--------------------------------------------------
round # 23		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4841	loss_val: 1.5089	loss_test: 1.5428	accuracy_train: 0.3142	accuracy_val: 0.2832	accuracy_test: 0.2696
[server]	loss_train: 1.4065	loss_val: 1.4175	loss_test: 1.4806	accuracy_train: 0.3859	accuracy_val: 0.3261	accuracy_test: 0.2292
[server]	loss_train: 1.3241	loss_val: 1.3958	loss_test: 1.3720	accuracy_train: 0.4545	accuracy_val: 0.3303	accuracy_test: 0.3874
[server]	loss_train: 1.4617	loss_val: 1.4377	loss_test: 1.4754	accuracy_train: 0.3313	accuracy_val: 0.3415	accuracy_test: 0.3735
[server]	loss_train: 1.3910	loss_val: 1.4473	loss_test: 1.4728	accuracy_train: 0.3832	accuracy_val: 0.3333	accuracy_test: 0.2752
[server]	loss_train: 1.4030	loss_val: 1.4413	loss_test: 1.3862	accuracy_train: 0.3988	accuracy_val: 0.2593	accuracy_test: 0.3452
[server]	loss_train: 1.3889	loss_val: 1.4020	loss_test: 1.4550	accuracy_train: 0.4211	accuracy_val: 0.3789	accuracy_test: 0.3505
[server]	loss_train: 1.4054	loss_val: 1.4458	loss_test: 1.4140	accuracy_train: 0.3774	accuracy_val: 0.3271	accuracy_test: 0.3119
[server]	loss_train: 1.4442	loss_val: 1.4560	loss_test: 1.4451	accuracy_train: 0.3642	accuracy_val: 0.2439	accuracy_test: 0.2619
[server]	loss_train: 1.3850	loss_val: 1.4017	loss_test: 1.4115	accuracy_train: 0.3641	accuracy_val: 0.3704	accuracy_test: 0.3153
[server]	loss_train: 1.4335	loss_val: 1.4644	loss_test: 1.4944	accuracy_train: 0.3667	accuracy_val: 0.2973	accuracy_test: 0.2208
[server]	loss_train: 1.4327	loss_val: 1.4374	loss_test: 1.3940	accuracy_train: 0.3412	accuracy_val: 0.2791	accuracy_test: 0.3218
[server]	loss_train: 1.3972	loss_val: 1.4315	loss_test: 1.4376	accuracy_train: 0.4054	accuracy_val: 0.3649	accuracy_test: 0.3117
[server]	loss_train: 1.3820	loss_val: 1.3915	loss_test: 1.4631	accuracy_train: 0.3657	accuracy_val: 0.3371	accuracy_test: 0.2857
[server]	loss_train: 1.3368	loss_val: 1.3978	loss_test: 1.4493	accuracy_train: 0.4421	accuracy_val: 0.3404	accuracy_test: 0.3131
[server]	loss_train: 1.4555	loss_val: 1.4933	loss_test: 1.4529	accuracy_train: 0.3043	accuracy_val: 0.2941	accuracy_test: 0.3396
[server]	loss_train: 1.4356	loss_val: 1.4715	loss_test: 1.4586	accuracy_train: 0.3628	accuracy_val: 0.3451	accuracy_test: 0.3130
[server]	loss_train: 1.4364	loss_val: 1.4551	loss_test: 1.4463	accuracy_train: 0.2890	accuracy_val: 0.3294	accuracy_test: 0.2921
[server]	loss_train: 1.4643	loss_val: 1.4669	loss_test: 1.4762	accuracy_train: 0.2883	accuracy_val: 0.2716	accuracy_test: 0.3333
[server]	loss_train: 1.4295	loss_val: 1.4630	loss_test: 1.4438	accuracy_train: 0.3049	accuracy_val: 0.3153	accuracy_test: 0.2719
curr_round: 23	curr_val_accuracy: 0.3197	curr_test_accuracy: 0.3066
best_round: 21	best_val_accuracy: 0.3213	best_test_accuracy: 0.3036
--------------------------------------------------
round # 24		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4771	loss_val: 1.5046	loss_test: 1.5409	accuracy_train: 0.3186	accuracy_val: 0.2920	accuracy_test: 0.2783
[server]	loss_train: 1.3983	loss_val: 1.4098	loss_test: 1.4747	accuracy_train: 0.3859	accuracy_val: 0.3587	accuracy_test: 0.2396
[server]	loss_train: 1.3180	loss_val: 1.3926	loss_test: 1.3695	accuracy_train: 0.4500	accuracy_val: 0.3119	accuracy_test: 0.3784
[server]	loss_train: 1.4602	loss_val: 1.4359	loss_test: 1.4726	accuracy_train: 0.3313	accuracy_val: 0.3415	accuracy_test: 0.3614
[server]	loss_train: 1.3825	loss_val: 1.4437	loss_test: 1.4699	accuracy_train: 0.3785	accuracy_val: 0.3056	accuracy_test: 0.2661
[server]	loss_train: 1.3952	loss_val: 1.4396	loss_test: 1.3784	accuracy_train: 0.4049	accuracy_val: 0.2840	accuracy_test: 0.3452
[server]	loss_train: 1.3809	loss_val: 1.3953	loss_test: 1.4538	accuracy_train: 0.4263	accuracy_val: 0.3895	accuracy_test: 0.3608
[server]	loss_train: 1.3984	loss_val: 1.4417	loss_test: 1.4067	accuracy_train: 0.3821	accuracy_val: 0.3271	accuracy_test: 0.3119
[server]	loss_train: 1.4352	loss_val: 1.4498	loss_test: 1.4350	accuracy_train: 0.3827	accuracy_val: 0.2561	accuracy_test: 0.2738
[server]	loss_train: 1.3779	loss_val: 1.3966	loss_test: 1.4076	accuracy_train: 0.3687	accuracy_val: 0.3889	accuracy_test: 0.3514
[server]	loss_train: 1.4260	loss_val: 1.4600	loss_test: 1.4901	accuracy_train: 0.3667	accuracy_val: 0.2838	accuracy_test: 0.2208
[server]	loss_train: 1.4294	loss_val: 1.4328	loss_test: 1.3891	accuracy_train: 0.3471	accuracy_val: 0.2907	accuracy_test: 0.3218
[server]	loss_train: 1.3877	loss_val: 1.4234	loss_test: 1.4312	accuracy_train: 0.4189	accuracy_val: 0.3649	accuracy_test: 0.3117
[server]	loss_train: 1.3747	loss_val: 1.3864	loss_test: 1.4634	accuracy_train: 0.3657	accuracy_val: 0.3708	accuracy_test: 0.2857
[server]	loss_train: 1.3299	loss_val: 1.3936	loss_test: 1.4468	accuracy_train: 0.4474	accuracy_val: 0.3298	accuracy_test: 0.3131
[server]	loss_train: 1.4493	loss_val: 1.4915	loss_test: 1.4467	accuracy_train: 0.3043	accuracy_val: 0.2843	accuracy_test: 0.3679
[server]	loss_train: 1.4293	loss_val: 1.4666	loss_test: 1.4549	accuracy_train: 0.3761	accuracy_val: 0.3628	accuracy_test: 0.3130
[server]	loss_train: 1.4281	loss_val: 1.4503	loss_test: 1.4382	accuracy_train: 0.3006	accuracy_val: 0.3412	accuracy_test: 0.2921
[server]	loss_train: 1.4573	loss_val: 1.4626	loss_test: 1.4712	accuracy_train: 0.2945	accuracy_val: 0.2716	accuracy_test: 0.3452
[server]	loss_train: 1.4209	loss_val: 1.4578	loss_test: 1.4356	accuracy_train: 0.3229	accuracy_val: 0.3153	accuracy_test: 0.2719
curr_round: 24	curr_val_accuracy: 0.3245	curr_test_accuracy: 0.3112
best_round: 24	best_val_accuracy: 0.3245	best_test_accuracy: 0.3112
--------------------------------------------------
round # 25		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4706	loss_val: 1.5006	loss_test: 1.5393	accuracy_train: 0.3186	accuracy_val: 0.2920	accuracy_test: 0.2696
[server]	loss_train: 1.3906	loss_val: 1.4028	loss_test: 1.4696	accuracy_train: 0.3967	accuracy_val: 0.3696	accuracy_test: 0.2500
[server]	loss_train: 1.3127	loss_val: 1.3901	loss_test: 1.3681	accuracy_train: 0.4636	accuracy_val: 0.3119	accuracy_test: 0.3604
[server]	loss_train: 1.4592	loss_val: 1.4347	loss_test: 1.4703	accuracy_train: 0.3313	accuracy_val: 0.3415	accuracy_test: 0.3614
[server]	loss_train: 1.3744	loss_val: 1.4405	loss_test: 1.4674	accuracy_train: 0.3832	accuracy_val: 0.3148	accuracy_test: 0.2569
[server]	loss_train: 1.3879	loss_val: 1.4382	loss_test: 1.3712	accuracy_train: 0.4110	accuracy_val: 0.2963	accuracy_test: 0.3452
[server]	loss_train: 1.3734	loss_val: 1.3893	loss_test: 1.4530	accuracy_train: 0.4158	accuracy_val: 0.4105	accuracy_test: 0.3711
[server]	loss_train: 1.3921	loss_val: 1.4382	loss_test: 1.4002	accuracy_train: 0.3962	accuracy_val: 0.3458	accuracy_test: 0.3119
[server]	loss_train: 1.4268	loss_val: 1.4441	loss_test: 1.4253	accuracy_train: 0.3765	accuracy_val: 0.2683	accuracy_test: 0.3095
[server]	loss_train: 1.3714	loss_val: 1.3919	loss_test: 1.4042	accuracy_train: 0.3779	accuracy_val: 0.3889	accuracy_test: 0.3514
[server]	loss_train: 1.4191	loss_val: 1.4565	loss_test: 1.4861	accuracy_train: 0.3667	accuracy_val: 0.2973	accuracy_test: 0.2208
[server]	loss_train: 1.4263	loss_val: 1.4287	loss_test: 1.3852	accuracy_train: 0.3471	accuracy_val: 0.2907	accuracy_test: 0.3563
[server]	loss_train: 1.3787	loss_val: 1.4163	loss_test: 1.4255	accuracy_train: 0.4189	accuracy_val: 0.3784	accuracy_test: 0.2987
[server]	loss_train: 1.3681	loss_val: 1.3821	loss_test: 1.4642	accuracy_train: 0.3657	accuracy_val: 0.3708	accuracy_test: 0.2967
[server]	loss_train: 1.3236	loss_val: 1.3900	loss_test: 1.4448	accuracy_train: 0.4474	accuracy_val: 0.3085	accuracy_test: 0.3131
[server]	loss_train: 1.4437	loss_val: 1.4902	loss_test: 1.4409	accuracy_train: 0.3188	accuracy_val: 0.2843	accuracy_test: 0.3774
[server]	loss_train: 1.4234	loss_val: 1.4622	loss_test: 1.4516	accuracy_train: 0.3805	accuracy_val: 0.3717	accuracy_test: 0.3217
[server]	loss_train: 1.4203	loss_val: 1.4458	loss_test: 1.4306	accuracy_train: 0.3121	accuracy_val: 0.3412	accuracy_test: 0.2809
[server]	loss_train: 1.4505	loss_val: 1.4587	loss_test: 1.4666	accuracy_train: 0.3006	accuracy_val: 0.2716	accuracy_test: 0.3452
[server]	loss_train: 1.4127	loss_val: 1.4533	loss_test: 1.4278	accuracy_train: 0.3274	accuracy_val: 0.3243	accuracy_test: 0.2632
curr_round: 25	curr_val_accuracy: 0.3298	curr_test_accuracy: 0.3133
best_round: 25	best_val_accuracy: 0.3298	best_test_accuracy: 0.3133
--------------------------------------------------
round # 26		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4646	loss_val: 1.4970	loss_test: 1.5380	accuracy_train: 0.3186	accuracy_val: 0.2920	accuracy_test: 0.2957
[server]	loss_train: 1.3836	loss_val: 1.3966	loss_test: 1.4653	accuracy_train: 0.3913	accuracy_val: 0.3587	accuracy_test: 0.2396
[server]	loss_train: 1.3077	loss_val: 1.3879	loss_test: 1.3672	accuracy_train: 0.4636	accuracy_val: 0.3028	accuracy_test: 0.3694
[server]	loss_train: 1.4582	loss_val: 1.4339	loss_test: 1.4681	accuracy_train: 0.3190	accuracy_val: 0.3537	accuracy_test: 0.3373
[server]	loss_train: 1.3668	loss_val: 1.4378	loss_test: 1.4654	accuracy_train: 0.3832	accuracy_val: 0.2870	accuracy_test: 0.2385
[server]	loss_train: 1.3811	loss_val: 1.4373	loss_test: 1.3648	accuracy_train: 0.4172	accuracy_val: 0.2963	accuracy_test: 0.3452
[server]	loss_train: 1.3664	loss_val: 1.3837	loss_test: 1.4524	accuracy_train: 0.4211	accuracy_val: 0.4105	accuracy_test: 0.3814
[server]	loss_train: 1.3864	loss_val: 1.4354	loss_test: 1.3945	accuracy_train: 0.4057	accuracy_val: 0.3551	accuracy_test: 0.3119
[server]	loss_train: 1.4189	loss_val: 1.4390	loss_test: 1.4162	accuracy_train: 0.3765	accuracy_val: 0.2683	accuracy_test: 0.3214
[server]	loss_train: 1.3653	loss_val: 1.3877	loss_test: 1.4014	accuracy_train: 0.3917	accuracy_val: 0.3704	accuracy_test: 0.3514
[server]	loss_train: 1.4126	loss_val: 1.4539	loss_test: 1.4829	accuracy_train: 0.3733	accuracy_val: 0.2703	accuracy_test: 0.2338
[server]	loss_train: 1.4235	loss_val: 1.4249	loss_test: 1.3819	accuracy_train: 0.3412	accuracy_val: 0.2791	accuracy_test: 0.3678
[server]	loss_train: 1.3705	loss_val: 1.4102	loss_test: 1.4203	accuracy_train: 0.4257	accuracy_val: 0.3784	accuracy_test: 0.2987
[server]	loss_train: 1.3619	loss_val: 1.3783	loss_test: 1.4652	accuracy_train: 0.3714	accuracy_val: 0.3708	accuracy_test: 0.2637
[server]	loss_train: 1.3177	loss_val: 1.3870	loss_test: 1.4431	accuracy_train: 0.4316	accuracy_val: 0.3085	accuracy_test: 0.3030
[server]	loss_train: 1.4385	loss_val: 1.4896	loss_test: 1.4355	accuracy_train: 0.3188	accuracy_val: 0.2843	accuracy_test: 0.3774
[server]	loss_train: 1.4181	loss_val: 1.4584	loss_test: 1.4487	accuracy_train: 0.3761	accuracy_val: 0.3894	accuracy_test: 0.3304
[server]	loss_train: 1.4132	loss_val: 1.4416	loss_test: 1.4236	accuracy_train: 0.3121	accuracy_val: 0.3412	accuracy_test: 0.2809
[server]	loss_train: 1.4440	loss_val: 1.4554	loss_test: 1.4625	accuracy_train: 0.3067	accuracy_val: 0.2716	accuracy_test: 0.3333
[server]	loss_train: 1.4051	loss_val: 1.4494	loss_test: 1.4206	accuracy_train: 0.3318	accuracy_val: 0.3243	accuracy_test: 0.2719
curr_round: 26	curr_val_accuracy: 0.3266	curr_test_accuracy: 0.3133
best_round: 25	best_val_accuracy: 0.3298	best_test_accuracy: 0.3133
--------------------------------------------------
round # 27		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4591	loss_val: 1.4937	loss_test: 1.5369	accuracy_train: 0.3230	accuracy_val: 0.2832	accuracy_test: 0.3043
[server]	loss_train: 1.3772	loss_val: 1.3910	loss_test: 1.4618	accuracy_train: 0.3967	accuracy_val: 0.3587	accuracy_test: 0.2396
[server]	loss_train: 1.3030	loss_val: 1.3862	loss_test: 1.3665	accuracy_train: 0.4682	accuracy_val: 0.3119	accuracy_test: 0.3604
[server]	loss_train: 1.4572	loss_val: 1.4331	loss_test: 1.4659	accuracy_train: 0.3067	accuracy_val: 0.3537	accuracy_test: 0.3133
[server]	loss_train: 1.3598	loss_val: 1.4354	loss_test: 1.4638	accuracy_train: 0.3832	accuracy_val: 0.2870	accuracy_test: 0.2294
[server]	loss_train: 1.3748	loss_val: 1.4367	loss_test: 1.3591	accuracy_train: 0.4172	accuracy_val: 0.3086	accuracy_test: 0.3452
[server]	loss_train: 1.3600	loss_val: 1.3787	loss_test: 1.4522	accuracy_train: 0.4053	accuracy_val: 0.3895	accuracy_test: 0.3814
[server]	loss_train: 1.3813	loss_val: 1.4330	loss_test: 1.3897	accuracy_train: 0.3962	accuracy_val: 0.3551	accuracy_test: 0.3119
[server]	loss_train: 1.4115	loss_val: 1.4344	loss_test: 1.4075	accuracy_train: 0.3889	accuracy_val: 0.2683	accuracy_test: 0.3214
[server]	loss_train: 1.3595	loss_val: 1.3837	loss_test: 1.3991	accuracy_train: 0.4240	accuracy_val: 0.3611	accuracy_test: 0.3333
[server]	loss_train: 1.4064	loss_val: 1.4519	loss_test: 1.4804	accuracy_train: 0.3867	accuracy_val: 0.2703	accuracy_test: 0.2727
[server]	loss_train: 1.4209	loss_val: 1.4212	loss_test: 1.3791	accuracy_train: 0.3529	accuracy_val: 0.2907	accuracy_test: 0.3678
[server]	loss_train: 1.3630	loss_val: 1.4051	loss_test: 1.4156	accuracy_train: 0.4324	accuracy_val: 0.3649	accuracy_test: 0.2987
[server]	loss_train: 1.3560	loss_val: 1.3749	loss_test: 1.4663	accuracy_train: 0.3886	accuracy_val: 0.3708	accuracy_test: 0.2637
[server]	loss_train: 1.3122	loss_val: 1.3845	loss_test: 1.4417	accuracy_train: 0.4368	accuracy_val: 0.3085	accuracy_test: 0.3030
[server]	loss_train: 1.4338	loss_val: 1.4895	loss_test: 1.4306	accuracy_train: 0.3333	accuracy_val: 0.2843	accuracy_test: 0.3868
[server]	loss_train: 1.4132	loss_val: 1.4551	loss_test: 1.4462	accuracy_train: 0.3673	accuracy_val: 0.3894	accuracy_test: 0.3304
[server]	loss_train: 1.4068	loss_val: 1.4377	loss_test: 1.4173	accuracy_train: 0.3121	accuracy_val: 0.3647	accuracy_test: 0.2809
[server]	loss_train: 1.4379	loss_val: 1.4527	loss_test: 1.4589	accuracy_train: 0.3129	accuracy_val: 0.2716	accuracy_test: 0.3095
[server]	loss_train: 1.3981	loss_val: 1.4463	loss_test: 1.4140	accuracy_train: 0.3453	accuracy_val: 0.3153	accuracy_test: 0.2807
curr_round: 27	curr_val_accuracy: 0.3261	curr_test_accuracy: 0.3123
best_round: 25	best_val_accuracy: 0.3298	best_test_accuracy: 0.3133
--------------------------------------------------
round # 28		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4539	loss_val: 1.4907	loss_test: 1.5357	accuracy_train: 0.3142	accuracy_val: 0.3009	accuracy_test: 0.2870
[server]	loss_train: 1.3714	loss_val: 1.3862	loss_test: 1.4591	accuracy_train: 0.3967	accuracy_val: 0.3478	accuracy_test: 0.2292
[server]	loss_train: 1.2988	loss_val: 1.3848	loss_test: 1.3659	accuracy_train: 0.4455	accuracy_val: 0.3211	accuracy_test: 0.3874
[server]	loss_train: 1.4562	loss_val: 1.4324	loss_test: 1.4639	accuracy_train: 0.3313	accuracy_val: 0.3415	accuracy_test: 0.3614
[server]	loss_train: 1.3533	loss_val: 1.4334	loss_test: 1.4625	accuracy_train: 0.3832	accuracy_val: 0.2963	accuracy_test: 0.2294
[server]	loss_train: 1.3690	loss_val: 1.4363	loss_test: 1.3540	accuracy_train: 0.4172	accuracy_val: 0.3333	accuracy_test: 0.3690
[server]	loss_train: 1.3541	loss_val: 1.3743	loss_test: 1.4524	accuracy_train: 0.4053	accuracy_val: 0.3895	accuracy_test: 0.3814
[server]	loss_train: 1.3767	loss_val: 1.4310	loss_test: 1.3856	accuracy_train: 0.4198	accuracy_val: 0.3364	accuracy_test: 0.2936
[server]	loss_train: 1.4046	loss_val: 1.4300	loss_test: 1.3992	accuracy_train: 0.3827	accuracy_val: 0.2683	accuracy_test: 0.3095
[server]	loss_train: 1.3540	loss_val: 1.3800	loss_test: 1.3973	accuracy_train: 0.4378	accuracy_val: 0.3426	accuracy_test: 0.3514
[server]	loss_train: 1.4004	loss_val: 1.4504	loss_test: 1.4786	accuracy_train: 0.4000	accuracy_val: 0.2973	accuracy_test: 0.2857
[server]	loss_train: 1.4185	loss_val: 1.4177	loss_test: 1.3767	accuracy_train: 0.3471	accuracy_val: 0.2907	accuracy_test: 0.3333
[server]	loss_train: 1.3561	loss_val: 1.4009	loss_test: 1.4113	accuracy_train: 0.4392	accuracy_val: 0.3649	accuracy_test: 0.2857
[server]	loss_train: 1.3506	loss_val: 1.3719	loss_test: 1.4675	accuracy_train: 0.3943	accuracy_val: 0.3708	accuracy_test: 0.2527
[server]	loss_train: 1.3072	loss_val: 1.3825	loss_test: 1.4407	accuracy_train: 0.4474	accuracy_val: 0.3085	accuracy_test: 0.3030
[server]	loss_train: 1.4295	loss_val: 1.4896	loss_test: 1.4260	accuracy_train: 0.3285	accuracy_val: 0.2843	accuracy_test: 0.3868
[server]	loss_train: 1.4086	loss_val: 1.4523	loss_test: 1.4440	accuracy_train: 0.3761	accuracy_val: 0.3894	accuracy_test: 0.3391
[server]	loss_train: 1.4009	loss_val: 1.4340	loss_test: 1.4116	accuracy_train: 0.3064	accuracy_val: 0.3294	accuracy_test: 0.2921
[server]	loss_train: 1.4322	loss_val: 1.4504	loss_test: 1.4559	accuracy_train: 0.3374	accuracy_val: 0.2469	accuracy_test: 0.3095
[server]	loss_train: 1.3916	loss_val: 1.4436	loss_test: 1.4079	accuracy_train: 0.3587	accuracy_val: 0.3063	accuracy_test: 0.3070
curr_round: 28	curr_val_accuracy: 0.3239	curr_test_accuracy: 0.3154
best_round: 25	best_val_accuracy: 0.3298	best_test_accuracy: 0.3133
--------------------------------------------------
round # 29		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4490	loss_val: 1.4878	loss_test: 1.5346	accuracy_train: 0.3186	accuracy_val: 0.2920	accuracy_test: 0.2870
[server]	loss_train: 1.3660	loss_val: 1.3819	loss_test: 1.4570	accuracy_train: 0.3859	accuracy_val: 0.3587	accuracy_test: 0.2083
[server]	loss_train: 1.2950	loss_val: 1.3839	loss_test: 1.3656	accuracy_train: 0.4545	accuracy_val: 0.3211	accuracy_test: 0.3964
[server]	loss_train: 1.4551	loss_val: 1.4316	loss_test: 1.4619	accuracy_train: 0.3436	accuracy_val: 0.3415	accuracy_test: 0.3373
[server]	loss_train: 1.3474	loss_val: 1.4318	loss_test: 1.4615	accuracy_train: 0.3925	accuracy_val: 0.2870	accuracy_test: 0.2477
[server]	loss_train: 1.3635	loss_val: 1.4362	loss_test: 1.3495	accuracy_train: 0.4233	accuracy_val: 0.3333	accuracy_test: 0.3690
[server]	loss_train: 1.3488	loss_val: 1.3706	loss_test: 1.4530	accuracy_train: 0.4105	accuracy_val: 0.3684	accuracy_test: 0.3711
[server]	loss_train: 1.3724	loss_val: 1.4293	loss_test: 1.3821	accuracy_train: 0.4340	accuracy_val: 0.3271	accuracy_test: 0.3211
[server]	loss_train: 1.3982	loss_val: 1.4260	loss_test: 1.3913	accuracy_train: 0.3889	accuracy_val: 0.2805	accuracy_test: 0.3333
[server]	loss_train: 1.3488	loss_val: 1.3767	loss_test: 1.3959	accuracy_train: 0.4424	accuracy_val: 0.3426	accuracy_test: 0.3604
[server]	loss_train: 1.3945	loss_val: 1.4493	loss_test: 1.4773	accuracy_train: 0.3933	accuracy_val: 0.3243	accuracy_test: 0.2857
[server]	loss_train: 1.4163	loss_val: 1.4145	loss_test: 1.3747	accuracy_train: 0.3529	accuracy_val: 0.2907	accuracy_test: 0.3333
[server]	loss_train: 1.3499	loss_val: 1.3974	loss_test: 1.4074	accuracy_train: 0.4392	accuracy_val: 0.3919	accuracy_test: 0.2857
[server]	loss_train: 1.3455	loss_val: 1.3694	loss_test: 1.4689	accuracy_train: 0.4000	accuracy_val: 0.3596	accuracy_test: 0.2418
[server]	loss_train: 1.3026	loss_val: 1.3810	loss_test: 1.4401	accuracy_train: 0.4526	accuracy_val: 0.3298	accuracy_test: 0.3232
[server]	loss_train: 1.4255	loss_val: 1.4898	loss_test: 1.4218	accuracy_train: 0.3430	accuracy_val: 0.2941	accuracy_test: 0.4057
[server]	loss_train: 1.4043	loss_val: 1.4498	loss_test: 1.4419	accuracy_train: 0.3805	accuracy_val: 0.3894	accuracy_test: 0.3478
[server]	loss_train: 1.3955	loss_val: 1.4307	loss_test: 1.4065	accuracy_train: 0.3121	accuracy_val: 0.3176	accuracy_test: 0.2921
[server]	loss_train: 1.4268	loss_val: 1.4484	loss_test: 1.4534	accuracy_train: 0.3436	accuracy_val: 0.2593	accuracy_test: 0.3095
[server]	loss_train: 1.3857	loss_val: 1.4414	loss_test: 1.4023	accuracy_train: 0.3812	accuracy_val: 0.3153	accuracy_test: 0.3070
curr_round: 29	curr_val_accuracy: 0.3261	curr_test_accuracy: 0.3195
best_round: 25	best_val_accuracy: 0.3298	best_test_accuracy: 0.3133
--------------------------------------------------
round # 30		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4443	loss_val: 1.4851	loss_test: 1.5336	accuracy_train: 0.3142	accuracy_val: 0.3009	accuracy_test: 0.2957
[server]	loss_train: 1.3611	loss_val: 1.3782	loss_test: 1.4554	accuracy_train: 0.3967	accuracy_val: 0.3370	accuracy_test: 0.1979
[server]	loss_train: 1.2917	loss_val: 1.3834	loss_test: 1.3655	accuracy_train: 0.4500	accuracy_val: 0.3211	accuracy_test: 0.3874
[server]	loss_train: 1.4541	loss_val: 1.4309	loss_test: 1.4603	accuracy_train: 0.3313	accuracy_val: 0.3537	accuracy_test: 0.3373
[server]	loss_train: 1.3419	loss_val: 1.4305	loss_test: 1.4606	accuracy_train: 0.3879	accuracy_val: 0.2963	accuracy_test: 0.2661
[server]	loss_train: 1.3584	loss_val: 1.4363	loss_test: 1.3454	accuracy_train: 0.4233	accuracy_val: 0.3333	accuracy_test: 0.3690
[server]	loss_train: 1.3439	loss_val: 1.3676	loss_test: 1.4540	accuracy_train: 0.4000	accuracy_val: 0.3684	accuracy_test: 0.3711
[server]	loss_train: 1.3686	loss_val: 1.4279	loss_test: 1.3790	accuracy_train: 0.4340	accuracy_val: 0.3551	accuracy_test: 0.3303
[server]	loss_train: 1.3922	loss_val: 1.4222	loss_test: 1.3839	accuracy_train: 0.3765	accuracy_val: 0.2683	accuracy_test: 0.3333
[server]	loss_train: 1.3439	loss_val: 1.3737	loss_test: 1.3948	accuracy_train: 0.4332	accuracy_val: 0.3611	accuracy_test: 0.3784
[server]	loss_train: 1.3889	loss_val: 1.4484	loss_test: 1.4765	accuracy_train: 0.4067	accuracy_val: 0.3378	accuracy_test: 0.2857
[server]	loss_train: 1.4143	loss_val: 1.4116	loss_test: 1.3731	accuracy_train: 0.3471	accuracy_val: 0.2907	accuracy_test: 0.3333
[server]	loss_train: 1.3442	loss_val: 1.3945	loss_test: 1.4038	accuracy_train: 0.4527	accuracy_val: 0.3784	accuracy_test: 0.2857
[server]	loss_train: 1.3410	loss_val: 1.3672	loss_test: 1.4704	accuracy_train: 0.4114	accuracy_val: 0.3596	accuracy_test: 0.2418
[server]	loss_train: 1.2984	loss_val: 1.3799	loss_test: 1.4399	accuracy_train: 0.4684	accuracy_val: 0.3298	accuracy_test: 0.3333
[server]	loss_train: 1.4217	loss_val: 1.4902	loss_test: 1.4180	accuracy_train: 0.3478	accuracy_val: 0.2941	accuracy_test: 0.4151
[server]	loss_train: 1.4003	loss_val: 1.4477	loss_test: 1.4401	accuracy_train: 0.3805	accuracy_val: 0.3982	accuracy_test: 0.3478
[server]	loss_train: 1.3904	loss_val: 1.4277	loss_test: 1.4018	accuracy_train: 0.3179	accuracy_val: 0.3059	accuracy_test: 0.2809
[server]	loss_train: 1.4218	loss_val: 1.4467	loss_test: 1.4512	accuracy_train: 0.3436	accuracy_val: 0.2469	accuracy_test: 0.3095
[server]	loss_train: 1.3801	loss_val: 1.4395	loss_test: 1.3971	accuracy_train: 0.3991	accuracy_val: 0.3423	accuracy_test: 0.2982
curr_round: 30	curr_val_accuracy: 0.3298	curr_test_accuracy: 0.3216
best_round: 30	best_val_accuracy: 0.3298	best_test_accuracy: 0.3216
--------------------------------------------------
round # 31		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4399	loss_val: 1.4827	loss_test: 1.5328	accuracy_train: 0.3142	accuracy_val: 0.3009	accuracy_test: 0.2696
[server]	loss_train: 1.3565	loss_val: 1.3750	loss_test: 1.4543	accuracy_train: 0.4076	accuracy_val: 0.3370	accuracy_test: 0.2188
[server]	loss_train: 1.2888	loss_val: 1.3832	loss_test: 1.3658	accuracy_train: 0.4727	accuracy_val: 0.3211	accuracy_test: 0.3874
[server]	loss_train: 1.4531	loss_val: 1.4302	loss_test: 1.4588	accuracy_train: 0.3252	accuracy_val: 0.3415	accuracy_test: 0.3253
[server]	loss_train: 1.3368	loss_val: 1.4295	loss_test: 1.4600	accuracy_train: 0.3785	accuracy_val: 0.3056	accuracy_test: 0.2844
[server]	loss_train: 1.3537	loss_val: 1.4365	loss_test: 1.3418	accuracy_train: 0.4049	accuracy_val: 0.3086	accuracy_test: 0.3690
[server]	loss_train: 1.3395	loss_val: 1.3651	loss_test: 1.4551	accuracy_train: 0.4263	accuracy_val: 0.3684	accuracy_test: 0.3711
[server]	loss_train: 1.3651	loss_val: 1.4269	loss_test: 1.3765	accuracy_train: 0.4387	accuracy_val: 0.3458	accuracy_test: 0.3486
[server]	loss_train: 1.3868	loss_val: 1.4188	loss_test: 1.3771	accuracy_train: 0.3704	accuracy_val: 0.2561	accuracy_test: 0.3452
[server]	loss_train: 1.3393	loss_val: 1.3710	loss_test: 1.3941	accuracy_train: 0.4332	accuracy_val: 0.3519	accuracy_test: 0.3694
[server]	loss_train: 1.3835	loss_val: 1.4478	loss_test: 1.4761	accuracy_train: 0.4133	accuracy_val: 0.3243	accuracy_test: 0.2987
[server]	loss_train: 1.4125	loss_val: 1.4090	loss_test: 1.3718	accuracy_train: 0.3412	accuracy_val: 0.3256	accuracy_test: 0.3448
[server]	loss_train: 1.3389	loss_val: 1.3920	loss_test: 1.4005	accuracy_train: 0.4459	accuracy_val: 0.3514	accuracy_test: 0.2857
[server]	loss_train: 1.3369	loss_val: 1.3653	loss_test: 1.4721	accuracy_train: 0.4229	accuracy_val: 0.3596	accuracy_test: 0.2637
[server]	loss_train: 1.2946	loss_val: 1.3792	loss_test: 1.4400	accuracy_train: 0.4579	accuracy_val: 0.3298	accuracy_test: 0.3131
[server]	loss_train: 1.4182	loss_val: 1.4905	loss_test: 1.4145	accuracy_train: 0.3575	accuracy_val: 0.2745	accuracy_test: 0.4151
[server]	loss_train: 1.3965	loss_val: 1.4459	loss_test: 1.4384	accuracy_train: 0.3805	accuracy_val: 0.3894	accuracy_test: 0.3391
[server]	loss_train: 1.3857	loss_val: 1.4250	loss_test: 1.3976	accuracy_train: 0.3295	accuracy_val: 0.3294	accuracy_test: 0.2921
[server]	loss_train: 1.4170	loss_val: 1.4453	loss_test: 1.4494	accuracy_train: 0.3497	accuracy_val: 0.2469	accuracy_test: 0.2857
[server]	loss_train: 1.3749	loss_val: 1.4380	loss_test: 1.3924	accuracy_train: 0.4126	accuracy_val: 0.3514	accuracy_test: 0.2982
curr_round: 31	curr_val_accuracy: 0.3271	curr_test_accuracy: 0.3226
best_round: 30	best_val_accuracy: 0.3298	best_test_accuracy: 0.3216
--------------------------------------------------
round # 32		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4357	loss_val: 1.4804	loss_test: 1.5320	accuracy_train: 0.3319	accuracy_val: 0.3097	accuracy_test: 0.2609
[server]	loss_train: 1.3522	loss_val: 1.3721	loss_test: 1.4535	accuracy_train: 0.4076	accuracy_val: 0.3478	accuracy_test: 0.2083
[server]	loss_train: 1.2863	loss_val: 1.3831	loss_test: 1.3665	accuracy_train: 0.4682	accuracy_val: 0.3303	accuracy_test: 0.4054
[server]	loss_train: 1.4522	loss_val: 1.4295	loss_test: 1.4576	accuracy_train: 0.3374	accuracy_val: 0.3171	accuracy_test: 0.3373
[server]	loss_train: 1.3319	loss_val: 1.4288	loss_test: 1.4595	accuracy_train: 0.3879	accuracy_val: 0.2870	accuracy_test: 0.2936
[server]	loss_train: 1.3492	loss_val: 1.4369	loss_test: 1.3386	accuracy_train: 0.4233	accuracy_val: 0.3086	accuracy_test: 0.3810
[server]	loss_train: 1.3353	loss_val: 1.3631	loss_test: 1.4564	accuracy_train: 0.4263	accuracy_val: 0.3579	accuracy_test: 0.3814
[server]	loss_train: 1.3618	loss_val: 1.4261	loss_test: 1.3743	accuracy_train: 0.4340	accuracy_val: 0.3271	accuracy_test: 0.3394
[server]	loss_train: 1.3817	loss_val: 1.4157	loss_test: 1.3708	accuracy_train: 0.3951	accuracy_val: 0.2561	accuracy_test: 0.3690
[server]	loss_train: 1.3349	loss_val: 1.3685	loss_test: 1.3935	accuracy_train: 0.4286	accuracy_val: 0.3426	accuracy_test: 0.3784
[server]	loss_train: 1.3783	loss_val: 1.4475	loss_test: 1.4759	accuracy_train: 0.4133	accuracy_val: 0.3243	accuracy_test: 0.3247
[server]	loss_train: 1.4107	loss_val: 1.4067	loss_test: 1.3707	accuracy_train: 0.3353	accuracy_val: 0.3256	accuracy_test: 0.3333
[server]	loss_train: 1.3341	loss_val: 1.3899	loss_test: 1.3975	accuracy_train: 0.4797	accuracy_val: 0.3243	accuracy_test: 0.2727
[server]	loss_train: 1.3332	loss_val: 1.3638	loss_test: 1.4740	accuracy_train: 0.4343	accuracy_val: 0.3146	accuracy_test: 0.2637
[server]	loss_train: 1.2910	loss_val: 1.3789	loss_test: 1.4403	accuracy_train: 0.4526	accuracy_val: 0.3298	accuracy_test: 0.3131
[server]	loss_train: 1.4149	loss_val: 1.4909	loss_test: 1.4113	accuracy_train: 0.3575	accuracy_val: 0.2745	accuracy_test: 0.4245
[server]	loss_train: 1.3930	loss_val: 1.4442	loss_test: 1.4368	accuracy_train: 0.3673	accuracy_val: 0.3982	accuracy_test: 0.3478
[server]	loss_train: 1.3813	loss_val: 1.4227	loss_test: 1.3937	accuracy_train: 0.3353	accuracy_val: 0.3294	accuracy_test: 0.2697
[server]	loss_train: 1.4125	loss_val: 1.4442	loss_test: 1.4479	accuracy_train: 0.3742	accuracy_val: 0.2593	accuracy_test: 0.3095
[server]	loss_train: 1.3701	loss_val: 1.4367	loss_test: 1.3880	accuracy_train: 0.4126	accuracy_val: 0.3514	accuracy_test: 0.3070
curr_round: 32	curr_val_accuracy: 0.3224	curr_test_accuracy: 0.3273
best_round: 30	best_val_accuracy: 0.3298	best_test_accuracy: 0.3216
--------------------------------------------------
round # 33		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4318	loss_val: 1.4784	loss_test: 1.5314	accuracy_train: 0.3274	accuracy_val: 0.3363	accuracy_test: 0.2696
[server]	loss_train: 1.3483	loss_val: 1.3696	loss_test: 1.4529	accuracy_train: 0.4185	accuracy_val: 0.3478	accuracy_test: 0.2396
[server]	loss_train: 1.2841	loss_val: 1.3833	loss_test: 1.3674	accuracy_train: 0.4773	accuracy_val: 0.3394	accuracy_test: 0.4054
[server]	loss_train: 1.4512	loss_val: 1.4290	loss_test: 1.4565	accuracy_train: 0.3374	accuracy_val: 0.3171	accuracy_test: 0.3253
[server]	loss_train: 1.3274	loss_val: 1.4283	loss_test: 1.4592	accuracy_train: 0.4065	accuracy_val: 0.2870	accuracy_test: 0.2936
[server]	loss_train: 1.3451	loss_val: 1.4374	loss_test: 1.3357	accuracy_train: 0.4172	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.3314	loss_val: 1.3615	loss_test: 1.4578	accuracy_train: 0.4263	accuracy_val: 0.3684	accuracy_test: 0.3711
[server]	loss_train: 1.3588	loss_val: 1.4255	loss_test: 1.3724	accuracy_train: 0.4245	accuracy_val: 0.3271	accuracy_test: 0.3578
[server]	loss_train: 1.3771	loss_val: 1.4129	loss_test: 1.3652	accuracy_train: 0.4259	accuracy_val: 0.2561	accuracy_test: 0.3810
[server]	loss_train: 1.3309	loss_val: 1.3662	loss_test: 1.3931	accuracy_train: 0.4424	accuracy_val: 0.3519	accuracy_test: 0.3423
[server]	loss_train: 1.3734	loss_val: 1.4473	loss_test: 1.4760	accuracy_train: 0.4200	accuracy_val: 0.3108	accuracy_test: 0.3247
[server]	loss_train: 1.4091	loss_val: 1.4048	loss_test: 1.3699	accuracy_train: 0.3412	accuracy_val: 0.3140	accuracy_test: 0.3333
[server]	loss_train: 1.3296	loss_val: 1.3880	loss_test: 1.3948	accuracy_train: 0.4730	accuracy_val: 0.3514	accuracy_test: 0.2987
[server]	loss_train: 1.3299	loss_val: 1.3626	loss_test: 1.4761	accuracy_train: 0.4343	accuracy_val: 0.3146	accuracy_test: 0.2637
[server]	loss_train: 1.2877	loss_val: 1.3788	loss_test: 1.4407	accuracy_train: 0.4579	accuracy_val: 0.3298	accuracy_test: 0.3030
[server]	loss_train: 1.4118	loss_val: 1.4913	loss_test: 1.4086	accuracy_train: 0.3671	accuracy_val: 0.2941	accuracy_test: 0.4245
[server]	loss_train: 1.3896	loss_val: 1.4428	loss_test: 1.4352	accuracy_train: 0.3761	accuracy_val: 0.4071	accuracy_test: 0.3478
[server]	loss_train: 1.3772	loss_val: 1.4208	loss_test: 1.3902	accuracy_train: 0.3410	accuracy_val: 0.3412	accuracy_test: 0.2809
[server]	loss_train: 1.4082	loss_val: 1.4433	loss_test: 1.4465	accuracy_train: 0.3620	accuracy_val: 0.2593	accuracy_test: 0.3095
[server]	loss_train: 1.3654	loss_val: 1.4358	loss_test: 1.3841	accuracy_train: 0.4260	accuracy_val: 0.3514	accuracy_test: 0.3421
curr_round: 33	curr_val_accuracy: 0.3266	curr_test_accuracy: 0.3314
best_round: 30	best_val_accuracy: 0.3298	best_test_accuracy: 0.3216
--------------------------------------------------
round # 34		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4281	loss_val: 1.4767	loss_test: 1.5310	accuracy_train: 0.3319	accuracy_val: 0.3363	accuracy_test: 0.2783
[server]	loss_train: 1.3446	loss_val: 1.3673	loss_test: 1.4524	accuracy_train: 0.4185	accuracy_val: 0.3261	accuracy_test: 0.2812
[server]	loss_train: 1.2821	loss_val: 1.3835	loss_test: 1.3685	accuracy_train: 0.4818	accuracy_val: 0.3486	accuracy_test: 0.4054
[server]	loss_train: 1.4504	loss_val: 1.4285	loss_test: 1.4556	accuracy_train: 0.3436	accuracy_val: 0.2927	accuracy_test: 0.3253
[server]	loss_train: 1.3231	loss_val: 1.4280	loss_test: 1.4589	accuracy_train: 0.4112	accuracy_val: 0.2870	accuracy_test: 0.2936
[server]	loss_train: 1.3413	loss_val: 1.4380	loss_test: 1.3332	accuracy_train: 0.4294	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.3277	loss_val: 1.3602	loss_test: 1.4591	accuracy_train: 0.4158	accuracy_val: 0.3684	accuracy_test: 0.3918
[server]	loss_train: 1.3560	loss_val: 1.4252	loss_test: 1.3708	accuracy_train: 0.4292	accuracy_val: 0.3364	accuracy_test: 0.3486
[server]	loss_train: 1.3728	loss_val: 1.4104	loss_test: 1.3601	accuracy_train: 0.4259	accuracy_val: 0.2805	accuracy_test: 0.3810
[server]	loss_train: 1.3272	loss_val: 1.3642	loss_test: 1.3928	accuracy_train: 0.4654	accuracy_val: 0.3611	accuracy_test: 0.3423
[server]	loss_train: 1.3687	loss_val: 1.4473	loss_test: 1.4762	accuracy_train: 0.4267	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.4075	loss_val: 1.4032	loss_test: 1.3693	accuracy_train: 0.3471	accuracy_val: 0.3256	accuracy_test: 0.3333
[server]	loss_train: 1.3254	loss_val: 1.3862	loss_test: 1.3924	accuracy_train: 0.4595	accuracy_val: 0.3784	accuracy_test: 0.3117
[server]	loss_train: 1.3270	loss_val: 1.3616	loss_test: 1.4783	accuracy_train: 0.4400	accuracy_val: 0.3258	accuracy_test: 0.2637
[server]	loss_train: 1.2845	loss_val: 1.3790	loss_test: 1.4412	accuracy_train: 0.4526	accuracy_val: 0.3404	accuracy_test: 0.2929
[server]	loss_train: 1.4089	loss_val: 1.4917	loss_test: 1.4061	accuracy_train: 0.3671	accuracy_val: 0.2941	accuracy_test: 0.3962
[server]	loss_train: 1.3864	loss_val: 1.4415	loss_test: 1.4337	accuracy_train: 0.3805	accuracy_val: 0.4071	accuracy_test: 0.3478
[server]	loss_train: 1.3734	loss_val: 1.4193	loss_test: 1.3870	accuracy_train: 0.3468	accuracy_val: 0.3294	accuracy_test: 0.2921
[server]	loss_train: 1.4041	loss_val: 1.4426	loss_test: 1.4453	accuracy_train: 0.3804	accuracy_val: 0.2840	accuracy_test: 0.2976
[server]	loss_train: 1.3611	loss_val: 1.4350	loss_test: 1.3804	accuracy_train: 0.4350	accuracy_val: 0.3514	accuracy_test: 0.3509
curr_round: 34	curr_val_accuracy: 0.3303	curr_test_accuracy: 0.3329
best_round: 34	best_val_accuracy: 0.3303	best_test_accuracy: 0.3329
--------------------------------------------------
round # 35		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4246	loss_val: 1.4751	loss_test: 1.5306	accuracy_train: 0.3407	accuracy_val: 0.3274	accuracy_test: 0.2783
[server]	loss_train: 1.3411	loss_val: 1.3654	loss_test: 1.4521	accuracy_train: 0.4185	accuracy_val: 0.3261	accuracy_test: 0.3021
[server]	loss_train: 1.2803	loss_val: 1.3837	loss_test: 1.3697	accuracy_train: 0.4773	accuracy_val: 0.3486	accuracy_test: 0.3964
[server]	loss_train: 1.4495	loss_val: 1.4281	loss_test: 1.4548	accuracy_train: 0.3681	accuracy_val: 0.2927	accuracy_test: 0.3253
[server]	loss_train: 1.3190	loss_val: 1.4279	loss_test: 1.4588	accuracy_train: 0.4206	accuracy_val: 0.2870	accuracy_test: 0.2752
[server]	loss_train: 1.3377	loss_val: 1.4387	loss_test: 1.3309	accuracy_train: 0.4294	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.3242	loss_val: 1.3593	loss_test: 1.4604	accuracy_train: 0.4158	accuracy_val: 0.3684	accuracy_test: 0.3918
[server]	loss_train: 1.3534	loss_val: 1.4250	loss_test: 1.3695	accuracy_train: 0.4198	accuracy_val: 0.3364	accuracy_test: 0.3486
[server]	loss_train: 1.3689	loss_val: 1.4082	loss_test: 1.3554	accuracy_train: 0.4198	accuracy_val: 0.2927	accuracy_test: 0.3929
[server]	loss_train: 1.3236	loss_val: 1.3624	loss_test: 1.3927	accuracy_train: 0.4654	accuracy_val: 0.3704	accuracy_test: 0.3333
[server]	loss_train: 1.3641	loss_val: 1.4475	loss_test: 1.4765	accuracy_train: 0.4333	accuracy_val: 0.3108	accuracy_test: 0.2987
[server]	loss_train: 1.4060	loss_val: 1.4019	loss_test: 1.3687	accuracy_train: 0.3412	accuracy_val: 0.3256	accuracy_test: 0.3333
[server]	loss_train: 1.3215	loss_val: 1.3846	loss_test: 1.3902	accuracy_train: 0.4595	accuracy_val: 0.3649	accuracy_test: 0.3247
[server]	loss_train: 1.3244	loss_val: 1.3608	loss_test: 1.4805	accuracy_train: 0.4514	accuracy_val: 0.3258	accuracy_test: 0.2637
[server]	loss_train: 1.2816	loss_val: 1.3794	loss_test: 1.4417	accuracy_train: 0.4526	accuracy_val: 0.3404	accuracy_test: 0.2929
[server]	loss_train: 1.4062	loss_val: 1.4921	loss_test: 1.4041	accuracy_train: 0.3720	accuracy_val: 0.2941	accuracy_test: 0.3962
[server]	loss_train: 1.3834	loss_val: 1.4404	loss_test: 1.4323	accuracy_train: 0.3894	accuracy_val: 0.4248	accuracy_test: 0.3391
[server]	loss_train: 1.3698	loss_val: 1.4182	loss_test: 1.3841	accuracy_train: 0.3526	accuracy_val: 0.3176	accuracy_test: 0.3034
[server]	loss_train: 1.4002	loss_val: 1.4421	loss_test: 1.4443	accuracy_train: 0.3804	accuracy_val: 0.2840	accuracy_test: 0.2976
[server]	loss_train: 1.3569	loss_val: 1.4345	loss_test: 1.3770	accuracy_train: 0.4260	accuracy_val: 0.3694	accuracy_test: 0.3684
curr_round: 35	curr_val_accuracy: 0.3319	curr_test_accuracy: 0.3334
best_round: 35	best_val_accuracy: 0.3319	best_test_accuracy: 0.3334
--------------------------------------------------
round # 36		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4212	loss_val: 1.4737	loss_test: 1.5302	accuracy_train: 0.3761	accuracy_val: 0.3097	accuracy_test: 0.2870
[server]	loss_train: 1.3379	loss_val: 1.3636	loss_test: 1.4518	accuracy_train: 0.4565	accuracy_val: 0.3152	accuracy_test: 0.2812
[server]	loss_train: 1.2787	loss_val: 1.3840	loss_test: 1.3710	accuracy_train: 0.4727	accuracy_val: 0.3486	accuracy_test: 0.3964
[server]	loss_train: 1.4486	loss_val: 1.4277	loss_test: 1.4541	accuracy_train: 0.3742	accuracy_val: 0.2927	accuracy_test: 0.3133
[server]	loss_train: 1.3152	loss_val: 1.4280	loss_test: 1.4587	accuracy_train: 0.4439	accuracy_val: 0.2778	accuracy_test: 0.2844
[server]	loss_train: 1.3344	loss_val: 1.4394	loss_test: 1.3288	accuracy_train: 0.4356	accuracy_val: 0.3086	accuracy_test: 0.3929
[server]	loss_train: 1.3209	loss_val: 1.3585	loss_test: 1.4616	accuracy_train: 0.4211	accuracy_val: 0.4000	accuracy_test: 0.3814
[server]	loss_train: 1.3510	loss_val: 1.4249	loss_test: 1.3684	accuracy_train: 0.4245	accuracy_val: 0.3645	accuracy_test: 0.3394
[server]	loss_train: 1.3652	loss_val: 1.4061	loss_test: 1.3511	accuracy_train: 0.4136	accuracy_val: 0.2927	accuracy_test: 0.3929
[server]	loss_train: 1.3203	loss_val: 1.3608	loss_test: 1.3927	accuracy_train: 0.4654	accuracy_val: 0.3611	accuracy_test: 0.3333
[server]	loss_train: 1.3598	loss_val: 1.4478	loss_test: 1.4769	accuracy_train: 0.4533	accuracy_val: 0.3108	accuracy_test: 0.2987
[server]	loss_train: 1.4045	loss_val: 1.4008	loss_test: 1.3682	accuracy_train: 0.3471	accuracy_val: 0.3372	accuracy_test: 0.3678
[server]	loss_train: 1.3179	loss_val: 1.3830	loss_test: 1.3883	accuracy_train: 0.4662	accuracy_val: 0.3784	accuracy_test: 0.3506
[server]	loss_train: 1.3220	loss_val: 1.3602	loss_test: 1.4828	accuracy_train: 0.4514	accuracy_val: 0.3146	accuracy_test: 0.2857
[server]	loss_train: 1.2788	loss_val: 1.3799	loss_test: 1.4422	accuracy_train: 0.4579	accuracy_val: 0.3404	accuracy_test: 0.2929
[server]	loss_train: 1.4037	loss_val: 1.4924	loss_test: 1.4023	accuracy_train: 0.4010	accuracy_val: 0.3137	accuracy_test: 0.3868
[server]	loss_train: 1.3806	loss_val: 1.4394	loss_test: 1.4310	accuracy_train: 0.3938	accuracy_val: 0.4513	accuracy_test: 0.3478
[server]	loss_train: 1.3664	loss_val: 1.4173	loss_test: 1.3814	accuracy_train: 0.3699	accuracy_val: 0.3176	accuracy_test: 0.3146
[server]	loss_train: 1.3965	loss_val: 1.4417	loss_test: 1.4434	accuracy_train: 0.3865	accuracy_val: 0.2963	accuracy_test: 0.3214
[server]	loss_train: 1.3528	loss_val: 1.4341	loss_test: 1.3738	accuracy_train: 0.4350	accuracy_val: 0.3694	accuracy_test: 0.3684
curr_round: 36	curr_val_accuracy: 0.3372	curr_test_accuracy: 0.3370
best_round: 36	best_val_accuracy: 0.3372	best_test_accuracy: 0.3370
--------------------------------------------------
round # 37		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4180	loss_val: 1.4725	loss_test: 1.5300	accuracy_train: 0.3850	accuracy_val: 0.3097	accuracy_test: 0.2783
[server]	loss_train: 1.3348	loss_val: 1.3621	loss_test: 1.4516	accuracy_train: 0.4565	accuracy_val: 0.3370	accuracy_test: 0.2812
[server]	loss_train: 1.2772	loss_val: 1.3844	loss_test: 1.3723	accuracy_train: 0.4682	accuracy_val: 0.3578	accuracy_test: 0.3964
[server]	loss_train: 1.4476	loss_val: 1.4273	loss_test: 1.4534	accuracy_train: 0.3681	accuracy_val: 0.2927	accuracy_test: 0.3012
[server]	loss_train: 1.3115	loss_val: 1.4282	loss_test: 1.4587	accuracy_train: 0.4439	accuracy_val: 0.2685	accuracy_test: 0.2936
[server]	loss_train: 1.3312	loss_val: 1.4401	loss_test: 1.3269	accuracy_train: 0.4356	accuracy_val: 0.3086	accuracy_test: 0.3810
[server]	loss_train: 1.3178	loss_val: 1.3579	loss_test: 1.4628	accuracy_train: 0.4158	accuracy_val: 0.4105	accuracy_test: 0.3814
[server]	loss_train: 1.3487	loss_val: 1.4250	loss_test: 1.3676	accuracy_train: 0.4104	accuracy_val: 0.3645	accuracy_test: 0.3303
[server]	loss_train: 1.3617	loss_val: 1.4043	loss_test: 1.3471	accuracy_train: 0.4136	accuracy_val: 0.3049	accuracy_test: 0.3810
[server]	loss_train: 1.3172	loss_val: 1.3593	loss_test: 1.3928	accuracy_train: 0.4470	accuracy_val: 0.3519	accuracy_test: 0.3423
[server]	loss_train: 1.3556	loss_val: 1.4481	loss_test: 1.4774	accuracy_train: 0.4400	accuracy_val: 0.2973	accuracy_test: 0.2987
[server]	loss_train: 1.4030	loss_val: 1.4000	loss_test: 1.3678	accuracy_train: 0.3412	accuracy_val: 0.3372	accuracy_test: 0.3793
[server]	loss_train: 1.3144	loss_val: 1.3815	loss_test: 1.3866	accuracy_train: 0.5068	accuracy_val: 0.3649	accuracy_test: 0.3117
[server]	loss_train: 1.3199	loss_val: 1.3597	loss_test: 1.4851	accuracy_train: 0.4343	accuracy_val: 0.3371	accuracy_test: 0.2857
[server]	loss_train: 1.2762	loss_val: 1.3806	loss_test: 1.4428	accuracy_train: 0.4526	accuracy_val: 0.3298	accuracy_test: 0.2828
[server]	loss_train: 1.4013	loss_val: 1.4927	loss_test: 1.4007	accuracy_train: 0.4010	accuracy_val: 0.3039	accuracy_test: 0.3868
[server]	loss_train: 1.3779	loss_val: 1.4385	loss_test: 1.4297	accuracy_train: 0.3761	accuracy_val: 0.4336	accuracy_test: 0.3391
[server]	loss_train: 1.3632	loss_val: 1.4168	loss_test: 1.3789	accuracy_train: 0.3988	accuracy_val: 0.3176	accuracy_test: 0.3146
[server]	loss_train: 1.3929	loss_val: 1.4414	loss_test: 1.4427	accuracy_train: 0.3681	accuracy_val: 0.3086	accuracy_test: 0.3095
[server]	loss_train: 1.3490	loss_val: 1.4338	loss_test: 1.3708	accuracy_train: 0.4395	accuracy_val: 0.3784	accuracy_test: 0.3772
curr_round: 37	curr_val_accuracy: 0.3377	curr_test_accuracy: 0.3334
best_round: 37	best_val_accuracy: 0.3377	best_test_accuracy: 0.3334
--------------------------------------------------
round # 38		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4148	loss_val: 1.4714	loss_test: 1.5297	accuracy_train: 0.3850	accuracy_val: 0.2920	accuracy_test: 0.2870
[server]	loss_train: 1.3319	loss_val: 1.3608	loss_test: 1.4515	accuracy_train: 0.4674	accuracy_val: 0.3587	accuracy_test: 0.2812
[server]	loss_train: 1.2758	loss_val: 1.3848	loss_test: 1.3735	accuracy_train: 0.4682	accuracy_val: 0.3578	accuracy_test: 0.3964
[server]	loss_train: 1.4466	loss_val: 1.4270	loss_test: 1.4528	accuracy_train: 0.3681	accuracy_val: 0.2927	accuracy_test: 0.2892
[server]	loss_train: 1.3081	loss_val: 1.4284	loss_test: 1.4586	accuracy_train: 0.4533	accuracy_val: 0.2685	accuracy_test: 0.3028
[server]	loss_train: 1.3283	loss_val: 1.4408	loss_test: 1.3251	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.3810
[server]	loss_train: 1.3149	loss_val: 1.3575	loss_test: 1.4639	accuracy_train: 0.4105	accuracy_val: 0.3895	accuracy_test: 0.3711
[server]	loss_train: 1.3466	loss_val: 1.4252	loss_test: 1.3669	accuracy_train: 0.3962	accuracy_val: 0.3738	accuracy_test: 0.3211
[server]	loss_train: 1.3585	loss_val: 1.4025	loss_test: 1.3434	accuracy_train: 0.3889	accuracy_val: 0.3171	accuracy_test: 0.3810
[server]	loss_train: 1.3142	loss_val: 1.3580	loss_test: 1.3929	accuracy_train: 0.4608	accuracy_val: 0.3704	accuracy_test: 0.3604
[server]	loss_train: 1.3516	loss_val: 1.4485	loss_test: 1.4780	accuracy_train: 0.4600	accuracy_val: 0.2973	accuracy_test: 0.2857
[server]	loss_train: 1.4015	loss_val: 1.3993	loss_test: 1.3673	accuracy_train: 0.3412	accuracy_val: 0.3372	accuracy_test: 0.3908
[server]	loss_train: 1.3112	loss_val: 1.3800	loss_test: 1.3851	accuracy_train: 0.5000	accuracy_val: 0.3919	accuracy_test: 0.3117
[server]	loss_train: 1.3181	loss_val: 1.3594	loss_test: 1.4874	accuracy_train: 0.4400	accuracy_val: 0.3371	accuracy_test: 0.2637
[server]	loss_train: 1.2737	loss_val: 1.3814	loss_test: 1.4433	accuracy_train: 0.4474	accuracy_val: 0.3404	accuracy_test: 0.2929
[server]	loss_train: 1.3990	loss_val: 1.4930	loss_test: 1.3994	accuracy_train: 0.4155	accuracy_val: 0.3039	accuracy_test: 0.3962
[server]	loss_train: 1.3754	loss_val: 1.4377	loss_test: 1.4285	accuracy_train: 0.3805	accuracy_val: 0.4159	accuracy_test: 0.3478
[server]	loss_train: 1.3601	loss_val: 1.4165	loss_test: 1.3767	accuracy_train: 0.3988	accuracy_val: 0.3294	accuracy_test: 0.3258
[server]	loss_train: 1.3894	loss_val: 1.4412	loss_test: 1.4421	accuracy_train: 0.3681	accuracy_val: 0.3086	accuracy_test: 0.3095
[server]	loss_train: 1.3453	loss_val: 1.4336	loss_test: 1.3681	accuracy_train: 0.4529	accuracy_val: 0.3784	accuracy_test: 0.3772
curr_round: 38	curr_val_accuracy: 0.3388	curr_test_accuracy: 0.3350
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 39		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4118	loss_val: 1.4704	loss_test: 1.5296	accuracy_train: 0.3761	accuracy_val: 0.3009	accuracy_test: 0.2696
[server]	loss_train: 1.3292	loss_val: 1.3596	loss_test: 1.4514	accuracy_train: 0.4728	accuracy_val: 0.3478	accuracy_test: 0.2812
[server]	loss_train: 1.2746	loss_val: 1.3853	loss_test: 1.3748	accuracy_train: 0.4727	accuracy_val: 0.3578	accuracy_test: 0.4054
[server]	loss_train: 1.4456	loss_val: 1.4266	loss_test: 1.4522	accuracy_train: 0.3558	accuracy_val: 0.2927	accuracy_test: 0.3012
[server]	loss_train: 1.3048	loss_val: 1.4287	loss_test: 1.4587	accuracy_train: 0.4533	accuracy_val: 0.2685	accuracy_test: 0.3119
[server]	loss_train: 1.3255	loss_val: 1.4416	loss_test: 1.3235	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.3810
[server]	loss_train: 1.3121	loss_val: 1.3572	loss_test: 1.4651	accuracy_train: 0.4158	accuracy_val: 0.4000	accuracy_test: 0.3814
[server]	loss_train: 1.3446	loss_val: 1.4255	loss_test: 1.3665	accuracy_train: 0.4104	accuracy_val: 0.3738	accuracy_test: 0.3303
[server]	loss_train: 1.3555	loss_val: 1.4010	loss_test: 1.3400	accuracy_train: 0.4012	accuracy_val: 0.3171	accuracy_test: 0.3810
[server]	loss_train: 1.3114	loss_val: 1.3568	loss_test: 1.3932	accuracy_train: 0.4608	accuracy_val: 0.3704	accuracy_test: 0.3694
[server]	loss_train: 1.3476	loss_val: 1.4490	loss_test: 1.4786	accuracy_train: 0.4600	accuracy_val: 0.2973	accuracy_test: 0.2857
[server]	loss_train: 1.4001	loss_val: 1.3987	loss_test: 1.3669	accuracy_train: 0.3353	accuracy_val: 0.3140	accuracy_test: 0.3793
[server]	loss_train: 1.3082	loss_val: 1.3786	loss_test: 1.3838	accuracy_train: 0.5000	accuracy_val: 0.3919	accuracy_test: 0.3247
[server]	loss_train: 1.3164	loss_val: 1.3592	loss_test: 1.4897	accuracy_train: 0.4286	accuracy_val: 0.3371	accuracy_test: 0.2527
[server]	loss_train: 1.2713	loss_val: 1.3823	loss_test: 1.4438	accuracy_train: 0.4526	accuracy_val: 0.3298	accuracy_test: 0.2929
[server]	loss_train: 1.3968	loss_val: 1.4933	loss_test: 1.3983	accuracy_train: 0.4106	accuracy_val: 0.3039	accuracy_test: 0.3868
[server]	loss_train: 1.3730	loss_val: 1.4370	loss_test: 1.4274	accuracy_train: 0.3850	accuracy_val: 0.4159	accuracy_test: 0.3739
[server]	loss_train: 1.3573	loss_val: 1.4164	loss_test: 1.3747	accuracy_train: 0.3931	accuracy_val: 0.3294	accuracy_test: 0.3146
[server]	loss_train: 1.3862	loss_val: 1.4411	loss_test: 1.4416	accuracy_train: 0.3681	accuracy_val: 0.2963	accuracy_test: 0.3095
[server]	loss_train: 1.3418	loss_val: 1.4335	loss_test: 1.3655	accuracy_train: 0.4439	accuracy_val: 0.3784	accuracy_test: 0.3684
curr_round: 39	curr_val_accuracy: 0.3372	curr_test_accuracy: 0.3365
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 40		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4089	loss_val: 1.4696	loss_test: 1.5294	accuracy_train: 0.3761	accuracy_val: 0.2920	accuracy_test: 0.2783
[server]	loss_train: 1.3266	loss_val: 1.3586	loss_test: 1.4514	accuracy_train: 0.4728	accuracy_val: 0.3261	accuracy_test: 0.2917
[server]	loss_train: 1.2734	loss_val: 1.3858	loss_test: 1.3761	accuracy_train: 0.4727	accuracy_val: 0.3578	accuracy_test: 0.4054
[server]	loss_train: 1.4445	loss_val: 1.4263	loss_test: 1.4517	accuracy_train: 0.3558	accuracy_val: 0.2805	accuracy_test: 0.3012
[server]	loss_train: 1.3017	loss_val: 1.4291	loss_test: 1.4587	accuracy_train: 0.4579	accuracy_val: 0.2685	accuracy_test: 0.3119
[server]	loss_train: 1.3229	loss_val: 1.4423	loss_test: 1.3221	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.3095	loss_val: 1.3570	loss_test: 1.4662	accuracy_train: 0.4053	accuracy_val: 0.4000	accuracy_test: 0.3814
[server]	loss_train: 1.3428	loss_val: 1.4259	loss_test: 1.3662	accuracy_train: 0.4104	accuracy_val: 0.3645	accuracy_test: 0.3303
[server]	loss_train: 1.3526	loss_val: 1.3995	loss_test: 1.3369	accuracy_train: 0.4074	accuracy_val: 0.3293	accuracy_test: 0.3929
[server]	loss_train: 1.3087	loss_val: 1.3557	loss_test: 1.3936	accuracy_train: 0.4562	accuracy_val: 0.3704	accuracy_test: 0.3694
[server]	loss_train: 1.3438	loss_val: 1.4495	loss_test: 1.4793	accuracy_train: 0.4533	accuracy_val: 0.3108	accuracy_test: 0.2857
[server]	loss_train: 1.3987	loss_val: 1.3984	loss_test: 1.3666	accuracy_train: 0.3412	accuracy_val: 0.3256	accuracy_test: 0.3793
[server]	loss_train: 1.3053	loss_val: 1.3772	loss_test: 1.3827	accuracy_train: 0.4932	accuracy_val: 0.3919	accuracy_test: 0.3377
[server]	loss_train: 1.3148	loss_val: 1.3591	loss_test: 1.4919	accuracy_train: 0.4229	accuracy_val: 0.3371	accuracy_test: 0.2527
[server]	loss_train: 1.2691	loss_val: 1.3833	loss_test: 1.4444	accuracy_train: 0.4579	accuracy_val: 0.3298	accuracy_test: 0.2828
[server]	loss_train: 1.3947	loss_val: 1.4936	loss_test: 1.3973	accuracy_train: 0.4010	accuracy_val: 0.2843	accuracy_test: 0.3962
[server]	loss_train: 1.3707	loss_val: 1.4363	loss_test: 1.4263	accuracy_train: 0.3894	accuracy_val: 0.4159	accuracy_test: 0.3826
[server]	loss_train: 1.3545	loss_val: 1.4164	loss_test: 1.3728	accuracy_train: 0.3988	accuracy_val: 0.3412	accuracy_test: 0.3258
[server]	loss_train: 1.3830	loss_val: 1.4410	loss_test: 1.4413	accuracy_train: 0.3558	accuracy_val: 0.2963	accuracy_test: 0.2857
[server]	loss_train: 1.3384	loss_val: 1.4335	loss_test: 1.3632	accuracy_train: 0.4529	accuracy_val: 0.3694	accuracy_test: 0.3772
curr_round: 40	curr_val_accuracy: 0.3351	curr_test_accuracy: 0.3396
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 41		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4061	loss_val: 1.4688	loss_test: 1.5293	accuracy_train: 0.3761	accuracy_val: 0.2920	accuracy_test: 0.2870
[server]	loss_train: 1.3241	loss_val: 1.3576	loss_test: 1.4513	accuracy_train: 0.4728	accuracy_val: 0.3152	accuracy_test: 0.3021
[server]	loss_train: 1.2723	loss_val: 1.3864	loss_test: 1.3774	accuracy_train: 0.4727	accuracy_val: 0.3670	accuracy_test: 0.3964
[server]	loss_train: 1.4434	loss_val: 1.4260	loss_test: 1.4512	accuracy_train: 0.3436	accuracy_val: 0.2927	accuracy_test: 0.3012
[server]	loss_train: 1.2988	loss_val: 1.4296	loss_test: 1.4587	accuracy_train: 0.4626	accuracy_val: 0.2870	accuracy_test: 0.3119
[server]	loss_train: 1.3205	loss_val: 1.4431	loss_test: 1.3207	accuracy_train: 0.4540	accuracy_val: 0.2963	accuracy_test: 0.4048
[server]	loss_train: 1.3071	loss_val: 1.3569	loss_test: 1.4673	accuracy_train: 0.4211	accuracy_val: 0.4105	accuracy_test: 0.3918
[server]	loss_train: 1.3410	loss_val: 1.4263	loss_test: 1.3660	accuracy_train: 0.3962	accuracy_val: 0.3645	accuracy_test: 0.3119
[server]	loss_train: 1.3499	loss_val: 1.3982	loss_test: 1.3341	accuracy_train: 0.4012	accuracy_val: 0.3293	accuracy_test: 0.4167
[server]	loss_train: 1.3061	loss_val: 1.3547	loss_test: 1.3940	accuracy_train: 0.4654	accuracy_val: 0.3704	accuracy_test: 0.3604
[server]	loss_train: 1.3401	loss_val: 1.4501	loss_test: 1.4800	accuracy_train: 0.4667	accuracy_val: 0.3108	accuracy_test: 0.2857
[server]	loss_train: 1.3974	loss_val: 1.3981	loss_test: 1.3663	accuracy_train: 0.3412	accuracy_val: 0.3488	accuracy_test: 0.3793
[server]	loss_train: 1.3026	loss_val: 1.3759	loss_test: 1.3818	accuracy_train: 0.4797	accuracy_val: 0.3919	accuracy_test: 0.3377
[server]	loss_train: 1.3134	loss_val: 1.3591	loss_test: 1.4941	accuracy_train: 0.4229	accuracy_val: 0.3483	accuracy_test: 0.2527
[server]	loss_train: 1.2669	loss_val: 1.3843	loss_test: 1.4449	accuracy_train: 0.4684	accuracy_val: 0.3404	accuracy_test: 0.2828
[server]	loss_train: 1.3926	loss_val: 1.4938	loss_test: 1.3965	accuracy_train: 0.4010	accuracy_val: 0.2843	accuracy_test: 0.3962
[server]	loss_train: 1.3686	loss_val: 1.4358	loss_test: 1.4253	accuracy_train: 0.3938	accuracy_val: 0.4248	accuracy_test: 0.3739
[server]	loss_train: 1.3519	loss_val: 1.4166	loss_test: 1.3712	accuracy_train: 0.4046	accuracy_val: 0.3529	accuracy_test: 0.3258
[server]	loss_train: 1.3800	loss_val: 1.4410	loss_test: 1.4410	accuracy_train: 0.3497	accuracy_val: 0.2840	accuracy_test: 0.2976
[server]	loss_train: 1.3352	loss_val: 1.4335	loss_test: 1.3609	accuracy_train: 0.4484	accuracy_val: 0.3423	accuracy_test: 0.3772
curr_round: 41	curr_val_accuracy: 0.3388	curr_test_accuracy: 0.3407
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 42		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4034	loss_val: 1.4681	loss_test: 1.5292	accuracy_train: 0.3938	accuracy_val: 0.2832	accuracy_test: 0.2783
[server]	loss_train: 1.3218	loss_val: 1.3568	loss_test: 1.4514	accuracy_train: 0.4620	accuracy_val: 0.3152	accuracy_test: 0.3229
[server]	loss_train: 1.2712	loss_val: 1.3870	loss_test: 1.3786	accuracy_train: 0.4682	accuracy_val: 0.3578	accuracy_test: 0.3964
[server]	loss_train: 1.4422	loss_val: 1.4257	loss_test: 1.4507	accuracy_train: 0.3436	accuracy_val: 0.3049	accuracy_test: 0.2771
[server]	loss_train: 1.2959	loss_val: 1.4301	loss_test: 1.4588	accuracy_train: 0.4720	accuracy_val: 0.2870	accuracy_test: 0.3119
[server]	loss_train: 1.3181	loss_val: 1.4438	loss_test: 1.3195	accuracy_train: 0.4540	accuracy_val: 0.2963	accuracy_test: 0.3929
[server]	loss_train: 1.3048	loss_val: 1.3568	loss_test: 1.4684	accuracy_train: 0.4211	accuracy_val: 0.4105	accuracy_test: 0.3814
[server]	loss_train: 1.3393	loss_val: 1.4269	loss_test: 1.3659	accuracy_train: 0.4009	accuracy_val: 0.3551	accuracy_test: 0.3211
[server]	loss_train: 1.3474	loss_val: 1.3969	loss_test: 1.3314	accuracy_train: 0.3951	accuracy_val: 0.3293	accuracy_test: 0.4167
[server]	loss_train: 1.3036	loss_val: 1.3538	loss_test: 1.3945	accuracy_train: 0.4516	accuracy_val: 0.3796	accuracy_test: 0.3514
[server]	loss_train: 1.3365	loss_val: 1.4507	loss_test: 1.4807	accuracy_train: 0.4800	accuracy_val: 0.3108	accuracy_test: 0.2597
[server]	loss_train: 1.3960	loss_val: 1.3979	loss_test: 1.3661	accuracy_train: 0.3412	accuracy_val: 0.3488	accuracy_test: 0.3678
[server]	loss_train: 1.3000	loss_val: 1.3746	loss_test: 1.3810	accuracy_train: 0.4797	accuracy_val: 0.3919	accuracy_test: 0.3377
[server]	loss_train: 1.3122	loss_val: 1.3593	loss_test: 1.4962	accuracy_train: 0.4229	accuracy_val: 0.3483	accuracy_test: 0.2637
[server]	loss_train: 1.2649	loss_val: 1.3854	loss_test: 1.4453	accuracy_train: 0.4632	accuracy_val: 0.3298	accuracy_test: 0.3030
[server]	loss_train: 1.3907	loss_val: 1.4941	loss_test: 1.3958	accuracy_train: 0.4010	accuracy_val: 0.2941	accuracy_test: 0.4245
[server]	loss_train: 1.3665	loss_val: 1.4354	loss_test: 1.4243	accuracy_train: 0.3938	accuracy_val: 0.4159	accuracy_test: 0.3739
[server]	loss_train: 1.3494	loss_val: 1.4169	loss_test: 1.3697	accuracy_train: 0.4104	accuracy_val: 0.3529	accuracy_test: 0.3371
[server]	loss_train: 1.3771	loss_val: 1.4411	loss_test: 1.4408	accuracy_train: 0.3681	accuracy_val: 0.2840	accuracy_test: 0.3095
[server]	loss_train: 1.3322	loss_val: 1.4336	loss_test: 1.3589	accuracy_train: 0.4619	accuracy_val: 0.3514	accuracy_test: 0.3860
curr_round: 42	curr_val_accuracy: 0.3383	curr_test_accuracy: 0.3422
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 43		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4008	loss_val: 1.4675	loss_test: 1.5292	accuracy_train: 0.3982	accuracy_val: 0.2832	accuracy_test: 0.2783
[server]	loss_train: 1.3195	loss_val: 1.3561	loss_test: 1.4514	accuracy_train: 0.4620	accuracy_val: 0.3261	accuracy_test: 0.3229
[server]	loss_train: 1.2703	loss_val: 1.3877	loss_test: 1.3799	accuracy_train: 0.4682	accuracy_val: 0.3394	accuracy_test: 0.3874
[server]	loss_train: 1.4410	loss_val: 1.4255	loss_test: 1.4503	accuracy_train: 0.3436	accuracy_val: 0.3049	accuracy_test: 0.2771
[server]	loss_train: 1.2932	loss_val: 1.4306	loss_test: 1.4589	accuracy_train: 0.4766	accuracy_val: 0.2870	accuracy_test: 0.3211
[server]	loss_train: 1.3159	loss_val: 1.4446	loss_test: 1.3184	accuracy_train: 0.4540	accuracy_val: 0.2963	accuracy_test: 0.3810
[server]	loss_train: 1.3026	loss_val: 1.3569	loss_test: 1.4694	accuracy_train: 0.4158	accuracy_val: 0.4211	accuracy_test: 0.3711
[server]	loss_train: 1.3377	loss_val: 1.4275	loss_test: 1.3660	accuracy_train: 0.3962	accuracy_val: 0.3551	accuracy_test: 0.3119
[server]	loss_train: 1.3450	loss_val: 1.3958	loss_test: 1.3289	accuracy_train: 0.3889	accuracy_val: 0.3415	accuracy_test: 0.4048
[server]	loss_train: 1.3012	loss_val: 1.3529	loss_test: 1.3951	accuracy_train: 0.4562	accuracy_val: 0.3796	accuracy_test: 0.3514
[server]	loss_train: 1.3330	loss_val: 1.4513	loss_test: 1.4814	accuracy_train: 0.4867	accuracy_val: 0.3108	accuracy_test: 0.2468
[server]	loss_train: 1.3947	loss_val: 1.3979	loss_test: 1.3659	accuracy_train: 0.3529	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.2976	loss_val: 1.3733	loss_test: 1.3803	accuracy_train: 0.4730	accuracy_val: 0.3919	accuracy_test: 0.3377
[server]	loss_train: 1.3110	loss_val: 1.3595	loss_test: 1.4983	accuracy_train: 0.4229	accuracy_val: 0.3371	accuracy_test: 0.2527
[server]	loss_train: 1.2629	loss_val: 1.3865	loss_test: 1.4458	accuracy_train: 0.4632	accuracy_val: 0.3298	accuracy_test: 0.2929
[server]	loss_train: 1.3888	loss_val: 1.4943	loss_test: 1.3953	accuracy_train: 0.4058	accuracy_val: 0.2843	accuracy_test: 0.4151
[server]	loss_train: 1.3645	loss_val: 1.4350	loss_test: 1.4233	accuracy_train: 0.3850	accuracy_val: 0.4159	accuracy_test: 0.3826
[server]	loss_train: 1.3471	loss_val: 1.4173	loss_test: 1.3684	accuracy_train: 0.4104	accuracy_val: 0.3412	accuracy_test: 0.3258
[server]	loss_train: 1.3743	loss_val: 1.4412	loss_test: 1.4407	accuracy_train: 0.3681	accuracy_val: 0.2840	accuracy_test: 0.3095
[server]	loss_train: 1.3293	loss_val: 1.4336	loss_test: 1.3569	accuracy_train: 0.4484	accuracy_val: 0.3604	accuracy_test: 0.3947
curr_round: 43	curr_val_accuracy: 0.3377	curr_test_accuracy: 0.3380
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 44		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3982	loss_val: 1.4669	loss_test: 1.5291	accuracy_train: 0.4027	accuracy_val: 0.2920	accuracy_test: 0.2696
[server]	loss_train: 1.3174	loss_val: 1.3555	loss_test: 1.4515	accuracy_train: 0.4511	accuracy_val: 0.3261	accuracy_test: 0.3229
[server]	loss_train: 1.2693	loss_val: 1.3883	loss_test: 1.3811	accuracy_train: 0.4727	accuracy_val: 0.3394	accuracy_test: 0.3784
[server]	loss_train: 1.4398	loss_val: 1.4252	loss_test: 1.4498	accuracy_train: 0.3436	accuracy_val: 0.3415	accuracy_test: 0.2771
[server]	loss_train: 1.2906	loss_val: 1.4311	loss_test: 1.4590	accuracy_train: 0.4813	accuracy_val: 0.2870	accuracy_test: 0.3211
[server]	loss_train: 1.3138	loss_val: 1.4453	loss_test: 1.3174	accuracy_train: 0.4540	accuracy_val: 0.2963	accuracy_test: 0.3810
[server]	loss_train: 1.3006	loss_val: 1.3569	loss_test: 1.4705	accuracy_train: 0.4105	accuracy_val: 0.4211	accuracy_test: 0.3711
[server]	loss_train: 1.3361	loss_val: 1.4281	loss_test: 1.3661	accuracy_train: 0.3915	accuracy_val: 0.3551	accuracy_test: 0.3028
[server]	loss_train: 1.3427	loss_val: 1.3948	loss_test: 1.3267	accuracy_train: 0.3889	accuracy_val: 0.3293	accuracy_test: 0.3929
[server]	loss_train: 1.2990	loss_val: 1.3522	loss_test: 1.3957	accuracy_train: 0.4562	accuracy_val: 0.3796	accuracy_test: 0.3514
[server]	loss_train: 1.3296	loss_val: 1.4520	loss_test: 1.4822	accuracy_train: 0.4867	accuracy_val: 0.2838	accuracy_test: 0.2597
[server]	loss_train: 1.3934	loss_val: 1.3979	loss_test: 1.3657	accuracy_train: 0.3529	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.2952	loss_val: 1.3721	loss_test: 1.3797	accuracy_train: 0.4730	accuracy_val: 0.3919	accuracy_test: 0.3377
[server]	loss_train: 1.3100	loss_val: 1.3598	loss_test: 1.5004	accuracy_train: 0.4171	accuracy_val: 0.3371	accuracy_test: 0.2527
[server]	loss_train: 1.2611	loss_val: 1.3877	loss_test: 1.4462	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.2828
[server]	loss_train: 1.3869	loss_val: 1.4946	loss_test: 1.3948	accuracy_train: 0.4155	accuracy_val: 0.2843	accuracy_test: 0.4151
[server]	loss_train: 1.3625	loss_val: 1.4347	loss_test: 1.4224	accuracy_train: 0.3850	accuracy_val: 0.3982	accuracy_test: 0.3826
[server]	loss_train: 1.3448	loss_val: 1.4178	loss_test: 1.3672	accuracy_train: 0.4104	accuracy_val: 0.3294	accuracy_test: 0.3371
[server]	loss_train: 1.3717	loss_val: 1.4414	loss_test: 1.4407	accuracy_train: 0.3742	accuracy_val: 0.2963	accuracy_test: 0.3095
[server]	loss_train: 1.3265	loss_val: 1.4338	loss_test: 1.3551	accuracy_train: 0.4484	accuracy_val: 0.3694	accuracy_test: 0.3947
curr_round: 44	curr_val_accuracy: 0.3372	curr_test_accuracy: 0.3365
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 45		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3957	loss_val: 1.4664	loss_test: 1.5291	accuracy_train: 0.4071	accuracy_val: 0.2832	accuracy_test: 0.2696
[server]	loss_train: 1.3154	loss_val: 1.3549	loss_test: 1.4515	accuracy_train: 0.4565	accuracy_val: 0.3370	accuracy_test: 0.3125
[server]	loss_train: 1.2684	loss_val: 1.3890	loss_test: 1.3823	accuracy_train: 0.4682	accuracy_val: 0.3486	accuracy_test: 0.3784
[server]	loss_train: 1.4385	loss_val: 1.4250	loss_test: 1.4494	accuracy_train: 0.3374	accuracy_val: 0.3415	accuracy_test: 0.2892
[server]	loss_train: 1.2881	loss_val: 1.4317	loss_test: 1.4592	accuracy_train: 0.4813	accuracy_val: 0.2870	accuracy_test: 0.3303
[server]	loss_train: 1.3118	loss_val: 1.4460	loss_test: 1.3164	accuracy_train: 0.4479	accuracy_val: 0.2963	accuracy_test: 0.3810
[server]	loss_train: 1.2986	loss_val: 1.3570	loss_test: 1.4715	accuracy_train: 0.4158	accuracy_val: 0.4211	accuracy_test: 0.3608
[server]	loss_train: 1.3347	loss_val: 1.4289	loss_test: 1.3663	accuracy_train: 0.4057	accuracy_val: 0.3551	accuracy_test: 0.3119
[server]	loss_train: 1.3405	loss_val: 1.3938	loss_test: 1.3245	accuracy_train: 0.3889	accuracy_val: 0.3415	accuracy_test: 0.4048
[server]	loss_train: 1.2968	loss_val: 1.3514	loss_test: 1.3963	accuracy_train: 0.4562	accuracy_val: 0.3796	accuracy_test: 0.3514
[server]	loss_train: 1.3263	loss_val: 1.4527	loss_test: 1.4829	accuracy_train: 0.4933	accuracy_val: 0.2838	accuracy_test: 0.2597
[server]	loss_train: 1.3921	loss_val: 1.3979	loss_test: 1.3656	accuracy_train: 0.3588	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.2930	loss_val: 1.3709	loss_test: 1.3793	accuracy_train: 0.4797	accuracy_val: 0.3919	accuracy_test: 0.3377
[server]	loss_train: 1.3090	loss_val: 1.3601	loss_test: 1.5023	accuracy_train: 0.4114	accuracy_val: 0.3371	accuracy_test: 0.2527
[server]	loss_train: 1.2593	loss_val: 1.3889	loss_test: 1.4466	accuracy_train: 0.4737	accuracy_val: 0.3191	accuracy_test: 0.2929
[server]	loss_train: 1.3852	loss_val: 1.4949	loss_test: 1.3944	accuracy_train: 0.4155	accuracy_val: 0.2745	accuracy_test: 0.4057
[server]	loss_train: 1.3607	loss_val: 1.4345	loss_test: 1.4215	accuracy_train: 0.3894	accuracy_val: 0.3894	accuracy_test: 0.3826
[server]	loss_train: 1.3427	loss_val: 1.4184	loss_test: 1.3661	accuracy_train: 0.4104	accuracy_val: 0.3294	accuracy_test: 0.3371
[server]	loss_train: 1.3691	loss_val: 1.4416	loss_test: 1.4408	accuracy_train: 0.3865	accuracy_val: 0.2963	accuracy_test: 0.3095
[server]	loss_train: 1.3238	loss_val: 1.4339	loss_test: 1.3534	accuracy_train: 0.4484	accuracy_val: 0.3694	accuracy_test: 0.3947
curr_round: 45	curr_val_accuracy: 0.3372	curr_test_accuracy: 0.3375
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 46		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3933	loss_val: 1.4659	loss_test: 1.5290	accuracy_train: 0.4071	accuracy_val: 0.2832	accuracy_test: 0.2696
[server]	loss_train: 1.3134	loss_val: 1.3544	loss_test: 1.4516	accuracy_train: 0.4565	accuracy_val: 0.3478	accuracy_test: 0.3125
[server]	loss_train: 1.2676	loss_val: 1.3896	loss_test: 1.3835	accuracy_train: 0.4727	accuracy_val: 0.3486	accuracy_test: 0.3784
[server]	loss_train: 1.4373	loss_val: 1.4247	loss_test: 1.4490	accuracy_train: 0.3436	accuracy_val: 0.3415	accuracy_test: 0.2892
[server]	loss_train: 1.2857	loss_val: 1.4323	loss_test: 1.4593	accuracy_train: 0.4813	accuracy_val: 0.2870	accuracy_test: 0.3303
[server]	loss_train: 1.3099	loss_val: 1.4467	loss_test: 1.3156	accuracy_train: 0.4417	accuracy_val: 0.2963	accuracy_test: 0.3810
[server]	loss_train: 1.2967	loss_val: 1.3571	loss_test: 1.4725	accuracy_train: 0.4158	accuracy_val: 0.4211	accuracy_test: 0.3608
[server]	loss_train: 1.3333	loss_val: 1.4296	loss_test: 1.3666	accuracy_train: 0.4057	accuracy_val: 0.3551	accuracy_test: 0.3028
[server]	loss_train: 1.3384	loss_val: 1.3929	loss_test: 1.3226	accuracy_train: 0.3951	accuracy_val: 0.3415	accuracy_test: 0.4048
[server]	loss_train: 1.2946	loss_val: 1.3508	loss_test: 1.3969	accuracy_train: 0.4608	accuracy_val: 0.3796	accuracy_test: 0.3604
[server]	loss_train: 1.3230	loss_val: 1.4535	loss_test: 1.4837	accuracy_train: 0.4933	accuracy_val: 0.2703	accuracy_test: 0.2727
[server]	loss_train: 1.3909	loss_val: 1.3981	loss_test: 1.3654	accuracy_train: 0.3588	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.2908	loss_val: 1.3698	loss_test: 1.3789	accuracy_train: 0.4865	accuracy_val: 0.3784	accuracy_test: 0.3506
[server]	loss_train: 1.3081	loss_val: 1.3605	loss_test: 1.5043	accuracy_train: 0.4171	accuracy_val: 0.3371	accuracy_test: 0.2527
[server]	loss_train: 1.2576	loss_val: 1.3901	loss_test: 1.4469	accuracy_train: 0.4789	accuracy_val: 0.3191	accuracy_test: 0.2929
[server]	loss_train: 1.3834	loss_val: 1.4951	loss_test: 1.3942	accuracy_train: 0.4106	accuracy_val: 0.2843	accuracy_test: 0.4151
[server]	loss_train: 1.3589	loss_val: 1.4344	loss_test: 1.4206	accuracy_train: 0.3938	accuracy_val: 0.3894	accuracy_test: 0.3826
[server]	loss_train: 1.3406	loss_val: 1.4191	loss_test: 1.3652	accuracy_train: 0.4104	accuracy_val: 0.3176	accuracy_test: 0.3371
[server]	loss_train: 1.3665	loss_val: 1.4418	loss_test: 1.4409	accuracy_train: 0.3926	accuracy_val: 0.2963	accuracy_test: 0.2976
[server]	loss_train: 1.3212	loss_val: 1.4341	loss_test: 1.3518	accuracy_train: 0.4484	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 46	curr_val_accuracy: 0.3377	curr_test_accuracy: 0.3386
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 47		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3909	loss_val: 1.4655	loss_test: 1.5290	accuracy_train: 0.4115	accuracy_val: 0.2832	accuracy_test: 0.2783
[server]	loss_train: 1.3115	loss_val: 1.3540	loss_test: 1.4518	accuracy_train: 0.4511	accuracy_val: 0.3478	accuracy_test: 0.3229
[server]	loss_train: 1.2667	loss_val: 1.3903	loss_test: 1.3846	accuracy_train: 0.4727	accuracy_val: 0.3394	accuracy_test: 0.3784
[server]	loss_train: 1.4360	loss_val: 1.4245	loss_test: 1.4485	accuracy_train: 0.3436	accuracy_val: 0.3415	accuracy_test: 0.2892
[server]	loss_train: 1.2834	loss_val: 1.4329	loss_test: 1.4595	accuracy_train: 0.4813	accuracy_val: 0.2870	accuracy_test: 0.3394
[server]	loss_train: 1.3081	loss_val: 1.4474	loss_test: 1.3148	accuracy_train: 0.4417	accuracy_val: 0.2963	accuracy_test: 0.3810
[server]	loss_train: 1.2949	loss_val: 1.3573	loss_test: 1.4734	accuracy_train: 0.4263	accuracy_val: 0.4211	accuracy_test: 0.3402
[server]	loss_train: 1.3319	loss_val: 1.4305	loss_test: 1.3669	accuracy_train: 0.4057	accuracy_val: 0.3551	accuracy_test: 0.3028
[server]	loss_train: 1.3365	loss_val: 1.3921	loss_test: 1.3208	accuracy_train: 0.4012	accuracy_val: 0.3415	accuracy_test: 0.4048
[server]	loss_train: 1.2926	loss_val: 1.3501	loss_test: 1.3976	accuracy_train: 0.4654	accuracy_val: 0.3796	accuracy_test: 0.3604
[server]	loss_train: 1.3199	loss_val: 1.4543	loss_test: 1.4845	accuracy_train: 0.4867	accuracy_val: 0.2838	accuracy_test: 0.2727
[server]	loss_train: 1.3896	loss_val: 1.3982	loss_test: 1.3654	accuracy_train: 0.3529	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.2888	loss_val: 1.3687	loss_test: 1.3786	accuracy_train: 0.4932	accuracy_val: 0.3784	accuracy_test: 0.3506
[server]	loss_train: 1.3072	loss_val: 1.3609	loss_test: 1.5061	accuracy_train: 0.4171	accuracy_val: 0.3258	accuracy_test: 0.2527
[server]	loss_train: 1.2559	loss_val: 1.3913	loss_test: 1.4472	accuracy_train: 0.4789	accuracy_val: 0.3191	accuracy_test: 0.2929
[server]	loss_train: 1.3818	loss_val: 1.4955	loss_test: 1.3940	accuracy_train: 0.4058	accuracy_val: 0.2843	accuracy_test: 0.4151
[server]	loss_train: 1.3572	loss_val: 1.4344	loss_test: 1.4198	accuracy_train: 0.3850	accuracy_val: 0.3894	accuracy_test: 0.3913
[server]	loss_train: 1.3386	loss_val: 1.4198	loss_test: 1.3644	accuracy_train: 0.4046	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3641	loss_val: 1.4421	loss_test: 1.4411	accuracy_train: 0.3988	accuracy_val: 0.2963	accuracy_test: 0.2976
[server]	loss_train: 1.3188	loss_val: 1.4342	loss_test: 1.3503	accuracy_train: 0.4484	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 47	curr_val_accuracy: 0.3366	curr_test_accuracy: 0.3396
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 48		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3886	loss_val: 1.4651	loss_test: 1.5290	accuracy_train: 0.4159	accuracy_val: 0.2832	accuracy_test: 0.2609
[server]	loss_train: 1.3098	loss_val: 1.3537	loss_test: 1.4519	accuracy_train: 0.4511	accuracy_val: 0.3587	accuracy_test: 0.3333
[server]	loss_train: 1.2659	loss_val: 1.3910	loss_test: 1.3858	accuracy_train: 0.4727	accuracy_val: 0.3394	accuracy_test: 0.3784
[server]	loss_train: 1.4348	loss_val: 1.4243	loss_test: 1.4481	accuracy_train: 0.3497	accuracy_val: 0.3537	accuracy_test: 0.2892
[server]	loss_train: 1.2812	loss_val: 1.4335	loss_test: 1.4596	accuracy_train: 0.4766	accuracy_val: 0.2870	accuracy_test: 0.3303
[server]	loss_train: 1.3064	loss_val: 1.4481	loss_test: 1.3141	accuracy_train: 0.4417	accuracy_val: 0.2963	accuracy_test: 0.3810
[server]	loss_train: 1.2932	loss_val: 1.3575	loss_test: 1.4743	accuracy_train: 0.4263	accuracy_val: 0.4211	accuracy_test: 0.3402
[server]	loss_train: 1.3307	loss_val: 1.4313	loss_test: 1.3673	accuracy_train: 0.4009	accuracy_val: 0.3551	accuracy_test: 0.3028
[server]	loss_train: 1.3346	loss_val: 1.3913	loss_test: 1.3191	accuracy_train: 0.4012	accuracy_val: 0.3415	accuracy_test: 0.4048
[server]	loss_train: 1.2906	loss_val: 1.3496	loss_test: 1.3983	accuracy_train: 0.4654	accuracy_val: 0.3796	accuracy_test: 0.3604
[server]	loss_train: 1.3168	loss_val: 1.4551	loss_test: 1.4852	accuracy_train: 0.5000	accuracy_val: 0.2838	accuracy_test: 0.2857
[server]	loss_train: 1.3883	loss_val: 1.3985	loss_test: 1.3653	accuracy_train: 0.3647	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.2868	loss_val: 1.3677	loss_test: 1.3784	accuracy_train: 0.4797	accuracy_val: 0.3784	accuracy_test: 0.3506
[server]	loss_train: 1.3065	loss_val: 1.3613	loss_test: 1.5080	accuracy_train: 0.4171	accuracy_val: 0.3258	accuracy_test: 0.2527
[server]	loss_train: 1.2544	loss_val: 1.3925	loss_test: 1.4476	accuracy_train: 0.4842	accuracy_val: 0.3191	accuracy_test: 0.3131
[server]	loss_train: 1.3802	loss_val: 1.4958	loss_test: 1.3938	accuracy_train: 0.3961	accuracy_val: 0.2843	accuracy_test: 0.4057
[server]	loss_train: 1.3556	loss_val: 1.4344	loss_test: 1.4190	accuracy_train: 0.3850	accuracy_val: 0.3894	accuracy_test: 0.3913
[server]	loss_train: 1.3368	loss_val: 1.4205	loss_test: 1.3637	accuracy_train: 0.3988	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3617	loss_val: 1.4425	loss_test: 1.4413	accuracy_train: 0.4049	accuracy_val: 0.2963	accuracy_test: 0.2857
[server]	loss_train: 1.3164	loss_val: 1.4344	loss_test: 1.3489	accuracy_train: 0.4484	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 48	curr_val_accuracy: 0.3377	curr_test_accuracy: 0.3390
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 49		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3863	loss_val: 1.4647	loss_test: 1.5290	accuracy_train: 0.4204	accuracy_val: 0.2832	accuracy_test: 0.2609
[server]	loss_train: 1.3081	loss_val: 1.3534	loss_test: 1.4521	accuracy_train: 0.4457	accuracy_val: 0.3587	accuracy_test: 0.3333
[server]	loss_train: 1.2651	loss_val: 1.3916	loss_test: 1.3870	accuracy_train: 0.4727	accuracy_val: 0.3394	accuracy_test: 0.3784
[server]	loss_train: 1.4335	loss_val: 1.4242	loss_test: 1.4476	accuracy_train: 0.3436	accuracy_val: 0.3415	accuracy_test: 0.2892
[server]	loss_train: 1.2791	loss_val: 1.4342	loss_test: 1.4598	accuracy_train: 0.4766	accuracy_val: 0.2778	accuracy_test: 0.3211
[server]	loss_train: 1.3048	loss_val: 1.4488	loss_test: 1.3135	accuracy_train: 0.4356	accuracy_val: 0.2963	accuracy_test: 0.3929
[server]	loss_train: 1.2916	loss_val: 1.3577	loss_test: 1.4752	accuracy_train: 0.4368	accuracy_val: 0.4316	accuracy_test: 0.3402
[server]	loss_train: 1.3295	loss_val: 1.4322	loss_test: 1.3678	accuracy_train: 0.3962	accuracy_val: 0.3645	accuracy_test: 0.3028
[server]	loss_train: 1.3327	loss_val: 1.3906	loss_test: 1.3175	accuracy_train: 0.4136	accuracy_val: 0.3415	accuracy_test: 0.4048
[server]	loss_train: 1.2887	loss_val: 1.3490	loss_test: 1.3990	accuracy_train: 0.4654	accuracy_val: 0.3796	accuracy_test: 0.3423
[server]	loss_train: 1.3137	loss_val: 1.4560	loss_test: 1.4860	accuracy_train: 0.4933	accuracy_val: 0.2973	accuracy_test: 0.2987
[server]	loss_train: 1.3871	loss_val: 1.3988	loss_test: 1.3653	accuracy_train: 0.3706	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.2848	loss_val: 1.3667	loss_test: 1.3782	accuracy_train: 0.4730	accuracy_val: 0.3784	accuracy_test: 0.3506
[server]	loss_train: 1.3057	loss_val: 1.3618	loss_test: 1.5098	accuracy_train: 0.4057	accuracy_val: 0.3258	accuracy_test: 0.2637
[server]	loss_train: 1.2529	loss_val: 1.3937	loss_test: 1.4478	accuracy_train: 0.4842	accuracy_val: 0.3298	accuracy_test: 0.3232
[server]	loss_train: 1.3786	loss_val: 1.4961	loss_test: 1.3937	accuracy_train: 0.3913	accuracy_val: 0.2745	accuracy_test: 0.4151
[server]	loss_train: 1.3540	loss_val: 1.4344	loss_test: 1.4182	accuracy_train: 0.3761	accuracy_val: 0.3982	accuracy_test: 0.3913
[server]	loss_train: 1.3349	loss_val: 1.4213	loss_test: 1.3630	accuracy_train: 0.3988	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3594	loss_val: 1.4429	loss_test: 1.4415	accuracy_train: 0.4110	accuracy_val: 0.2840	accuracy_test: 0.2857
[server]	loss_train: 1.3141	loss_val: 1.4345	loss_test: 1.3475	accuracy_train: 0.4484	accuracy_val: 0.3874	accuracy_test: 0.4035
curr_round: 49	curr_val_accuracy: 0.3382	curr_test_accuracy: 0.3406
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 50		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3841	loss_val: 1.4644	loss_test: 1.5290	accuracy_train: 0.4159	accuracy_val: 0.2832	accuracy_test: 0.2609
[server]	loss_train: 1.3064	loss_val: 1.3531	loss_test: 1.4522	accuracy_train: 0.4457	accuracy_val: 0.3587	accuracy_test: 0.3333
[server]	loss_train: 1.2643	loss_val: 1.3922	loss_test: 1.3881	accuracy_train: 0.4727	accuracy_val: 0.3394	accuracy_test: 0.3784
[server]	loss_train: 1.4322	loss_val: 1.4240	loss_test: 1.4472	accuracy_train: 0.3374	accuracy_val: 0.3537	accuracy_test: 0.3012
[server]	loss_train: 1.2771	loss_val: 1.4348	loss_test: 1.4600	accuracy_train: 0.4860	accuracy_val: 0.2778	accuracy_test: 0.3119
[server]	loss_train: 1.3032	loss_val: 1.4495	loss_test: 1.3130	accuracy_train: 0.4417	accuracy_val: 0.2963	accuracy_test: 0.3810
[server]	loss_train: 1.2900	loss_val: 1.3579	loss_test: 1.4761	accuracy_train: 0.4368	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3283	loss_val: 1.4331	loss_test: 1.3682	accuracy_train: 0.3868	accuracy_val: 0.3738	accuracy_test: 0.3028
[server]	loss_train: 1.3310	loss_val: 1.3899	loss_test: 1.3160	accuracy_train: 0.4198	accuracy_val: 0.3415	accuracy_test: 0.4048
[server]	loss_train: 1.2869	loss_val: 1.3485	loss_test: 1.3997	accuracy_train: 0.4747	accuracy_val: 0.3611	accuracy_test: 0.3333
[server]	loss_train: 1.3108	loss_val: 1.4569	loss_test: 1.4867	accuracy_train: 0.4933	accuracy_val: 0.2973	accuracy_test: 0.3247
[server]	loss_train: 1.3859	loss_val: 1.3991	loss_test: 1.3653	accuracy_train: 0.3588	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.2830	loss_val: 1.3657	loss_test: 1.3782	accuracy_train: 0.4730	accuracy_val: 0.3784	accuracy_test: 0.3506
[server]	loss_train: 1.3050	loss_val: 1.3624	loss_test: 1.5115	accuracy_train: 0.4000	accuracy_val: 0.3258	accuracy_test: 0.2637
[server]	loss_train: 1.2514	loss_val: 1.3950	loss_test: 1.4481	accuracy_train: 0.4842	accuracy_val: 0.3298	accuracy_test: 0.3232
[server]	loss_train: 1.3771	loss_val: 1.4965	loss_test: 1.3937	accuracy_train: 0.3913	accuracy_val: 0.2647	accuracy_test: 0.4151
[server]	loss_train: 1.3525	loss_val: 1.4346	loss_test: 1.4175	accuracy_train: 0.3761	accuracy_val: 0.3982	accuracy_test: 0.3913
[server]	loss_train: 1.3332	loss_val: 1.4221	loss_test: 1.3625	accuracy_train: 0.3988	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3572	loss_val: 1.4433	loss_test: 1.4418	accuracy_train: 0.4110	accuracy_val: 0.2963	accuracy_test: 0.2857
[server]	loss_train: 1.3120	loss_val: 1.4347	loss_test: 1.3463	accuracy_train: 0.4529	accuracy_val: 0.3784	accuracy_test: 0.4035
curr_round: 50	curr_val_accuracy: 0.3371	curr_test_accuracy: 0.3401
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 51		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3820	loss_val: 1.4641	loss_test: 1.5291	accuracy_train: 0.4159	accuracy_val: 0.2832	accuracy_test: 0.2696
[server]	loss_train: 1.3049	loss_val: 1.3529	loss_test: 1.4524	accuracy_train: 0.4457	accuracy_val: 0.3587	accuracy_test: 0.3333
[server]	loss_train: 1.2636	loss_val: 1.3928	loss_test: 1.3892	accuracy_train: 0.4682	accuracy_val: 0.3394	accuracy_test: 0.3784
[server]	loss_train: 1.4310	loss_val: 1.4239	loss_test: 1.4468	accuracy_train: 0.3374	accuracy_val: 0.3537	accuracy_test: 0.3012
[server]	loss_train: 1.2752	loss_val: 1.4355	loss_test: 1.4602	accuracy_train: 0.4860	accuracy_val: 0.2870	accuracy_test: 0.3119
[server]	loss_train: 1.3018	loss_val: 1.4502	loss_test: 1.3125	accuracy_train: 0.4540	accuracy_val: 0.2963	accuracy_test: 0.3810
[server]	loss_train: 1.2884	loss_val: 1.3582	loss_test: 1.4769	accuracy_train: 0.4263	accuracy_val: 0.4316	accuracy_test: 0.3299
[server]	loss_train: 1.3272	loss_val: 1.4341	loss_test: 1.3688	accuracy_train: 0.3915	accuracy_val: 0.3738	accuracy_test: 0.3028
[server]	loss_train: 1.3293	loss_val: 1.3893	loss_test: 1.3146	accuracy_train: 0.4198	accuracy_val: 0.3537	accuracy_test: 0.4048
[server]	loss_train: 1.2851	loss_val: 1.3481	loss_test: 1.4005	accuracy_train: 0.4747	accuracy_val: 0.3611	accuracy_test: 0.3333
[server]	loss_train: 1.3079	loss_val: 1.4578	loss_test: 1.4875	accuracy_train: 0.5067	accuracy_val: 0.2973	accuracy_test: 0.3247
[server]	loss_train: 1.3846	loss_val: 1.3994	loss_test: 1.3653	accuracy_train: 0.3588	accuracy_val: 0.3488	accuracy_test: 0.3563
[server]	loss_train: 1.2812	loss_val: 1.3648	loss_test: 1.3781	accuracy_train: 0.4730	accuracy_val: 0.3514	accuracy_test: 0.3506
[server]	loss_train: 1.3044	loss_val: 1.3629	loss_test: 1.5133	accuracy_train: 0.4000	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2500	loss_val: 1.3962	loss_test: 1.4483	accuracy_train: 0.4737	accuracy_val: 0.3298	accuracy_test: 0.3232
[server]	loss_train: 1.3756	loss_val: 1.4968	loss_test: 1.3936	accuracy_train: 0.4010	accuracy_val: 0.2745	accuracy_test: 0.4057
[server]	loss_train: 1.3511	loss_val: 1.4347	loss_test: 1.4167	accuracy_train: 0.3717	accuracy_val: 0.3982	accuracy_test: 0.3913
[server]	loss_train: 1.3316	loss_val: 1.4229	loss_test: 1.3620	accuracy_train: 0.4046	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3550	loss_val: 1.4438	loss_test: 1.4421	accuracy_train: 0.3988	accuracy_val: 0.2963	accuracy_test: 0.2976
[server]	loss_train: 1.3099	loss_val: 1.4349	loss_test: 1.3451	accuracy_train: 0.4529	accuracy_val: 0.3694	accuracy_test: 0.4035
curr_round: 51	curr_val_accuracy: 0.3377	curr_test_accuracy: 0.3395
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 52		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3799	loss_val: 1.4638	loss_test: 1.5292	accuracy_train: 0.4115	accuracy_val: 0.2920	accuracy_test: 0.2696
[server]	loss_train: 1.3034	loss_val: 1.3527	loss_test: 1.4527	accuracy_train: 0.4402	accuracy_val: 0.3696	accuracy_test: 0.3333
[server]	loss_train: 1.2628	loss_val: 1.3934	loss_test: 1.3904	accuracy_train: 0.4636	accuracy_val: 0.3394	accuracy_test: 0.3964
[server]	loss_train: 1.4297	loss_val: 1.4238	loss_test: 1.4463	accuracy_train: 0.3374	accuracy_val: 0.3537	accuracy_test: 0.3012
[server]	loss_train: 1.2734	loss_val: 1.4361	loss_test: 1.4604	accuracy_train: 0.4907	accuracy_val: 0.2870	accuracy_test: 0.3028
[server]	loss_train: 1.3004	loss_val: 1.4508	loss_test: 1.3121	accuracy_train: 0.4479	accuracy_val: 0.2963	accuracy_test: 0.3810
[server]	loss_train: 1.2870	loss_val: 1.3585	loss_test: 1.4777	accuracy_train: 0.4316	accuracy_val: 0.4316	accuracy_test: 0.3299
[server]	loss_train: 1.3261	loss_val: 1.4350	loss_test: 1.3693	accuracy_train: 0.3868	accuracy_val: 0.3645	accuracy_test: 0.3028
[server]	loss_train: 1.3276	loss_val: 1.3887	loss_test: 1.3133	accuracy_train: 0.4198	accuracy_val: 0.3537	accuracy_test: 0.4048
[server]	loss_train: 1.2834	loss_val: 1.3477	loss_test: 1.4012	accuracy_train: 0.4654	accuracy_val: 0.3611	accuracy_test: 0.3333
[server]	loss_train: 1.3051	loss_val: 1.4588	loss_test: 1.4882	accuracy_train: 0.5067	accuracy_val: 0.2973	accuracy_test: 0.3247
[server]	loss_train: 1.3834	loss_val: 1.3998	loss_test: 1.3653	accuracy_train: 0.3647	accuracy_val: 0.3372	accuracy_test: 0.3563
[server]	loss_train: 1.2794	loss_val: 1.3640	loss_test: 1.3781	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3636
[server]	loss_train: 1.3038	loss_val: 1.3635	loss_test: 1.5150	accuracy_train: 0.4000	accuracy_val: 0.3371	accuracy_test: 0.2418
[server]	loss_train: 1.2487	loss_val: 1.3974	loss_test: 1.4485	accuracy_train: 0.4737	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3741	loss_val: 1.4972	loss_test: 1.3937	accuracy_train: 0.4010	accuracy_val: 0.2843	accuracy_test: 0.4057
[server]	loss_train: 1.3497	loss_val: 1.4349	loss_test: 1.4160	accuracy_train: 0.3761	accuracy_val: 0.3894	accuracy_test: 0.4000
[server]	loss_train: 1.3300	loss_val: 1.4238	loss_test: 1.3617	accuracy_train: 0.4046	accuracy_val: 0.3059	accuracy_test: 0.3483
[server]	loss_train: 1.3528	loss_val: 1.4443	loss_test: 1.4424	accuracy_train: 0.3988	accuracy_val: 0.2963	accuracy_test: 0.2976
[server]	loss_train: 1.3079	loss_val: 1.4351	loss_test: 1.3440	accuracy_train: 0.4574	accuracy_val: 0.3694	accuracy_test: 0.3947
curr_round: 52	curr_val_accuracy: 0.3377	curr_test_accuracy: 0.3411
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 53		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3779	loss_val: 1.4636	loss_test: 1.5293	accuracy_train: 0.4159	accuracy_val: 0.2920	accuracy_test: 0.2696
[server]	loss_train: 1.3019	loss_val: 1.3526	loss_test: 1.4529	accuracy_train: 0.4457	accuracy_val: 0.3696	accuracy_test: 0.3333
[server]	loss_train: 1.2621	loss_val: 1.3940	loss_test: 1.3915	accuracy_train: 0.4591	accuracy_val: 0.3394	accuracy_test: 0.3964
[server]	loss_train: 1.4285	loss_val: 1.4238	loss_test: 1.4459	accuracy_train: 0.3374	accuracy_val: 0.3415	accuracy_test: 0.3012
[server]	loss_train: 1.2716	loss_val: 1.4368	loss_test: 1.4606	accuracy_train: 0.4860	accuracy_val: 0.2870	accuracy_test: 0.2936
[server]	loss_train: 1.2990	loss_val: 1.4515	loss_test: 1.3118	accuracy_train: 0.4540	accuracy_val: 0.2963	accuracy_test: 0.3929
[server]	loss_train: 1.2855	loss_val: 1.3588	loss_test: 1.4785	accuracy_train: 0.4316	accuracy_val: 0.4316	accuracy_test: 0.3299
[server]	loss_train: 1.3251	loss_val: 1.4360	loss_test: 1.3699	accuracy_train: 0.3915	accuracy_val: 0.3645	accuracy_test: 0.3119
[server]	loss_train: 1.3260	loss_val: 1.3882	loss_test: 1.3121	accuracy_train: 0.4136	accuracy_val: 0.3659	accuracy_test: 0.4167
[server]	loss_train: 1.2818	loss_val: 1.3473	loss_test: 1.4020	accuracy_train: 0.4700	accuracy_val: 0.3704	accuracy_test: 0.3333
[server]	loss_train: 1.3024	loss_val: 1.4598	loss_test: 1.4890	accuracy_train: 0.5000	accuracy_val: 0.2973	accuracy_test: 0.3247
[server]	loss_train: 1.3822	loss_val: 1.4002	loss_test: 1.3654	accuracy_train: 0.3706	accuracy_val: 0.3372	accuracy_test: 0.3563
[server]	loss_train: 1.2777	loss_val: 1.3632	loss_test: 1.3782	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3636
[server]	loss_train: 1.3033	loss_val: 1.3642	loss_test: 1.5166	accuracy_train: 0.4000	accuracy_val: 0.3371	accuracy_test: 0.2418
[server]	loss_train: 1.2474	loss_val: 1.3987	loss_test: 1.4487	accuracy_train: 0.4737	accuracy_val: 0.3191	accuracy_test: 0.3333
[server]	loss_train: 1.3727	loss_val: 1.4976	loss_test: 1.3937	accuracy_train: 0.4010	accuracy_val: 0.2843	accuracy_test: 0.4057
[server]	loss_train: 1.3484	loss_val: 1.4351	loss_test: 1.4154	accuracy_train: 0.3850	accuracy_val: 0.3805	accuracy_test: 0.4000
[server]	loss_train: 1.3284	loss_val: 1.4246	loss_test: 1.3613	accuracy_train: 0.4046	accuracy_val: 0.3176	accuracy_test: 0.3483
[server]	loss_train: 1.3507	loss_val: 1.4448	loss_test: 1.4427	accuracy_train: 0.3988	accuracy_val: 0.2716	accuracy_test: 0.2976
[server]	loss_train: 1.3059	loss_val: 1.4352	loss_test: 1.3430	accuracy_train: 0.4574	accuracy_val: 0.3784	accuracy_test: 0.4035
curr_round: 53	curr_val_accuracy: 0.3377	curr_test_accuracy: 0.3431
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 54		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3759	loss_val: 1.4634	loss_test: 1.5294	accuracy_train: 0.4159	accuracy_val: 0.2920	accuracy_test: 0.2696
[server]	loss_train: 1.3005	loss_val: 1.3524	loss_test: 1.4532	accuracy_train: 0.4293	accuracy_val: 0.3696	accuracy_test: 0.3333
[server]	loss_train: 1.2614	loss_val: 1.3946	loss_test: 1.3927	accuracy_train: 0.4591	accuracy_val: 0.3394	accuracy_test: 0.3964
[server]	loss_train: 1.4272	loss_val: 1.4237	loss_test: 1.4455	accuracy_train: 0.3313	accuracy_val: 0.3415	accuracy_test: 0.3012
[server]	loss_train: 1.2699	loss_val: 1.4375	loss_test: 1.4609	accuracy_train: 0.4860	accuracy_val: 0.2870	accuracy_test: 0.2936
[server]	loss_train: 1.2977	loss_val: 1.4521	loss_test: 1.3115	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.3929
[server]	loss_train: 1.2841	loss_val: 1.3591	loss_test: 1.4793	accuracy_train: 0.4316	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3241	loss_val: 1.4370	loss_test: 1.3704	accuracy_train: 0.3962	accuracy_val: 0.3645	accuracy_test: 0.3028
[server]	loss_train: 1.3244	loss_val: 1.3877	loss_test: 1.3109	accuracy_train: 0.4136	accuracy_val: 0.3659	accuracy_test: 0.4167
[server]	loss_train: 1.2802	loss_val: 1.3469	loss_test: 1.4028	accuracy_train: 0.4700	accuracy_val: 0.3796	accuracy_test: 0.3333
[server]	loss_train: 1.2997	loss_val: 1.4609	loss_test: 1.4897	accuracy_train: 0.4933	accuracy_val: 0.3108	accuracy_test: 0.3247
[server]	loss_train: 1.3810	loss_val: 1.4006	loss_test: 1.3655	accuracy_train: 0.3706	accuracy_val: 0.3372	accuracy_test: 0.3563
[server]	loss_train: 1.2761	loss_val: 1.3625	loss_test: 1.3782	accuracy_train: 0.4865	accuracy_val: 0.3378	accuracy_test: 0.3636
[server]	loss_train: 1.3027	loss_val: 1.3648	loss_test: 1.5183	accuracy_train: 0.3943	accuracy_val: 0.3258	accuracy_test: 0.2308
[server]	loss_train: 1.2461	loss_val: 1.3999	loss_test: 1.4489	accuracy_train: 0.4737	accuracy_val: 0.3191	accuracy_test: 0.3333
[server]	loss_train: 1.3714	loss_val: 1.4980	loss_test: 1.3938	accuracy_train: 0.4058	accuracy_val: 0.2843	accuracy_test: 0.4057
[server]	loss_train: 1.3471	loss_val: 1.4354	loss_test: 1.4147	accuracy_train: 0.3850	accuracy_val: 0.3805	accuracy_test: 0.4087
[server]	loss_train: 1.3269	loss_val: 1.4255	loss_test: 1.3611	accuracy_train: 0.4220	accuracy_val: 0.3176	accuracy_test: 0.3483
[server]	loss_train: 1.3487	loss_val: 1.4454	loss_test: 1.4431	accuracy_train: 0.3988	accuracy_val: 0.2716	accuracy_test: 0.2976
[server]	loss_train: 1.3041	loss_val: 1.4354	loss_test: 1.3420	accuracy_train: 0.4574	accuracy_val: 0.3784	accuracy_test: 0.4035
curr_round: 54	curr_val_accuracy: 0.3372	curr_test_accuracy: 0.3426
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 55		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3740	loss_val: 1.4632	loss_test: 1.5296	accuracy_train: 0.4204	accuracy_val: 0.2920	accuracy_test: 0.2609
[server]	loss_train: 1.2992	loss_val: 1.3523	loss_test: 1.4535	accuracy_train: 0.4293	accuracy_val: 0.3587	accuracy_test: 0.3333
[server]	loss_train: 1.2607	loss_val: 1.3952	loss_test: 1.3938	accuracy_train: 0.4636	accuracy_val: 0.3394	accuracy_test: 0.3964
[server]	loss_train: 1.4260	loss_val: 1.4237	loss_test: 1.4451	accuracy_train: 0.3313	accuracy_val: 0.3415	accuracy_test: 0.3012
[server]	loss_train: 1.2682	loss_val: 1.4381	loss_test: 1.4611	accuracy_train: 0.4860	accuracy_val: 0.2870	accuracy_test: 0.2936
[server]	loss_train: 1.2965	loss_val: 1.4528	loss_test: 1.3112	accuracy_train: 0.4601	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.2828	loss_val: 1.3595	loss_test: 1.4801	accuracy_train: 0.4368	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3231	loss_val: 1.4380	loss_test: 1.3710	accuracy_train: 0.3962	accuracy_val: 0.3738	accuracy_test: 0.2844
[server]	loss_train: 1.3229	loss_val: 1.3872	loss_test: 1.3099	accuracy_train: 0.4136	accuracy_val: 0.3659	accuracy_test: 0.4167
[server]	loss_train: 1.2787	loss_val: 1.3466	loss_test: 1.4036	accuracy_train: 0.4700	accuracy_val: 0.3796	accuracy_test: 0.3423
[server]	loss_train: 1.2971	loss_val: 1.4619	loss_test: 1.4904	accuracy_train: 0.5000	accuracy_val: 0.3108	accuracy_test: 0.3247
[server]	loss_train: 1.3798	loss_val: 1.4011	loss_test: 1.3656	accuracy_train: 0.3706	accuracy_val: 0.3372	accuracy_test: 0.3563
[server]	loss_train: 1.2745	loss_val: 1.3618	loss_test: 1.3783	accuracy_train: 0.4865	accuracy_val: 0.3378	accuracy_test: 0.3506
[server]	loss_train: 1.3022	loss_val: 1.3655	loss_test: 1.5199	accuracy_train: 0.3829	accuracy_val: 0.3258	accuracy_test: 0.2308
[server]	loss_train: 1.2449	loss_val: 1.4011	loss_test: 1.4491	accuracy_train: 0.4737	accuracy_val: 0.3191	accuracy_test: 0.3333
[server]	loss_train: 1.3700	loss_val: 1.4984	loss_test: 1.3939	accuracy_train: 0.4155	accuracy_val: 0.2843	accuracy_test: 0.4151
[server]	loss_train: 1.3458	loss_val: 1.4357	loss_test: 1.4141	accuracy_train: 0.3850	accuracy_val: 0.3805	accuracy_test: 0.4087
[server]	loss_train: 1.3255	loss_val: 1.4264	loss_test: 1.3609	accuracy_train: 0.4220	accuracy_val: 0.3176	accuracy_test: 0.3371
[server]	loss_train: 1.3467	loss_val: 1.4460	loss_test: 1.4434	accuracy_train: 0.3988	accuracy_val: 0.2716	accuracy_test: 0.2976
[server]	loss_train: 1.3023	loss_val: 1.4356	loss_test: 1.3411	accuracy_train: 0.4574	accuracy_val: 0.3784	accuracy_test: 0.4035
curr_round: 55	curr_val_accuracy: 0.3366	curr_test_accuracy: 0.3411
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 56		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3721	loss_val: 1.4631	loss_test: 1.5297	accuracy_train: 0.4204	accuracy_val: 0.2920	accuracy_test: 0.2522
[server]	loss_train: 1.2979	loss_val: 1.3522	loss_test: 1.4538	accuracy_train: 0.4239	accuracy_val: 0.3587	accuracy_test: 0.3333
[server]	loss_train: 1.2600	loss_val: 1.3957	loss_test: 1.3950	accuracy_train: 0.4636	accuracy_val: 0.3394	accuracy_test: 0.3964
[server]	loss_train: 1.4248	loss_val: 1.4237	loss_test: 1.4447	accuracy_train: 0.3313	accuracy_val: 0.3415	accuracy_test: 0.3133
[server]	loss_train: 1.2666	loss_val: 1.4388	loss_test: 1.4614	accuracy_train: 0.4907	accuracy_val: 0.2870	accuracy_test: 0.2936
[server]	loss_train: 1.2953	loss_val: 1.4534	loss_test: 1.3110	accuracy_train: 0.4540	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.2815	loss_val: 1.3599	loss_test: 1.4808	accuracy_train: 0.4316	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3221	loss_val: 1.4390	loss_test: 1.3716	accuracy_train: 0.3915	accuracy_val: 0.3738	accuracy_test: 0.2936
[server]	loss_train: 1.3215	loss_val: 1.3868	loss_test: 1.3088	accuracy_train: 0.4136	accuracy_val: 0.3659	accuracy_test: 0.4167
[server]	loss_train: 1.2772	loss_val: 1.3463	loss_test: 1.4043	accuracy_train: 0.4654	accuracy_val: 0.3796	accuracy_test: 0.3423
[server]	loss_train: 1.2945	loss_val: 1.4629	loss_test: 1.4911	accuracy_train: 0.5000	accuracy_val: 0.3108	accuracy_test: 0.3377
[server]	loss_train: 1.3786	loss_val: 1.4016	loss_test: 1.3657	accuracy_train: 0.3706	accuracy_val: 0.3372	accuracy_test: 0.3563
[server]	loss_train: 1.2729	loss_val: 1.3612	loss_test: 1.3784	accuracy_train: 0.4865	accuracy_val: 0.3378	accuracy_test: 0.3506
[server]	loss_train: 1.3018	loss_val: 1.3662	loss_test: 1.5215	accuracy_train: 0.3771	accuracy_val: 0.3258	accuracy_test: 0.2308
[server]	loss_train: 1.2438	loss_val: 1.4024	loss_test: 1.4493	accuracy_train: 0.4684	accuracy_val: 0.3298	accuracy_test: 0.3333
[server]	loss_train: 1.3687	loss_val: 1.4988	loss_test: 1.3941	accuracy_train: 0.4106	accuracy_val: 0.2843	accuracy_test: 0.4151
[server]	loss_train: 1.3446	loss_val: 1.4360	loss_test: 1.4135	accuracy_train: 0.3894	accuracy_val: 0.3805	accuracy_test: 0.4174
[server]	loss_train: 1.3241	loss_val: 1.4273	loss_test: 1.3608	accuracy_train: 0.4220	accuracy_val: 0.3176	accuracy_test: 0.3483
[server]	loss_train: 1.3447	loss_val: 1.4466	loss_test: 1.4438	accuracy_train: 0.3988	accuracy_val: 0.2840	accuracy_test: 0.2857
[server]	loss_train: 1.3006	loss_val: 1.4357	loss_test: 1.3403	accuracy_train: 0.4574	accuracy_val: 0.3784	accuracy_test: 0.4123
curr_round: 56	curr_val_accuracy: 0.3377	curr_test_accuracy: 0.3432
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 57		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3703	loss_val: 1.4630	loss_test: 1.5299	accuracy_train: 0.4204	accuracy_val: 0.2920	accuracy_test: 0.2522
[server]	loss_train: 1.2967	loss_val: 1.3521	loss_test: 1.4541	accuracy_train: 0.4130	accuracy_val: 0.3478	accuracy_test: 0.3333
[server]	loss_train: 1.2593	loss_val: 1.3963	loss_test: 1.3961	accuracy_train: 0.4636	accuracy_val: 0.3394	accuracy_test: 0.3964
[server]	loss_train: 1.4235	loss_val: 1.4238	loss_test: 1.4442	accuracy_train: 0.3313	accuracy_val: 0.3415	accuracy_test: 0.3133
[server]	loss_train: 1.2651	loss_val: 1.4395	loss_test: 1.4616	accuracy_train: 0.4907	accuracy_val: 0.2870	accuracy_test: 0.2936
[server]	loss_train: 1.2942	loss_val: 1.4540	loss_test: 1.3109	accuracy_train: 0.4540	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.2802	loss_val: 1.3603	loss_test: 1.4815	accuracy_train: 0.4316	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3212	loss_val: 1.4400	loss_test: 1.3722	accuracy_train: 0.3962	accuracy_val: 0.3645	accuracy_test: 0.2936
[server]	loss_train: 1.3200	loss_val: 1.3863	loss_test: 1.3079	accuracy_train: 0.4136	accuracy_val: 0.3780	accuracy_test: 0.4167
[server]	loss_train: 1.2758	loss_val: 1.3461	loss_test: 1.4051	accuracy_train: 0.4654	accuracy_val: 0.3889	accuracy_test: 0.3423
[server]	loss_train: 1.2920	loss_val: 1.4640	loss_test: 1.4918	accuracy_train: 0.5000	accuracy_val: 0.3108	accuracy_test: 0.3377
[server]	loss_train: 1.3774	loss_val: 1.4021	loss_test: 1.3658	accuracy_train: 0.3706	accuracy_val: 0.3372	accuracy_test: 0.3448
[server]	loss_train: 1.2714	loss_val: 1.3606	loss_test: 1.3786	accuracy_train: 0.4865	accuracy_val: 0.3514	accuracy_test: 0.3506
[server]	loss_train: 1.3013	loss_val: 1.3669	loss_test: 1.5231	accuracy_train: 0.3771	accuracy_val: 0.3258	accuracy_test: 0.2308
[server]	loss_train: 1.2426	loss_val: 1.4036	loss_test: 1.4494	accuracy_train: 0.4737	accuracy_val: 0.3298	accuracy_test: 0.3434
[server]	loss_train: 1.3675	loss_val: 1.4992	loss_test: 1.3943	accuracy_train: 0.4106	accuracy_val: 0.2941	accuracy_test: 0.4151
[server]	loss_train: 1.3434	loss_val: 1.4363	loss_test: 1.4129	accuracy_train: 0.3850	accuracy_val: 0.3717	accuracy_test: 0.4174
[server]	loss_train: 1.3227	loss_val: 1.4281	loss_test: 1.3607	accuracy_train: 0.4162	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3428	loss_val: 1.4473	loss_test: 1.4441	accuracy_train: 0.3988	accuracy_val: 0.2716	accuracy_test: 0.2976
[server]	loss_train: 1.2990	loss_val: 1.4359	loss_test: 1.3395	accuracy_train: 0.4574	accuracy_val: 0.3784	accuracy_test: 0.4123
curr_round: 57	curr_val_accuracy: 0.3372	curr_test_accuracy: 0.3431
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 58		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3685	loss_val: 1.4629	loss_test: 1.5301	accuracy_train: 0.4204	accuracy_val: 0.2920	accuracy_test: 0.2522
[server]	loss_train: 1.2955	loss_val: 1.3521	loss_test: 1.4544	accuracy_train: 0.4239	accuracy_val: 0.3478	accuracy_test: 0.3333
[server]	loss_train: 1.2586	loss_val: 1.3968	loss_test: 1.3972	accuracy_train: 0.4682	accuracy_val: 0.3394	accuracy_test: 0.3964
[server]	loss_train: 1.4223	loss_val: 1.4239	loss_test: 1.4438	accuracy_train: 0.3313	accuracy_val: 0.3415	accuracy_test: 0.3133
[server]	loss_train: 1.2636	loss_val: 1.4401	loss_test: 1.4619	accuracy_train: 0.4907	accuracy_val: 0.2778	accuracy_test: 0.2936
[server]	loss_train: 1.2932	loss_val: 1.4545	loss_test: 1.3107	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.2790	loss_val: 1.3607	loss_test: 1.4822	accuracy_train: 0.4421	accuracy_val: 0.4211	accuracy_test: 0.3196
[server]	loss_train: 1.3204	loss_val: 1.4409	loss_test: 1.3728	accuracy_train: 0.3962	accuracy_val: 0.3645	accuracy_test: 0.2936
[server]	loss_train: 1.3186	loss_val: 1.3859	loss_test: 1.3070	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4167
[server]	loss_train: 1.2744	loss_val: 1.3458	loss_test: 1.4059	accuracy_train: 0.4700	accuracy_val: 0.3889	accuracy_test: 0.3333
[server]	loss_train: 1.2896	loss_val: 1.4651	loss_test: 1.4924	accuracy_train: 0.5000	accuracy_val: 0.2973	accuracy_test: 0.3377
[server]	loss_train: 1.3762	loss_val: 1.4026	loss_test: 1.3659	accuracy_train: 0.3706	accuracy_val: 0.3372	accuracy_test: 0.3448
[server]	loss_train: 1.2699	loss_val: 1.3600	loss_test: 1.3787	accuracy_train: 0.4932	accuracy_val: 0.3514	accuracy_test: 0.3506
[server]	loss_train: 1.3009	loss_val: 1.3676	loss_test: 1.5247	accuracy_train: 0.3771	accuracy_val: 0.3258	accuracy_test: 0.2308
[server]	loss_train: 1.2415	loss_val: 1.4048	loss_test: 1.4495	accuracy_train: 0.4737	accuracy_val: 0.3298	accuracy_test: 0.3434
[server]	loss_train: 1.3662	loss_val: 1.4996	loss_test: 1.3945	accuracy_train: 0.4106	accuracy_val: 0.2941	accuracy_test: 0.4151
[server]	loss_train: 1.3422	loss_val: 1.4366	loss_test: 1.4124	accuracy_train: 0.3850	accuracy_val: 0.3717	accuracy_test: 0.4087
[server]	loss_train: 1.3214	loss_val: 1.4290	loss_test: 1.3606	accuracy_train: 0.4162	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3410	loss_val: 1.4480	loss_test: 1.4445	accuracy_train: 0.3988	accuracy_val: 0.2716	accuracy_test: 0.2976
[server]	loss_train: 1.2974	loss_val: 1.4361	loss_test: 1.3387	accuracy_train: 0.4619	accuracy_val: 0.3784	accuracy_test: 0.4123
curr_round: 58	curr_val_accuracy: 0.3356	curr_test_accuracy: 0.3416
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 59		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3667	loss_val: 1.4628	loss_test: 1.5303	accuracy_train: 0.4204	accuracy_val: 0.2920	accuracy_test: 0.2522
[server]	loss_train: 1.2944	loss_val: 1.3521	loss_test: 1.4547	accuracy_train: 0.4239	accuracy_val: 0.3478	accuracy_test: 0.3333
[server]	loss_train: 1.2580	loss_val: 1.3973	loss_test: 1.3984	accuracy_train: 0.4727	accuracy_val: 0.3394	accuracy_test: 0.3874
[server]	loss_train: 1.4212	loss_val: 1.4239	loss_test: 1.4435	accuracy_train: 0.3313	accuracy_val: 0.3415	accuracy_test: 0.3133
[server]	loss_train: 1.2622	loss_val: 1.4408	loss_test: 1.4622	accuracy_train: 0.4907	accuracy_val: 0.2778	accuracy_test: 0.2936
[server]	loss_train: 1.2922	loss_val: 1.4551	loss_test: 1.3107	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.2778	loss_val: 1.3612	loss_test: 1.4828	accuracy_train: 0.4421	accuracy_val: 0.4211	accuracy_test: 0.3196
[server]	loss_train: 1.3195	loss_val: 1.4419	loss_test: 1.3734	accuracy_train: 0.4009	accuracy_val: 0.3645	accuracy_test: 0.2936
[server]	loss_train: 1.3173	loss_val: 1.3855	loss_test: 1.3061	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2731	loss_val: 1.3456	loss_test: 1.4067	accuracy_train: 0.4700	accuracy_val: 0.3889	accuracy_test: 0.3333
[server]	loss_train: 1.2872	loss_val: 1.4661	loss_test: 1.4931	accuracy_train: 0.4933	accuracy_val: 0.2973	accuracy_test: 0.3377
[server]	loss_train: 1.3751	loss_val: 1.4031	loss_test: 1.3660	accuracy_train: 0.3706	accuracy_val: 0.3372	accuracy_test: 0.3448
[server]	loss_train: 1.2685	loss_val: 1.3595	loss_test: 1.3789	accuracy_train: 0.4865	accuracy_val: 0.3514	accuracy_test: 0.3506
[server]	loss_train: 1.3005	loss_val: 1.3683	loss_test: 1.5262	accuracy_train: 0.3657	accuracy_val: 0.3258	accuracy_test: 0.2308
[server]	loss_train: 1.2405	loss_val: 1.4060	loss_test: 1.4497	accuracy_train: 0.4789	accuracy_val: 0.3298	accuracy_test: 0.3333
[server]	loss_train: 1.3650	loss_val: 1.5001	loss_test: 1.3947	accuracy_train: 0.4106	accuracy_val: 0.2941	accuracy_test: 0.4057
[server]	loss_train: 1.3411	loss_val: 1.4370	loss_test: 1.4119	accuracy_train: 0.3850	accuracy_val: 0.3628	accuracy_test: 0.4087
[server]	loss_train: 1.3201	loss_val: 1.4299	loss_test: 1.3606	accuracy_train: 0.4220	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3391	loss_val: 1.4487	loss_test: 1.4449	accuracy_train: 0.4049	accuracy_val: 0.2716	accuracy_test: 0.2976
[server]	loss_train: 1.2959	loss_val: 1.4362	loss_test: 1.3380	accuracy_train: 0.4619	accuracy_val: 0.3874	accuracy_test: 0.4123
curr_round: 59	curr_val_accuracy: 0.3356	curr_test_accuracy: 0.3406
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 60		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3650	loss_val: 1.4627	loss_test: 1.5306	accuracy_train: 0.4204	accuracy_val: 0.2920	accuracy_test: 0.2522
[server]	loss_train: 1.2933	loss_val: 1.3520	loss_test: 1.4551	accuracy_train: 0.4239	accuracy_val: 0.3478	accuracy_test: 0.3333
[server]	loss_train: 1.2573	loss_val: 1.3977	loss_test: 1.3995	accuracy_train: 0.4682	accuracy_val: 0.3394	accuracy_test: 0.3874
[server]	loss_train: 1.4200	loss_val: 1.4240	loss_test: 1.4431	accuracy_train: 0.3313	accuracy_val: 0.3415	accuracy_test: 0.3133
[server]	loss_train: 1.2608	loss_val: 1.4415	loss_test: 1.4624	accuracy_train: 0.4907	accuracy_val: 0.2778	accuracy_test: 0.2936
[server]	loss_train: 1.2912	loss_val: 1.4557	loss_test: 1.3106	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.3810
[server]	loss_train: 1.2766	loss_val: 1.3616	loss_test: 1.4835	accuracy_train: 0.4421	accuracy_val: 0.4211	accuracy_test: 0.3196
[server]	loss_train: 1.3187	loss_val: 1.4429	loss_test: 1.3740	accuracy_train: 0.3962	accuracy_val: 0.3551	accuracy_test: 0.3028
[server]	loss_train: 1.3159	loss_val: 1.3852	loss_test: 1.3054	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2718	loss_val: 1.3454	loss_test: 1.4075	accuracy_train: 0.4747	accuracy_val: 0.3889	accuracy_test: 0.3333
[server]	loss_train: 1.2848	loss_val: 1.4672	loss_test: 1.4938	accuracy_train: 0.4933	accuracy_val: 0.2973	accuracy_test: 0.3377
[server]	loss_train: 1.3739	loss_val: 1.4036	loss_test: 1.3661	accuracy_train: 0.3706	accuracy_val: 0.3372	accuracy_test: 0.3448
[server]	loss_train: 1.2671	loss_val: 1.3590	loss_test: 1.3790	accuracy_train: 0.4865	accuracy_val: 0.3514	accuracy_test: 0.3636
[server]	loss_train: 1.3001	loss_val: 1.3690	loss_test: 1.5278	accuracy_train: 0.3600	accuracy_val: 0.3258	accuracy_test: 0.2308
[server]	loss_train: 1.2394	loss_val: 1.4072	loss_test: 1.4498	accuracy_train: 0.4842	accuracy_val: 0.3298	accuracy_test: 0.3333
[server]	loss_train: 1.3639	loss_val: 1.5005	loss_test: 1.3950	accuracy_train: 0.4106	accuracy_val: 0.2941	accuracy_test: 0.4057
[server]	loss_train: 1.3400	loss_val: 1.4374	loss_test: 1.4114	accuracy_train: 0.3894	accuracy_val: 0.3540	accuracy_test: 0.4087
[server]	loss_train: 1.3189	loss_val: 1.4308	loss_test: 1.3607	accuracy_train: 0.4277	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3374	loss_val: 1.4494	loss_test: 1.4453	accuracy_train: 0.4049	accuracy_val: 0.2716	accuracy_test: 0.2976
[server]	loss_train: 1.2945	loss_val: 1.4364	loss_test: 1.3374	accuracy_train: 0.4664	accuracy_val: 0.3964	accuracy_test: 0.4123
curr_round: 60	curr_val_accuracy: 0.3350	curr_test_accuracy: 0.3411
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 61		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3634	loss_val: 1.4627	loss_test: 1.5308	accuracy_train: 0.4159	accuracy_val: 0.3009	accuracy_test: 0.2522
[server]	loss_train: 1.2922	loss_val: 1.3520	loss_test: 1.4554	accuracy_train: 0.4293	accuracy_val: 0.3478	accuracy_test: 0.3333
[server]	loss_train: 1.2566	loss_val: 1.3982	loss_test: 1.4007	accuracy_train: 0.4682	accuracy_val: 0.3394	accuracy_test: 0.3784
[server]	loss_train: 1.4188	loss_val: 1.4241	loss_test: 1.4427	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3133
[server]	loss_train: 1.2595	loss_val: 1.4421	loss_test: 1.4627	accuracy_train: 0.4907	accuracy_val: 0.2778	accuracy_test: 0.2936
[server]	loss_train: 1.2903	loss_val: 1.4562	loss_test: 1.3106	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.3810
[server]	loss_train: 1.2754	loss_val: 1.3620	loss_test: 1.4842	accuracy_train: 0.4368	accuracy_val: 0.4211	accuracy_test: 0.3196
[server]	loss_train: 1.3179	loss_val: 1.4439	loss_test: 1.3746	accuracy_train: 0.3962	accuracy_val: 0.3551	accuracy_test: 0.3028
[server]	loss_train: 1.3146	loss_val: 1.3849	loss_test: 1.3047	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2706	loss_val: 1.3452	loss_test: 1.4083	accuracy_train: 0.4747	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2825	loss_val: 1.4683	loss_test: 1.4944	accuracy_train: 0.4933	accuracy_val: 0.2973	accuracy_test: 0.3247
[server]	loss_train: 1.3728	loss_val: 1.4042	loss_test: 1.3662	accuracy_train: 0.3706	accuracy_val: 0.3372	accuracy_test: 0.3448
[server]	loss_train: 1.2658	loss_val: 1.3586	loss_test: 1.3792	accuracy_train: 0.4865	accuracy_val: 0.3649	accuracy_test: 0.3636
[server]	loss_train: 1.2997	loss_val: 1.3697	loss_test: 1.5293	accuracy_train: 0.3600	accuracy_val: 0.3258	accuracy_test: 0.2308
[server]	loss_train: 1.2384	loss_val: 1.4083	loss_test: 1.4498	accuracy_train: 0.4737	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3627	loss_val: 1.5010	loss_test: 1.3953	accuracy_train: 0.4155	accuracy_val: 0.2941	accuracy_test: 0.4057
[server]	loss_train: 1.3390	loss_val: 1.4378	loss_test: 1.4110	accuracy_train: 0.3894	accuracy_val: 0.3540	accuracy_test: 0.4000
[server]	loss_train: 1.3177	loss_val: 1.4317	loss_test: 1.3608	accuracy_train: 0.4277	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3356	loss_val: 1.4501	loss_test: 1.4456	accuracy_train: 0.4049	accuracy_val: 0.2716	accuracy_test: 0.3095
[server]	loss_train: 1.2931	loss_val: 1.4366	loss_test: 1.3368	accuracy_train: 0.4709	accuracy_val: 0.3964	accuracy_test: 0.4123
curr_round: 61	curr_val_accuracy: 0.3356	curr_test_accuracy: 0.3395
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 62		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3617	loss_val: 1.4627	loss_test: 1.5311	accuracy_train: 0.4159	accuracy_val: 0.3009	accuracy_test: 0.2522
[server]	loss_train: 1.2911	loss_val: 1.3520	loss_test: 1.4558	accuracy_train: 0.4239	accuracy_val: 0.3587	accuracy_test: 0.3333
[server]	loss_train: 1.2560	loss_val: 1.3987	loss_test: 1.4018	accuracy_train: 0.4682	accuracy_val: 0.3394	accuracy_test: 0.3694
[server]	loss_train: 1.4177	loss_val: 1.4243	loss_test: 1.4423	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3133
[server]	loss_train: 1.2582	loss_val: 1.4428	loss_test: 1.4630	accuracy_train: 0.4953	accuracy_val: 0.2778	accuracy_test: 0.2936
[server]	loss_train: 1.2894	loss_val: 1.4567	loss_test: 1.3106	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.3810
[server]	loss_train: 1.2743	loss_val: 1.3625	loss_test: 1.4848	accuracy_train: 0.4421	accuracy_val: 0.4211	accuracy_test: 0.3196
[server]	loss_train: 1.3171	loss_val: 1.4448	loss_test: 1.3753	accuracy_train: 0.3962	accuracy_val: 0.3551	accuracy_test: 0.3028
[server]	loss_train: 1.3133	loss_val: 1.3846	loss_test: 1.3040	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2694	loss_val: 1.3450	loss_test: 1.4090	accuracy_train: 0.4747	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2803	loss_val: 1.4694	loss_test: 1.4950	accuracy_train: 0.5000	accuracy_val: 0.2973	accuracy_test: 0.3247
[server]	loss_train: 1.3717	loss_val: 1.4047	loss_test: 1.3663	accuracy_train: 0.3647	accuracy_val: 0.3372	accuracy_test: 0.3448
[server]	loss_train: 1.2645	loss_val: 1.3582	loss_test: 1.3794	accuracy_train: 0.4865	accuracy_val: 0.3649	accuracy_test: 0.3636
[server]	loss_train: 1.2994	loss_val: 1.3704	loss_test: 1.5308	accuracy_train: 0.3600	accuracy_val: 0.3258	accuracy_test: 0.2308
[server]	loss_train: 1.2375	loss_val: 1.4095	loss_test: 1.4499	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3617	loss_val: 1.5015	loss_test: 1.3956	accuracy_train: 0.4155	accuracy_val: 0.2941	accuracy_test: 0.4057
[server]	loss_train: 1.3380	loss_val: 1.4383	loss_test: 1.4106	accuracy_train: 0.3894	accuracy_val: 0.3540	accuracy_test: 0.4000
[server]	loss_train: 1.3165	loss_val: 1.4326	loss_test: 1.3609	accuracy_train: 0.4335	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3339	loss_val: 1.4509	loss_test: 1.4460	accuracy_train: 0.4049	accuracy_val: 0.2716	accuracy_test: 0.3095
[server]	loss_train: 1.2918	loss_val: 1.4367	loss_test: 1.3362	accuracy_train: 0.4709	accuracy_val: 0.3964	accuracy_test: 0.4123
curr_round: 62	curr_val_accuracy: 0.3361	curr_test_accuracy: 0.3390
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 63		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3602	loss_val: 1.4627	loss_test: 1.5314	accuracy_train: 0.4071	accuracy_val: 0.3009	accuracy_test: 0.2522
[server]	loss_train: 1.2901	loss_val: 1.3521	loss_test: 1.4561	accuracy_train: 0.4239	accuracy_val: 0.3587	accuracy_test: 0.3333
[server]	loss_train: 1.2554	loss_val: 1.3991	loss_test: 1.4030	accuracy_train: 0.4682	accuracy_val: 0.3394	accuracy_test: 0.3694
[server]	loss_train: 1.4166	loss_val: 1.4244	loss_test: 1.4419	accuracy_train: 0.3313	accuracy_val: 0.3171	accuracy_test: 0.3133
[server]	loss_train: 1.2570	loss_val: 1.4435	loss_test: 1.4632	accuracy_train: 0.4953	accuracy_val: 0.2778	accuracy_test: 0.2936
[server]	loss_train: 1.2885	loss_val: 1.4573	loss_test: 1.3106	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.2732	loss_val: 1.3630	loss_test: 1.4854	accuracy_train: 0.4474	accuracy_val: 0.4316	accuracy_test: 0.3196
[server]	loss_train: 1.3164	loss_val: 1.4458	loss_test: 1.3759	accuracy_train: 0.3962	accuracy_val: 0.3364	accuracy_test: 0.3028
[server]	loss_train: 1.3121	loss_val: 1.3843	loss_test: 1.3033	accuracy_train: 0.4321	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2682	loss_val: 1.3449	loss_test: 1.4098	accuracy_train: 0.4700	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2781	loss_val: 1.4705	loss_test: 1.4956	accuracy_train: 0.5000	accuracy_val: 0.2973	accuracy_test: 0.3247
[server]	loss_train: 1.3705	loss_val: 1.4053	loss_test: 1.3665	accuracy_train: 0.3647	accuracy_val: 0.3372	accuracy_test: 0.3448
[server]	loss_train: 1.2632	loss_val: 1.3579	loss_test: 1.3796	accuracy_train: 0.4865	accuracy_val: 0.3649	accuracy_test: 0.3636
[server]	loss_train: 1.2990	loss_val: 1.3711	loss_test: 1.5323	accuracy_train: 0.3600	accuracy_val: 0.3258	accuracy_test: 0.2308
[server]	loss_train: 1.2365	loss_val: 1.4106	loss_test: 1.4499	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3606	loss_val: 1.5020	loss_test: 1.3959	accuracy_train: 0.4155	accuracy_val: 0.2941	accuracy_test: 0.4057
[server]	loss_train: 1.3369	loss_val: 1.4387	loss_test: 1.4102	accuracy_train: 0.3894	accuracy_val: 0.3451	accuracy_test: 0.4000
[server]	loss_train: 1.3153	loss_val: 1.4335	loss_test: 1.3610	accuracy_train: 0.4335	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3322	loss_val: 1.4516	loss_test: 1.4464	accuracy_train: 0.4110	accuracy_val: 0.2716	accuracy_test: 0.3214
[server]	loss_train: 1.2905	loss_val: 1.4369	loss_test: 1.3357	accuracy_train: 0.4709	accuracy_val: 0.3964	accuracy_test: 0.4123
curr_round: 63	curr_val_accuracy: 0.3345	curr_test_accuracy: 0.3400
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 64		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3586	loss_val: 1.4627	loss_test: 1.5317	accuracy_train: 0.4071	accuracy_val: 0.3009	accuracy_test: 0.2609
[server]	loss_train: 1.2891	loss_val: 1.3521	loss_test: 1.4565	accuracy_train: 0.4239	accuracy_val: 0.3696	accuracy_test: 0.3333
[server]	loss_train: 1.2547	loss_val: 1.3996	loss_test: 1.4041	accuracy_train: 0.4682	accuracy_val: 0.3211	accuracy_test: 0.3604
[server]	loss_train: 1.4156	loss_val: 1.4246	loss_test: 1.4416	accuracy_train: 0.3313	accuracy_val: 0.3171	accuracy_test: 0.3133
[server]	loss_train: 1.2558	loss_val: 1.4441	loss_test: 1.4635	accuracy_train: 0.4860	accuracy_val: 0.2778	accuracy_test: 0.2936
[server]	loss_train: 1.2877	loss_val: 1.4578	loss_test: 1.3107	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.2721	loss_val: 1.3634	loss_test: 1.4860	accuracy_train: 0.4474	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3156	loss_val: 1.4468	loss_test: 1.3765	accuracy_train: 0.4009	accuracy_val: 0.3364	accuracy_test: 0.2936
[server]	loss_train: 1.3109	loss_val: 1.3840	loss_test: 1.3027	accuracy_train: 0.4321	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2671	loss_val: 1.3447	loss_test: 1.4106	accuracy_train: 0.4700	accuracy_val: 0.3889	accuracy_test: 0.3333
[server]	loss_train: 1.2760	loss_val: 1.4716	loss_test: 1.4962	accuracy_train: 0.5000	accuracy_val: 0.2973	accuracy_test: 0.3247
[server]	loss_train: 1.3694	loss_val: 1.4059	loss_test: 1.3666	accuracy_train: 0.3647	accuracy_val: 0.3372	accuracy_test: 0.3448
[server]	loss_train: 1.2619	loss_val: 1.3576	loss_test: 1.3799	accuracy_train: 0.4865	accuracy_val: 0.3649	accuracy_test: 0.3766
[server]	loss_train: 1.2987	loss_val: 1.3719	loss_test: 1.5337	accuracy_train: 0.3600	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2356	loss_val: 1.4117	loss_test: 1.4500	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3596	loss_val: 1.5025	loss_test: 1.3962	accuracy_train: 0.4155	accuracy_val: 0.2941	accuracy_test: 0.4057
[server]	loss_train: 1.3360	loss_val: 1.4391	loss_test: 1.4099	accuracy_train: 0.3894	accuracy_val: 0.3451	accuracy_test: 0.4000
[server]	loss_train: 1.3142	loss_val: 1.4344	loss_test: 1.3612	accuracy_train: 0.4335	accuracy_val: 0.3059	accuracy_test: 0.3258
[server]	loss_train: 1.3306	loss_val: 1.4523	loss_test: 1.4467	accuracy_train: 0.4110	accuracy_val: 0.2716	accuracy_test: 0.3214
[server]	loss_train: 1.2893	loss_val: 1.4371	loss_test: 1.3352	accuracy_train: 0.4709	accuracy_val: 0.3874	accuracy_test: 0.4123
curr_round: 64	curr_val_accuracy: 0.3324	curr_test_accuracy: 0.3405
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 65		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3571	loss_val: 1.4627	loss_test: 1.5320	accuracy_train: 0.4027	accuracy_val: 0.3009	accuracy_test: 0.2609
[server]	loss_train: 1.2881	loss_val: 1.3521	loss_test: 1.4568	accuracy_train: 0.4293	accuracy_val: 0.3913	accuracy_test: 0.3333
[server]	loss_train: 1.2541	loss_val: 1.4000	loss_test: 1.4052	accuracy_train: 0.4682	accuracy_val: 0.3211	accuracy_test: 0.3604
[server]	loss_train: 1.4145	loss_val: 1.4248	loss_test: 1.4412	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3133
[server]	loss_train: 1.2546	loss_val: 1.4448	loss_test: 1.4638	accuracy_train: 0.4907	accuracy_val: 0.2778	accuracy_test: 0.2844
[server]	loss_train: 1.2869	loss_val: 1.4582	loss_test: 1.3108	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.2710	loss_val: 1.3639	loss_test: 1.4866	accuracy_train: 0.4474	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3149	loss_val: 1.4477	loss_test: 1.3771	accuracy_train: 0.4009	accuracy_val: 0.3364	accuracy_test: 0.2752
[server]	loss_train: 1.3097	loss_val: 1.3838	loss_test: 1.3021	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2660	loss_val: 1.3446	loss_test: 1.4113	accuracy_train: 0.4700	accuracy_val: 0.3889	accuracy_test: 0.3333
[server]	loss_train: 1.2739	loss_val: 1.4727	loss_test: 1.4968	accuracy_train: 0.5000	accuracy_val: 0.2973	accuracy_test: 0.3117
[server]	loss_train: 1.3684	loss_val: 1.4064	loss_test: 1.3667	accuracy_train: 0.3647	accuracy_val: 0.3372	accuracy_test: 0.3448
[server]	loss_train: 1.2607	loss_val: 1.3573	loss_test: 1.3801	accuracy_train: 0.4797	accuracy_val: 0.3649	accuracy_test: 0.3766
[server]	loss_train: 1.2984	loss_val: 1.3726	loss_test: 1.5351	accuracy_train: 0.3600	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2347	loss_val: 1.4128	loss_test: 1.4500	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3586	loss_val: 1.5030	loss_test: 1.3966	accuracy_train: 0.4203	accuracy_val: 0.2941	accuracy_test: 0.4151
[server]	loss_train: 1.3350	loss_val: 1.4395	loss_test: 1.4096	accuracy_train: 0.3894	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.3131	loss_val: 1.4353	loss_test: 1.3614	accuracy_train: 0.4335	accuracy_val: 0.3059	accuracy_test: 0.3258
[server]	loss_train: 1.3290	loss_val: 1.4531	loss_test: 1.4471	accuracy_train: 0.4172	accuracy_val: 0.2716	accuracy_test: 0.3214
[server]	loss_train: 1.2881	loss_val: 1.4372	loss_test: 1.3347	accuracy_train: 0.4709	accuracy_val: 0.3874	accuracy_test: 0.4123
curr_round: 65	curr_val_accuracy: 0.3335	curr_test_accuracy: 0.3385
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 66		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3556	loss_val: 1.4627	loss_test: 1.5323	accuracy_train: 0.4071	accuracy_val: 0.3009	accuracy_test: 0.2609
[server]	loss_train: 1.2871	loss_val: 1.3522	loss_test: 1.4572	accuracy_train: 0.4293	accuracy_val: 0.3913	accuracy_test: 0.3333
[server]	loss_train: 1.2535	loss_val: 1.4004	loss_test: 1.4063	accuracy_train: 0.4682	accuracy_val: 0.3211	accuracy_test: 0.3604
[server]	loss_train: 1.4134	loss_val: 1.4250	loss_test: 1.4408	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3133
[server]	loss_train: 1.2535	loss_val: 1.4454	loss_test: 1.4641	accuracy_train: 0.4907	accuracy_val: 0.2778	accuracy_test: 0.2844
[server]	loss_train: 1.2861	loss_val: 1.4587	loss_test: 1.3109	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.2700	loss_val: 1.3644	loss_test: 1.4872	accuracy_train: 0.4474	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3143	loss_val: 1.4486	loss_test: 1.3777	accuracy_train: 0.4009	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.3085	loss_val: 1.3835	loss_test: 1.3016	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2650	loss_val: 1.3444	loss_test: 1.4121	accuracy_train: 0.4700	accuracy_val: 0.3889	accuracy_test: 0.3423
[server]	loss_train: 1.2719	loss_val: 1.4738	loss_test: 1.4974	accuracy_train: 0.5000	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3673	loss_val: 1.4070	loss_test: 1.3669	accuracy_train: 0.3647	accuracy_val: 0.3372	accuracy_test: 0.3333
[server]	loss_train: 1.2595	loss_val: 1.3570	loss_test: 1.3803	accuracy_train: 0.4797	accuracy_val: 0.3649	accuracy_test: 0.3896
[server]	loss_train: 1.2981	loss_val: 1.3734	loss_test: 1.5365	accuracy_train: 0.3600	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2338	loss_val: 1.4139	loss_test: 1.4500	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3576	loss_val: 1.5036	loss_test: 1.3969	accuracy_train: 0.4203	accuracy_val: 0.2941	accuracy_test: 0.3962
[server]	loss_train: 1.3341	loss_val: 1.4400	loss_test: 1.4093	accuracy_train: 0.3894	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.3120	loss_val: 1.4361	loss_test: 1.3616	accuracy_train: 0.4335	accuracy_val: 0.3059	accuracy_test: 0.3258
[server]	loss_train: 1.3274	loss_val: 1.4538	loss_test: 1.4475	accuracy_train: 0.4172	accuracy_val: 0.2716	accuracy_test: 0.3214
[server]	loss_train: 1.2869	loss_val: 1.4374	loss_test: 1.3342	accuracy_train: 0.4753	accuracy_val: 0.3874	accuracy_test: 0.4123
curr_round: 66	curr_val_accuracy: 0.3335	curr_test_accuracy: 0.3374
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 67		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3541	loss_val: 1.4627	loss_test: 1.5326	accuracy_train: 0.4071	accuracy_val: 0.3097	accuracy_test: 0.2609
[server]	loss_train: 1.2862	loss_val: 1.3522	loss_test: 1.4576	accuracy_train: 0.4348	accuracy_val: 0.3913	accuracy_test: 0.3333
[server]	loss_train: 1.2528	loss_val: 1.4009	loss_test: 1.4074	accuracy_train: 0.4682	accuracy_val: 0.3211	accuracy_test: 0.3604
[server]	loss_train: 1.4124	loss_val: 1.4252	loss_test: 1.4405	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3133
[server]	loss_train: 1.2524	loss_val: 1.4460	loss_test: 1.4644	accuracy_train: 0.4907	accuracy_val: 0.2778	accuracy_test: 0.2844
[server]	loss_train: 1.2853	loss_val: 1.4592	loss_test: 1.3110	accuracy_train: 0.4540	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.2689	loss_val: 1.3649	loss_test: 1.4878	accuracy_train: 0.4474	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3136	loss_val: 1.4495	loss_test: 1.3784	accuracy_train: 0.4057	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.3073	loss_val: 1.3834	loss_test: 1.3011	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4167
[server]	loss_train: 1.2640	loss_val: 1.3443	loss_test: 1.4129	accuracy_train: 0.4654	accuracy_val: 0.3889	accuracy_test: 0.3243
[server]	loss_train: 1.2699	loss_val: 1.4749	loss_test: 1.4980	accuracy_train: 0.5000	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3663	loss_val: 1.4075	loss_test: 1.3670	accuracy_train: 0.3765	accuracy_val: 0.3372	accuracy_test: 0.3333
[server]	loss_train: 1.2583	loss_val: 1.3568	loss_test: 1.3806	accuracy_train: 0.4797	accuracy_val: 0.3649	accuracy_test: 0.3896
[server]	loss_train: 1.2978	loss_val: 1.3741	loss_test: 1.5379	accuracy_train: 0.3600	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2330	loss_val: 1.4150	loss_test: 1.4500	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3567	loss_val: 1.5041	loss_test: 1.3973	accuracy_train: 0.4251	accuracy_val: 0.2941	accuracy_test: 0.3962
[server]	loss_train: 1.3331	loss_val: 1.4404	loss_test: 1.4091	accuracy_train: 0.3894	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.3110	loss_val: 1.4370	loss_test: 1.3619	accuracy_train: 0.4335	accuracy_val: 0.3176	accuracy_test: 0.3258
[server]	loss_train: 1.3258	loss_val: 1.4546	loss_test: 1.4479	accuracy_train: 0.4233	accuracy_val: 0.2840	accuracy_test: 0.3214
[server]	loss_train: 1.2859	loss_val: 1.4376	loss_test: 1.3338	accuracy_train: 0.4753	accuracy_val: 0.3874	accuracy_test: 0.4035
curr_round: 67	curr_val_accuracy: 0.3351	curr_test_accuracy: 0.3354
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 68		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3527	loss_val: 1.4628	loss_test: 1.5329	accuracy_train: 0.4071	accuracy_val: 0.3097	accuracy_test: 0.2609
[server]	loss_train: 1.2853	loss_val: 1.3523	loss_test: 1.4580	accuracy_train: 0.4348	accuracy_val: 0.3913	accuracy_test: 0.3333
[server]	loss_train: 1.2522	loss_val: 1.4012	loss_test: 1.4085	accuracy_train: 0.4682	accuracy_val: 0.3211	accuracy_test: 0.3694
[server]	loss_train: 1.4113	loss_val: 1.4254	loss_test: 1.4401	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3133
[server]	loss_train: 1.2513	loss_val: 1.4467	loss_test: 1.4646	accuracy_train: 0.4813	accuracy_val: 0.2778	accuracy_test: 0.2844
[server]	loss_train: 1.2846	loss_val: 1.4596	loss_test: 1.3111	accuracy_train: 0.4601	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.2679	loss_val: 1.3655	loss_test: 1.4884	accuracy_train: 0.4474	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3130	loss_val: 1.4504	loss_test: 1.3790	accuracy_train: 0.4009	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.3062	loss_val: 1.3832	loss_test: 1.3006	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4167
[server]	loss_train: 1.2630	loss_val: 1.3442	loss_test: 1.4136	accuracy_train: 0.4654	accuracy_val: 0.3889	accuracy_test: 0.3243
[server]	loss_train: 1.2679	loss_val: 1.4760	loss_test: 1.4985	accuracy_train: 0.5067	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3652	loss_val: 1.4080	loss_test: 1.3671	accuracy_train: 0.3765	accuracy_val: 0.3372	accuracy_test: 0.3333
[server]	loss_train: 1.2572	loss_val: 1.3566	loss_test: 1.3808	accuracy_train: 0.4797	accuracy_val: 0.3649	accuracy_test: 0.3896
[server]	loss_train: 1.2975	loss_val: 1.3748	loss_test: 1.5393	accuracy_train: 0.3600	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2322	loss_val: 1.4160	loss_test: 1.4499	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3558	loss_val: 1.5046	loss_test: 1.3977	accuracy_train: 0.4203	accuracy_val: 0.2941	accuracy_test: 0.3962
[server]	loss_train: 1.3322	loss_val: 1.4409	loss_test: 1.4089	accuracy_train: 0.3894	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.3100	loss_val: 1.4379	loss_test: 1.3622	accuracy_train: 0.4335	accuracy_val: 0.3176	accuracy_test: 0.3258
[server]	loss_train: 1.3243	loss_val: 1.4553	loss_test: 1.4482	accuracy_train: 0.4356	accuracy_val: 0.2840	accuracy_test: 0.3214
[server]	loss_train: 1.2848	loss_val: 1.4377	loss_test: 1.3334	accuracy_train: 0.4753	accuracy_val: 0.3874	accuracy_test: 0.4123
curr_round: 68	curr_val_accuracy: 0.3351	curr_test_accuracy: 0.3364
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 69		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3513	loss_val: 1.4628	loss_test: 1.5332	accuracy_train: 0.4071	accuracy_val: 0.3097	accuracy_test: 0.2609
[server]	loss_train: 1.2844	loss_val: 1.3523	loss_test: 1.4583	accuracy_train: 0.4348	accuracy_val: 0.3913	accuracy_test: 0.3333
[server]	loss_train: 1.2516	loss_val: 1.4016	loss_test: 1.4095	accuracy_train: 0.4636	accuracy_val: 0.3211	accuracy_test: 0.3694
[server]	loss_train: 1.4103	loss_val: 1.4256	loss_test: 1.4397	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3133
[server]	loss_train: 1.2503	loss_val: 1.4473	loss_test: 1.4649	accuracy_train: 0.4813	accuracy_val: 0.2778	accuracy_test: 0.2844
[server]	loss_train: 1.2839	loss_val: 1.4601	loss_test: 1.3113	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.3929
[server]	loss_train: 1.2669	loss_val: 1.3660	loss_test: 1.4890	accuracy_train: 0.4474	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3123	loss_val: 1.4513	loss_test: 1.3796	accuracy_train: 0.4009	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.3051	loss_val: 1.3831	loss_test: 1.3002	accuracy_train: 0.4198	accuracy_val: 0.3659	accuracy_test: 0.4167
[server]	loss_train: 1.2620	loss_val: 1.3441	loss_test: 1.4143	accuracy_train: 0.4654	accuracy_val: 0.3889	accuracy_test: 0.3243
[server]	loss_train: 1.2660	loss_val: 1.4771	loss_test: 1.4991	accuracy_train: 0.5067	accuracy_val: 0.2973	accuracy_test: 0.3117
[server]	loss_train: 1.3642	loss_val: 1.4086	loss_test: 1.3672	accuracy_train: 0.3765	accuracy_val: 0.3372	accuracy_test: 0.3333
[server]	loss_train: 1.2561	loss_val: 1.3564	loss_test: 1.3811	accuracy_train: 0.4797	accuracy_val: 0.3784	accuracy_test: 0.3896
[server]	loss_train: 1.2972	loss_val: 1.3756	loss_test: 1.5406	accuracy_train: 0.3657	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2313	loss_val: 1.4171	loss_test: 1.4499	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3549	loss_val: 1.5052	loss_test: 1.3981	accuracy_train: 0.4251	accuracy_val: 0.2941	accuracy_test: 0.3962
[server]	loss_train: 1.3314	loss_val: 1.4414	loss_test: 1.4087	accuracy_train: 0.3894	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.3090	loss_val: 1.4387	loss_test: 1.3624	accuracy_train: 0.4335	accuracy_val: 0.3176	accuracy_test: 0.3258
[server]	loss_train: 1.3229	loss_val: 1.4561	loss_test: 1.4486	accuracy_train: 0.4356	accuracy_val: 0.2840	accuracy_test: 0.3214
[server]	loss_train: 1.2838	loss_val: 1.4379	loss_test: 1.3331	accuracy_train: 0.4753	accuracy_val: 0.3964	accuracy_test: 0.4035
curr_round: 69	curr_val_accuracy: 0.3361	curr_test_accuracy: 0.3359
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 70		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3500	loss_val: 1.4629	loss_test: 1.5335	accuracy_train: 0.4159	accuracy_val: 0.3097	accuracy_test: 0.2696
[server]	loss_train: 1.2835	loss_val: 1.3524	loss_test: 1.4587	accuracy_train: 0.4348	accuracy_val: 0.3913	accuracy_test: 0.3333
[server]	loss_train: 1.2510	loss_val: 1.4021	loss_test: 1.4106	accuracy_train: 0.4682	accuracy_val: 0.3211	accuracy_test: 0.3604
[server]	loss_train: 1.4093	loss_val: 1.4259	loss_test: 1.4394	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3133
[server]	loss_train: 1.2493	loss_val: 1.4479	loss_test: 1.4652	accuracy_train: 0.4766	accuracy_val: 0.2778	accuracy_test: 0.2844
[server]	loss_train: 1.2832	loss_val: 1.4605	loss_test: 1.3115	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.3810
[server]	loss_train: 1.2660	loss_val: 1.3665	loss_test: 1.4896	accuracy_train: 0.4474	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3117	loss_val: 1.4522	loss_test: 1.3802	accuracy_train: 0.4057	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.3041	loss_val: 1.3829	loss_test: 1.2998	accuracy_train: 0.4136	accuracy_val: 0.3659	accuracy_test: 0.4048
[server]	loss_train: 1.2611	loss_val: 1.3440	loss_test: 1.4151	accuracy_train: 0.4654	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2642	loss_val: 1.4783	loss_test: 1.4997	accuracy_train: 0.5067	accuracy_val: 0.2973	accuracy_test: 0.3117
[server]	loss_train: 1.3632	loss_val: 1.4091	loss_test: 1.3673	accuracy_train: 0.3765	accuracy_val: 0.3372	accuracy_test: 0.3333
[server]	loss_train: 1.2550	loss_val: 1.3563	loss_test: 1.3813	accuracy_train: 0.4797	accuracy_val: 0.3784	accuracy_test: 0.3766
[server]	loss_train: 1.2969	loss_val: 1.3763	loss_test: 1.5420	accuracy_train: 0.3657	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2305	loss_val: 1.4181	loss_test: 1.4499	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3540	loss_val: 1.5057	loss_test: 1.3985	accuracy_train: 0.4251	accuracy_val: 0.2941	accuracy_test: 0.3962
[server]	loss_train: 1.3305	loss_val: 1.4419	loss_test: 1.4085	accuracy_train: 0.3850	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.3080	loss_val: 1.4396	loss_test: 1.3628	accuracy_train: 0.4335	accuracy_val: 0.3176	accuracy_test: 0.3258
[server]	loss_train: 1.3215	loss_val: 1.4568	loss_test: 1.4490	accuracy_train: 0.4356	accuracy_val: 0.2840	accuracy_test: 0.3095
[server]	loss_train: 1.2828	loss_val: 1.4381	loss_test: 1.3328	accuracy_train: 0.4753	accuracy_val: 0.3964	accuracy_test: 0.4035
curr_round: 70	curr_val_accuracy: 0.3367	curr_test_accuracy: 0.3343
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 71		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3486	loss_val: 1.4630	loss_test: 1.5339	accuracy_train: 0.4159	accuracy_val: 0.3009	accuracy_test: 0.2696
[server]	loss_train: 1.2826	loss_val: 1.3524	loss_test: 1.4591	accuracy_train: 0.4293	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2504	loss_val: 1.4025	loss_test: 1.4117	accuracy_train: 0.4682	accuracy_val: 0.3211	accuracy_test: 0.3604
[server]	loss_train: 1.4084	loss_val: 1.4261	loss_test: 1.4390	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3133
[server]	loss_train: 1.2483	loss_val: 1.4485	loss_test: 1.4654	accuracy_train: 0.4766	accuracy_val: 0.2778	accuracy_test: 0.2844
[server]	loss_train: 1.2825	loss_val: 1.4609	loss_test: 1.3116	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.3810
[server]	loss_train: 1.2650	loss_val: 1.3670	loss_test: 1.4901	accuracy_train: 0.4474	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3111	loss_val: 1.4530	loss_test: 1.3808	accuracy_train: 0.4057	accuracy_val: 0.3364	accuracy_test: 0.2661
[server]	loss_train: 1.3030	loss_val: 1.3828	loss_test: 1.2994	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4048
[server]	loss_train: 1.2602	loss_val: 1.3439	loss_test: 1.4158	accuracy_train: 0.4654	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2623	loss_val: 1.4794	loss_test: 1.5002	accuracy_train: 0.5067	accuracy_val: 0.2973	accuracy_test: 0.3117
[server]	loss_train: 1.3622	loss_val: 1.4097	loss_test: 1.3675	accuracy_train: 0.3765	accuracy_val: 0.3372	accuracy_test: 0.3333
[server]	loss_train: 1.2539	loss_val: 1.3562	loss_test: 1.3816	accuracy_train: 0.4797	accuracy_val: 0.3649	accuracy_test: 0.3766
[server]	loss_train: 1.2967	loss_val: 1.3771	loss_test: 1.5433	accuracy_train: 0.3657	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2298	loss_val: 1.4191	loss_test: 1.4498	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3532	loss_val: 1.5063	loss_test: 1.3990	accuracy_train: 0.4251	accuracy_val: 0.2941	accuracy_test: 0.3962
[server]	loss_train: 1.3296	loss_val: 1.4424	loss_test: 1.4084	accuracy_train: 0.3850	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.3070	loss_val: 1.4404	loss_test: 1.3631	accuracy_train: 0.4393	accuracy_val: 0.3176	accuracy_test: 0.3258
[server]	loss_train: 1.3201	loss_val: 1.4576	loss_test: 1.4493	accuracy_train: 0.4356	accuracy_val: 0.2840	accuracy_test: 0.3095
[server]	loss_train: 1.2819	loss_val: 1.4383	loss_test: 1.3325	accuracy_train: 0.4753	accuracy_val: 0.3964	accuracy_test: 0.4035
curr_round: 71	curr_val_accuracy: 0.3356	curr_test_accuracy: 0.3343
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 72		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3473	loss_val: 1.4630	loss_test: 1.5342	accuracy_train: 0.4159	accuracy_val: 0.3009	accuracy_test: 0.2696
[server]	loss_train: 1.2818	loss_val: 1.3525	loss_test: 1.4594	accuracy_train: 0.4293	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2499	loss_val: 1.4029	loss_test: 1.4127	accuracy_train: 0.4727	accuracy_val: 0.3211	accuracy_test: 0.3604
[server]	loss_train: 1.4074	loss_val: 1.4264	loss_test: 1.4387	accuracy_train: 0.3313	accuracy_val: 0.3171	accuracy_test: 0.3133
[server]	loss_train: 1.2473	loss_val: 1.4490	loss_test: 1.4657	accuracy_train: 0.4813	accuracy_val: 0.2778	accuracy_test: 0.2844
[server]	loss_train: 1.2818	loss_val: 1.4613	loss_test: 1.3118	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.3810
[server]	loss_train: 1.2641	loss_val: 1.3675	loss_test: 1.4907	accuracy_train: 0.4526	accuracy_val: 0.4316	accuracy_test: 0.3402
[server]	loss_train: 1.3105	loss_val: 1.4539	loss_test: 1.3814	accuracy_train: 0.4057	accuracy_val: 0.3364	accuracy_test: 0.2661
[server]	loss_train: 1.3020	loss_val: 1.3827	loss_test: 1.2990	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4048
[server]	loss_train: 1.2594	loss_val: 1.3439	loss_test: 1.4165	accuracy_train: 0.4654	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2605	loss_val: 1.4805	loss_test: 1.5007	accuracy_train: 0.5067	accuracy_val: 0.2973	accuracy_test: 0.3117
[server]	loss_train: 1.3612	loss_val: 1.4102	loss_test: 1.3676	accuracy_train: 0.3765	accuracy_val: 0.3372	accuracy_test: 0.3333
[server]	loss_train: 1.2528	loss_val: 1.3561	loss_test: 1.3819	accuracy_train: 0.4797	accuracy_val: 0.3649	accuracy_test: 0.3896
[server]	loss_train: 1.2964	loss_val: 1.3779	loss_test: 1.5446	accuracy_train: 0.3657	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2290	loss_val: 1.4201	loss_test: 1.4498	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3523	loss_val: 1.5068	loss_test: 1.3994	accuracy_train: 0.4251	accuracy_val: 0.2941	accuracy_test: 0.3962
[server]	loss_train: 1.3288	loss_val: 1.4429	loss_test: 1.4083	accuracy_train: 0.3805	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.3061	loss_val: 1.4413	loss_test: 1.3634	accuracy_train: 0.4393	accuracy_val: 0.3176	accuracy_test: 0.3258
[server]	loss_train: 1.3187	loss_val: 1.4583	loss_test: 1.4497	accuracy_train: 0.4417	accuracy_val: 0.2840	accuracy_test: 0.3095
[server]	loss_train: 1.2810	loss_val: 1.4385	loss_test: 1.3322	accuracy_train: 0.4753	accuracy_val: 0.3964	accuracy_test: 0.4035
curr_round: 72	curr_val_accuracy: 0.3361	curr_test_accuracy: 0.3354
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 73		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3460	loss_val: 1.4631	loss_test: 1.5345	accuracy_train: 0.4204	accuracy_val: 0.3097	accuracy_test: 0.2696
[server]	loss_train: 1.2809	loss_val: 1.3525	loss_test: 1.4598	accuracy_train: 0.4402	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2493	loss_val: 1.4033	loss_test: 1.4137	accuracy_train: 0.4727	accuracy_val: 0.3211	accuracy_test: 0.3514
[server]	loss_train: 1.4065	loss_val: 1.4266	loss_test: 1.4384	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3133
[server]	loss_train: 1.2464	loss_val: 1.4496	loss_test: 1.4660	accuracy_train: 0.4813	accuracy_val: 0.2778	accuracy_test: 0.2844
[server]	loss_train: 1.2812	loss_val: 1.4616	loss_test: 1.3121	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.3810
[server]	loss_train: 1.2631	loss_val: 1.3681	loss_test: 1.4913	accuracy_train: 0.4526	accuracy_val: 0.4316	accuracy_test: 0.3402
[server]	loss_train: 1.3099	loss_val: 1.4547	loss_test: 1.3820	accuracy_train: 0.4057	accuracy_val: 0.3364	accuracy_test: 0.2661
[server]	loss_train: 1.3010	loss_val: 1.3826	loss_test: 1.2987	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2585	loss_val: 1.3438	loss_test: 1.4172	accuracy_train: 0.4654	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2587	loss_val: 1.4816	loss_test: 1.5012	accuracy_train: 0.5067	accuracy_val: 0.2973	accuracy_test: 0.3117
[server]	loss_train: 1.3602	loss_val: 1.4107	loss_test: 1.3677	accuracy_train: 0.3765	accuracy_val: 0.3372	accuracy_test: 0.3218
[server]	loss_train: 1.2518	loss_val: 1.3560	loss_test: 1.3821	accuracy_train: 0.4865	accuracy_val: 0.3649	accuracy_test: 0.3896
[server]	loss_train: 1.2961	loss_val: 1.3786	loss_test: 1.5459	accuracy_train: 0.3657	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2282	loss_val: 1.4211	loss_test: 1.4497	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3515	loss_val: 1.5074	loss_test: 1.3998	accuracy_train: 0.4251	accuracy_val: 0.2941	accuracy_test: 0.3868
[server]	loss_train: 1.3279	loss_val: 1.4435	loss_test: 1.4082	accuracy_train: 0.3850	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.3051	loss_val: 1.4421	loss_test: 1.3637	accuracy_train: 0.4393	accuracy_val: 0.3176	accuracy_test: 0.3258
[server]	loss_train: 1.3173	loss_val: 1.4591	loss_test: 1.4501	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.2857
[server]	loss_train: 1.2801	loss_val: 1.4387	loss_test: 1.3319	accuracy_train: 0.4753	accuracy_val: 0.3964	accuracy_test: 0.4035
curr_round: 73	curr_val_accuracy: 0.3367	curr_test_accuracy: 0.3338
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 74		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3447	loss_val: 1.4632	loss_test: 1.5348	accuracy_train: 0.4159	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2801	loss_val: 1.3526	loss_test: 1.4602	accuracy_train: 0.4348	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2487	loss_val: 1.4037	loss_test: 1.4147	accuracy_train: 0.4727	accuracy_val: 0.3211	accuracy_test: 0.3514
[server]	loss_train: 1.4055	loss_val: 1.4269	loss_test: 1.4380	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3133
[server]	loss_train: 1.2455	loss_val: 1.4502	loss_test: 1.4662	accuracy_train: 0.4813	accuracy_val: 0.2778	accuracy_test: 0.2844
[server]	loss_train: 1.2806	loss_val: 1.4620	loss_test: 1.3123	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.3929
[server]	loss_train: 1.2622	loss_val: 1.3686	loss_test: 1.4918	accuracy_train: 0.4474	accuracy_val: 0.4316	accuracy_test: 0.3402
[server]	loss_train: 1.3093	loss_val: 1.4555	loss_test: 1.3825	accuracy_train: 0.4057	accuracy_val: 0.3364	accuracy_test: 0.2661
[server]	loss_train: 1.3000	loss_val: 1.3826	loss_test: 1.2984	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2577	loss_val: 1.3437	loss_test: 1.4179	accuracy_train: 0.4608	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2570	loss_val: 1.4828	loss_test: 1.5017	accuracy_train: 0.5067	accuracy_val: 0.2973	accuracy_test: 0.3117
[server]	loss_train: 1.3592	loss_val: 1.4113	loss_test: 1.3678	accuracy_train: 0.3765	accuracy_val: 0.3372	accuracy_test: 0.3218
[server]	loss_train: 1.2508	loss_val: 1.3560	loss_test: 1.3824	accuracy_train: 0.4865	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2959	loss_val: 1.3793	loss_test: 1.5472	accuracy_train: 0.3657	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2275	loss_val: 1.4221	loss_test: 1.4496	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3507	loss_val: 1.5079	loss_test: 1.4003	accuracy_train: 0.4251	accuracy_val: 0.2941	accuracy_test: 0.3774
[server]	loss_train: 1.3271	loss_val: 1.4440	loss_test: 1.4082	accuracy_train: 0.3850	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.3042	loss_val: 1.4430	loss_test: 1.3641	accuracy_train: 0.4393	accuracy_val: 0.3176	accuracy_test: 0.3258
[server]	loss_train: 1.3160	loss_val: 1.4599	loss_test: 1.4505	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.2857
[server]	loss_train: 1.2793	loss_val: 1.4389	loss_test: 1.3317	accuracy_train: 0.4753	accuracy_val: 0.3964	accuracy_test: 0.4035
curr_round: 74	curr_val_accuracy: 0.3367	curr_test_accuracy: 0.3338
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 75		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3435	loss_val: 1.4632	loss_test: 1.5351	accuracy_train: 0.4159	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2793	loss_val: 1.3526	loss_test: 1.4606	accuracy_train: 0.4348	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2482	loss_val: 1.4041	loss_test: 1.4157	accuracy_train: 0.4727	accuracy_val: 0.3211	accuracy_test: 0.3514
[server]	loss_train: 1.4046	loss_val: 1.4271	loss_test: 1.4376	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3133
[server]	loss_train: 1.2446	loss_val: 1.4508	loss_test: 1.4665	accuracy_train: 0.4813	accuracy_val: 0.2778	accuracy_test: 0.2844
[server]	loss_train: 1.2800	loss_val: 1.4624	loss_test: 1.3125	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.4048
[server]	loss_train: 1.2613	loss_val: 1.3691	loss_test: 1.4924	accuracy_train: 0.4474	accuracy_val: 0.4316	accuracy_test: 0.3402
[server]	loss_train: 1.3087	loss_val: 1.4563	loss_test: 1.3831	accuracy_train: 0.4057	accuracy_val: 0.3364	accuracy_test: 0.2661
[server]	loss_train: 1.2990	loss_val: 1.3826	loss_test: 1.2980	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2569	loss_val: 1.3437	loss_test: 1.4186	accuracy_train: 0.4608	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2553	loss_val: 1.4839	loss_test: 1.5021	accuracy_train: 0.5067	accuracy_val: 0.2973	accuracy_test: 0.3247
[server]	loss_train: 1.3582	loss_val: 1.4118	loss_test: 1.3680	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2498	loss_val: 1.3559	loss_test: 1.3827	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2956	loss_val: 1.3800	loss_test: 1.5484	accuracy_train: 0.3657	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2268	loss_val: 1.4231	loss_test: 1.4495	accuracy_train: 0.4632	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3499	loss_val: 1.5085	loss_test: 1.4008	accuracy_train: 0.4251	accuracy_val: 0.2941	accuracy_test: 0.3774
[server]	loss_train: 1.3263	loss_val: 1.4445	loss_test: 1.4082	accuracy_train: 0.3805	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.3033	loss_val: 1.4438	loss_test: 1.3645	accuracy_train: 0.4335	accuracy_val: 0.3176	accuracy_test: 0.3258
[server]	loss_train: 1.3147	loss_val: 1.4606	loss_test: 1.4508	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.2857
[server]	loss_train: 1.2785	loss_val: 1.4391	loss_test: 1.3315	accuracy_train: 0.4753	accuracy_val: 0.3964	accuracy_test: 0.3947
curr_round: 75	curr_val_accuracy: 0.3361	curr_test_accuracy: 0.3343
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 76		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3422	loss_val: 1.4633	loss_test: 1.5355	accuracy_train: 0.4159	accuracy_val: 0.3097	accuracy_test: 0.2696
[server]	loss_train: 1.2785	loss_val: 1.3526	loss_test: 1.4609	accuracy_train: 0.4348	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2476	loss_val: 1.4045	loss_test: 1.4166	accuracy_train: 0.4727	accuracy_val: 0.3211	accuracy_test: 0.3514
[server]	loss_train: 1.4037	loss_val: 1.4274	loss_test: 1.4373	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3253
[server]	loss_train: 1.2438	loss_val: 1.4514	loss_test: 1.4667	accuracy_train: 0.4766	accuracy_val: 0.2778	accuracy_test: 0.2936
[server]	loss_train: 1.2794	loss_val: 1.4627	loss_test: 1.3128	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.4048
[server]	loss_train: 1.2605	loss_val: 1.3696	loss_test: 1.4929	accuracy_train: 0.4474	accuracy_val: 0.4316	accuracy_test: 0.3402
[server]	loss_train: 1.3082	loss_val: 1.4571	loss_test: 1.3837	accuracy_train: 0.4057	accuracy_val: 0.3364	accuracy_test: 0.2661
[server]	loss_train: 1.2981	loss_val: 1.3825	loss_test: 1.2977	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2561	loss_val: 1.3436	loss_test: 1.4193	accuracy_train: 0.4654	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2537	loss_val: 1.4851	loss_test: 1.5026	accuracy_train: 0.5133	accuracy_val: 0.2973	accuracy_test: 0.3247
[server]	loss_train: 1.3573	loss_val: 1.4123	loss_test: 1.3681	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2489	loss_val: 1.3559	loss_test: 1.3830	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2954	loss_val: 1.3808	loss_test: 1.5497	accuracy_train: 0.3657	accuracy_val: 0.3258	accuracy_test: 0.2418
[server]	loss_train: 1.2260	loss_val: 1.4240	loss_test: 1.4494	accuracy_train: 0.4632	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3492	loss_val: 1.5091	loss_test: 1.4012	accuracy_train: 0.4348	accuracy_val: 0.3039	accuracy_test: 0.3774
[server]	loss_train: 1.3255	loss_val: 1.4451	loss_test: 1.4082	accuracy_train: 0.3805	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.3024	loss_val: 1.4446	loss_test: 1.3648	accuracy_train: 0.4335	accuracy_val: 0.3176	accuracy_test: 0.3258
[server]	loss_train: 1.3134	loss_val: 1.4614	loss_test: 1.4512	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.2857
[server]	loss_train: 1.2777	loss_val: 1.4393	loss_test: 1.3313	accuracy_train: 0.4753	accuracy_val: 0.3964	accuracy_test: 0.3860
curr_round: 76	curr_val_accuracy: 0.3361	curr_test_accuracy: 0.3349
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 77		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3410	loss_val: 1.4634	loss_test: 1.5358	accuracy_train: 0.4159	accuracy_val: 0.3097	accuracy_test: 0.2696
[server]	loss_train: 1.2777	loss_val: 1.3527	loss_test: 1.4613	accuracy_train: 0.4348	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2471	loss_val: 1.4049	loss_test: 1.4176	accuracy_train: 0.4727	accuracy_val: 0.3211	accuracy_test: 0.3514
[server]	loss_train: 1.4028	loss_val: 1.4276	loss_test: 1.4370	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3253
[server]	loss_train: 1.2429	loss_val: 1.4520	loss_test: 1.4670	accuracy_train: 0.4813	accuracy_val: 0.2593	accuracy_test: 0.2936
[server]	loss_train: 1.2788	loss_val: 1.4631	loss_test: 1.3130	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.4048
[server]	loss_train: 1.2596	loss_val: 1.3701	loss_test: 1.4935	accuracy_train: 0.4474	accuracy_val: 0.4316	accuracy_test: 0.3402
[server]	loss_train: 1.3077	loss_val: 1.4579	loss_test: 1.3843	accuracy_train: 0.4057	accuracy_val: 0.3364	accuracy_test: 0.2661
[server]	loss_train: 1.2972	loss_val: 1.3826	loss_test: 1.2975	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2553	loss_val: 1.3436	loss_test: 1.4200	accuracy_train: 0.4654	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2520	loss_val: 1.4862	loss_test: 1.5030	accuracy_train: 0.5200	accuracy_val: 0.2973	accuracy_test: 0.3247
[server]	loss_train: 1.3563	loss_val: 1.4128	loss_test: 1.3681	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2479	loss_val: 1.3559	loss_test: 1.3834	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2952	loss_val: 1.3815	loss_test: 1.5509	accuracy_train: 0.3657	accuracy_val: 0.3371	accuracy_test: 0.2418
[server]	loss_train: 1.2253	loss_val: 1.4250	loss_test: 1.4493	accuracy_train: 0.4632	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3485	loss_val: 1.5097	loss_test: 1.4017	accuracy_train: 0.4348	accuracy_val: 0.3039	accuracy_test: 0.3774
[server]	loss_train: 1.3246	loss_val: 1.4457	loss_test: 1.4082	accuracy_train: 0.3805	accuracy_val: 0.3451	accuracy_test: 0.4000
[server]	loss_train: 1.3015	loss_val: 1.4454	loss_test: 1.3652	accuracy_train: 0.4335	accuracy_val: 0.3059	accuracy_test: 0.3258
[server]	loss_train: 1.3122	loss_val: 1.4621	loss_test: 1.4516	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.2857
[server]	loss_train: 1.2770	loss_val: 1.4395	loss_test: 1.3311	accuracy_train: 0.4753	accuracy_val: 0.3964	accuracy_test: 0.3860
curr_round: 77	curr_val_accuracy: 0.3351	curr_test_accuracy: 0.3354
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 78		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3399	loss_val: 1.4635	loss_test: 1.5361	accuracy_train: 0.4159	accuracy_val: 0.3097	accuracy_test: 0.2696
[server]	loss_train: 1.2769	loss_val: 1.3527	loss_test: 1.4617	accuracy_train: 0.4348	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2465	loss_val: 1.4053	loss_test: 1.4185	accuracy_train: 0.4727	accuracy_val: 0.3211	accuracy_test: 0.3514
[server]	loss_train: 1.4019	loss_val: 1.4279	loss_test: 1.4366	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3253
[server]	loss_train: 1.2421	loss_val: 1.4526	loss_test: 1.4672	accuracy_train: 0.4813	accuracy_val: 0.2593	accuracy_test: 0.2936
[server]	loss_train: 1.2782	loss_val: 1.4634	loss_test: 1.3133	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.4048
[server]	loss_train: 1.2587	loss_val: 1.3706	loss_test: 1.4940	accuracy_train: 0.4526	accuracy_val: 0.4316	accuracy_test: 0.3402
[server]	loss_train: 1.3071	loss_val: 1.4587	loss_test: 1.3849	accuracy_train: 0.4057	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2963	loss_val: 1.3826	loss_test: 1.2972	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2545	loss_val: 1.3436	loss_test: 1.4206	accuracy_train: 0.4654	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2504	loss_val: 1.4873	loss_test: 1.5035	accuracy_train: 0.5200	accuracy_val: 0.2973	accuracy_test: 0.3247
[server]	loss_train: 1.3554	loss_val: 1.4133	loss_test: 1.3682	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2470	loss_val: 1.3560	loss_test: 1.3837	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2949	loss_val: 1.3823	loss_test: 1.5521	accuracy_train: 0.3657	accuracy_val: 0.3371	accuracy_test: 0.2308
[server]	loss_train: 1.2246	loss_val: 1.4259	loss_test: 1.4492	accuracy_train: 0.4632	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3478	loss_val: 1.5103	loss_test: 1.4022	accuracy_train: 0.4348	accuracy_val: 0.3039	accuracy_test: 0.3774
[server]	loss_train: 1.3238	loss_val: 1.4463	loss_test: 1.4082	accuracy_train: 0.3805	accuracy_val: 0.3451	accuracy_test: 0.4000
[server]	loss_train: 1.3006	loss_val: 1.4463	loss_test: 1.3656	accuracy_train: 0.4335	accuracy_val: 0.3059	accuracy_test: 0.3258
[server]	loss_train: 1.3110	loss_val: 1.4629	loss_test: 1.4519	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.2857
[server]	loss_train: 1.2763	loss_val: 1.4397	loss_test: 1.3309	accuracy_train: 0.4709	accuracy_val: 0.3964	accuracy_test: 0.3860
curr_round: 78	curr_val_accuracy: 0.3346	curr_test_accuracy: 0.3349
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 79		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3387	loss_val: 1.4636	loss_test: 1.5365	accuracy_train: 0.4159	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2761	loss_val: 1.3528	loss_test: 1.4621	accuracy_train: 0.4348	accuracy_val: 0.3696	accuracy_test: 0.3333
[server]	loss_train: 1.2460	loss_val: 1.4057	loss_test: 1.4195	accuracy_train: 0.4727	accuracy_val: 0.3119	accuracy_test: 0.3514
[server]	loss_train: 1.4010	loss_val: 1.4282	loss_test: 1.4363	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3253
[server]	loss_train: 1.2413	loss_val: 1.4532	loss_test: 1.4675	accuracy_train: 0.4766	accuracy_val: 0.2593	accuracy_test: 0.2936
[server]	loss_train: 1.2776	loss_val: 1.4637	loss_test: 1.3136	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.4048
[server]	loss_train: 1.2579	loss_val: 1.3712	loss_test: 1.4945	accuracy_train: 0.4526	accuracy_val: 0.4316	accuracy_test: 0.3402
[server]	loss_train: 1.3066	loss_val: 1.4595	loss_test: 1.3855	accuracy_train: 0.4057	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2954	loss_val: 1.3826	loss_test: 1.2970	accuracy_train: 0.4259	accuracy_val: 0.3659	accuracy_test: 0.4286
[server]	loss_train: 1.2538	loss_val: 1.3435	loss_test: 1.4213	accuracy_train: 0.4654	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2489	loss_val: 1.4884	loss_test: 1.5039	accuracy_train: 0.5267	accuracy_val: 0.2973	accuracy_test: 0.3247
[server]	loss_train: 1.3545	loss_val: 1.4138	loss_test: 1.3683	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2461	loss_val: 1.3561	loss_test: 1.3840	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2947	loss_val: 1.3830	loss_test: 1.5533	accuracy_train: 0.3657	accuracy_val: 0.3371	accuracy_test: 0.2308
[server]	loss_train: 1.2239	loss_val: 1.4269	loss_test: 1.4491	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3471	loss_val: 1.5109	loss_test: 1.4026	accuracy_train: 0.4348	accuracy_val: 0.3137	accuracy_test: 0.3774
[server]	loss_train: 1.3230	loss_val: 1.4468	loss_test: 1.4083	accuracy_train: 0.3850	accuracy_val: 0.3363	accuracy_test: 0.3913
[server]	loss_train: 1.2998	loss_val: 1.4471	loss_test: 1.3660	accuracy_train: 0.4335	accuracy_val: 0.3059	accuracy_test: 0.3258
[server]	loss_train: 1.3098	loss_val: 1.4636	loss_test: 1.4523	accuracy_train: 0.4479	accuracy_val: 0.2840	accuracy_test: 0.2857
[server]	loss_train: 1.2756	loss_val: 1.4400	loss_test: 1.3308	accuracy_train: 0.4709	accuracy_val: 0.3964	accuracy_test: 0.3860
curr_round: 79	curr_val_accuracy: 0.3340	curr_test_accuracy: 0.3343
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 80		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3375	loss_val: 1.4637	loss_test: 1.5369	accuracy_train: 0.4159	accuracy_val: 0.3097	accuracy_test: 0.2696
[server]	loss_train: 1.2754	loss_val: 1.3528	loss_test: 1.4625	accuracy_train: 0.4348	accuracy_val: 0.3696	accuracy_test: 0.3333
[server]	loss_train: 1.2455	loss_val: 1.4061	loss_test: 1.4204	accuracy_train: 0.4727	accuracy_val: 0.3119	accuracy_test: 0.3514
[server]	loss_train: 1.4001	loss_val: 1.4284	loss_test: 1.4360	accuracy_train: 0.3252	accuracy_val: 0.3171	accuracy_test: 0.3253
[server]	loss_train: 1.2405	loss_val: 1.4538	loss_test: 1.4677	accuracy_train: 0.4766	accuracy_val: 0.2593	accuracy_test: 0.2936
[server]	loss_train: 1.2771	loss_val: 1.4640	loss_test: 1.3139	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.3929
[server]	loss_train: 1.2570	loss_val: 1.3717	loss_test: 1.4951	accuracy_train: 0.4526	accuracy_val: 0.4316	accuracy_test: 0.3402
[server]	loss_train: 1.3061	loss_val: 1.4602	loss_test: 1.3860	accuracy_train: 0.4057	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2945	loss_val: 1.3826	loss_test: 1.2968	accuracy_train: 0.4259	accuracy_val: 0.3537	accuracy_test: 0.4286
[server]	loss_train: 1.2531	loss_val: 1.3435	loss_test: 1.4220	accuracy_train: 0.4700	accuracy_val: 0.3981	accuracy_test: 0.3333
[server]	loss_train: 1.2473	loss_val: 1.4895	loss_test: 1.5043	accuracy_train: 0.5333	accuracy_val: 0.3108	accuracy_test: 0.3247
[server]	loss_train: 1.3535	loss_val: 1.4143	loss_test: 1.3684	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2453	loss_val: 1.3561	loss_test: 1.3844	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2945	loss_val: 1.3837	loss_test: 1.5545	accuracy_train: 0.3657	accuracy_val: 0.3371	accuracy_test: 0.2308
[server]	loss_train: 1.2232	loss_val: 1.4278	loss_test: 1.4490	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3464	loss_val: 1.5115	loss_test: 1.4031	accuracy_train: 0.4300	accuracy_val: 0.3137	accuracy_test: 0.3774
[server]	loss_train: 1.3223	loss_val: 1.4474	loss_test: 1.4084	accuracy_train: 0.3850	accuracy_val: 0.3363	accuracy_test: 0.3913
[server]	loss_train: 1.2989	loss_val: 1.4479	loss_test: 1.3664	accuracy_train: 0.4335	accuracy_val: 0.3059	accuracy_test: 0.3258
[server]	loss_train: 1.3086	loss_val: 1.4644	loss_test: 1.4527	accuracy_train: 0.4479	accuracy_val: 0.2963	accuracy_test: 0.2857
[server]	loss_train: 1.2749	loss_val: 1.4402	loss_test: 1.3307	accuracy_train: 0.4709	accuracy_val: 0.3874	accuracy_test: 0.3860
curr_round: 80	curr_val_accuracy: 0.3335	curr_test_accuracy: 0.3338
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 81		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3364	loss_val: 1.4639	loss_test: 1.5372	accuracy_train: 0.4159	accuracy_val: 0.3097	accuracy_test: 0.2696
[server]	loss_train: 1.2746	loss_val: 1.3529	loss_test: 1.4628	accuracy_train: 0.4348	accuracy_val: 0.3696	accuracy_test: 0.3333
[server]	loss_train: 1.2449	loss_val: 1.4065	loss_test: 1.4214	accuracy_train: 0.4727	accuracy_val: 0.3119	accuracy_test: 0.3514
[server]	loss_train: 1.3992	loss_val: 1.4287	loss_test: 1.4357	accuracy_train: 0.3252	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.2397	loss_val: 1.4544	loss_test: 1.4680	accuracy_train: 0.4813	accuracy_val: 0.2593	accuracy_test: 0.2936
[server]	loss_train: 1.2766	loss_val: 1.4643	loss_test: 1.3142	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.3929
[server]	loss_train: 1.2562	loss_val: 1.3722	loss_test: 1.4956	accuracy_train: 0.4526	accuracy_val: 0.4316	accuracy_test: 0.3299
[server]	loss_train: 1.3056	loss_val: 1.4609	loss_test: 1.3866	accuracy_train: 0.4009	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2936	loss_val: 1.3826	loss_test: 1.2966	accuracy_train: 0.4259	accuracy_val: 0.3780	accuracy_test: 0.4286
[server]	loss_train: 1.2524	loss_val: 1.3434	loss_test: 1.4226	accuracy_train: 0.4700	accuracy_val: 0.3981	accuracy_test: 0.3243
[server]	loss_train: 1.2458	loss_val: 1.4905	loss_test: 1.5047	accuracy_train: 0.5333	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3526	loss_val: 1.4148	loss_test: 1.3685	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2444	loss_val: 1.3562	loss_test: 1.3847	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2943	loss_val: 1.3845	loss_test: 1.5557	accuracy_train: 0.3543	accuracy_val: 0.3371	accuracy_test: 0.2308
[server]	loss_train: 1.2225	loss_val: 1.4287	loss_test: 1.4489	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3458	loss_val: 1.5121	loss_test: 1.4036	accuracy_train: 0.4300	accuracy_val: 0.3137	accuracy_test: 0.3774
[server]	loss_train: 1.3215	loss_val: 1.4480	loss_test: 1.4085	accuracy_train: 0.3894	accuracy_val: 0.3363	accuracy_test: 0.3913
[server]	loss_train: 1.2981	loss_val: 1.4487	loss_test: 1.3668	accuracy_train: 0.4335	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3074	loss_val: 1.4651	loss_test: 1.4530	accuracy_train: 0.4479	accuracy_val: 0.2963	accuracy_test: 0.2857
[server]	loss_train: 1.2743	loss_val: 1.4404	loss_test: 1.3305	accuracy_train: 0.4664	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 81	curr_val_accuracy: 0.3351	curr_test_accuracy: 0.3333
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 82		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3353	loss_val: 1.4640	loss_test: 1.5376	accuracy_train: 0.4159	accuracy_val: 0.3097	accuracy_test: 0.2696
[server]	loss_train: 1.2739	loss_val: 1.3529	loss_test: 1.4632	accuracy_train: 0.4348	accuracy_val: 0.3696	accuracy_test: 0.3333
[server]	loss_train: 1.2444	loss_val: 1.4069	loss_test: 1.4223	accuracy_train: 0.4727	accuracy_val: 0.3028	accuracy_test: 0.3604
[server]	loss_train: 1.3984	loss_val: 1.4290	loss_test: 1.4355	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.2389	loss_val: 1.4550	loss_test: 1.4682	accuracy_train: 0.4813	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2760	loss_val: 1.4646	loss_test: 1.3146	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.3929
[server]	loss_train: 1.2554	loss_val: 1.3728	loss_test: 1.4961	accuracy_train: 0.4526	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3051	loss_val: 1.4616	loss_test: 1.3871	accuracy_train: 0.4009	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2928	loss_val: 1.3827	loss_test: 1.2964	accuracy_train: 0.4198	accuracy_val: 0.3902	accuracy_test: 0.4286
[server]	loss_train: 1.2517	loss_val: 1.3434	loss_test: 1.4233	accuracy_train: 0.4654	accuracy_val: 0.3981	accuracy_test: 0.3243
[server]	loss_train: 1.2443	loss_val: 1.4916	loss_test: 1.5051	accuracy_train: 0.5333	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3517	loss_val: 1.4153	loss_test: 1.3685	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2436	loss_val: 1.3563	loss_test: 1.3850	accuracy_train: 0.4730	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2940	loss_val: 1.3852	loss_test: 1.5569	accuracy_train: 0.3543	accuracy_val: 0.3371	accuracy_test: 0.2308
[server]	loss_train: 1.2218	loss_val: 1.4296	loss_test: 1.4487	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3451	loss_val: 1.5127	loss_test: 1.4041	accuracy_train: 0.4300	accuracy_val: 0.3137	accuracy_test: 0.3774
[server]	loss_train: 1.3207	loss_val: 1.4486	loss_test: 1.4086	accuracy_train: 0.3894	accuracy_val: 0.3363	accuracy_test: 0.3913
[server]	loss_train: 1.2973	loss_val: 1.4495	loss_test: 1.3673	accuracy_train: 0.4335	accuracy_val: 0.3176	accuracy_test: 0.3371
[server]	loss_train: 1.3063	loss_val: 1.4658	loss_test: 1.4534	accuracy_train: 0.4479	accuracy_val: 0.2963	accuracy_test: 0.2857
[server]	loss_train: 1.2736	loss_val: 1.4406	loss_test: 1.3304	accuracy_train: 0.4664	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 82	curr_val_accuracy: 0.3346	curr_test_accuracy: 0.3338
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 83		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3342	loss_val: 1.4641	loss_test: 1.5379	accuracy_train: 0.4204	accuracy_val: 0.3097	accuracy_test: 0.2696
[server]	loss_train: 1.2731	loss_val: 1.3530	loss_test: 1.4636	accuracy_train: 0.4293	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2439	loss_val: 1.4073	loss_test: 1.4232	accuracy_train: 0.4727	accuracy_val: 0.3028	accuracy_test: 0.3604
[server]	loss_train: 1.3975	loss_val: 1.4292	loss_test: 1.4352	accuracy_train: 0.3252	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.2382	loss_val: 1.4556	loss_test: 1.4685	accuracy_train: 0.4813	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2755	loss_val: 1.4649	loss_test: 1.3149	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.3929
[server]	loss_train: 1.2546	loss_val: 1.3733	loss_test: 1.4966	accuracy_train: 0.4526	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3046	loss_val: 1.4623	loss_test: 1.3876	accuracy_train: 0.4057	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2920	loss_val: 1.3828	loss_test: 1.2963	accuracy_train: 0.4198	accuracy_val: 0.3902	accuracy_test: 0.4286
[server]	loss_train: 1.2510	loss_val: 1.3433	loss_test: 1.4239	accuracy_train: 0.4654	accuracy_val: 0.4074	accuracy_test: 0.3243
[server]	loss_train: 1.2429	loss_val: 1.4926	loss_test: 1.5055	accuracy_train: 0.5333	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3508	loss_val: 1.4157	loss_test: 1.3686	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2427	loss_val: 1.3564	loss_test: 1.3854	accuracy_train: 0.4730	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2938	loss_val: 1.3859	loss_test: 1.5581	accuracy_train: 0.3486	accuracy_val: 0.3371	accuracy_test: 0.2308
[server]	loss_train: 1.2212	loss_val: 1.4305	loss_test: 1.4486	accuracy_train: 0.4684	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3445	loss_val: 1.5133	loss_test: 1.4046	accuracy_train: 0.4300	accuracy_val: 0.3137	accuracy_test: 0.3679
[server]	loss_train: 1.3200	loss_val: 1.4492	loss_test: 1.4087	accuracy_train: 0.3894	accuracy_val: 0.3363	accuracy_test: 0.3913
[server]	loss_train: 1.2965	loss_val: 1.4502	loss_test: 1.3677	accuracy_train: 0.4335	accuracy_val: 0.3176	accuracy_test: 0.3371
[server]	loss_train: 1.3052	loss_val: 1.4666	loss_test: 1.4537	accuracy_train: 0.4479	accuracy_val: 0.2963	accuracy_test: 0.2857
[server]	loss_train: 1.2730	loss_val: 1.4409	loss_test: 1.3303	accuracy_train: 0.4664	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 83	curr_val_accuracy: 0.3356	curr_test_accuracy: 0.3333
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 84		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3332	loss_val: 1.4643	loss_test: 1.5383	accuracy_train: 0.4204	accuracy_val: 0.3097	accuracy_test: 0.2696
[server]	loss_train: 1.2724	loss_val: 1.3530	loss_test: 1.4639	accuracy_train: 0.4293	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2434	loss_val: 1.4076	loss_test: 1.4241	accuracy_train: 0.4727	accuracy_val: 0.3028	accuracy_test: 0.3604
[server]	loss_train: 1.3967	loss_val: 1.4294	loss_test: 1.4349	accuracy_train: 0.3252	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.2375	loss_val: 1.4562	loss_test: 1.4687	accuracy_train: 0.4813	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2750	loss_val: 1.4651	loss_test: 1.3153	accuracy_train: 0.4601	accuracy_val: 0.2963	accuracy_test: 0.3929
[server]	loss_train: 1.2538	loss_val: 1.3738	loss_test: 1.4971	accuracy_train: 0.4526	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3041	loss_val: 1.4630	loss_test: 1.3882	accuracy_train: 0.4057	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2912	loss_val: 1.3828	loss_test: 1.2961	accuracy_train: 0.4198	accuracy_val: 0.3902	accuracy_test: 0.4286
[server]	loss_train: 1.2503	loss_val: 1.3433	loss_test: 1.4245	accuracy_train: 0.4654	accuracy_val: 0.4074	accuracy_test: 0.3243
[server]	loss_train: 1.2414	loss_val: 1.4936	loss_test: 1.5058	accuracy_train: 0.5333	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3499	loss_val: 1.4162	loss_test: 1.3686	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2419	loss_val: 1.3565	loss_test: 1.3858	accuracy_train: 0.4730	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2936	loss_val: 1.3866	loss_test: 1.5593	accuracy_train: 0.3486	accuracy_val: 0.3371	accuracy_test: 0.2308
[server]	loss_train: 1.2205	loss_val: 1.4314	loss_test: 1.4484	accuracy_train: 0.4632	accuracy_val: 0.3191	accuracy_test: 0.3131
[server]	loss_train: 1.3440	loss_val: 1.5140	loss_test: 1.4051	accuracy_train: 0.4300	accuracy_val: 0.3137	accuracy_test: 0.3679
[server]	loss_train: 1.3192	loss_val: 1.4498	loss_test: 1.4088	accuracy_train: 0.3894	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.2957	loss_val: 1.4510	loss_test: 1.3681	accuracy_train: 0.4335	accuracy_val: 0.3176	accuracy_test: 0.3371
[server]	loss_train: 1.3041	loss_val: 1.4673	loss_test: 1.4540	accuracy_train: 0.4479	accuracy_val: 0.2963	accuracy_test: 0.2857
[server]	loss_train: 1.2724	loss_val: 1.4411	loss_test: 1.3303	accuracy_train: 0.4753	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 84	curr_val_accuracy: 0.3362	curr_test_accuracy: 0.3328
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 85		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3321	loss_val: 1.4644	loss_test: 1.5387	accuracy_train: 0.4204	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2717	loss_val: 1.3531	loss_test: 1.4643	accuracy_train: 0.4293	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2429	loss_val: 1.4080	loss_test: 1.4250	accuracy_train: 0.4727	accuracy_val: 0.3028	accuracy_test: 0.3604
[server]	loss_train: 1.3958	loss_val: 1.4297	loss_test: 1.4346	accuracy_train: 0.3252	accuracy_val: 0.3415	accuracy_test: 0.3253
[server]	loss_train: 1.2368	loss_val: 1.4568	loss_test: 1.4689	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2745	loss_val: 1.4654	loss_test: 1.3157	accuracy_train: 0.4663	accuracy_val: 0.2963	accuracy_test: 0.3929
[server]	loss_train: 1.2530	loss_val: 1.3743	loss_test: 1.4976	accuracy_train: 0.4579	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3036	loss_val: 1.4637	loss_test: 1.3887	accuracy_train: 0.4057	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2903	loss_val: 1.3829	loss_test: 1.2960	accuracy_train: 0.4198	accuracy_val: 0.3902	accuracy_test: 0.4286
[server]	loss_train: 1.2497	loss_val: 1.3433	loss_test: 1.4252	accuracy_train: 0.4654	accuracy_val: 0.4074	accuracy_test: 0.3153
[server]	loss_train: 1.2400	loss_val: 1.4946	loss_test: 1.5062	accuracy_train: 0.5333	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3491	loss_val: 1.4166	loss_test: 1.3687	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2411	loss_val: 1.3567	loss_test: 1.3861	accuracy_train: 0.4662	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2934	loss_val: 1.3873	loss_test: 1.5604	accuracy_train: 0.3543	accuracy_val: 0.3371	accuracy_test: 0.2308
[server]	loss_train: 1.2198	loss_val: 1.4323	loss_test: 1.4483	accuracy_train: 0.4632	accuracy_val: 0.3191	accuracy_test: 0.3131
[server]	loss_train: 1.3434	loss_val: 1.5146	loss_test: 1.4056	accuracy_train: 0.4300	accuracy_val: 0.3039	accuracy_test: 0.3679
[server]	loss_train: 1.3185	loss_val: 1.4504	loss_test: 1.4090	accuracy_train: 0.3894	accuracy_val: 0.3451	accuracy_test: 0.3913
[server]	loss_train: 1.2949	loss_val: 1.4517	loss_test: 1.3686	accuracy_train: 0.4335	accuracy_val: 0.3176	accuracy_test: 0.3371
[server]	loss_train: 1.3031	loss_val: 1.4680	loss_test: 1.4543	accuracy_train: 0.4540	accuracy_val: 0.3086	accuracy_test: 0.2857
[server]	loss_train: 1.2719	loss_val: 1.4413	loss_test: 1.3302	accuracy_train: 0.4753	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 85	curr_val_accuracy: 0.3372	curr_test_accuracy: 0.3323
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 86		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3311	loss_val: 1.4646	loss_test: 1.5391	accuracy_train: 0.4204	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2710	loss_val: 1.3531	loss_test: 1.4647	accuracy_train: 0.4239	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2424	loss_val: 1.4083	loss_test: 1.4259	accuracy_train: 0.4727	accuracy_val: 0.3028	accuracy_test: 0.3604
[server]	loss_train: 1.3950	loss_val: 1.4300	loss_test: 1.4344	accuracy_train: 0.3252	accuracy_val: 0.3415	accuracy_test: 0.3253
[server]	loss_train: 1.2361	loss_val: 1.4573	loss_test: 1.4691	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2740	loss_val: 1.4656	loss_test: 1.3160	accuracy_train: 0.4663	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.2522	loss_val: 1.3749	loss_test: 1.4982	accuracy_train: 0.4579	accuracy_val: 0.4211	accuracy_test: 0.3299
[server]	loss_train: 1.3032	loss_val: 1.4644	loss_test: 1.3892	accuracy_train: 0.4104	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2896	loss_val: 1.3830	loss_test: 1.2959	accuracy_train: 0.4198	accuracy_val: 0.3902	accuracy_test: 0.4286
[server]	loss_train: 1.2490	loss_val: 1.3433	loss_test: 1.4258	accuracy_train: 0.4654	accuracy_val: 0.4074	accuracy_test: 0.3063
[server]	loss_train: 1.2386	loss_val: 1.4956	loss_test: 1.5066	accuracy_train: 0.5333	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3482	loss_val: 1.4170	loss_test: 1.3687	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2404	loss_val: 1.3568	loss_test: 1.3865	accuracy_train: 0.4662	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2932	loss_val: 1.3880	loss_test: 1.5616	accuracy_train: 0.3543	accuracy_val: 0.3371	accuracy_test: 0.2308
[server]	loss_train: 1.2191	loss_val: 1.4331	loss_test: 1.4482	accuracy_train: 0.4632	accuracy_val: 0.3085	accuracy_test: 0.3131
[server]	loss_train: 1.3428	loss_val: 1.5152	loss_test: 1.4061	accuracy_train: 0.4300	accuracy_val: 0.3039	accuracy_test: 0.3679
[server]	loss_train: 1.3177	loss_val: 1.4510	loss_test: 1.4092	accuracy_train: 0.3894	accuracy_val: 0.3451	accuracy_test: 0.3826
[server]	loss_train: 1.2941	loss_val: 1.4525	loss_test: 1.3690	accuracy_train: 0.4335	accuracy_val: 0.3176	accuracy_test: 0.3371
[server]	loss_train: 1.3020	loss_val: 1.4686	loss_test: 1.4547	accuracy_train: 0.4540	accuracy_val: 0.3086	accuracy_test: 0.2857
[server]	loss_train: 1.2713	loss_val: 1.4416	loss_test: 1.3301	accuracy_train: 0.4798	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 86	curr_val_accuracy: 0.3361	curr_test_accuracy: 0.3313
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 87		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3301	loss_val: 1.4647	loss_test: 1.5394	accuracy_train: 0.4204	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2703	loss_val: 1.3532	loss_test: 1.4650	accuracy_train: 0.4185	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2419	loss_val: 1.4087	loss_test: 1.4268	accuracy_train: 0.4727	accuracy_val: 0.3028	accuracy_test: 0.3604
[server]	loss_train: 1.3942	loss_val: 1.4302	loss_test: 1.4341	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3373
[server]	loss_train: 1.2354	loss_val: 1.4579	loss_test: 1.4694	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2735	loss_val: 1.4658	loss_test: 1.3164	accuracy_train: 0.4663	accuracy_val: 0.2840	accuracy_test: 0.3929
[server]	loss_train: 1.2514	loss_val: 1.3754	loss_test: 1.4987	accuracy_train: 0.4632	accuracy_val: 0.4211	accuracy_test: 0.3196
[server]	loss_train: 1.3027	loss_val: 1.4650	loss_test: 1.3898	accuracy_train: 0.4057	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2888	loss_val: 1.3831	loss_test: 1.2958	accuracy_train: 0.4198	accuracy_val: 0.3902	accuracy_test: 0.4286
[server]	loss_train: 1.2484	loss_val: 1.3432	loss_test: 1.4265	accuracy_train: 0.4654	accuracy_val: 0.4074	accuracy_test: 0.3063
[server]	loss_train: 1.2372	loss_val: 1.4967	loss_test: 1.5070	accuracy_train: 0.5333	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3474	loss_val: 1.4175	loss_test: 1.3688	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2396	loss_val: 1.3569	loss_test: 1.3869	accuracy_train: 0.4730	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2930	loss_val: 1.3887	loss_test: 1.5627	accuracy_train: 0.3543	accuracy_val: 0.3371	accuracy_test: 0.2308
[server]	loss_train: 1.2185	loss_val: 1.4340	loss_test: 1.4480	accuracy_train: 0.4579	accuracy_val: 0.3085	accuracy_test: 0.3131
[server]	loss_train: 1.3423	loss_val: 1.5159	loss_test: 1.4066	accuracy_train: 0.4300	accuracy_val: 0.3039	accuracy_test: 0.3679
[server]	loss_train: 1.3170	loss_val: 1.4516	loss_test: 1.4094	accuracy_train: 0.3894	accuracy_val: 0.3451	accuracy_test: 0.3826
[server]	loss_train: 1.2933	loss_val: 1.4532	loss_test: 1.3695	accuracy_train: 0.4277	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3010	loss_val: 1.4693	loss_test: 1.4550	accuracy_train: 0.4540	accuracy_val: 0.3086	accuracy_test: 0.2857
[server]	loss_train: 1.2708	loss_val: 1.4418	loss_test: 1.3300	accuracy_train: 0.4798	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 87	curr_val_accuracy: 0.3351	curr_test_accuracy: 0.3313
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 88		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3291	loss_val: 1.4649	loss_test: 1.5398	accuracy_train: 0.4204	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2695	loss_val: 1.3532	loss_test: 1.4654	accuracy_train: 0.4185	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2414	loss_val: 1.4090	loss_test: 1.4277	accuracy_train: 0.4727	accuracy_val: 0.3028	accuracy_test: 0.3604
[server]	loss_train: 1.3933	loss_val: 1.4304	loss_test: 1.4339	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3373
[server]	loss_train: 1.2347	loss_val: 1.4585	loss_test: 1.4696	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2730	loss_val: 1.4661	loss_test: 1.3168	accuracy_train: 0.4663	accuracy_val: 0.2840	accuracy_test: 0.4048
[server]	loss_train: 1.2506	loss_val: 1.3759	loss_test: 1.4992	accuracy_train: 0.4632	accuracy_val: 0.4105	accuracy_test: 0.3196
[server]	loss_train: 1.3023	loss_val: 1.4657	loss_test: 1.3903	accuracy_train: 0.4057	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2880	loss_val: 1.3832	loss_test: 1.2957	accuracy_train: 0.4198	accuracy_val: 0.3902	accuracy_test: 0.4167
[server]	loss_train: 1.2478	loss_val: 1.3432	loss_test: 1.4271	accuracy_train: 0.4654	accuracy_val: 0.4074	accuracy_test: 0.3063
[server]	loss_train: 1.2358	loss_val: 1.4977	loss_test: 1.5073	accuracy_train: 0.5333	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3465	loss_val: 1.4179	loss_test: 1.3689	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2388	loss_val: 1.3571	loss_test: 1.3872	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2928	loss_val: 1.3894	loss_test: 1.5638	accuracy_train: 0.3600	accuracy_val: 0.3371	accuracy_test: 0.2308
[server]	loss_train: 1.2178	loss_val: 1.4348	loss_test: 1.4479	accuracy_train: 0.4579	accuracy_val: 0.3085	accuracy_test: 0.3131
[server]	loss_train: 1.3418	loss_val: 1.5165	loss_test: 1.4071	accuracy_train: 0.4300	accuracy_val: 0.3039	accuracy_test: 0.3679
[server]	loss_train: 1.3163	loss_val: 1.4523	loss_test: 1.4096	accuracy_train: 0.3894	accuracy_val: 0.3451	accuracy_test: 0.3826
[server]	loss_train: 1.2926	loss_val: 1.4539	loss_test: 1.3699	accuracy_train: 0.4277	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.3001	loss_val: 1.4700	loss_test: 1.4553	accuracy_train: 0.4601	accuracy_val: 0.3086	accuracy_test: 0.2738
[server]	loss_train: 1.2703	loss_val: 1.4421	loss_test: 1.3299	accuracy_train: 0.4798	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 88	curr_val_accuracy: 0.3345	curr_test_accuracy: 0.3307
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 89		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3281	loss_val: 1.4650	loss_test: 1.5402	accuracy_train: 0.4248	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2688	loss_val: 1.3533	loss_test: 1.4657	accuracy_train: 0.4185	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2409	loss_val: 1.4094	loss_test: 1.4286	accuracy_train: 0.4727	accuracy_val: 0.3028	accuracy_test: 0.3604
[server]	loss_train: 1.3925	loss_val: 1.4307	loss_test: 1.4336	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3373
[server]	loss_train: 1.2340	loss_val: 1.4590	loss_test: 1.4698	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2726	loss_val: 1.4663	loss_test: 1.3172	accuracy_train: 0.4663	accuracy_val: 0.2840	accuracy_test: 0.4048
[server]	loss_train: 1.2499	loss_val: 1.3764	loss_test: 1.4997	accuracy_train: 0.4632	accuracy_val: 0.4105	accuracy_test: 0.3196
[server]	loss_train: 1.3018	loss_val: 1.4663	loss_test: 1.3909	accuracy_train: 0.4057	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2873	loss_val: 1.3833	loss_test: 1.2957	accuracy_train: 0.4198	accuracy_val: 0.3902	accuracy_test: 0.4167
[server]	loss_train: 1.2472	loss_val: 1.3432	loss_test: 1.4277	accuracy_train: 0.4654	accuracy_val: 0.4074	accuracy_test: 0.3063
[server]	loss_train: 1.2345	loss_val: 1.4987	loss_test: 1.5077	accuracy_train: 0.5267	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3457	loss_val: 1.4183	loss_test: 1.3689	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2381	loss_val: 1.3572	loss_test: 1.3876	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2926	loss_val: 1.3900	loss_test: 1.5650	accuracy_train: 0.3600	accuracy_val: 0.3483	accuracy_test: 0.2308
[server]	loss_train: 1.2172	loss_val: 1.4357	loss_test: 1.4477	accuracy_train: 0.4579	accuracy_val: 0.3085	accuracy_test: 0.3131
[server]	loss_train: 1.3412	loss_val: 1.5171	loss_test: 1.4076	accuracy_train: 0.4251	accuracy_val: 0.3039	accuracy_test: 0.3679
[server]	loss_train: 1.3156	loss_val: 1.4529	loss_test: 1.4099	accuracy_train: 0.3894	accuracy_val: 0.3363	accuracy_test: 0.3739
[server]	loss_train: 1.2918	loss_val: 1.4546	loss_test: 1.3703	accuracy_train: 0.4335	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.2991	loss_val: 1.4707	loss_test: 1.4556	accuracy_train: 0.4601	accuracy_val: 0.3086	accuracy_test: 0.2738
[server]	loss_train: 1.2698	loss_val: 1.4424	loss_test: 1.3299	accuracy_train: 0.4843	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 89	curr_val_accuracy: 0.3345	curr_test_accuracy: 0.3302
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 90		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3271	loss_val: 1.4652	loss_test: 1.5406	accuracy_train: 0.4248	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2681	loss_val: 1.3533	loss_test: 1.4661	accuracy_train: 0.4185	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2404	loss_val: 1.4097	loss_test: 1.4294	accuracy_train: 0.4727	accuracy_val: 0.3028	accuracy_test: 0.3694
[server]	loss_train: 1.3917	loss_val: 1.4309	loss_test: 1.4334	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3373
[server]	loss_train: 1.2333	loss_val: 1.4596	loss_test: 1.4700	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2721	loss_val: 1.4665	loss_test: 1.3175	accuracy_train: 0.4663	accuracy_val: 0.2840	accuracy_test: 0.4048
[server]	loss_train: 1.2491	loss_val: 1.3769	loss_test: 1.5002	accuracy_train: 0.4632	accuracy_val: 0.4105	accuracy_test: 0.3196
[server]	loss_train: 1.3014	loss_val: 1.4670	loss_test: 1.3914	accuracy_train: 0.4057	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2865	loss_val: 1.3834	loss_test: 1.2956	accuracy_train: 0.4198	accuracy_val: 0.3902	accuracy_test: 0.4167
[server]	loss_train: 1.2466	loss_val: 1.3432	loss_test: 1.4283	accuracy_train: 0.4654	accuracy_val: 0.4074	accuracy_test: 0.2973
[server]	loss_train: 1.2331	loss_val: 1.4997	loss_test: 1.5080	accuracy_train: 0.5333	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3449	loss_val: 1.4187	loss_test: 1.3690	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2373	loss_val: 1.3574	loss_test: 1.3880	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2924	loss_val: 1.3907	loss_test: 1.5661	accuracy_train: 0.3600	accuracy_val: 0.3483	accuracy_test: 0.2308
[server]	loss_train: 1.2166	loss_val: 1.4365	loss_test: 1.4476	accuracy_train: 0.4579	accuracy_val: 0.3191	accuracy_test: 0.3131
[server]	loss_train: 1.3407	loss_val: 1.5178	loss_test: 1.4081	accuracy_train: 0.4251	accuracy_val: 0.3039	accuracy_test: 0.3679
[server]	loss_train: 1.3148	loss_val: 1.4535	loss_test: 1.4101	accuracy_train: 0.3894	accuracy_val: 0.3363	accuracy_test: 0.3739
[server]	loss_train: 1.2911	loss_val: 1.4553	loss_test: 1.3708	accuracy_train: 0.4335	accuracy_val: 0.3059	accuracy_test: 0.3371
[server]	loss_train: 1.2982	loss_val: 1.4713	loss_test: 1.4559	accuracy_train: 0.4601	accuracy_val: 0.3086	accuracy_test: 0.2738
[server]	loss_train: 1.2693	loss_val: 1.4427	loss_test: 1.3298	accuracy_train: 0.4843	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 90	curr_val_accuracy: 0.3351	curr_test_accuracy: 0.3302
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 91		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3261	loss_val: 1.4654	loss_test: 1.5410	accuracy_train: 0.4248	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2675	loss_val: 1.3533	loss_test: 1.4665	accuracy_train: 0.4130	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2400	loss_val: 1.4101	loss_test: 1.4303	accuracy_train: 0.4727	accuracy_val: 0.3028	accuracy_test: 0.3694
[server]	loss_train: 1.3909	loss_val: 1.4312	loss_test: 1.4332	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3373
[server]	loss_train: 1.2327	loss_val: 1.4601	loss_test: 1.4702	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2716	loss_val: 1.4667	loss_test: 1.3180	accuracy_train: 0.4663	accuracy_val: 0.2840	accuracy_test: 0.4048
[server]	loss_train: 1.2484	loss_val: 1.3774	loss_test: 1.5007	accuracy_train: 0.4632	accuracy_val: 0.4105	accuracy_test: 0.3196
[server]	loss_train: 1.3010	loss_val: 1.4676	loss_test: 1.3919	accuracy_train: 0.4057	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2858	loss_val: 1.3836	loss_test: 1.2955	accuracy_train: 0.4259	accuracy_val: 0.3902	accuracy_test: 0.4048
[server]	loss_train: 1.2460	loss_val: 1.3431	loss_test: 1.4289	accuracy_train: 0.4654	accuracy_val: 0.4074	accuracy_test: 0.2973
[server]	loss_train: 1.2318	loss_val: 1.5007	loss_test: 1.5084	accuracy_train: 0.5333	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3440	loss_val: 1.4190	loss_test: 1.3690	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3218
[server]	loss_train: 1.2366	loss_val: 1.3576	loss_test: 1.3884	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2923	loss_val: 1.3913	loss_test: 1.5672	accuracy_train: 0.3600	accuracy_val: 0.3483	accuracy_test: 0.2308
[server]	loss_train: 1.2159	loss_val: 1.4374	loss_test: 1.4474	accuracy_train: 0.4579	accuracy_val: 0.3191	accuracy_test: 0.3131
[server]	loss_train: 1.3402	loss_val: 1.5184	loss_test: 1.4087	accuracy_train: 0.4251	accuracy_val: 0.3039	accuracy_test: 0.3679
[server]	loss_train: 1.3141	loss_val: 1.4541	loss_test: 1.4104	accuracy_train: 0.3894	accuracy_val: 0.3363	accuracy_test: 0.3739
[server]	loss_train: 1.2903	loss_val: 1.4560	loss_test: 1.3712	accuracy_train: 0.4335	accuracy_val: 0.2941	accuracy_test: 0.3371
[server]	loss_train: 1.2972	loss_val: 1.4720	loss_test: 1.4562	accuracy_train: 0.4601	accuracy_val: 0.3086	accuracy_test: 0.2738
[server]	loss_train: 1.2689	loss_val: 1.4429	loss_test: 1.3298	accuracy_train: 0.4843	accuracy_val: 0.3964	accuracy_test: 0.3947
curr_round: 91	curr_val_accuracy: 0.3351	curr_test_accuracy: 0.3297
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 92		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3252	loss_val: 1.4655	loss_test: 1.5414	accuracy_train: 0.4292	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2668	loss_val: 1.3534	loss_test: 1.4668	accuracy_train: 0.4185	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2395	loss_val: 1.4104	loss_test: 1.4312	accuracy_train: 0.4727	accuracy_val: 0.2936	accuracy_test: 0.3694
[server]	loss_train: 1.3901	loss_val: 1.4315	loss_test: 1.4330	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3373
[server]	loss_train: 1.2321	loss_val: 1.4607	loss_test: 1.4704	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2712	loss_val: 1.4668	loss_test: 1.3184	accuracy_train: 0.4663	accuracy_val: 0.2840	accuracy_test: 0.4048
[server]	loss_train: 1.2476	loss_val: 1.3779	loss_test: 1.5012	accuracy_train: 0.4632	accuracy_val: 0.4105	accuracy_test: 0.3093
[server]	loss_train: 1.3006	loss_val: 1.4682	loss_test: 1.3925	accuracy_train: 0.4104	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2851	loss_val: 1.3837	loss_test: 1.2955	accuracy_train: 0.4259	accuracy_val: 0.3902	accuracy_test: 0.4048
[server]	loss_train: 1.2454	loss_val: 1.3431	loss_test: 1.4295	accuracy_train: 0.4654	accuracy_val: 0.4074	accuracy_test: 0.2973
[server]	loss_train: 1.2305	loss_val: 1.5017	loss_test: 1.5088	accuracy_train: 0.5400	accuracy_val: 0.3108	accuracy_test: 0.3117
[server]	loss_train: 1.3432	loss_val: 1.4194	loss_test: 1.3690	accuracy_train: 0.3706	accuracy_val: 0.3256	accuracy_test: 0.3333
[server]	loss_train: 1.2359	loss_val: 1.3578	loss_test: 1.3888	accuracy_train: 0.4797	accuracy_val: 0.3514	accuracy_test: 0.3896
[server]	loss_train: 1.2921	loss_val: 1.3919	loss_test: 1.5682	accuracy_train: 0.3600	accuracy_val: 0.3483	accuracy_test: 0.2308
[server]	loss_train: 1.2153	loss_val: 1.4382	loss_test: 1.4472	accuracy_train: 0.4579	accuracy_val: 0.3191	accuracy_test: 0.3131
[server]	loss_train: 1.3397	loss_val: 1.5190	loss_test: 1.4092	accuracy_train: 0.4300	accuracy_val: 0.3039	accuracy_test: 0.3585
[server]	loss_train: 1.3134	loss_val: 1.4547	loss_test: 1.4107	accuracy_train: 0.3894	accuracy_val: 0.3363	accuracy_test: 0.3739
[server]	loss_train: 1.2896	loss_val: 1.4567	loss_test: 1.3716	accuracy_train: 0.4335	accuracy_val: 0.2941	accuracy_test: 0.3371
[server]	loss_train: 1.2963	loss_val: 1.4727	loss_test: 1.4565	accuracy_train: 0.4601	accuracy_val: 0.3210	accuracy_test: 0.2738
[server]	loss_train: 1.2684	loss_val: 1.4432	loss_test: 1.3298	accuracy_train: 0.4843	accuracy_val: 0.3784	accuracy_test: 0.3947
curr_round: 92	curr_val_accuracy: 0.3340	curr_test_accuracy: 0.3292
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 93		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3242	loss_val: 1.4657	loss_test: 1.5418	accuracy_train: 0.4292	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2661	loss_val: 1.3534	loss_test: 1.4672	accuracy_train: 0.4185	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2391	loss_val: 1.4108	loss_test: 1.4320	accuracy_train: 0.4727	accuracy_val: 0.2936	accuracy_test: 0.3694
[server]	loss_train: 1.3893	loss_val: 1.4317	loss_test: 1.4328	accuracy_train: 0.3313	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.2314	loss_val: 1.4612	loss_test: 1.4706	accuracy_train: 0.4813	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2707	loss_val: 1.4670	loss_test: 1.3188	accuracy_train: 0.4663	accuracy_val: 0.2840	accuracy_test: 0.4048
[server]	loss_train: 1.2469	loss_val: 1.3784	loss_test: 1.5018	accuracy_train: 0.4632	accuracy_val: 0.4105	accuracy_test: 0.3093
[server]	loss_train: 1.3002	loss_val: 1.4688	loss_test: 1.3930	accuracy_train: 0.4104	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2844	loss_val: 1.3838	loss_test: 1.2954	accuracy_train: 0.4259	accuracy_val: 0.3902	accuracy_test: 0.4048
[server]	loss_train: 1.2449	loss_val: 1.3431	loss_test: 1.4302	accuracy_train: 0.4654	accuracy_val: 0.4074	accuracy_test: 0.2973
[server]	loss_train: 1.2292	loss_val: 1.5027	loss_test: 1.5091	accuracy_train: 0.5400	accuracy_val: 0.3243	accuracy_test: 0.3117
[server]	loss_train: 1.3424	loss_val: 1.4198	loss_test: 1.3691	accuracy_train: 0.3765	accuracy_val: 0.3256	accuracy_test: 0.3333
[server]	loss_train: 1.2352	loss_val: 1.3579	loss_test: 1.3891	accuracy_train: 0.4797	accuracy_val: 0.3378	accuracy_test: 0.3766
[server]	loss_train: 1.2919	loss_val: 1.3925	loss_test: 1.5693	accuracy_train: 0.3600	accuracy_val: 0.3483	accuracy_test: 0.2308
[server]	loss_train: 1.2147	loss_val: 1.4390	loss_test: 1.4470	accuracy_train: 0.4579	accuracy_val: 0.3191	accuracy_test: 0.3131
[server]	loss_train: 1.3392	loss_val: 1.5196	loss_test: 1.4097	accuracy_train: 0.4300	accuracy_val: 0.3039	accuracy_test: 0.3585
[server]	loss_train: 1.3127	loss_val: 1.4553	loss_test: 1.4109	accuracy_train: 0.3894	accuracy_val: 0.3363	accuracy_test: 0.3652
[server]	loss_train: 1.2889	loss_val: 1.4574	loss_test: 1.3721	accuracy_train: 0.4335	accuracy_val: 0.2941	accuracy_test: 0.3371
[server]	loss_train: 1.2954	loss_val: 1.4733	loss_test: 1.4568	accuracy_train: 0.4601	accuracy_val: 0.3210	accuracy_test: 0.2738
[server]	loss_train: 1.2680	loss_val: 1.4435	loss_test: 1.3297	accuracy_train: 0.4843	accuracy_val: 0.3784	accuracy_test: 0.3947
curr_round: 93	curr_val_accuracy: 0.3340	curr_test_accuracy: 0.3276
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 94		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3233	loss_val: 1.4658	loss_test: 1.5422	accuracy_train: 0.4292	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2655	loss_val: 1.3534	loss_test: 1.4675	accuracy_train: 0.4185	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2386	loss_val: 1.4111	loss_test: 1.4329	accuracy_train: 0.4727	accuracy_val: 0.2936	accuracy_test: 0.3694
[server]	loss_train: 1.3885	loss_val: 1.4320	loss_test: 1.4326	accuracy_train: 0.3374	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.2308	loss_val: 1.4617	loss_test: 1.4708	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2703	loss_val: 1.4672	loss_test: 1.3192	accuracy_train: 0.4601	accuracy_val: 0.2840	accuracy_test: 0.4048
[server]	loss_train: 1.2462	loss_val: 1.3789	loss_test: 1.5022	accuracy_train: 0.4632	accuracy_val: 0.4105	accuracy_test: 0.3093
[server]	loss_train: 1.2998	loss_val: 1.4693	loss_test: 1.3936	accuracy_train: 0.4104	accuracy_val: 0.3271	accuracy_test: 0.2661
[server]	loss_train: 1.2837	loss_val: 1.3840	loss_test: 1.2954	accuracy_train: 0.4259	accuracy_val: 0.3780	accuracy_test: 0.4048
[server]	loss_train: 1.2443	loss_val: 1.3431	loss_test: 1.4308	accuracy_train: 0.4654	accuracy_val: 0.4074	accuracy_test: 0.2973
[server]	loss_train: 1.2280	loss_val: 1.5037	loss_test: 1.5095	accuracy_train: 0.5400	accuracy_val: 0.3243	accuracy_test: 0.3117
[server]	loss_train: 1.3416	loss_val: 1.4202	loss_test: 1.3691	accuracy_train: 0.3765	accuracy_val: 0.3256	accuracy_test: 0.3333
[server]	loss_train: 1.2345	loss_val: 1.3581	loss_test: 1.3895	accuracy_train: 0.4797	accuracy_val: 0.3378	accuracy_test: 0.3766
[server]	loss_train: 1.2917	loss_val: 1.3931	loss_test: 1.5704	accuracy_train: 0.3600	accuracy_val: 0.3483	accuracy_test: 0.2308
[server]	loss_train: 1.2141	loss_val: 1.4399	loss_test: 1.4469	accuracy_train: 0.4579	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3387	loss_val: 1.5203	loss_test: 1.4102	accuracy_train: 0.4300	accuracy_val: 0.3039	accuracy_test: 0.3585
[server]	loss_train: 1.3120	loss_val: 1.4559	loss_test: 1.4112	accuracy_train: 0.3894	accuracy_val: 0.3363	accuracy_test: 0.3652
[server]	loss_train: 1.2882	loss_val: 1.4580	loss_test: 1.3725	accuracy_train: 0.4335	accuracy_val: 0.2941	accuracy_test: 0.3483
[server]	loss_train: 1.2946	loss_val: 1.4740	loss_test: 1.4570	accuracy_train: 0.4663	accuracy_val: 0.3210	accuracy_test: 0.2738
[server]	loss_train: 1.2675	loss_val: 1.4438	loss_test: 1.3297	accuracy_train: 0.4888	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 94	curr_val_accuracy: 0.3340	curr_test_accuracy: 0.3287
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 95		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3223	loss_val: 1.4660	loss_test: 1.5426	accuracy_train: 0.4292	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2648	loss_val: 1.3534	loss_test: 1.4679	accuracy_train: 0.4130	accuracy_val: 0.3804	accuracy_test: 0.3333
[server]	loss_train: 1.2382	loss_val: 1.4115	loss_test: 1.4337	accuracy_train: 0.4727	accuracy_val: 0.2936	accuracy_test: 0.3694
[server]	loss_train: 1.3877	loss_val: 1.4322	loss_test: 1.4324	accuracy_train: 0.3374	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.2302	loss_val: 1.4622	loss_test: 1.4710	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2698	loss_val: 1.4674	loss_test: 1.3197	accuracy_train: 0.4601	accuracy_val: 0.2840	accuracy_test: 0.4048
[server]	loss_train: 1.2455	loss_val: 1.3795	loss_test: 1.5028	accuracy_train: 0.4632	accuracy_val: 0.4105	accuracy_test: 0.3093
[server]	loss_train: 1.2994	loss_val: 1.4699	loss_test: 1.3941	accuracy_train: 0.4104	accuracy_val: 0.3178	accuracy_test: 0.2661
[server]	loss_train: 1.2830	loss_val: 1.3841	loss_test: 1.2954	accuracy_train: 0.4259	accuracy_val: 0.3780	accuracy_test: 0.4048
[server]	loss_train: 1.2438	loss_val: 1.3431	loss_test: 1.4314	accuracy_train: 0.4562	accuracy_val: 0.3981	accuracy_test: 0.2973
[server]	loss_train: 1.2267	loss_val: 1.5047	loss_test: 1.5098	accuracy_train: 0.5400	accuracy_val: 0.3378	accuracy_test: 0.3117
[server]	loss_train: 1.3409	loss_val: 1.4205	loss_test: 1.3692	accuracy_train: 0.3824	accuracy_val: 0.3256	accuracy_test: 0.3333
[server]	loss_train: 1.2338	loss_val: 1.3583	loss_test: 1.3899	accuracy_train: 0.4797	accuracy_val: 0.3378	accuracy_test: 0.3766
[server]	loss_train: 1.2915	loss_val: 1.3937	loss_test: 1.5715	accuracy_train: 0.3600	accuracy_val: 0.3483	accuracy_test: 0.2308
[server]	loss_train: 1.2136	loss_val: 1.4407	loss_test: 1.4467	accuracy_train: 0.4632	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3383	loss_val: 1.5209	loss_test: 1.4107	accuracy_train: 0.4300	accuracy_val: 0.3039	accuracy_test: 0.3585
[server]	loss_train: 1.3113	loss_val: 1.4565	loss_test: 1.4115	accuracy_train: 0.3894	accuracy_val: 0.3363	accuracy_test: 0.3652
[server]	loss_train: 1.2875	loss_val: 1.4587	loss_test: 1.3729	accuracy_train: 0.4335	accuracy_val: 0.2941	accuracy_test: 0.3483
[server]	loss_train: 1.2937	loss_val: 1.4746	loss_test: 1.4573	accuracy_train: 0.4663	accuracy_val: 0.3210	accuracy_test: 0.2738
[server]	loss_train: 1.2671	loss_val: 1.4440	loss_test: 1.3297	accuracy_train: 0.4933	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 95	curr_val_accuracy: 0.3335	curr_test_accuracy: 0.3287
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 96		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3214	loss_val: 1.4662	loss_test: 1.5430	accuracy_train: 0.4292	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2642	loss_val: 1.3534	loss_test: 1.4682	accuracy_train: 0.4130	accuracy_val: 0.3696	accuracy_test: 0.3333
[server]	loss_train: 1.2377	loss_val: 1.4118	loss_test: 1.4345	accuracy_train: 0.4727	accuracy_val: 0.2936	accuracy_test: 0.3694
[server]	loss_train: 1.3870	loss_val: 1.4325	loss_test: 1.4322	accuracy_train: 0.3374	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.2296	loss_val: 1.4628	loss_test: 1.4711	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2694	loss_val: 1.4675	loss_test: 1.3201	accuracy_train: 0.4601	accuracy_val: 0.2840	accuracy_test: 0.4048
[server]	loss_train: 1.2448	loss_val: 1.3800	loss_test: 1.5033	accuracy_train: 0.4684	accuracy_val: 0.4105	accuracy_test: 0.3093
[server]	loss_train: 1.2991	loss_val: 1.4705	loss_test: 1.3946	accuracy_train: 0.4104	accuracy_val: 0.3178	accuracy_test: 0.2661
[server]	loss_train: 1.2823	loss_val: 1.3843	loss_test: 1.2953	accuracy_train: 0.4259	accuracy_val: 0.3780	accuracy_test: 0.4048
[server]	loss_train: 1.2432	loss_val: 1.3431	loss_test: 1.4320	accuracy_train: 0.4562	accuracy_val: 0.3981	accuracy_test: 0.2973
[server]	loss_train: 1.2255	loss_val: 1.5056	loss_test: 1.5102	accuracy_train: 0.5467	accuracy_val: 0.3378	accuracy_test: 0.3117
[server]	loss_train: 1.3401	loss_val: 1.4209	loss_test: 1.3692	accuracy_train: 0.3824	accuracy_val: 0.3256	accuracy_test: 0.3333
[server]	loss_train: 1.2331	loss_val: 1.3585	loss_test: 1.3903	accuracy_train: 0.4797	accuracy_val: 0.3378	accuracy_test: 0.3766
[server]	loss_train: 1.2913	loss_val: 1.3943	loss_test: 1.5725	accuracy_train: 0.3600	accuracy_val: 0.3596	accuracy_test: 0.2308
[server]	loss_train: 1.2130	loss_val: 1.4416	loss_test: 1.4465	accuracy_train: 0.4632	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3378	loss_val: 1.5215	loss_test: 1.4111	accuracy_train: 0.4300	accuracy_val: 0.3039	accuracy_test: 0.3585
[server]	loss_train: 1.3107	loss_val: 1.4571	loss_test: 1.4118	accuracy_train: 0.3894	accuracy_val: 0.3363	accuracy_test: 0.3652
[server]	loss_train: 1.2869	loss_val: 1.4594	loss_test: 1.3734	accuracy_train: 0.4393	accuracy_val: 0.2941	accuracy_test: 0.3483
[server]	loss_train: 1.2928	loss_val: 1.4753	loss_test: 1.4576	accuracy_train: 0.4663	accuracy_val: 0.3210	accuracy_test: 0.2738
[server]	loss_train: 1.2668	loss_val: 1.4443	loss_test: 1.3297	accuracy_train: 0.4933	accuracy_val: 0.3874	accuracy_test: 0.3947
curr_round: 96	curr_val_accuracy: 0.3335	curr_test_accuracy: 0.3287
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 97		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3205	loss_val: 1.4663	loss_test: 1.5434	accuracy_train: 0.4292	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2636	loss_val: 1.3534	loss_test: 1.4686	accuracy_train: 0.4130	accuracy_val: 0.3587	accuracy_test: 0.3333
[server]	loss_train: 1.2373	loss_val: 1.4121	loss_test: 1.4354	accuracy_train: 0.4727	accuracy_val: 0.2936	accuracy_test: 0.3694
[server]	loss_train: 1.3862	loss_val: 1.4327	loss_test: 1.4320	accuracy_train: 0.3374	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.2290	loss_val: 1.4633	loss_test: 1.4713	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2690	loss_val: 1.4677	loss_test: 1.3205	accuracy_train: 0.4601	accuracy_val: 0.2840	accuracy_test: 0.4048
[server]	loss_train: 1.2440	loss_val: 1.3805	loss_test: 1.5038	accuracy_train: 0.4684	accuracy_val: 0.4105	accuracy_test: 0.3093
[server]	loss_train: 1.2987	loss_val: 1.4710	loss_test: 1.3952	accuracy_train: 0.4057	accuracy_val: 0.3178	accuracy_test: 0.2661
[server]	loss_train: 1.2816	loss_val: 1.3844	loss_test: 1.2953	accuracy_train: 0.4321	accuracy_val: 0.3780	accuracy_test: 0.3929
[server]	loss_train: 1.2427	loss_val: 1.3431	loss_test: 1.4326	accuracy_train: 0.4562	accuracy_val: 0.3981	accuracy_test: 0.2973
[server]	loss_train: 1.2243	loss_val: 1.5066	loss_test: 1.5105	accuracy_train: 0.5467	accuracy_val: 0.3378	accuracy_test: 0.3117
[server]	loss_train: 1.3393	loss_val: 1.4212	loss_test: 1.3693	accuracy_train: 0.3824	accuracy_val: 0.3256	accuracy_test: 0.3333
[server]	loss_train: 1.2325	loss_val: 1.3586	loss_test: 1.3908	accuracy_train: 0.4797	accuracy_val: 0.3378	accuracy_test: 0.3766
[server]	loss_train: 1.2912	loss_val: 1.3949	loss_test: 1.5735	accuracy_train: 0.3600	accuracy_val: 0.3596	accuracy_test: 0.2308
[server]	loss_train: 1.2124	loss_val: 1.4424	loss_test: 1.4463	accuracy_train: 0.4632	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3374	loss_val: 1.5222	loss_test: 1.4116	accuracy_train: 0.4251	accuracy_val: 0.3039	accuracy_test: 0.3585
[server]	loss_train: 1.3100	loss_val: 1.4577	loss_test: 1.4120	accuracy_train: 0.3938	accuracy_val: 0.3363	accuracy_test: 0.3652
[server]	loss_train: 1.2862	loss_val: 1.4600	loss_test: 1.3738	accuracy_train: 0.4393	accuracy_val: 0.2941	accuracy_test: 0.3483
[server]	loss_train: 1.2920	loss_val: 1.4759	loss_test: 1.4579	accuracy_train: 0.4663	accuracy_val: 0.3210	accuracy_test: 0.2738
[server]	loss_train: 1.2664	loss_val: 1.4446	loss_test: 1.3296	accuracy_train: 0.4933	accuracy_val: 0.3784	accuracy_test: 0.3860
curr_round: 97	curr_val_accuracy: 0.3324	curr_test_accuracy: 0.3276
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 98		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3197	loss_val: 1.4665	loss_test: 1.5438	accuracy_train: 0.4292	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2630	loss_val: 1.3534	loss_test: 1.4689	accuracy_train: 0.4130	accuracy_val: 0.3587	accuracy_test: 0.3333
[server]	loss_train: 1.2369	loss_val: 1.4124	loss_test: 1.4362	accuracy_train: 0.4727	accuracy_val: 0.2844	accuracy_test: 0.3694
[server]	loss_train: 1.3855	loss_val: 1.4330	loss_test: 1.4319	accuracy_train: 0.3374	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.2284	loss_val: 1.4639	loss_test: 1.4714	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2685	loss_val: 1.4679	loss_test: 1.3210	accuracy_train: 0.4601	accuracy_val: 0.2840	accuracy_test: 0.4048
[server]	loss_train: 1.2433	loss_val: 1.3810	loss_test: 1.5043	accuracy_train: 0.4684	accuracy_val: 0.4105	accuracy_test: 0.3093
[server]	loss_train: 1.2983	loss_val: 1.4716	loss_test: 1.3957	accuracy_train: 0.4057	accuracy_val: 0.3178	accuracy_test: 0.2661
[server]	loss_train: 1.2810	loss_val: 1.3846	loss_test: 1.2953	accuracy_train: 0.4321	accuracy_val: 0.3780	accuracy_test: 0.3929
[server]	loss_train: 1.2421	loss_val: 1.3431	loss_test: 1.4332	accuracy_train: 0.4516	accuracy_val: 0.3981	accuracy_test: 0.3063
[server]	loss_train: 1.2231	loss_val: 1.5076	loss_test: 1.5108	accuracy_train: 0.5533	accuracy_val: 0.3514	accuracy_test: 0.3117
[server]	loss_train: 1.3385	loss_val: 1.4216	loss_test: 1.3693	accuracy_train: 0.3882	accuracy_val: 0.3256	accuracy_test: 0.3333
[server]	loss_train: 1.2318	loss_val: 1.3588	loss_test: 1.3912	accuracy_train: 0.4865	accuracy_val: 0.3378	accuracy_test: 0.3766
[server]	loss_train: 1.2910	loss_val: 1.3955	loss_test: 1.5746	accuracy_train: 0.3600	accuracy_val: 0.3596	accuracy_test: 0.2308
[server]	loss_train: 1.2119	loss_val: 1.4433	loss_test: 1.4462	accuracy_train: 0.4632	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3369	loss_val: 1.5228	loss_test: 1.4121	accuracy_train: 0.4251	accuracy_val: 0.3039	accuracy_test: 0.3585
[server]	loss_train: 1.3093	loss_val: 1.4583	loss_test: 1.4124	accuracy_train: 0.3938	accuracy_val: 0.3363	accuracy_test: 0.3652
[server]	loss_train: 1.2855	loss_val: 1.4606	loss_test: 1.3743	accuracy_train: 0.4393	accuracy_val: 0.3059	accuracy_test: 0.3483
[server]	loss_train: 1.2912	loss_val: 1.4766	loss_test: 1.4582	accuracy_train: 0.4601	accuracy_val: 0.3210	accuracy_test: 0.2738
[server]	loss_train: 1.2660	loss_val: 1.4449	loss_test: 1.3296	accuracy_train: 0.4888	accuracy_val: 0.3784	accuracy_test: 0.3860
curr_round: 98	curr_val_accuracy: 0.3330	curr_test_accuracy: 0.3282
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
round # 99		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3188	loss_val: 1.4667	loss_test: 1.5442	accuracy_train: 0.4292	accuracy_val: 0.3186	accuracy_test: 0.2696
[server]	loss_train: 1.2624	loss_val: 1.3534	loss_test: 1.4692	accuracy_train: 0.4130	accuracy_val: 0.3587	accuracy_test: 0.3333
[server]	loss_train: 1.2365	loss_val: 1.4127	loss_test: 1.4371	accuracy_train: 0.4682	accuracy_val: 0.2844	accuracy_test: 0.3694
[server]	loss_train: 1.3847	loss_val: 1.4332	loss_test: 1.4317	accuracy_train: 0.3374	accuracy_val: 0.3293	accuracy_test: 0.3253
[server]	loss_train: 1.2278	loss_val: 1.4644	loss_test: 1.4715	accuracy_train: 0.4766	accuracy_val: 0.2500	accuracy_test: 0.2936
[server]	loss_train: 1.2681	loss_val: 1.4681	loss_test: 1.3215	accuracy_train: 0.4601	accuracy_val: 0.2840	accuracy_test: 0.4048
[server]	loss_train: 1.2426	loss_val: 1.3815	loss_test: 1.5048	accuracy_train: 0.4684	accuracy_val: 0.4105	accuracy_test: 0.3093
[server]	loss_train: 1.2980	loss_val: 1.4721	loss_test: 1.3962	accuracy_train: 0.4057	accuracy_val: 0.3178	accuracy_test: 0.2661
[server]	loss_train: 1.2803	loss_val: 1.3848	loss_test: 1.2953	accuracy_train: 0.4321	accuracy_val: 0.3780	accuracy_test: 0.3929
[server]	loss_train: 1.2416	loss_val: 1.3431	loss_test: 1.4338	accuracy_train: 0.4516	accuracy_val: 0.3981	accuracy_test: 0.3063
[server]	loss_train: 1.2219	loss_val: 1.5086	loss_test: 1.5112	accuracy_train: 0.5533	accuracy_val: 0.3514	accuracy_test: 0.3117
[server]	loss_train: 1.3378	loss_val: 1.4219	loss_test: 1.3694	accuracy_train: 0.3882	accuracy_val: 0.3256	accuracy_test: 0.3333
[server]	loss_train: 1.2311	loss_val: 1.3589	loss_test: 1.3916	accuracy_train: 0.4865	accuracy_val: 0.3514	accuracy_test: 0.3766
[server]	loss_train: 1.2908	loss_val: 1.3961	loss_test: 1.5756	accuracy_train: 0.3600	accuracy_val: 0.3596	accuracy_test: 0.2308
[server]	loss_train: 1.2113	loss_val: 1.4441	loss_test: 1.4460	accuracy_train: 0.4632	accuracy_val: 0.3191	accuracy_test: 0.3232
[server]	loss_train: 1.3365	loss_val: 1.5234	loss_test: 1.4126	accuracy_train: 0.4251	accuracy_val: 0.3039	accuracy_test: 0.3585
[server]	loss_train: 1.3086	loss_val: 1.4589	loss_test: 1.4127	accuracy_train: 0.3938	accuracy_val: 0.3363	accuracy_test: 0.3652
[server]	loss_train: 1.2849	loss_val: 1.4612	loss_test: 1.3747	accuracy_train: 0.4335	accuracy_val: 0.3059	accuracy_test: 0.3483
[server]	loss_train: 1.2903	loss_val: 1.4772	loss_test: 1.4585	accuracy_train: 0.4601	accuracy_val: 0.3333	accuracy_test: 0.2738
[server]	loss_train: 1.2657	loss_val: 1.4452	loss_test: 1.3296	accuracy_train: 0.4888	accuracy_val: 0.3784	accuracy_test: 0.3860
curr_round: 99	curr_val_accuracy: 0.3340	curr_test_accuracy: 0.3282
best_round: 38	best_val_accuracy: 0.3388	best_test_accuracy: 0.3350
--------------------------------------------------
