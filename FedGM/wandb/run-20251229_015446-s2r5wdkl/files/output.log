G:\conda\envs\gfl\Lib\site-packages\torch_geometric\data\in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
Associating local subgraph with global graph...: 100%|██████████████████████████| 1084/1084 [00:00<00:00, 13507.82it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1094/1094 [00:00<00:00, 17786.39it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1724/1724 [00:00<00:00, 13149.13it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 2192/2192 [00:00<00:00, 18482.90it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1026/1026 [00:00<00:00, 12896.19it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1512/1512 [00:00<00:00, 21807.17it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1106/1106 [00:00<00:00, 17660.90it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1384/1384 [00:00<00:00, 24496.21it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1212/1212 [00:00<00:00, 22383.41it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1482/1482 [00:00<00:00, 23459.19it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1110/1110 [00:00<00:00, 19743.76it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 940/940 [00:00<00:00, 19553.67it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 990/990 [00:00<00:00, 23284.18it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 964/964 [00:00<00:00, 22212.93it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1402/1402 [00:00<00:00, 20684.13it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1730/1730 [00:00<00:00, 17369.13it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1264/1264 [00:00<00:00, 19576.32it/s]
Associating local subgraph with global graph...: 100%|████████████████████████████| 698/698 [00:00<00:00, 16775.49it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1586/1586 [00:00<00:00, 20988.59it/s]
Associating local subgraph with global graph...: 100%|██████████████████████████| 1422/1422 [00:00<00:00, 14821.93it/s]
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.0896	loss_train: 0.1274	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 2.3122	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.3731	loss_train: 0.1110	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 1.9841	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.4254	loss_train: 0.1023	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 1.8112	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.1017	loss_train: 0.1257	loss_degree: 0.2049	loss_feat: 0.0000	loss_cls: 2.3093	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.3390	acc_cls: 0.3136	loss_train: 0.2396	loss_degree: 1.3170	loss_feat: 0.0783	loss_cls: 2.1671	loss_other: 1.2305
[client 1 neighGen phase]	acc_degree: 0.6271	acc_cls: 0.5678	loss_train: 0.1205	loss_degree: 0.2752	loss_feat: 0.0110	loss_cls: 1.9380	loss_other: 0.1865
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.0184	loss_train: 0.1330	loss_degree: 0.2664	loss_feat: 0.0000	loss_cls: 2.3942	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.3558	acc_cls: 0.3742	loss_train: 0.2282	loss_degree: 1.2057	loss_feat: 0.0713	loss_cls: 2.0180	loss_other: 1.2693
[client 2 neighGen phase]	acc_degree: 0.6442	acc_cls: 0.5276	loss_train: 0.1260	loss_degree: 0.3508	loss_feat: 0.0147	loss_cls: 1.8914	loss_other: 0.2636
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.0519	loss_train: 0.1393	loss_degree: 0.4359	loss_feat: 0.0000	loss_cls: 2.3493	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.3185	acc_cls: 0.4889	loss_train: 0.2383	loss_degree: 1.5159	loss_feat: 0.0673	loss_cls: 2.0183	loss_other: 1.1642
[client 3 neighGen phase]	acc_degree: 0.6074	acc_cls: 0.5333	loss_train: 0.1304	loss_degree: 0.5709	loss_feat: 0.0166	loss_cls: 1.7564	loss_other: 0.2631
[client 4 neighGen phase]	acc_degree: 0.7040	acc_cls: 0.0960	loss_train: 0.1374	loss_degree: 0.3790	loss_feat: 0.0000	loss_cls: 2.3681	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.4160	acc_cls: 0.2880	loss_train: 0.2505	loss_degree: 1.4643	loss_feat: 0.0724	loss_cls: 2.1387	loss_other: 1.3337
[client 4 neighGen phase]	acc_degree: 0.5760	acc_cls: 0.3680	loss_train: 0.1341	loss_degree: 0.4578	loss_feat: 0.0135	loss_cls: 1.9663	loss_other: 0.2451
[client 5 neighGen phase]	acc_degree: 0.7795	acc_cls: 0.3307	loss_train: 0.1189	loss_degree: 0.1852	loss_feat: 0.0000	loss_cls: 2.1922	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.3780	acc_cls: 0.4409	loss_train: 0.1927	loss_degree: 1.0388	loss_feat: 0.0304	loss_cls: 2.0560	loss_other: 0.7283
[client 5 neighGen phase]	acc_degree: 0.6929	acc_cls: 0.4803	loss_train: 0.1054	loss_degree: 0.2666	loss_feat: 0.0074	loss_cls: 1.6818	loss_other: 0.1518
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.1478	loss_train: 0.1281	loss_degree: 0.2467	loss_feat: 0.0000	loss_cls: 2.3151	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.6696	acc_cls: 0.3391	loss_train: 0.1231	loss_degree: 0.2623	loss_feat: 0.0095	loss_cls: 1.9867	loss_other: 0.2037
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.4957	loss_train: 0.1073	loss_degree: 0.2402	loss_feat: 0.0000	loss_cls: 1.9062	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.0526	loss_train: 0.1273	loss_degree: 0.1987	loss_feat: 0.0000	loss_cls: 2.3465	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.6842	acc_cls: 0.4436	loss_train: 0.1183	loss_degree: 0.2710	loss_feat: 0.0096	loss_cls: 1.9273	loss_other: 0.1585
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.4887	loss_train: 0.0987	loss_degree: 0.2193	loss_feat: 0.0000	loss_cls: 1.7538	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.1920	loss_train: 0.1238	loss_degree: 0.2649	loss_feat: 0.0000	loss_cls: 2.2105	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.4400	acc_cls: 0.4080	loss_train: 0.2172	loss_degree: 1.0575	loss_feat: 0.0560	loss_cls: 2.0440	loss_other: 1.1857
[client 8 neighGen phase]	acc_degree: 0.6000	acc_cls: 0.4720	loss_train: 0.1156	loss_degree: 0.3124	loss_feat: 0.0115	loss_cls: 1.7731	loss_other: 0.2147
[client 9 neighGen phase]	acc_degree: 0.7299	acc_cls: 0.0876	loss_train: 0.1305	loss_degree: 0.2771	loss_feat: 0.0000	loss_cls: 2.3339	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.7299	acc_cls: 0.4307	loss_train: 0.1088	loss_degree: 0.2700	loss_feat: 0.0000	loss_cls: 1.9061	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.7299	acc_cls: 0.5036	loss_train: 0.1021	loss_degree: 0.2642	loss_feat: 0.0000	loss_cls: 1.7770	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.1145	loss_train: 0.1229	loss_degree: 0.1642	loss_feat: 0.0000	loss_cls: 2.2943	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.3893	loss_train: 0.1075	loss_degree: 0.1641	loss_feat: 0.0000	loss_cls: 1.9852	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.4427	loss_train: 0.1004	loss_degree: 0.1641	loss_feat: 0.0000	loss_cls: 1.8429	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.7955	acc_cls: 0.0985	loss_train: 0.1294	loss_degree: 0.1666	loss_feat: 0.0000	loss_cls: 2.4218	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.7955	acc_cls: 0.3030	loss_train: 0.1126	loss_degree: 0.1749	loss_feat: 0.0000	loss_cls: 2.0776	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.8030	acc_cls: 0.4091	loss_train: 0.1031	loss_degree: 0.1405	loss_feat: 0.0006	loss_cls: 1.9043	loss_other: 0.0170
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.0597	loss_train: 0.1248	loss_degree: 0.1435	loss_feat: 0.0000	loss_cls: 2.3526	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.4104	acc_cls: 0.4552	loss_train: 0.1977	loss_degree: 1.2168	loss_feat: 0.0371	loss_cls: 2.0207	loss_other: 0.6803
[client 12 neighGen phase]	acc_degree: 0.7015	acc_cls: 0.5000	loss_train: 0.1112	loss_degree: 0.2662	loss_feat: 0.0069	loss_cls: 1.8394	loss_other: 0.1117
[client 13 neighGen phase]	acc_degree: 0.7206	acc_cls: 0.0515	loss_train: 0.1284	loss_degree: 0.1963	loss_feat: 0.0000	loss_cls: 2.3726	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.4632	acc_cls: 0.4191	loss_train: 0.1981	loss_degree: 0.9601	loss_feat: 0.0508	loss_cls: 2.0526	loss_other: 0.8978
[client 13 neighGen phase]	acc_degree: 0.6618	acc_cls: 0.4412	loss_train: 0.1097	loss_degree: 0.2769	loss_feat: 0.0085	loss_cls: 1.7903	loss_other: 0.1189
[client 14 neighGen phase]	acc_degree: 0.6871	acc_cls: 0.0612	loss_train: 0.1288	loss_degree: 0.2535	loss_feat: 0.0000	loss_cls: 2.3220	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.4762	acc_cls: 0.3810	loss_train: 0.1779	loss_degree: 0.6770	loss_feat: 0.0640	loss_cls: 1.9344	loss_other: 0.8820
[client 14 neighGen phase]	acc_degree: 0.6667	acc_cls: 0.4082	loss_train: 0.1017	loss_degree: 0.1831	loss_feat: 0.0020	loss_cls: 1.8192	loss_other: 0.0290
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.0571	loss_train: 0.1339	loss_degree: 0.2362	loss_feat: 0.0000	loss_cls: 2.4418	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.4000	acc_cls: 0.5143	loss_train: 0.1955	loss_degree: 1.1351	loss_feat: 0.0379	loss_cls: 1.8040	loss_other: 0.9336
[client 15 neighGen phase]	acc_degree: 0.6500	acc_cls: 0.5357	loss_train: 0.0987	loss_degree: 0.2730	loss_feat: 0.0027	loss_cls: 1.6511	loss_other: 0.0477
[client 16 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.1691	loss_train: 0.1306	loss_degree: 0.3119	loss_feat: 0.0000	loss_cls: 2.3004	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.4559	acc_cls: 0.4044	loss_train: 0.2096	loss_degree: 0.9640	loss_feat: 0.0476	loss_cls: 2.1374	loss_other: 1.0426
[client 16 neighGen phase]	acc_degree: 0.6471	acc_cls: 0.5000	loss_train: 0.1197	loss_degree: 0.3155	loss_feat: 0.0095	loss_cls: 1.8800	loss_other: 0.1893
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.1622	loss_train: 0.1182	loss_degree: 0.0983	loss_feat: 0.0000	loss_cls: 2.2649	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.4505	loss_train: 0.0988	loss_degree: 0.0938	loss_feat: 0.0000	loss_cls: 1.8819	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8198	acc_cls: 0.4505	loss_train: 0.0906	loss_degree: 0.1266	loss_feat: 0.0000	loss_cls: 1.6858	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.7021	acc_cls: 0.0496	loss_train: 0.1310	loss_degree: 0.2915	loss_feat: 0.0000	loss_cls: 2.3276	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.4468	acc_cls: 0.5177	loss_train: 0.1833	loss_degree: 0.8090	loss_feat: 0.0476	loss_cls: 1.8214	loss_other: 0.9874
[client 18 neighGen phase]	acc_degree: 0.7234	acc_cls: 0.5887	loss_train: 0.0966	loss_degree: 0.2236	loss_feat: 0.0035	loss_cls: 1.6467	loss_other: 0.0579
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.0795	loss_train: 0.1254	loss_degree: 0.1776	loss_feat: 0.0000	loss_cls: 2.3302	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.3974	acc_cls: 0.2914	loss_train: 0.1952	loss_degree: 1.1242	loss_feat: 0.0312	loss_cls: 1.9335	loss_other: 0.8141
[client 19 neighGen phase]	acc_degree: 0.7152	acc_cls: 0.4437	loss_train: 0.1064	loss_degree: 0.2249	loss_feat: 0.0039	loss_cls: 1.7836	loss_other: 0.1164
[server]	loss_train: 2.3163	loss_val: 2.3550	loss_test: 2.3476	accuracy_train: 0.0746	accuracy_val: 0.0618	accuracy_test: 0.0824
[server]	loss_train: 2.3318	loss_val: 2.3371	loss_test: 2.3170	accuracy_train: 0.1017	accuracy_val: 0.1053	accuracy_test: 0.1240
[server]	loss_train: 2.3395	loss_val: 2.3753	loss_test: 2.3592	accuracy_train: 0.0920	accuracy_val: 0.0659	accuracy_test: 0.0625
[server]	loss_train: 2.3066	loss_val: 2.3201	loss_test: 2.3063	accuracy_train: 0.0667	accuracy_val: 0.0922	accuracy_test: 0.1099
[server]	loss_train: 2.3538	loss_val: 2.3289	loss_test: 2.3189	accuracy_train: 0.1200	accuracy_val: 0.1016	accuracy_test: 0.1379
[server]	loss_train: 2.3086	loss_val: 2.3127	loss_test: 2.3046	accuracy_train: 0.0945	accuracy_val: 0.1145	accuracy_test: 0.0947
[server]	loss_train: 2.3946	loss_val: 2.4021	loss_test: 2.3890	accuracy_train: 0.0609	accuracy_val: 0.1079	accuracy_test: 0.0868
[server]	loss_train: 2.2895	loss_val: 2.2933	loss_test: 2.3176	accuracy_train: 0.1504	accuracy_val: 0.1223	accuracy_test: 0.1032
[server]	loss_train: 2.3428	loss_val: 2.3536	loss_test: 2.3436	accuracy_train: 0.0880	accuracy_val: 0.1158	accuracy_test: 0.0992
[server]	loss_train: 2.3404	loss_val: 2.3415	loss_test: 2.3347	accuracy_train: 0.1095	accuracy_val: 0.0883	accuracy_test: 0.1049
[server]	loss_train: 2.3546	loss_val: 2.3257	loss_test: 2.3258	accuracy_train: 0.0763	accuracy_val: 0.1045	accuracy_test: 0.0882
[server]	loss_train: 2.3064	loss_val: 2.3143	loss_test: 2.3198	accuracy_train: 0.0833	accuracy_val: 0.1095	accuracy_test: 0.1159
[server]	loss_train: 2.3541	loss_val: 2.3844	loss_test: 2.3755	accuracy_train: 0.1045	accuracy_val: 0.0903	accuracy_test: 0.0821
[server]	loss_train: 2.2988	loss_val: 2.3100	loss_test: 2.3112	accuracy_train: 0.1103	accuracy_val: 0.1000	accuracy_test: 0.1404
[server]	loss_train: 2.3535	loss_val: 2.3719	loss_test: 2.3651	accuracy_train: 0.1224	accuracy_val: 0.0872	accuracy_test: 0.1000
[server]	loss_train: 2.2717	loss_val: 2.2768	loss_test: 2.2717	accuracy_train: 0.1071	accuracy_val: 0.1038	accuracy_test: 0.0959
[server]	loss_train: 2.3449	loss_val: 2.3229	loss_test: 2.3546	accuracy_train: 0.0809	accuracy_val: 0.0929	accuracy_test: 0.1127
[server]	loss_train: 2.2917	loss_val: 2.3083	loss_test: 2.2887	accuracy_train: 0.1081	accuracy_val: 0.1478	accuracy_test: 0.0983
[server]	loss_train: 2.2396	loss_val: 2.2482	loss_test: 2.2472	accuracy_train: 0.1489	accuracy_val: 0.1359	accuracy_test: 0.1276
[server]	loss_train: 2.3565	loss_val: 2.3494	loss_test: 2.3542	accuracy_train: 0.0861	accuracy_val: 0.0452	accuracy_test: 0.0540
curr_round: 0	curr_val_accuracy: 0.0984	curr_test_accuracy: 0.1003
best_round: 0	best_val_accuracy: 0.0984	best_test_accuracy: 0.1003
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.5299	loss_train: 0.0983	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 1.7315	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.6343	loss_train: 0.0919	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 1.6029	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.6642	loss_train: 0.0871	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 1.5073	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.5847	loss_train: 0.1023	loss_degree: 0.2151	loss_feat: 0.0000	loss_cls: 1.8304	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.7881	loss_train: 0.0949	loss_degree: 0.2192	loss_feat: 0.0000	loss_cls: 1.6781	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.7373	loss_train: 0.0887	loss_degree: 0.2200	loss_feat: 0.0000	loss_cls: 1.5550	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.4969	loss_train: 0.0989	loss_degree: 0.2373	loss_feat: 0.0000	loss_cls: 1.7405	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.6012	loss_train: 0.0946	loss_degree: 0.2814	loss_feat: 0.0000	loss_cls: 1.6115	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.6380	loss_train: 0.0884	loss_degree: 0.2840	loss_feat: 0.0000	loss_cls: 1.4850	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.5704	loss_train: 0.1054	loss_degree: 0.4365	loss_feat: 0.0000	loss_cls: 1.6712	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.6074	loss_train: 0.1010	loss_degree: 0.4641	loss_feat: 0.0000	loss_cls: 1.5550	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.6296	loss_train: 0.0952	loss_degree: 0.4652	loss_feat: 0.0000	loss_cls: 1.4385	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.7040	acc_cls: 0.4800	loss_train: 0.1085	loss_degree: 0.3565	loss_feat: 0.0000	loss_cls: 1.8142	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.7040	acc_cls: 0.5520	loss_train: 0.1055	loss_degree: 0.3803	loss_feat: 0.0000	loss_cls: 1.7292	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.7040	acc_cls: 0.6640	loss_train: 0.0983	loss_degree: 0.3796	loss_feat: 0.0000	loss_cls: 1.5868	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.7795	acc_cls: 0.5748	loss_train: 0.0892	loss_degree: 0.1735	loss_feat: 0.0000	loss_cls: 1.6100	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.7795	acc_cls: 0.6378	loss_train: 0.0875	loss_degree: 0.1845	loss_feat: 0.0000	loss_cls: 1.5661	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.7795	acc_cls: 0.6457	loss_train: 0.0801	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 1.4203	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.6348	loss_train: 0.0988	loss_degree: 0.2472	loss_feat: 0.0000	loss_cls: 1.7293	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.5826	loss_train: 0.0960	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 1.6712	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.7304	loss_train: 0.0878	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 1.5089	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.6316	loss_train: 0.0950	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 1.6778	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.6090	loss_train: 0.0882	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 1.5419	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.6391	loss_train: 0.0825	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 1.4288	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.4880	loss_train: 0.0991	loss_degree: 0.2547	loss_feat: 0.0000	loss_cls: 1.7277	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.6400	loss_train: 0.0939	loss_degree: 0.2817	loss_feat: 0.0000	loss_cls: 1.5968	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.6720	loss_train: 0.0887	loss_degree: 0.2827	loss_feat: 0.0000	loss_cls: 1.4918	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.6131	acc_cls: 0.6204	loss_train: 0.1125	loss_degree: 0.3196	loss_feat: 0.0129	loss_cls: 1.6391	loss_other: 0.2775
[client 9 neighGen phase]	acc_degree: 0.7299	acc_cls: 0.7153	loss_train: 0.0880	loss_degree: 0.2486	loss_feat: 0.0000	loss_cls: 1.5118	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.7299	acc_cls: 0.7299	loss_train: 0.0826	loss_degree: 0.2649	loss_feat: 0.0000	loss_cls: 1.3874	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.5115	loss_train: 0.0934	loss_degree: 0.1641	loss_feat: 0.0000	loss_cls: 1.7031	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.5115	loss_train: 0.0863	loss_degree: 0.1641	loss_feat: 0.0000	loss_cls: 1.5611	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.5191	loss_train: 0.0796	loss_degree: 0.1641	loss_feat: 0.0000	loss_cls: 1.4276	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.7803	acc_cls: 0.5455	loss_train: 0.1119	loss_degree: 0.2002	loss_feat: 0.0108	loss_cls: 1.7571	loss_other: 0.2698
[client 11 neighGen phase]	acc_degree: 0.7955	acc_cls: 0.6515	loss_train: 0.0879	loss_degree: 0.1503	loss_feat: 0.0000	loss_cls: 1.6078	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.7955	acc_cls: 0.6970	loss_train: 0.0820	loss_degree: 0.1744	loss_feat: 0.0000	loss_cls: 1.4649	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.5672	loss_train: 0.0918	loss_degree: 0.1486	loss_feat: 0.0000	loss_cls: 1.6867	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.6269	loss_train: 0.0876	loss_degree: 0.1528	loss_feat: 0.0000	loss_cls: 1.5983	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.6493	loss_train: 0.0808	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 1.4634	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7206	acc_cls: 0.5368	loss_train: 0.0919	loss_degree: 0.1685	loss_feat: 0.0000	loss_cls: 1.6690	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7206	acc_cls: 0.6029	loss_train: 0.0886	loss_degree: 0.1954	loss_feat: 0.0000	loss_cls: 1.5769	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7206	acc_cls: 0.6324	loss_train: 0.0829	loss_degree: 0.2010	loss_feat: 0.0000	loss_cls: 1.4574	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.6871	acc_cls: 0.6259	loss_train: 0.0943	loss_degree: 0.2395	loss_feat: 0.0000	loss_cls: 1.6473	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.6871	acc_cls: 0.6871	loss_train: 0.0902	loss_degree: 0.2522	loss_feat: 0.0000	loss_cls: 1.5522	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.6871	acc_cls: 0.7959	loss_train: 0.0838	loss_degree: 0.2538	loss_feat: 0.0000	loss_cls: 1.4229	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.6429	loss_train: 0.0913	loss_degree: 0.2391	loss_feat: 0.0000	loss_cls: 1.5878	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.6643	loss_train: 0.0856	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 1.4688	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.6286	loss_train: 0.0816	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 1.3889	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.6471	loss_train: 0.1003	loss_degree: 0.2837	loss_feat: 0.0000	loss_cls: 1.7225	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.6618	loss_train: 0.0967	loss_degree: 0.3130	loss_feat: 0.0000	loss_cls: 1.6216	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.6103	loss_train: 0.0937	loss_degree: 0.3149	loss_feat: 0.0000	loss_cls: 1.5583	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.5766	loss_train: 0.0844	loss_degree: 0.0927	loss_feat: 0.0000	loss_cls: 1.5946	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.6126	loss_train: 0.0783	loss_degree: 0.0958	loss_feat: 0.0000	loss_cls: 1.4694	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.5946	loss_train: 0.0728	loss_degree: 0.0969	loss_feat: 0.0000	loss_cls: 1.3582	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.7021	acc_cls: 0.6383	loss_train: 0.0897	loss_degree: 0.2713	loss_feat: 0.0000	loss_cls: 1.5224	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.7021	acc_cls: 0.6454	loss_train: 0.0849	loss_degree: 0.2885	loss_feat: 0.0000	loss_cls: 1.4097	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.7021	acc_cls: 0.6525	loss_train: 0.0801	loss_degree: 0.2900	loss_feat: 0.0000	loss_cls: 1.3123	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.5629	loss_train: 0.0930	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 1.6779	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.6358	loss_train: 0.0858	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 1.5338	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.5695	loss_train: 0.0816	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 1.4493	loss_other: 0.0000
[server]	loss_train: 2.3163	loss_val: 2.3550	loss_test: 2.3476	accuracy_train: 0.0746	accuracy_val: 0.0618	accuracy_test: 0.0824
[server]	loss_train: 2.3318	loss_val: 2.3371	loss_test: 2.3170	accuracy_train: 0.1017	accuracy_val: 0.1053	accuracy_test: 0.1240
[server]	loss_train: 2.3395	loss_val: 2.3753	loss_test: 2.3592	accuracy_train: 0.0920	accuracy_val: 0.0659	accuracy_test: 0.0625
[server]	loss_train: 2.3066	loss_val: 2.3201	loss_test: 2.3063	accuracy_train: 0.0667	accuracy_val: 0.0922	accuracy_test: 0.1099
[server]	loss_train: 2.3538	loss_val: 2.3289	loss_test: 2.3189	accuracy_train: 0.1200	accuracy_val: 0.1016	accuracy_test: 0.1379
[server]	loss_train: 2.3086	loss_val: 2.3127	loss_test: 2.3046	accuracy_train: 0.0945	accuracy_val: 0.1145	accuracy_test: 0.0947
[server]	loss_train: 2.3946	loss_val: 2.4021	loss_test: 2.3890	accuracy_train: 0.0609	accuracy_val: 0.1079	accuracy_test: 0.0868
[server]	loss_train: 2.2895	loss_val: 2.2933	loss_test: 2.3176	accuracy_train: 0.1504	accuracy_val: 0.1223	accuracy_test: 0.1032
[server]	loss_train: 2.3428	loss_val: 2.3536	loss_test: 2.3436	accuracy_train: 0.0880	accuracy_val: 0.1158	accuracy_test: 0.0992
[server]	loss_train: 2.3404	loss_val: 2.3415	loss_test: 2.3347	accuracy_train: 0.1095	accuracy_val: 0.0883	accuracy_test: 0.1049
[server]	loss_train: 2.3546	loss_val: 2.3257	loss_test: 2.3258	accuracy_train: 0.0763	accuracy_val: 0.1045	accuracy_test: 0.0882
[server]	loss_train: 2.3064	loss_val: 2.3143	loss_test: 2.3198	accuracy_train: 0.0833	accuracy_val: 0.1095	accuracy_test: 0.1159
[server]	loss_train: 2.3541	loss_val: 2.3844	loss_test: 2.3755	accuracy_train: 0.1045	accuracy_val: 0.0903	accuracy_test: 0.0821
[server]	loss_train: 2.2988	loss_val: 2.3100	loss_test: 2.3112	accuracy_train: 0.1103	accuracy_val: 0.1000	accuracy_test: 0.1404
[server]	loss_train: 2.3535	loss_val: 2.3719	loss_test: 2.3651	accuracy_train: 0.1224	accuracy_val: 0.0872	accuracy_test: 0.1000
[server]	loss_train: 2.2717	loss_val: 2.2768	loss_test: 2.2717	accuracy_train: 0.1071	accuracy_val: 0.1038	accuracy_test: 0.0959
[server]	loss_train: 2.3449	loss_val: 2.3229	loss_test: 2.3546	accuracy_train: 0.0809	accuracy_val: 0.0929	accuracy_test: 0.1127
[server]	loss_train: 2.2917	loss_val: 2.3083	loss_test: 2.2887	accuracy_train: 0.1081	accuracy_val: 0.1478	accuracy_test: 0.0983
[server]	loss_train: 2.2396	loss_val: 2.2482	loss_test: 2.2472	accuracy_train: 0.1489	accuracy_val: 0.1359	accuracy_test: 0.1276
[server]	loss_train: 2.3565	loss_val: 2.3494	loss_test: 2.3542	accuracy_train: 0.0861	accuracy_val: 0.0452	accuracy_test: 0.0540
curr_round: 1	curr_val_accuracy: 0.0984	curr_test_accuracy: 0.1003
best_round: 0	best_val_accuracy: 0.0984	best_test_accuracy: 0.1003
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.7388	loss_train: 0.0822	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 1.4095	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.8507	loss_train: 0.0768	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 1.3003	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.8507	loss_train: 0.0719	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 1.2035	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.7288	loss_train: 0.0824	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 1.4274	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.8390	loss_train: 0.0749	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 1.2776	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.8898	loss_train: 0.0694	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 1.1684	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.6564	loss_train: 0.0821	loss_degree: 0.2844	loss_feat: 0.0000	loss_cls: 1.3581	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.6871	loss_train: 0.0768	loss_degree: 0.2843	loss_feat: 0.0000	loss_cls: 1.2511	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.7546	loss_train: 0.0712	loss_degree: 0.2840	loss_feat: 0.0000	loss_cls: 1.1401	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.6667	loss_train: 0.0922	loss_degree: 0.4653	loss_feat: 0.0000	loss_cls: 1.3789	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.6741	loss_train: 0.0874	loss_degree: 0.4651	loss_feat: 0.0000	loss_cls: 1.2836	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.7481	loss_train: 0.0816	loss_degree: 0.4646	loss_feat: 0.0000	loss_cls: 1.1675	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.7040	acc_cls: 0.7120	loss_train: 0.0926	loss_degree: 0.3718	loss_feat: 0.0000	loss_cls: 1.4798	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.7040	acc_cls: 0.7520	loss_train: 0.0871	loss_degree: 0.3612	loss_feat: 0.0000	loss_cls: 1.3799	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.6880	acc_cls: 0.7440	loss_train: 0.0815	loss_degree: 0.3511	loss_feat: 0.0000	loss_cls: 1.2797	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.7795	acc_cls: 0.6457	loss_train: 0.0764	loss_degree: 0.1767	loss_feat: 0.0000	loss_cls: 1.3507	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.7795	acc_cls: 0.6693	loss_train: 0.0733	loss_degree: 0.1709	loss_feat: 0.0000	loss_cls: 1.2954	loss_other: 0.0000
[client 5 neighGen phase]	acc_degree: 0.7795	acc_cls: 0.7008	loss_train: 0.0687	loss_degree: 0.1658	loss_feat: 0.0008	loss_cls: 1.1972	loss_other: 0.0106
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.7217	loss_train: 0.0822	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 1.3970	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.7826	loss_train: 0.0766	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 1.2838	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.7739	loss_train: 0.0718	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 1.1872	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.7068	loss_train: 0.0763	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 1.3048	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.8195	loss_train: 0.0714	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 1.2054	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.8571	loss_train: 0.0662	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 1.1028	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.7040	loss_train: 0.0848	loss_degree: 0.2795	loss_feat: 0.0000	loss_cls: 1.4168	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.7840	loss_train: 0.0801	loss_degree: 0.2733	loss_feat: 0.0000	loss_cls: 1.3291	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.8000	loss_train: 0.0753	loss_degree: 0.2630	loss_feat: 0.0000	loss_cls: 1.2434	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.7299	acc_cls: 0.7810	loss_train: 0.0765	loss_degree: 0.2632	loss_feat: 0.0000	loss_cls: 1.2663	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.7299	acc_cls: 0.8029	loss_train: 0.0699	loss_degree: 0.2456	loss_feat: 0.0000	loss_cls: 1.1521	loss_other: 0.0000
[client 9 neighGen phase]	acc_degree: 0.7299	acc_cls: 0.8248	loss_train: 0.0634	loss_degree: 0.2179	loss_feat: 0.0000	loss_cls: 1.0506	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.6412	loss_train: 0.0731	loss_degree: 0.1641	loss_feat: 0.0000	loss_cls: 1.2972	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.7481	loss_train: 0.0676	loss_degree: 0.1641	loss_feat: 0.0000	loss_cls: 1.1877	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.8015	loss_train: 0.0617	loss_degree: 0.1641	loss_feat: 0.0000	loss_cls: 1.0701	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.7955	acc_cls: 0.7424	loss_train: 0.0753	loss_degree: 0.1807	loss_feat: 0.0000	loss_cls: 1.3260	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.7955	acc_cls: 0.8106	loss_train: 0.0692	loss_degree: 0.1825	loss_feat: 0.0000	loss_cls: 1.2005	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.7955	acc_cls: 0.8788	loss_train: 0.0630	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 1.0788	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.6866	loss_train: 0.0758	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 1.3620	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.7164	loss_train: 0.0709	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 1.2652	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.7537	loss_train: 0.0652	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 1.1508	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7206	acc_cls: 0.6618	loss_train: 0.0776	loss_degree: 0.1984	loss_feat: 0.0000	loss_cls: 1.3533	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7206	acc_cls: 0.6912	loss_train: 0.0726	loss_degree: 0.1933	loss_feat: 0.0000	loss_cls: 1.2577	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7206	acc_cls: 0.7647	loss_train: 0.0665	loss_degree: 0.1852	loss_feat: 0.0000	loss_cls: 1.1455	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.6871	acc_cls: 0.8095	loss_train: 0.0776	loss_degree: 0.2528	loss_feat: 0.0000	loss_cls: 1.2984	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.6871	acc_cls: 0.8299	loss_train: 0.0727	loss_degree: 0.2489	loss_feat: 0.0000	loss_cls: 1.2047	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.6871	acc_cls: 0.8367	loss_train: 0.0670	loss_degree: 0.2425	loss_feat: 0.0000	loss_cls: 1.0966	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.6286	loss_train: 0.0789	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 1.3356	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.6571	loss_train: 0.0747	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 1.2518	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.7071	loss_train: 0.0699	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 1.1551	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.6471	loss_train: 0.0877	loss_degree: 0.3126	loss_feat: 0.0000	loss_cls: 1.4423	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.7353	loss_train: 0.0814	loss_degree: 0.3085	loss_feat: 0.0000	loss_cls: 1.3202	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.7721	loss_train: 0.0781	loss_degree: 0.3012	loss_feat: 0.0000	loss_cls: 1.2617	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.6126	loss_train: 0.0685	loss_degree: 0.0971	loss_feat: 0.0000	loss_cls: 1.2724	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.6667	loss_train: 0.0631	loss_degree: 0.0963	loss_feat: 0.0000	loss_cls: 1.1652	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.7568	loss_train: 0.0577	loss_degree: 0.0949	loss_feat: 0.0000	loss_cls: 1.0588	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.7021	acc_cls: 0.6738	loss_train: 0.0742	loss_degree: 0.2881	loss_feat: 0.0000	loss_cls: 1.1965	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.7021	acc_cls: 0.6879	loss_train: 0.0685	loss_degree: 0.2846	loss_feat: 0.0000	loss_cls: 1.0861	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.7021	acc_cls: 0.7092	loss_train: 0.0639	loss_degree: 0.2796	loss_feat: 0.0000	loss_cls: 0.9982	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.7086	loss_train: 0.0751	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 1.3206	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.7947	loss_train: 0.0694	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 1.2056	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.8146	loss_train: 0.0651	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 1.1198	loss_other: 0.0000
[server]	loss_train: 2.3163	loss_val: 2.3550	loss_test: 2.3476	accuracy_train: 0.0746	accuracy_val: 0.0618	accuracy_test: 0.0824
[server]	loss_train: 2.3318	loss_val: 2.3371	loss_test: 2.3170	accuracy_train: 0.1017	accuracy_val: 0.1053	accuracy_test: 0.1240
[server]	loss_train: 2.3395	loss_val: 2.3753	loss_test: 2.3592	accuracy_train: 0.0920	accuracy_val: 0.0659	accuracy_test: 0.0625
[server]	loss_train: 2.3066	loss_val: 2.3201	loss_test: 2.3063	accuracy_train: 0.0667	accuracy_val: 0.0922	accuracy_test: 0.1099
[server]	loss_train: 2.3538	loss_val: 2.3289	loss_test: 2.3189	accuracy_train: 0.1200	accuracy_val: 0.1016	accuracy_test: 0.1379
[server]	loss_train: 2.3086	loss_val: 2.3127	loss_test: 2.3046	accuracy_train: 0.0945	accuracy_val: 0.1145	accuracy_test: 0.0947
[server]	loss_train: 2.3946	loss_val: 2.4021	loss_test: 2.3890	accuracy_train: 0.0609	accuracy_val: 0.1079	accuracy_test: 0.0868
[server]	loss_train: 2.2895	loss_val: 2.2933	loss_test: 2.3176	accuracy_train: 0.1504	accuracy_val: 0.1223	accuracy_test: 0.1032
[server]	loss_train: 2.3428	loss_val: 2.3536	loss_test: 2.3436	accuracy_train: 0.0880	accuracy_val: 0.1158	accuracy_test: 0.0992
[server]	loss_train: 2.3404	loss_val: 2.3415	loss_test: 2.3347	accuracy_train: 0.1095	accuracy_val: 0.0883	accuracy_test: 0.1049
[server]	loss_train: 2.3546	loss_val: 2.3257	loss_test: 2.3258	accuracy_train: 0.0763	accuracy_val: 0.1045	accuracy_test: 0.0882
[server]	loss_train: 2.3064	loss_val: 2.3143	loss_test: 2.3198	accuracy_train: 0.0833	accuracy_val: 0.1095	accuracy_test: 0.1159
[server]	loss_train: 2.3541	loss_val: 2.3844	loss_test: 2.3755	accuracy_train: 0.1045	accuracy_val: 0.0903	accuracy_test: 0.0821
[server]	loss_train: 2.2988	loss_val: 2.3100	loss_test: 2.3112	accuracy_train: 0.1103	accuracy_val: 0.1000	accuracy_test: 0.1404
[server]	loss_train: 2.3535	loss_val: 2.3719	loss_test: 2.3651	accuracy_train: 0.1224	accuracy_val: 0.0872	accuracy_test: 0.1000
[server]	loss_train: 2.2717	loss_val: 2.2768	loss_test: 2.2717	accuracy_train: 0.1071	accuracy_val: 0.1038	accuracy_test: 0.0959
[server]	loss_train: 2.3449	loss_val: 2.3229	loss_test: 2.3546	accuracy_train: 0.0809	accuracy_val: 0.0929	accuracy_test: 0.1127
[server]	loss_train: 2.2917	loss_val: 2.3083	loss_test: 2.2887	accuracy_train: 0.1081	accuracy_val: 0.1478	accuracy_test: 0.0983
[server]	loss_train: 2.2396	loss_val: 2.2482	loss_test: 2.2472	accuracy_train: 0.1489	accuracy_val: 0.1359	accuracy_test: 0.1276
[server]	loss_train: 2.3565	loss_val: 2.3494	loss_test: 2.3542	accuracy_train: 0.0861	accuracy_val: 0.0452	accuracy_test: 0.0540
curr_round: 2	curr_val_accuracy: 0.0984	curr_test_accuracy: 0.1003
best_round: 0	best_val_accuracy: 0.0984	best_test_accuracy: 0.1003
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.8433	loss_train: 0.0675	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 1.1159	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.8731	loss_train: 0.0630	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 1.0241	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.8955	loss_train: 0.0592	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.9499	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.9153	loss_train: 0.0639	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 1.0571	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.9237	loss_train: 0.0580	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.9405	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.9237	loss_train: 0.0537	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.8530	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.8037	loss_train: 0.0658	loss_degree: 0.2836	loss_feat: 0.0000	loss_cls: 1.0320	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.8650	loss_train: 0.0606	loss_degree: 0.2827	loss_feat: 0.0000	loss_cls: 0.9285	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.8957	loss_train: 0.0559	loss_degree: 0.2807	loss_feat: 0.0000	loss_cls: 0.8377	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.8148	loss_train: 0.0772	loss_degree: 0.4639	loss_feat: 0.0000	loss_cls: 1.0801	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.8222	loss_train: 0.0733	loss_degree: 0.4631	loss_feat: 0.0000	loss_cls: 1.0019	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.8296	loss_train: 0.0688	loss_degree: 0.4622	loss_feat: 0.0000	loss_cls: 0.9133	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.6880	acc_cls: 0.8160	loss_train: 0.0765	loss_degree: 0.3419	loss_feat: 0.0010	loss_cls: 1.1651	loss_other: 0.0224
[client 4 neighGen phase]	acc_degree: 0.6880	acc_cls: 0.8640	loss_train: 0.0734	loss_degree: 0.3374	loss_feat: 0.0022	loss_cls: 1.0792	loss_other: 0.0490
[client 4 neighGen phase]	acc_degree: 0.6880	acc_cls: 0.8880	loss_train: 0.0706	loss_degree: 0.3365	loss_feat: 0.0037	loss_cls: 0.9969	loss_other: 0.0755
[client 5 neighGen phase]	acc_degree: 0.7795	acc_cls: 0.7717	loss_train: 0.0641	loss_degree: 0.1624	loss_feat: 0.0007	loss_cls: 1.1079	loss_other: 0.0106
[client 5 neighGen phase]	acc_degree: 0.7874	acc_cls: 0.8110	loss_train: 0.0611	loss_degree: 0.1598	loss_feat: 0.0012	loss_cls: 1.0418	loss_other: 0.0190
[client 5 neighGen phase]	acc_degree: 0.7795	acc_cls: 0.8189	loss_train: 0.0579	loss_degree: 0.1561	loss_feat: 0.0013	loss_cls: 0.9722	loss_other: 0.0284
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.8261	loss_train: 0.0665	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 1.0831	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.8783	loss_train: 0.0613	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.9781	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.9304	loss_train: 0.0571	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.8950	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.8647	loss_train: 0.0614	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 1.0055	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.8872	loss_train: 0.0571	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.9211	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.9173	loss_train: 0.0529	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.8370	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.8080	loss_train: 0.0694	loss_degree: 0.2474	loss_feat: 0.0000	loss_cls: 1.1400	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.8480	loss_train: 0.0644	loss_degree: 0.2293	loss_feat: 0.0000	loss_cls: 1.0595	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6800	acc_cls: 0.8640	loss_train: 0.0628	loss_degree: 0.2276	loss_feat: 0.0017	loss_cls: 0.9923	loss_other: 0.0348
[client 9 neighGen phase]	acc_degree: 0.7299	acc_cls: 0.8540	loss_train: 0.0586	loss_degree: 0.2066	loss_feat: 0.0001	loss_cls: 0.9547	loss_other: 0.0100
[client 9 neighGen phase]	acc_degree: 0.7226	acc_cls: 0.8759	loss_train: 0.0590	loss_degree: 0.2114	loss_feat: 0.0051	loss_cls: 0.8621	loss_other: 0.1013
[client 9 neighGen phase]	acc_degree: 0.7372	acc_cls: 0.8905	loss_train: 0.0507	loss_degree: 0.1917	loss_feat: 0.0025	loss_cls: 0.7787	loss_other: 0.0414
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.8397	loss_train: 0.0567	loss_degree: 0.1641	loss_feat: 0.0000	loss_cls: 0.9698	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.8779	loss_train: 0.0521	loss_degree: 0.1640	loss_feat: 0.0000	loss_cls: 0.8783	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.9237	loss_train: 0.0473	loss_degree: 0.1549	loss_feat: 0.0000	loss_cls: 0.7902	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.7955	acc_cls: 0.8939	loss_train: 0.0572	loss_degree: 0.1797	loss_feat: 0.0000	loss_cls: 0.9635	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.7955	acc_cls: 0.9394	loss_train: 0.0520	loss_degree: 0.1757	loss_feat: 0.0000	loss_cls: 0.8645	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.7955	acc_cls: 0.9470	loss_train: 0.0473	loss_degree: 0.1705	loss_feat: 0.0000	loss_cls: 0.7761	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.8134	loss_train: 0.0600	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 1.0462	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.8657	loss_train: 0.0556	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.9592	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.8806	loss_train: 0.0513	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.8735	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7206	acc_cls: 0.8676	loss_train: 0.0612	loss_degree: 0.1742	loss_feat: 0.0000	loss_cls: 1.0491	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7279	acc_cls: 0.9044	loss_train: 0.0571	loss_degree: 0.1673	loss_feat: 0.0009	loss_cls: 0.9652	loss_other: 0.0092
[client 13 neighGen phase]	acc_degree: 0.7426	acc_cls: 0.9044	loss_train: 0.0538	loss_degree: 0.1687	loss_feat: 0.0018	loss_cls: 0.8813	loss_other: 0.0240
[client 14 neighGen phase]	acc_degree: 0.6871	acc_cls: 0.8571	loss_train: 0.0618	loss_degree: 0.2319	loss_feat: 0.0000	loss_cls: 1.0036	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.6871	acc_cls: 0.8912	loss_train: 0.0569	loss_degree: 0.2182	loss_feat: 0.0000	loss_cls: 0.9199	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.6735	acc_cls: 0.9184	loss_train: 0.0528	loss_degree: 0.2063	loss_feat: 0.0005	loss_cls: 0.8407	loss_other: 0.0094
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.8071	loss_train: 0.0661	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 1.0786	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.8071	loss_train: 0.0627	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 1.0114	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.8000	loss_train: 0.0593	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.9426	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.7868	loss_train: 0.0734	loss_degree: 0.2891	loss_feat: 0.0000	loss_cls: 1.1797	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.8309	loss_train: 0.0679	loss_degree: 0.2689	loss_feat: 0.0000	loss_cls: 1.0898	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7279	acc_cls: 0.8309	loss_train: 0.0637	loss_degree: 0.2482	loss_feat: 0.0000	loss_cls: 1.0255	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.8378	loss_train: 0.0533	loss_degree: 0.0931	loss_feat: 0.0000	loss_cls: 0.9720	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.8559	loss_train: 0.0491	loss_degree: 0.0909	loss_feat: 0.0000	loss_cls: 0.8902	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.8649	loss_train: 0.0450	loss_degree: 0.0875	loss_feat: 0.0000	loss_cls: 0.8128	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.7021	acc_cls: 0.7660	loss_train: 0.0587	loss_degree: 0.2729	loss_feat: 0.0000	loss_cls: 0.9003	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.7021	acc_cls: 0.7801	loss_train: 0.0541	loss_degree: 0.2639	loss_feat: 0.0000	loss_cls: 0.8187	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.7021	acc_cls: 0.8156	loss_train: 0.0499	loss_degree: 0.2522	loss_feat: 0.0000	loss_cls: 0.7449	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.8742	loss_train: 0.0594	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 1.0065	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.8742	loss_train: 0.0558	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.9344	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9073	loss_train: 0.0519	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.8567	loss_other: 0.0000
[server]	loss_train: 2.3163	loss_val: 2.3550	loss_test: 2.3476	accuracy_train: 0.0746	accuracy_val: 0.0618	accuracy_test: 0.0824
[server]	loss_train: 2.3318	loss_val: 2.3371	loss_test: 2.3170	accuracy_train: 0.1017	accuracy_val: 0.1053	accuracy_test: 0.1240
[server]	loss_train: 2.3395	loss_val: 2.3753	loss_test: 2.3592	accuracy_train: 0.0920	accuracy_val: 0.0659	accuracy_test: 0.0625
[server]	loss_train: 2.3066	loss_val: 2.3201	loss_test: 2.3063	accuracy_train: 0.0667	accuracy_val: 0.0922	accuracy_test: 0.1099
[server]	loss_train: 2.3538	loss_val: 2.3289	loss_test: 2.3189	accuracy_train: 0.1200	accuracy_val: 0.1016	accuracy_test: 0.1379
[server]	loss_train: 2.3086	loss_val: 2.3127	loss_test: 2.3046	accuracy_train: 0.0945	accuracy_val: 0.1145	accuracy_test: 0.0947
[server]	loss_train: 2.3946	loss_val: 2.4021	loss_test: 2.3890	accuracy_train: 0.0609	accuracy_val: 0.1079	accuracy_test: 0.0868
[server]	loss_train: 2.2895	loss_val: 2.2933	loss_test: 2.3176	accuracy_train: 0.1504	accuracy_val: 0.1223	accuracy_test: 0.1032
[server]	loss_train: 2.3428	loss_val: 2.3536	loss_test: 2.3436	accuracy_train: 0.0880	accuracy_val: 0.1158	accuracy_test: 0.0992
[server]	loss_train: 2.3404	loss_val: 2.3415	loss_test: 2.3347	accuracy_train: 0.1095	accuracy_val: 0.0883	accuracy_test: 0.1049
[server]	loss_train: 2.3546	loss_val: 2.3257	loss_test: 2.3258	accuracy_train: 0.0763	accuracy_val: 0.1045	accuracy_test: 0.0882
[server]	loss_train: 2.3064	loss_val: 2.3143	loss_test: 2.3198	accuracy_train: 0.0833	accuracy_val: 0.1095	accuracy_test: 0.1159
[server]	loss_train: 2.3541	loss_val: 2.3844	loss_test: 2.3755	accuracy_train: 0.1045	accuracy_val: 0.0903	accuracy_test: 0.0821
[server]	loss_train: 2.2988	loss_val: 2.3100	loss_test: 2.3112	accuracy_train: 0.1103	accuracy_val: 0.1000	accuracy_test: 0.1404
[server]	loss_train: 2.3535	loss_val: 2.3719	loss_test: 2.3651	accuracy_train: 0.1224	accuracy_val: 0.0872	accuracy_test: 0.1000
[server]	loss_train: 2.2717	loss_val: 2.2768	loss_test: 2.2717	accuracy_train: 0.1071	accuracy_val: 0.1038	accuracy_test: 0.0959
[server]	loss_train: 2.3449	loss_val: 2.3229	loss_test: 2.3546	accuracy_train: 0.0809	accuracy_val: 0.0929	accuracy_test: 0.1127
[server]	loss_train: 2.2917	loss_val: 2.3083	loss_test: 2.2887	accuracy_train: 0.1081	accuracy_val: 0.1478	accuracy_test: 0.0983
[server]	loss_train: 2.2396	loss_val: 2.2482	loss_test: 2.2472	accuracy_train: 0.1489	accuracy_val: 0.1359	accuracy_test: 0.1276
[server]	loss_train: 2.3565	loss_val: 2.3494	loss_test: 2.3542	accuracy_train: 0.0861	accuracy_val: 0.0452	accuracy_test: 0.0540
curr_round: 3	curr_val_accuracy: 0.0984	curr_test_accuracy: 0.1003
best_round: 0	best_val_accuracy: 0.0984	best_test_accuracy: 0.1003
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.8955	loss_train: 0.0558	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.8811	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9104	loss_train: 0.0522	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.8085	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9254	loss_train: 0.0490	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.7450	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.9492	loss_train: 0.0494	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.7679	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.9746	loss_train: 0.0451	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.6817	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.9661	loss_train: 0.0417	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.6139	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.9141	loss_train: 0.0515	loss_degree: 0.2767	loss_feat: 0.0000	loss_cls: 0.7528	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.9325	loss_train: 0.0474	loss_degree: 0.2704	loss_feat: 0.0000	loss_cls: 0.6780	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.9509	loss_train: 0.0436	loss_degree: 0.2614	loss_feat: 0.0000	loss_cls: 0.6101	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.8519	loss_train: 0.0649	loss_degree: 0.4613	loss_feat: 0.0000	loss_cls: 0.8372	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.8815	loss_train: 0.0609	loss_degree: 0.4600	loss_feat: 0.0000	loss_cls: 0.7581	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9481	loss_train: 0.0572	loss_degree: 0.4588	loss_feat: 0.0000	loss_cls: 0.6856	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.8960	loss_train: 0.0680	loss_degree: 0.3373	loss_feat: 0.0049	loss_cls: 0.9105	loss_other: 0.1078
[client 4 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.9040	loss_train: 0.0642	loss_degree: 0.3322	loss_feat: 0.0047	loss_cls: 0.8389	loss_other: 0.1079
[client 4 neighGen phase]	acc_degree: 0.6880	acc_cls: 0.9280	loss_train: 0.0588	loss_degree: 0.3201	loss_feat: 0.0040	loss_cls: 0.7725	loss_other: 0.0795
[client 5 neighGen phase]	acc_degree: 0.7953	acc_cls: 0.8346	loss_train: 0.0544	loss_degree: 0.1508	loss_feat: 0.0013	loss_cls: 0.9084	loss_other: 0.0268
[client 5 neighGen phase]	acc_degree: 0.7874	acc_cls: 0.8583	loss_train: 0.0506	loss_degree: 0.1463	loss_feat: 0.0010	loss_cls: 0.8433	loss_other: 0.0204
[client 5 neighGen phase]	acc_degree: 0.7874	acc_cls: 0.8583	loss_train: 0.0471	loss_degree: 0.1393	loss_feat: 0.0012	loss_cls: 0.7826	loss_other: 0.0195
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.9391	loss_train: 0.0527	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.8069	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.9391	loss_train: 0.0487	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.7270	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.9478	loss_train: 0.0453	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.6585	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.9248	loss_train: 0.0494	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.7654	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.9474	loss_train: 0.0458	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.6935	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.9774	loss_train: 0.0426	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.6311	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6720	acc_cls: 0.9040	loss_train: 0.0617	loss_degree: 0.2330	loss_feat: 0.0042	loss_cls: 0.9122	loss_other: 0.0841
[client 8 neighGen phase]	acc_degree: 0.6800	acc_cls: 0.9040	loss_train: 0.0556	loss_degree: 0.2121	loss_feat: 0.0026	loss_cls: 0.8450	loss_other: 0.0525
[client 8 neighGen phase]	acc_degree: 0.7040	acc_cls: 0.9120	loss_train: 0.0501	loss_degree: 0.2027	loss_feat: 0.0006	loss_cls: 0.7844	loss_other: 0.0149
[client 9 neighGen phase]	acc_degree: 0.7299	acc_cls: 0.9270	loss_train: 0.0451	loss_degree: 0.1730	loss_feat: 0.0015	loss_cls: 0.7081	loss_other: 0.0197
[client 9 neighGen phase]	acc_degree: 0.7299	acc_cls: 0.9416	loss_train: 0.0409	loss_degree: 0.1655	loss_feat: 0.0006	loss_cls: 0.6395	loss_other: 0.0117
[client 9 neighGen phase]	acc_degree: 0.7372	acc_cls: 0.9489	loss_train: 0.0393	loss_degree: 0.1580	loss_feat: 0.0035	loss_cls: 0.5749	loss_other: 0.0486
[client 10 neighGen phase]	acc_degree: 0.8168	acc_cls: 0.9618	loss_train: 0.0447	loss_degree: 0.1827	loss_feat: 0.0000	loss_cls: 0.7111	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.9695	loss_train: 0.0394	loss_degree: 0.1482	loss_feat: 0.0000	loss_cls: 0.6393	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.9695	loss_train: 0.0367	loss_degree: 0.1577	loss_feat: 0.0000	loss_cls: 0.5763	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.7955	acc_cls: 0.9545	loss_train: 0.0434	loss_degree: 0.1623	loss_feat: 0.0003	loss_cls: 0.6965	loss_other: 0.0089
[client 11 neighGen phase]	acc_degree: 0.7955	acc_cls: 0.9621	loss_train: 0.0395	loss_degree: 0.1512	loss_feat: 0.0003	loss_cls: 0.6256	loss_other: 0.0122
[client 11 neighGen phase]	acc_degree: 0.8030	acc_cls: 0.9621	loss_train: 0.0366	loss_degree: 0.1492	loss_feat: 0.0014	loss_cls: 0.5614	loss_other: 0.0208
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.8881	loss_train: 0.0473	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.7933	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.8955	loss_train: 0.0437	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.7213	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.9104	loss_train: 0.0404	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.6545	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7426	acc_cls: 0.9044	loss_train: 0.0499	loss_degree: 0.1616	loss_feat: 0.0020	loss_cls: 0.8079	loss_other: 0.0268
[client 13 neighGen phase]	acc_degree: 0.7206	acc_cls: 0.9118	loss_train: 0.0445	loss_degree: 0.1487	loss_feat: 0.0000	loss_cls: 0.7421	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7206	acc_cls: 0.9412	loss_train: 0.0409	loss_degree: 0.1413	loss_feat: 0.0000	loss_cls: 0.6763	loss_other: 0.0000
[client 14 neighGen phase]	acc_degree: 0.6871	acc_cls: 0.9320	loss_train: 0.0517	loss_degree: 0.2013	loss_feat: 0.0035	loss_cls: 0.7678	loss_other: 0.0615
[client 14 neighGen phase]	acc_degree: 0.6939	acc_cls: 0.9456	loss_train: 0.0492	loss_degree: 0.1999	loss_feat: 0.0049	loss_cls: 0.6992	loss_other: 0.0808
[client 14 neighGen phase]	acc_degree: 0.7211	acc_cls: 0.9592	loss_train: 0.0481	loss_degree: 0.1850	loss_feat: 0.0085	loss_cls: 0.6356	loss_other: 0.1331
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.8143	loss_train: 0.0562	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.8819	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.8357	loss_train: 0.0528	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.8134	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.8643	loss_train: 0.0496	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.7497	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7279	acc_cls: 0.8824	loss_train: 0.0630	loss_degree: 0.2459	loss_feat: 0.0033	loss_cls: 0.9517	loss_other: 0.0594
[client 16 neighGen phase]	acc_degree: 0.7132	acc_cls: 0.8971	loss_train: 0.0625	loss_degree: 0.2580	loss_feat: 0.0052	loss_cls: 0.8875	loss_other: 0.0984
[client 16 neighGen phase]	acc_degree: 0.7132	acc_cls: 0.8971	loss_train: 0.0583	loss_degree: 0.2461	loss_feat: 0.0044	loss_cls: 0.8294	loss_other: 0.0854
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.8829	loss_train: 0.0413	loss_degree: 0.0835	loss_feat: 0.0000	loss_cls: 0.7426	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8649	acc_cls: 0.9009	loss_train: 0.0386	loss_degree: 0.0827	loss_feat: 0.0005	loss_cls: 0.6738	loss_other: 0.0150
[client 17 neighGen phase]	acc_degree: 0.8649	acc_cls: 0.9279	loss_train: 0.0356	loss_degree: 0.0833	loss_feat: 0.0005	loss_cls: 0.6094	loss_other: 0.0194
[client 18 neighGen phase]	acc_degree: 0.7092	acc_cls: 0.8936	loss_train: 0.0459	loss_degree: 0.2381	loss_feat: 0.0003	loss_cls: 0.6714	loss_other: 0.0081
[client 18 neighGen phase]	acc_degree: 0.7305	acc_cls: 0.9220	loss_train: 0.0447	loss_degree: 0.2236	loss_feat: 0.0035	loss_cls: 0.6106	loss_other: 0.0570
[client 18 neighGen phase]	acc_degree: 0.7376	acc_cls: 0.9362	loss_train: 0.0454	loss_degree: 0.2241	loss_feat: 0.0067	loss_cls: 0.5548	loss_other: 0.1215
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9139	loss_train: 0.0479	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.7755	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9205	loss_train: 0.0448	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.7147	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9404	loss_train: 0.0415	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.6486	loss_other: 0.0000
[server]	loss_train: 2.3163	loss_val: 2.3550	loss_test: 2.3476	accuracy_train: 0.0746	accuracy_val: 0.0618	accuracy_test: 0.0824
[server]	loss_train: 2.3318	loss_val: 2.3371	loss_test: 2.3170	accuracy_train: 0.1017	accuracy_val: 0.1053	accuracy_test: 0.1240
[server]	loss_train: 2.3395	loss_val: 2.3753	loss_test: 2.3592	accuracy_train: 0.0920	accuracy_val: 0.0659	accuracy_test: 0.0625
[server]	loss_train: 2.3066	loss_val: 2.3201	loss_test: 2.3063	accuracy_train: 0.0667	accuracy_val: 0.0922	accuracy_test: 0.1099
[server]	loss_train: 2.3538	loss_val: 2.3289	loss_test: 2.3189	accuracy_train: 0.1200	accuracy_val: 0.1016	accuracy_test: 0.1379
[server]	loss_train: 2.3086	loss_val: 2.3127	loss_test: 2.3046	accuracy_train: 0.0945	accuracy_val: 0.1145	accuracy_test: 0.0947
[server]	loss_train: 2.3946	loss_val: 2.4021	loss_test: 2.3890	accuracy_train: 0.0609	accuracy_val: 0.1079	accuracy_test: 0.0868
[server]	loss_train: 2.2895	loss_val: 2.2933	loss_test: 2.3176	accuracy_train: 0.1504	accuracy_val: 0.1223	accuracy_test: 0.1032
[server]	loss_train: 2.3428	loss_val: 2.3536	loss_test: 2.3436	accuracy_train: 0.0880	accuracy_val: 0.1158	accuracy_test: 0.0992
[server]	loss_train: 2.3404	loss_val: 2.3415	loss_test: 2.3347	accuracy_train: 0.1095	accuracy_val: 0.0883	accuracy_test: 0.1049
[server]	loss_train: 2.3546	loss_val: 2.3257	loss_test: 2.3258	accuracy_train: 0.0763	accuracy_val: 0.1045	accuracy_test: 0.0882
[server]	loss_train: 2.3064	loss_val: 2.3143	loss_test: 2.3198	accuracy_train: 0.0833	accuracy_val: 0.1095	accuracy_test: 0.1159
[server]	loss_train: 2.3541	loss_val: 2.3844	loss_test: 2.3755	accuracy_train: 0.1045	accuracy_val: 0.0903	accuracy_test: 0.0821
[server]	loss_train: 2.2988	loss_val: 2.3100	loss_test: 2.3112	accuracy_train: 0.1103	accuracy_val: 0.1000	accuracy_test: 0.1404
[server]	loss_train: 2.3535	loss_val: 2.3719	loss_test: 2.3651	accuracy_train: 0.1224	accuracy_val: 0.0872	accuracy_test: 0.1000
[server]	loss_train: 2.2717	loss_val: 2.2768	loss_test: 2.2717	accuracy_train: 0.1071	accuracy_val: 0.1038	accuracy_test: 0.0959
[server]	loss_train: 2.3449	loss_val: 2.3229	loss_test: 2.3546	accuracy_train: 0.0809	accuracy_val: 0.0929	accuracy_test: 0.1127
[server]	loss_train: 2.2917	loss_val: 2.3083	loss_test: 2.2887	accuracy_train: 0.1081	accuracy_val: 0.1478	accuracy_test: 0.0983
[server]	loss_train: 2.2396	loss_val: 2.2482	loss_test: 2.2472	accuracy_train: 0.1489	accuracy_val: 0.1359	accuracy_test: 0.1276
[server]	loss_train: 2.3565	loss_val: 2.3494	loss_test: 2.3542	accuracy_train: 0.0861	accuracy_val: 0.0452	accuracy_test: 0.0540
curr_round: 4	curr_val_accuracy: 0.0984	curr_test_accuracy: 0.1003
best_round: 0	best_val_accuracy: 0.0984	best_test_accuracy: 0.1003
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9328	loss_train: 0.0461	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.6867	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9478	loss_train: 0.0434	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.6330	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9478	loss_train: 0.0410	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.5841	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 0.9746	loss_train: 0.0388	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.5553	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0358	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.4957	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0332	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.4439	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.9632	loss_train: 0.0398	loss_degree: 0.2459	loss_feat: 0.0000	loss_cls: 0.5499	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7055	acc_cls: 0.9632	loss_train: 0.0360	loss_degree: 0.2257	loss_feat: 0.0000	loss_cls: 0.4935	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7055	acc_cls: 0.9693	loss_train: 0.0365	loss_degree: 0.2119	loss_feat: 0.0024	loss_cls: 0.4451	loss_other: 0.0711
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9778	loss_train: 0.0542	loss_degree: 0.4569	loss_feat: 0.0000	loss_cls: 0.6272	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9852	loss_train: 0.0511	loss_degree: 0.4551	loss_feat: 0.0000	loss_cls: 0.5664	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9852	loss_train: 0.0481	loss_degree: 0.4522	loss_feat: 0.0000	loss_cls: 0.5091	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.6800	acc_cls: 0.9440	loss_train: 0.0530	loss_degree: 0.3116	loss_feat: 0.0018	loss_cls: 0.7114	loss_other: 0.0358
[client 4 neighGen phase]	acc_degree: 0.6880	acc_cls: 0.9440	loss_train: 0.0491	loss_degree: 0.3065	loss_feat: 0.0010	loss_cls: 0.6523	loss_other: 0.0225
[client 4 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.9520	loss_train: 0.0459	loss_degree: 0.2958	loss_feat: 0.0010	loss_cls: 0.5980	loss_other: 0.0234
[client 5 neighGen phase]	acc_degree: 0.7953	acc_cls: 0.9134	loss_train: 0.0445	loss_degree: 0.1234	loss_feat: 0.0016	loss_cls: 0.7262	loss_other: 0.0379
[client 5 neighGen phase]	acc_degree: 0.8031	acc_cls: 0.9213	loss_train: 0.0450	loss_degree: 0.1235	loss_feat: 0.0039	loss_cls: 0.6753	loss_other: 0.0970
[client 5 neighGen phase]	acc_degree: 0.8031	acc_cls: 0.9449	loss_train: 0.0408	loss_degree: 0.1066	loss_feat: 0.0037	loss_cls: 0.6215	loss_other: 0.0839
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.9478	loss_train: 0.0422	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.5954	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.9739	loss_train: 0.0392	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.5353	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.9826	loss_train: 0.0366	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.4833	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.9850	loss_train: 0.0398	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.5747	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.9850	loss_train: 0.0371	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.5194	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.9850	loss_train: 0.0347	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.4723	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.9200	loss_train: 0.0467	loss_degree: 0.2037	loss_feat: 0.0003	loss_cls: 0.7204	loss_other: 0.0098
[client 8 neighGen phase]	acc_degree: 0.7040	acc_cls: 0.9520	loss_train: 0.0440	loss_degree: 0.1869	loss_feat: 0.0010	loss_cls: 0.6659	loss_other: 0.0263
[client 8 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.9440	loss_train: 0.0438	loss_degree: 0.1747	loss_feat: 0.0038	loss_cls: 0.6199	loss_other: 0.0779
[client 9 neighGen phase]	acc_degree: 0.7372	acc_cls: 0.9708	loss_train: 0.0369	loss_degree: 0.1499	loss_feat: 0.0047	loss_cls: 0.5165	loss_other: 0.0669
[client 9 neighGen phase]	acc_degree: 0.7445	acc_cls: 0.9854	loss_train: 0.0340	loss_degree: 0.1346	loss_feat: 0.0049	loss_cls: 0.4636	loss_other: 0.0765
[client 9 neighGen phase]	acc_degree: 0.7518	acc_cls: 0.9854	loss_train: 0.0322	loss_degree: 0.1223	loss_feat: 0.0057	loss_cls: 0.4166	loss_other: 0.0992
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.9847	loss_train: 0.0338	loss_degree: 0.1555	loss_feat: 0.0000	loss_cls: 0.5195	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 0.9924	loss_train: 0.0309	loss_degree: 0.1501	loss_feat: 0.0000	loss_cls: 0.4672	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 1.0000	loss_train: 0.0283	loss_degree: 0.1455	loss_feat: 0.0000	loss_cls: 0.4213	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.8182	acc_cls: 0.9697	loss_train: 0.0345	loss_degree: 0.1380	loss_feat: 0.0026	loss_cls: 0.5031	loss_other: 0.0469
[client 11 neighGen phase]	acc_degree: 0.8409	acc_cls: 0.9773	loss_train: 0.0326	loss_degree: 0.0991	loss_feat: 0.0043	loss_cls: 0.4502	loss_other: 0.0982
[client 11 neighGen phase]	acc_degree: 0.7500	acc_cls: 0.9848	loss_train: 0.0445	loss_degree: 0.2227	loss_feat: 0.0112	loss_cls: 0.4034	loss_other: 0.2529
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.9328	loss_train: 0.0373	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.5930	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.9627	loss_train: 0.0345	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.5374	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.9627	loss_train: 0.0320	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.4867	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7206	acc_cls: 0.9485	loss_train: 0.0378	loss_degree: 0.1361	loss_feat: 0.0000	loss_cls: 0.6199	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7206	acc_cls: 0.9559	loss_train: 0.0348	loss_degree: 0.1274	loss_feat: 0.0000	loss_cls: 0.5679	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.9706	loss_train: 0.0333	loss_degree: 0.1222	loss_feat: 0.0013	loss_cls: 0.5163	loss_other: 0.0254
[client 14 neighGen phase]	acc_degree: 0.7075	acc_cls: 0.9592	loss_train: 0.0424	loss_degree: 0.1623	loss_feat: 0.0074	loss_cls: 0.5795	loss_other: 0.0990
[client 14 neighGen phase]	acc_degree: 0.6939	acc_cls: 0.9660	loss_train: 0.0354	loss_degree: 0.1486	loss_feat: 0.0021	loss_cls: 0.5277	loss_other: 0.0302
[client 14 neighGen phase]	acc_degree: 0.6871	acc_cls: 0.9728	loss_train: 0.0319	loss_degree: 0.1497	loss_feat: 0.0006	loss_cls: 0.4793	loss_other: 0.0084
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9143	loss_train: 0.0468	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.6931	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9071	loss_train: 0.0441	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.6394	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9071	loss_train: 0.0417	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.5914	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.9044	loss_train: 0.0536	loss_degree: 0.2312	loss_feat: 0.0034	loss_cls: 0.7691	loss_other: 0.0685
[client 16 neighGen phase]	acc_degree: 0.7426	acc_cls: 0.9265	loss_train: 0.0490	loss_degree: 0.2328	loss_feat: 0.0015	loss_cls: 0.7152	loss_other: 0.0305
[client 16 neighGen phase]	acc_degree: 0.7426	acc_cls: 0.9191	loss_train: 0.0463	loss_degree: 0.2309	loss_feat: 0.0010	loss_cls: 0.6703	loss_other: 0.0231
[client 17 neighGen phase]	acc_degree: 0.8649	acc_cls: 0.9640	loss_train: 0.0327	loss_degree: 0.0796	loss_feat: 0.0005	loss_cls: 0.5542	loss_other: 0.0201
[client 17 neighGen phase]	acc_degree: 0.8649	acc_cls: 0.9640	loss_train: 0.0298	loss_degree: 0.0793	loss_feat: 0.0005	loss_cls: 0.5031	loss_other: 0.0141
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.9730	loss_train: 0.0266	loss_degree: 0.0791	loss_feat: 0.0000	loss_cls: 0.4530	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.7447	acc_cls: 0.9291	loss_train: 0.0407	loss_degree: 0.2080	loss_feat: 0.0054	loss_cls: 0.5054	loss_other: 0.0954
[client 18 neighGen phase]	acc_degree: 0.7021	acc_cls: 0.9362	loss_train: 0.0328	loss_degree: 0.1942	loss_feat: 0.0000	loss_cls: 0.4613	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.7021	acc_cls: 0.9504	loss_train: 0.0306	loss_degree: 0.1940	loss_feat: 0.0000	loss_cls: 0.4182	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9669	loss_train: 0.0385	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.5885	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9603	loss_train: 0.0362	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.5420	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9669	loss_train: 0.0339	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.4966	loss_other: 0.0000
[server]	loss_train: 2.3163	loss_val: 2.3550	loss_test: 2.3476	accuracy_train: 0.0746	accuracy_val: 0.0618	accuracy_test: 0.0824
[server]	loss_train: 2.3318	loss_val: 2.3371	loss_test: 2.3170	accuracy_train: 0.1017	accuracy_val: 0.1053	accuracy_test: 0.1240
[server]	loss_train: 2.3395	loss_val: 2.3753	loss_test: 2.3592	accuracy_train: 0.0920	accuracy_val: 0.0659	accuracy_test: 0.0625
[server]	loss_train: 2.3066	loss_val: 2.3201	loss_test: 2.3063	accuracy_train: 0.0667	accuracy_val: 0.0922	accuracy_test: 0.1099
[server]	loss_train: 2.3538	loss_val: 2.3289	loss_test: 2.3189	accuracy_train: 0.1200	accuracy_val: 0.1016	accuracy_test: 0.1379
[server]	loss_train: 2.3086	loss_val: 2.3127	loss_test: 2.3046	accuracy_train: 0.0945	accuracy_val: 0.1145	accuracy_test: 0.0947
[server]	loss_train: 2.3946	loss_val: 2.4021	loss_test: 2.3890	accuracy_train: 0.0609	accuracy_val: 0.1079	accuracy_test: 0.0868
[server]	loss_train: 2.2895	loss_val: 2.2933	loss_test: 2.3176	accuracy_train: 0.1504	accuracy_val: 0.1223	accuracy_test: 0.1032
[server]	loss_train: 2.3428	loss_val: 2.3536	loss_test: 2.3436	accuracy_train: 0.0880	accuracy_val: 0.1158	accuracy_test: 0.0992
[server]	loss_train: 2.3404	loss_val: 2.3415	loss_test: 2.3347	accuracy_train: 0.1095	accuracy_val: 0.0883	accuracy_test: 0.1049
[server]	loss_train: 2.3546	loss_val: 2.3257	loss_test: 2.3258	accuracy_train: 0.0763	accuracy_val: 0.1045	accuracy_test: 0.0882
[server]	loss_train: 2.3064	loss_val: 2.3143	loss_test: 2.3198	accuracy_train: 0.0833	accuracy_val: 0.1095	accuracy_test: 0.1159
[server]	loss_train: 2.3541	loss_val: 2.3844	loss_test: 2.3755	accuracy_train: 0.1045	accuracy_val: 0.0903	accuracy_test: 0.0821
[server]	loss_train: 2.2988	loss_val: 2.3100	loss_test: 2.3112	accuracy_train: 0.1103	accuracy_val: 0.1000	accuracy_test: 0.1404
[server]	loss_train: 2.3535	loss_val: 2.3719	loss_test: 2.3651	accuracy_train: 0.1224	accuracy_val: 0.0872	accuracy_test: 0.1000
[server]	loss_train: 2.2717	loss_val: 2.2768	loss_test: 2.2717	accuracy_train: 0.1071	accuracy_val: 0.1038	accuracy_test: 0.0959
[server]	loss_train: 2.3449	loss_val: 2.3229	loss_test: 2.3546	accuracy_train: 0.0809	accuracy_val: 0.0929	accuracy_test: 0.1127
[server]	loss_train: 2.2917	loss_val: 2.3083	loss_test: 2.2887	accuracy_train: 0.1081	accuracy_val: 0.1478	accuracy_test: 0.0983
[server]	loss_train: 2.2396	loss_val: 2.2482	loss_test: 2.2472	accuracy_train: 0.1489	accuracy_val: 0.1359	accuracy_test: 0.1276
[server]	loss_train: 2.3565	loss_val: 2.3494	loss_test: 2.3542	accuracy_train: 0.0861	accuracy_val: 0.0452	accuracy_test: 0.0540
curr_round: 5	curr_val_accuracy: 0.0984	curr_test_accuracy: 0.1003
best_round: 0	best_val_accuracy: 0.0984	best_test_accuracy: 0.1003
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9478	loss_train: 0.0387	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.5389	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9552	loss_train: 0.0366	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.4971	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9552	loss_train: 0.0347	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.4581	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0310	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.4001	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0290	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.3603	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0272	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.3231	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7055	acc_cls: 0.9755	loss_train: 0.0386	loss_degree: 0.2358	loss_feat: 0.0066	loss_cls: 0.4015	loss_other: 0.1291
[client 2 neighGen phase]	acc_degree: 0.7362	acc_cls: 0.9755	loss_train: 0.0359	loss_degree: 0.2205	loss_feat: 0.0068	loss_cls: 0.3623	loss_other: 0.1284
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.9816	loss_train: 0.0278	loss_degree: 0.2020	loss_feat: 0.0007	loss_cls: 0.3280	loss_other: 0.0260
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9778	loss_train: 0.0451	loss_degree: 0.4400	loss_feat: 0.0000	loss_cls: 0.4629	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9852	loss_train: 0.0420	loss_degree: 0.4213	loss_feat: 0.0000	loss_cls: 0.4186	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.6963	acc_cls: 0.9852	loss_train: 0.0399	loss_degree: 0.4230	loss_feat: 0.0000	loss_cls: 0.3740	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.7040	acc_cls: 0.9600	loss_train: 0.0455	loss_degree: 0.2870	loss_feat: 0.0037	loss_cls: 0.5491	loss_other: 0.0698
[client 4 neighGen phase]	acc_degree: 0.6960	acc_cls: 0.9760	loss_train: 0.0437	loss_degree: 0.2852	loss_feat: 0.0045	loss_cls: 0.5031	loss_other: 0.0812
[client 4 neighGen phase]	acc_degree: 0.7280	acc_cls: 0.9760	loss_train: 0.0404	loss_degree: 0.2733	loss_feat: 0.0041	loss_cls: 0.4598	loss_other: 0.0707
[client 5 neighGen phase]	acc_degree: 0.7874	acc_cls: 0.9685	loss_train: 0.0359	loss_degree: 0.1011	loss_feat: 0.0024	loss_cls: 0.5715	loss_other: 0.0427
[client 5 neighGen phase]	acc_degree: 0.7874	acc_cls: 0.9764	loss_train: 0.0339	loss_degree: 0.0934	loss_feat: 0.0027	loss_cls: 0.5308	loss_other: 0.0502
[client 5 neighGen phase]	acc_degree: 0.8031	acc_cls: 0.9764	loss_train: 0.0338	loss_degree: 0.0822	loss_feat: 0.0043	loss_cls: 0.4884	loss_other: 0.1008
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 0.9913	loss_train: 0.0343	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.4372	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 1.0000	loss_train: 0.0321	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.3939	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 1.0000	loss_train: 0.0303	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.3572	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 0.9925	loss_train: 0.0325	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.4285	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 1.0000	loss_train: 0.0304	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.3870	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 1.0000	loss_train: 0.0286	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.3509	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.7120	acc_cls: 0.9440	loss_train: 0.0430	loss_degree: 0.1717	loss_feat: 0.0055	loss_cls: 0.5705	loss_other: 0.1122
[client 8 neighGen phase]	acc_degree: 0.7200	acc_cls: 0.9600	loss_train: 0.0380	loss_degree: 0.1514	loss_feat: 0.0035	loss_cls: 0.5278	loss_other: 0.0778
[client 8 neighGen phase]	acc_degree: 0.7120	acc_cls: 0.9680	loss_train: 0.0353	loss_degree: 0.1465	loss_feat: 0.0033	loss_cls: 0.4896	loss_other: 0.0669
[client 9 neighGen phase]	acc_degree: 0.7737	acc_cls: 0.9854	loss_train: 0.0320	loss_degree: 0.1105	loss_feat: 0.0078	loss_cls: 0.3729	loss_other: 0.1484
[client 9 neighGen phase]	acc_degree: 0.8321	acc_cls: 0.9854	loss_train: 0.0346	loss_degree: 0.1018	loss_feat: 0.0132	loss_cls: 0.3337	loss_other: 0.2432
[client 9 neighGen phase]	acc_degree: 0.7810	acc_cls: 0.9927	loss_train: 0.0275	loss_degree: 0.0911	loss_feat: 0.0078	loss_cls: 0.2995	loss_other: 0.1517
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 1.0000	loss_train: 0.0262	loss_degree: 0.1418	loss_feat: 0.0000	loss_cls: 0.3822	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 1.0000	loss_train: 0.0240	loss_degree: 0.1354	loss_feat: 0.0000	loss_cls: 0.3455	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 1.0000	loss_train: 0.0219	loss_degree: 0.1266	loss_feat: 0.0000	loss_cls: 0.3105	loss_other: 0.0000
[client 11 neighGen phase]	acc_degree: 0.8333	acc_cls: 0.9848	loss_train: 0.0269	loss_degree: 0.1013	loss_feat: 0.0034	loss_cls: 0.3616	loss_other: 0.0711
[client 11 neighGen phase]	acc_degree: 0.8258	acc_cls: 0.9848	loss_train: 0.0252	loss_degree: 0.1304	loss_feat: 0.0021	loss_cls: 0.3233	loss_other: 0.0478
[client 11 neighGen phase]	acc_degree: 0.8106	acc_cls: 0.9848	loss_train: 0.0230	loss_degree: 0.1406	loss_feat: 0.0016	loss_cls: 0.2887	loss_other: 0.0291
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.9627	loss_train: 0.0296	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.4390	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.9701	loss_train: 0.0275	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.3961	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.9776	loss_train: 0.0256	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.3584	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.9706	loss_train: 0.0314	loss_degree: 0.1119	loss_feat: 0.0020	loss_cls: 0.4700	loss_other: 0.0445
[client 13 neighGen phase]	acc_degree: 0.7279	acc_cls: 0.9853	loss_train: 0.0280	loss_degree: 0.0997	loss_feat: 0.0015	loss_cls: 0.4277	loss_other: 0.0306
[client 13 neighGen phase]	acc_degree: 0.7279	acc_cls: 0.9926	loss_train: 0.0262	loss_degree: 0.0933	loss_feat: 0.0018	loss_cls: 0.3887	loss_other: 0.0401
[client 14 neighGen phase]	acc_degree: 0.6939	acc_cls: 0.9728	loss_train: 0.0298	loss_degree: 0.1454	loss_feat: 0.0012	loss_cls: 0.4366	loss_other: 0.0130
[client 14 neighGen phase]	acc_degree: 0.7075	acc_cls: 0.9728	loss_train: 0.0290	loss_degree: 0.1352	loss_feat: 0.0035	loss_cls: 0.3997	loss_other: 0.0418
[client 14 neighGen phase]	acc_degree: 0.6871	acc_cls: 0.9796	loss_train: 0.0261	loss_degree: 0.1217	loss_feat: 0.0023	loss_cls: 0.3662	loss_other: 0.0319
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9071	loss_train: 0.0395	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.5475	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9286	loss_train: 0.0373	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.5022	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9571	loss_train: 0.0352	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.4612	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.9265	loss_train: 0.0454	loss_degree: 0.2200	loss_feat: 0.0027	loss_cls: 0.6244	loss_other: 0.0616
[client 16 neighGen phase]	acc_degree: 0.7353	acc_cls: 0.9485	loss_train: 0.0438	loss_degree: 0.2093	loss_feat: 0.0041	loss_cls: 0.5791	loss_other: 0.0844
[client 16 neighGen phase]	acc_degree: 0.7279	acc_cls: 0.9559	loss_train: 0.0426	loss_degree: 0.2061	loss_feat: 0.0048	loss_cls: 0.5371	loss_other: 0.1040
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.9730	loss_train: 0.0244	loss_degree: 0.0787	loss_feat: 0.0000	loss_cls: 0.4084	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.9730	loss_train: 0.0224	loss_degree: 0.0781	loss_feat: 0.0000	loss_cls: 0.3695	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.9820	loss_train: 0.0206	loss_degree: 0.0774	loss_feat: 0.0000	loss_cls: 0.3336	loss_other: 0.0000
[client 18 neighGen phase]	acc_degree: 0.7163	acc_cls: 0.9504	loss_train: 0.0296	loss_degree: 0.1826	loss_feat: 0.0017	loss_cls: 0.3813	loss_other: 0.0256
[client 18 neighGen phase]	acc_degree: 0.7305	acc_cls: 0.9504	loss_train: 0.0306	loss_degree: 0.1845	loss_feat: 0.0039	loss_cls: 0.3480	loss_other: 0.0760
[client 18 neighGen phase]	acc_degree: 0.7376	acc_cls: 0.9574	loss_train: 0.0276	loss_degree: 0.1720	loss_feat: 0.0034	loss_cls: 0.3166	loss_other: 0.0605
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9735	loss_train: 0.0317	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.4520	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9801	loss_train: 0.0297	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.4126	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9801	loss_train: 0.0279	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.3765	loss_other: 0.0000
[server]	loss_train: 2.3163	loss_val: 2.3550	loss_test: 2.3476	accuracy_train: 0.0746	accuracy_val: 0.0618	accuracy_test: 0.0824
[server]	loss_train: 2.3318	loss_val: 2.3371	loss_test: 2.3170	accuracy_train: 0.1017	accuracy_val: 0.1053	accuracy_test: 0.1240
[server]	loss_train: 2.3395	loss_val: 2.3753	loss_test: 2.3592	accuracy_train: 0.0920	accuracy_val: 0.0659	accuracy_test: 0.0625
[server]	loss_train: 2.3066	loss_val: 2.3201	loss_test: 2.3063	accuracy_train: 0.0667	accuracy_val: 0.0922	accuracy_test: 0.1099
[server]	loss_train: 2.3538	loss_val: 2.3289	loss_test: 2.3189	accuracy_train: 0.1200	accuracy_val: 0.1016	accuracy_test: 0.1379
[server]	loss_train: 2.3086	loss_val: 2.3127	loss_test: 2.3046	accuracy_train: 0.0945	accuracy_val: 0.1145	accuracy_test: 0.0947
[server]	loss_train: 2.3946	loss_val: 2.4021	loss_test: 2.3890	accuracy_train: 0.0609	accuracy_val: 0.1079	accuracy_test: 0.0868
[server]	loss_train: 2.2895	loss_val: 2.2933	loss_test: 2.3176	accuracy_train: 0.1504	accuracy_val: 0.1223	accuracy_test: 0.1032
[server]	loss_train: 2.3428	loss_val: 2.3536	loss_test: 2.3436	accuracy_train: 0.0880	accuracy_val: 0.1158	accuracy_test: 0.0992
[server]	loss_train: 2.3404	loss_val: 2.3415	loss_test: 2.3347	accuracy_train: 0.1095	accuracy_val: 0.0883	accuracy_test: 0.1049
[server]	loss_train: 2.3546	loss_val: 2.3257	loss_test: 2.3258	accuracy_train: 0.0763	accuracy_val: 0.1045	accuracy_test: 0.0882
[server]	loss_train: 2.3064	loss_val: 2.3143	loss_test: 2.3198	accuracy_train: 0.0833	accuracy_val: 0.1095	accuracy_test: 0.1159
[server]	loss_train: 2.3541	loss_val: 2.3844	loss_test: 2.3755	accuracy_train: 0.1045	accuracy_val: 0.0903	accuracy_test: 0.0821
[server]	loss_train: 2.2988	loss_val: 2.3100	loss_test: 2.3112	accuracy_train: 0.1103	accuracy_val: 0.1000	accuracy_test: 0.1404
[server]	loss_train: 2.3535	loss_val: 2.3719	loss_test: 2.3651	accuracy_train: 0.1224	accuracy_val: 0.0872	accuracy_test: 0.1000
[server]	loss_train: 2.2717	loss_val: 2.2768	loss_test: 2.2717	accuracy_train: 0.1071	accuracy_val: 0.1038	accuracy_test: 0.0959
[server]	loss_train: 2.3449	loss_val: 2.3229	loss_test: 2.3546	accuracy_train: 0.0809	accuracy_val: 0.0929	accuracy_test: 0.1127
[server]	loss_train: 2.2917	loss_val: 2.3083	loss_test: 2.2887	accuracy_train: 0.1081	accuracy_val: 0.1478	accuracy_test: 0.0983
[server]	loss_train: 2.2396	loss_val: 2.2482	loss_test: 2.2472	accuracy_train: 0.1489	accuracy_val: 0.1359	accuracy_test: 0.1276
[server]	loss_train: 2.3565	loss_val: 2.3494	loss_test: 2.3542	accuracy_train: 0.0861	accuracy_val: 0.0452	accuracy_test: 0.0540
curr_round: 6	curr_val_accuracy: 0.0984	curr_test_accuracy: 0.1003
best_round: 0	best_val_accuracy: 0.0984	best_test_accuracy: 0.1003
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9701	loss_train: 0.0328	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.4213	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9701	loss_train: 0.0311	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.3878	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9776	loss_train: 0.0296	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.3575	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0255	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.2897	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0241	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.2612	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0228	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.2358	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.9816	loss_train: 0.0254	loss_degree: 0.2098	loss_feat: 0.0000	loss_cls: 0.2974	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.9816	loss_train: 0.0238	loss_degree: 0.2056	loss_feat: 0.0000	loss_cls: 0.2708	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.9877	loss_train: 0.0220	loss_degree: 0.1937	loss_feat: 0.0000	loss_cls: 0.2468	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9926	loss_train: 0.0370	loss_degree: 0.4021	loss_feat: 0.0000	loss_cls: 0.3374	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9926	loss_train: 0.0353	loss_degree: 0.3998	loss_feat: 0.0000	loss_cls: 0.3067	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9926	loss_train: 0.0340	loss_degree: 0.4029	loss_feat: 0.0000	loss_cls: 0.2769	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.7040	acc_cls: 0.9840	loss_train: 0.0367	loss_degree: 0.2681	loss_feat: 0.0021	loss_cls: 0.4223	loss_other: 0.0412
[client 4 neighGen phase]	acc_degree: 0.7200	acc_cls: 0.9920	loss_train: 0.0354	loss_degree: 0.2551	loss_feat: 0.0037	loss_cls: 0.3875	loss_other: 0.0620
[client 4 neighGen phase]	acc_degree: 0.7360	acc_cls: 0.9920	loss_train: 0.0354	loss_degree: 0.2513	loss_feat: 0.0054	loss_cls: 0.3538	loss_other: 0.0966
[client 5 neighGen phase]	acc_degree: 0.8031	acc_cls: 0.9764	loss_train: 0.0320	loss_degree: 0.0770	loss_feat: 0.0047	loss_cls: 0.4456	loss_other: 0.1124
[client 5 neighGen phase]	acc_degree: 0.7795	acc_cls: 0.9843	loss_train: 0.0268	loss_degree: 0.0640	loss_feat: 0.0028	loss_cls: 0.4099	loss_other: 0.0598
[client 5 neighGen phase]	acc_degree: 0.7795	acc_cls: 0.9843	loss_train: 0.0256	loss_degree: 0.0589	loss_feat: 0.0033	loss_cls: 0.3790	loss_other: 0.0715
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 1.0000	loss_train: 0.0286	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.3240	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 1.0000	loss_train: 0.0271	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.2949	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 1.0000	loss_train: 0.0258	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.2677	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 1.0000	loss_train: 0.0270	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.3176	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 1.0000	loss_train: 0.0254	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.2869	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 1.0000	loss_train: 0.0241	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.2599	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.7200	acc_cls: 0.9600	loss_train: 0.0334	loss_degree: 0.1289	loss_feat: 0.0039	loss_cls: 0.4512	loss_other: 0.0849
[client 8 neighGen phase]	acc_degree: 0.7520	acc_cls: 0.9680	loss_train: 0.0359	loss_degree: 0.1268	loss_feat: 0.0073	loss_cls: 0.4175	loss_other: 0.1664
[client 8 neighGen phase]	acc_degree: 0.7440	acc_cls: 0.9840	loss_train: 0.0329	loss_degree: 0.1057	loss_feat: 0.0068	loss_cls: 0.3860	loss_other: 0.1594
[client 9 neighGen phase]	acc_degree: 0.8540	acc_cls: 0.9927	loss_train: 0.0327	loss_degree: 0.0800	loss_feat: 0.0155	loss_cls: 0.2690	loss_other: 0.2897
[client 9 neighGen phase]	acc_degree: 0.8467	acc_cls: 0.9927	loss_train: 0.0292	loss_degree: 0.0698	loss_feat: 0.0141	loss_cls: 0.2413	loss_other: 0.2591
[client 9 neighGen phase]	acc_degree: 0.8321	acc_cls: 0.9927	loss_train: 0.0252	loss_degree: 0.0620	loss_feat: 0.0116	loss_cls: 0.2166	loss_other: 0.2145
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 1.0000	loss_train: 0.0201	loss_degree: 0.1217	loss_feat: 0.0000	loss_cls: 0.2801	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 1.0000	loss_train: 0.0185	loss_degree: 0.1157	loss_feat: 0.0000	loss_cls: 0.2542	loss_other: 0.0000
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 1.0000	loss_train: 0.0189	loss_degree: 0.1050	loss_feat: 0.0014	loss_cls: 0.2305	loss_other: 0.0414
[client 11 neighGen phase]	acc_degree: 0.8030	acc_cls: 0.9848	loss_train: 0.0212	loss_degree: 0.1443	loss_feat: 0.0013	loss_cls: 0.2576	loss_other: 0.0199
[client 11 neighGen phase]	acc_degree: 0.8030	acc_cls: 1.0000	loss_train: 0.0198	loss_degree: 0.1453	loss_feat: 0.0012	loss_cls: 0.2297	loss_other: 0.0189
[client 11 neighGen phase]	acc_degree: 0.8030	acc_cls: 1.0000	loss_train: 0.0185	loss_degree: 0.1439	loss_feat: 0.0012	loss_cls: 0.2049	loss_other: 0.0195
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 0.9851	loss_train: 0.0238	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.3237	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 1.0000	loss_train: 0.0222	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.2909	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 1.0000	loss_train: 0.0207	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.2615	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7500	acc_cls: 1.0000	loss_train: 0.0256	loss_degree: 0.0847	loss_feat: 0.0029	loss_cls: 0.3531	loss_other: 0.0709
[client 13 neighGen phase]	acc_degree: 0.7941	acc_cls: 1.0000	loss_train: 0.0263	loss_degree: 0.0765	loss_feat: 0.0062	loss_cls: 0.3206	loss_other: 0.1234
[client 13 neighGen phase]	acc_degree: 0.7794	acc_cls: 1.0000	loss_train: 0.0233	loss_degree: 0.0656	loss_feat: 0.0052	loss_cls: 0.2900	loss_other: 0.1044
[client 14 neighGen phase]	acc_degree: 0.7075	acc_cls: 0.9796	loss_train: 0.0258	loss_degree: 0.1176	loss_feat: 0.0039	loss_cls: 0.3346	loss_other: 0.0603
[client 14 neighGen phase]	acc_degree: 0.7687	acc_cls: 0.9864	loss_train: 0.0284	loss_degree: 0.1144	loss_feat: 0.0089	loss_cls: 0.3052	loss_other: 0.1393
[client 14 neighGen phase]	acc_degree: 0.7211	acc_cls: 0.9864	loss_train: 0.0235	loss_degree: 0.0996	loss_feat: 0.0054	loss_cls: 0.2786	loss_other: 0.0859
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9714	loss_train: 0.0335	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.4273	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9643	loss_train: 0.0318	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.3929	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9571	loss_train: 0.0302	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.3615	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7426	acc_cls: 0.9632	loss_train: 0.0402	loss_degree: 0.1951	loss_feat: 0.0051	loss_cls: 0.4991	loss_other: 0.1043
[client 16 neighGen phase]	acc_degree: 0.7500	acc_cls: 0.9632	loss_train: 0.0376	loss_degree: 0.1800	loss_feat: 0.0050	loss_cls: 0.4637	loss_other: 0.1037
[client 16 neighGen phase]	acc_degree: 0.7426	acc_cls: 0.9632	loss_train: 0.0342	loss_degree: 0.1714	loss_feat: 0.0037	loss_cls: 0.4286	loss_other: 0.0803
[client 17 neighGen phase]	acc_degree: 0.8559	acc_cls: 0.9910	loss_train: 0.0188	loss_degree: 0.0769	loss_feat: 0.0000	loss_cls: 0.2998	loss_other: 0.0000
[client 17 neighGen phase]	acc_degree: 0.8739	acc_cls: 0.9910	loss_train: 0.0191	loss_degree: 0.0767	loss_feat: 0.0008	loss_cls: 0.2694	loss_other: 0.0348
[client 17 neighGen phase]	acc_degree: 0.8919	acc_cls: 0.9910	loss_train: 0.0193	loss_degree: 0.0767	loss_feat: 0.0015	loss_cls: 0.2426	loss_other: 0.0646
[client 18 neighGen phase]	acc_degree: 0.7092	acc_cls: 0.9574	loss_train: 0.0236	loss_degree: 0.1690	loss_feat: 0.0014	loss_cls: 0.2889	loss_other: 0.0133
[client 18 neighGen phase]	acc_degree: 0.7305	acc_cls: 0.9716	loss_train: 0.0243	loss_degree: 0.1536	loss_feat: 0.0035	loss_cls: 0.2635	loss_other: 0.0661
[client 18 neighGen phase]	acc_degree: 0.8014	acc_cls: 0.9716	loss_train: 0.0292	loss_degree: 0.1519	loss_feat: 0.0090	loss_cls: 0.2396	loss_other: 0.1829
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9801	loss_train: 0.0263	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.3434	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9801	loss_train: 0.0248	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.3130	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9801	loss_train: 0.0234	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.2864	loss_other: 0.0000
[server]	loss_train: 2.3163	loss_val: 2.3550	loss_test: 2.3476	accuracy_train: 0.0746	accuracy_val: 0.0618	accuracy_test: 0.0824
[server]	loss_train: 2.3318	loss_val: 2.3371	loss_test: 2.3170	accuracy_train: 0.1017	accuracy_val: 0.1053	accuracy_test: 0.1240
[server]	loss_train: 2.3395	loss_val: 2.3753	loss_test: 2.3592	accuracy_train: 0.0920	accuracy_val: 0.0659	accuracy_test: 0.0625
[server]	loss_train: 2.3066	loss_val: 2.3201	loss_test: 2.3063	accuracy_train: 0.0667	accuracy_val: 0.0922	accuracy_test: 0.1099
[server]	loss_train: 2.3538	loss_val: 2.3289	loss_test: 2.3189	accuracy_train: 0.1200	accuracy_val: 0.1016	accuracy_test: 0.1379
[server]	loss_train: 2.3086	loss_val: 2.3127	loss_test: 2.3046	accuracy_train: 0.0945	accuracy_val: 0.1145	accuracy_test: 0.0947
[server]	loss_train: 2.3946	loss_val: 2.4021	loss_test: 2.3890	accuracy_train: 0.0609	accuracy_val: 0.1079	accuracy_test: 0.0868
[server]	loss_train: 2.2895	loss_val: 2.2933	loss_test: 2.3176	accuracy_train: 0.1504	accuracy_val: 0.1223	accuracy_test: 0.1032
[server]	loss_train: 2.3428	loss_val: 2.3536	loss_test: 2.3436	accuracy_train: 0.0880	accuracy_val: 0.1158	accuracy_test: 0.0992
[server]	loss_train: 2.3404	loss_val: 2.3415	loss_test: 2.3347	accuracy_train: 0.1095	accuracy_val: 0.0883	accuracy_test: 0.1049
[server]	loss_train: 2.3546	loss_val: 2.3257	loss_test: 2.3258	accuracy_train: 0.0763	accuracy_val: 0.1045	accuracy_test: 0.0882
[server]	loss_train: 2.3064	loss_val: 2.3143	loss_test: 2.3198	accuracy_train: 0.0833	accuracy_val: 0.1095	accuracy_test: 0.1159
[server]	loss_train: 2.3541	loss_val: 2.3844	loss_test: 2.3755	accuracy_train: 0.1045	accuracy_val: 0.0903	accuracy_test: 0.0821
[server]	loss_train: 2.2988	loss_val: 2.3100	loss_test: 2.3112	accuracy_train: 0.1103	accuracy_val: 0.1000	accuracy_test: 0.1404
[server]	loss_train: 2.3535	loss_val: 2.3719	loss_test: 2.3651	accuracy_train: 0.1224	accuracy_val: 0.0872	accuracy_test: 0.1000
[server]	loss_train: 2.2717	loss_val: 2.2768	loss_test: 2.2717	accuracy_train: 0.1071	accuracy_val: 0.1038	accuracy_test: 0.0959
[server]	loss_train: 2.3449	loss_val: 2.3229	loss_test: 2.3546	accuracy_train: 0.0809	accuracy_val: 0.0929	accuracy_test: 0.1127
[server]	loss_train: 2.2917	loss_val: 2.3083	loss_test: 2.2887	accuracy_train: 0.1081	accuracy_val: 0.1478	accuracy_test: 0.0983
[server]	loss_train: 2.2396	loss_val: 2.2482	loss_test: 2.2472	accuracy_train: 0.1489	accuracy_val: 0.1359	accuracy_test: 0.1276
[server]	loss_train: 2.3565	loss_val: 2.3494	loss_test: 2.3542	accuracy_train: 0.0861	accuracy_val: 0.0452	accuracy_test: 0.0540
curr_round: 7	curr_val_accuracy: 0.0984	curr_test_accuracy: 0.1003
best_round: 0	best_val_accuracy: 0.0984	best_test_accuracy: 0.1003
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9776	loss_train: 0.0282	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.3292	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9851	loss_train: 0.0269	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.3029	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 0.9925	loss_train: 0.0257	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.2787	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0216	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.2126	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0206	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.1920	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0197	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.1737	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.9939	loss_train: 0.0216	loss_degree: 0.1889	loss_feat: 0.0007	loss_cls: 0.2246	loss_other: 0.0179
[client 2 neighGen phase]	acc_degree: 0.7301	acc_cls: 0.9939	loss_train: 0.0231	loss_degree: 0.1895	loss_feat: 0.0031	loss_cls: 0.2049	loss_other: 0.0646
[client 2 neighGen phase]	acc_degree: 0.7239	acc_cls: 0.9939	loss_train: 0.0210	loss_degree: 0.1829	loss_feat: 0.0018	loss_cls: 0.1873	loss_other: 0.0474
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9926	loss_train: 0.0322	loss_degree: 0.3957	loss_feat: 0.0000	loss_cls: 0.2487	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9926	loss_train: 0.0308	loss_degree: 0.3921	loss_feat: 0.0000	loss_cls: 0.2242	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9926	loss_train: 0.0294	loss_degree: 0.3856	loss_feat: 0.0000	loss_cls: 0.2028	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.7360	acc_cls: 0.9840	loss_train: 0.0327	loss_degree: 0.2380	loss_feat: 0.0044	loss_cls: 0.3228	loss_other: 0.0890
[client 4 neighGen phase]	acc_degree: 0.7360	acc_cls: 0.9840	loss_train: 0.0308	loss_degree: 0.2328	loss_feat: 0.0043	loss_cls: 0.2953	loss_other: 0.0840
[client 4 neighGen phase]	acc_degree: 0.7680	acc_cls: 0.9840	loss_train: 0.0305	loss_degree: 0.2215	loss_feat: 0.0058	loss_cls: 0.2704	loss_other: 0.1115
[client 5 neighGen phase]	acc_degree: 0.8110	acc_cls: 0.9921	loss_train: 0.0255	loss_degree: 0.0520	loss_feat: 0.0048	loss_cls: 0.3462	loss_other: 0.1076
[client 5 neighGen phase]	acc_degree: 0.8268	acc_cls: 0.9921	loss_train: 0.0241	loss_degree: 0.0411	loss_feat: 0.0058	loss_cls: 0.3150	loss_other: 0.1203
[client 5 neighGen phase]	acc_degree: 0.8425	acc_cls: 0.9921	loss_train: 0.0238	loss_degree: 0.0390	loss_feat: 0.0083	loss_cls: 0.2892	loss_other: 0.1395
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 1.0000	loss_train: 0.0245	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.2431	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 1.0000	loss_train: 0.0235	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.2225	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 1.0000	loss_train: 0.0226	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.2041	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 1.0000	loss_train: 0.0228	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.2351	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 1.0000	loss_train: 0.0217	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.2127	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 1.0000	loss_train: 0.0208	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.1932	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.7360	acc_cls: 0.9920	loss_train: 0.0296	loss_degree: 0.1030	loss_feat: 0.0055	loss_cls: 0.3562	loss_other: 0.1279
[client 8 neighGen phase]	acc_degree: 0.7760	acc_cls: 0.9920	loss_train: 0.0305	loss_degree: 0.0884	loss_feat: 0.0083	loss_cls: 0.3292	loss_other: 0.1836
[client 8 neighGen phase]	acc_degree: 0.8000	acc_cls: 1.0000	loss_train: 0.0317	loss_degree: 0.0833	loss_feat: 0.0129	loss_cls: 0.3024	loss_other: 0.2343
[client 9 neighGen phase]	acc_degree: 0.9051	acc_cls: 0.9927	loss_train: 0.0280	loss_degree: 0.0568	loss_feat: 0.0163	loss_cls: 0.1948	loss_other: 0.2925
[client 9 neighGen phase]	acc_degree: 0.7664	acc_cls: 0.9927	loss_train: 0.0188	loss_degree: 0.0602	loss_feat: 0.0070	loss_cls: 0.1755	loss_other: 0.1342
[client 9 neighGen phase]	acc_degree: 0.9343	acc_cls: 1.0000	loss_train: 0.0273	loss_degree: 0.0536	loss_feat: 0.0170	loss_cls: 0.1582	loss_other: 0.3167
[client 10 neighGen phase]	acc_degree: 0.8244	acc_cls: 1.0000	loss_train: 0.0172	loss_degree: 0.0946	loss_feat: 0.0014	loss_cls: 0.2083	loss_other: 0.0398
[client 10 neighGen phase]	acc_degree: 0.8397	acc_cls: 1.0000	loss_train: 0.0171	loss_degree: 0.0882	loss_feat: 0.0028	loss_cls: 0.1883	loss_other: 0.0634
[client 10 neighGen phase]	acc_degree: 0.8397	acc_cls: 1.0000	loss_train: 0.0158	loss_degree: 0.0766	loss_feat: 0.0027	loss_cls: 0.1709	loss_other: 0.0657
[client 11 neighGen phase]	acc_degree: 0.7955	acc_cls: 1.0000	loss_train: 0.0166	loss_degree: 0.1403	loss_feat: 0.0003	loss_cls: 0.1832	loss_other: 0.0083
[client 11 neighGen phase]	acc_degree: 0.8030	acc_cls: 1.0000	loss_train: 0.0160	loss_degree: 0.1332	loss_feat: 0.0013	loss_cls: 0.1642	loss_other: 0.0222
[client 11 neighGen phase]	acc_degree: 0.8030	acc_cls: 1.0000	loss_train: 0.0151	loss_degree: 0.1218	loss_feat: 0.0018	loss_cls: 0.1472	loss_other: 0.0307
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 1.0000	loss_train: 0.0194	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.2352	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 1.0000	loss_train: 0.0182	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.2113	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 1.0000	loss_train: 0.0171	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.1896	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.7941	acc_cls: 1.0000	loss_train: 0.0231	loss_degree: 0.0592	loss_feat: 0.0062	loss_cls: 0.2618	loss_other: 0.1341
[client 13 neighGen phase]	acc_degree: 0.8235	acc_cls: 1.0000	loss_train: 0.0248	loss_degree: 0.0532	loss_feat: 0.0086	loss_cls: 0.2373	loss_other: 0.1963
[client 13 neighGen phase]	acc_degree: 0.8456	acc_cls: 1.0000	loss_train: 0.0244	loss_degree: 0.0438	loss_feat: 0.0096	loss_cls: 0.2153	loss_other: 0.2196
[client 14 neighGen phase]	acc_degree: 0.7619	acc_cls: 0.9932	loss_train: 0.0241	loss_degree: 0.0868	loss_feat: 0.0089	loss_cls: 0.2546	loss_other: 0.1316
[client 14 neighGen phase]	acc_degree: 0.7551	acc_cls: 0.9932	loss_train: 0.0220	loss_degree: 0.0819	loss_feat: 0.0076	loss_cls: 0.2328	loss_other: 0.1184
[client 14 neighGen phase]	acc_degree: 0.7483	acc_cls: 0.9932	loss_train: 0.0202	loss_degree: 0.0741	loss_feat: 0.0062	loss_cls: 0.2130	loss_other: 0.1118
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9571	loss_train: 0.0289	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.3342	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9571	loss_train: 0.0275	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.3069	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9643	loss_train: 0.0262	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.2814	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7500	acc_cls: 0.9706	loss_train: 0.0333	loss_degree: 0.1549	loss_feat: 0.0055	loss_cls: 0.3965	loss_other: 0.1087
[client 16 neighGen phase]	acc_degree: 0.8088	acc_cls: 0.9706	loss_train: 0.0354	loss_degree: 0.1485	loss_feat: 0.0085	loss_cls: 0.3684	loss_other: 0.1833
[client 16 neighGen phase]	acc_degree: 0.8088	acc_cls: 0.9706	loss_train: 0.0321	loss_degree: 0.1312	loss_feat: 0.0076	loss_cls: 0.3412	loss_other: 0.1620
[client 17 neighGen phase]	acc_degree: 0.9009	acc_cls: 0.9910	loss_train: 0.0187	loss_degree: 0.0767	loss_feat: 0.0030	loss_cls: 0.2184	loss_other: 0.0758
[client 17 neighGen phase]	acc_degree: 0.9009	acc_cls: 0.9910	loss_train: 0.0175	loss_degree: 0.0766	loss_feat: 0.0028	loss_cls: 0.1961	loss_other: 0.0741
[client 17 neighGen phase]	acc_degree: 0.9009	acc_cls: 0.9910	loss_train: 0.0162	loss_degree: 0.0764	loss_feat: 0.0028	loss_cls: 0.1758	loss_other: 0.0681
[client 18 neighGen phase]	acc_degree: 0.7518	acc_cls: 0.9716	loss_train: 0.0230	loss_degree: 0.1374	loss_feat: 0.0050	loss_cls: 0.2181	loss_other: 0.0986
[client 18 neighGen phase]	acc_degree: 0.7447	acc_cls: 0.9787	loss_train: 0.0213	loss_degree: 0.1324	loss_feat: 0.0047	loss_cls: 0.1988	loss_other: 0.0910
[client 18 neighGen phase]	acc_degree: 0.8227	acc_cls: 0.9858	loss_train: 0.0254	loss_degree: 0.1242	loss_feat: 0.0101	loss_cls: 0.1810	loss_other: 0.1925
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9868	loss_train: 0.0222	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.2627	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 0.9934	loss_train: 0.0211	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.2406	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 1.0000	loss_train: 0.0201	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.2196	loss_other: 0.0000
[server]	loss_train: 2.3163	loss_val: 2.3550	loss_test: 2.3476	accuracy_train: 0.0746	accuracy_val: 0.0618	accuracy_test: 0.0824
[server]	loss_train: 2.3318	loss_val: 2.3371	loss_test: 2.3170	accuracy_train: 0.1017	accuracy_val: 0.1053	accuracy_test: 0.1240
[server]	loss_train: 2.3395	loss_val: 2.3753	loss_test: 2.3592	accuracy_train: 0.0920	accuracy_val: 0.0659	accuracy_test: 0.0625
[server]	loss_train: 2.3066	loss_val: 2.3201	loss_test: 2.3063	accuracy_train: 0.0667	accuracy_val: 0.0922	accuracy_test: 0.1099
[server]	loss_train: 2.3538	loss_val: 2.3289	loss_test: 2.3189	accuracy_train: 0.1200	accuracy_val: 0.1016	accuracy_test: 0.1379
[server]	loss_train: 2.3086	loss_val: 2.3127	loss_test: 2.3046	accuracy_train: 0.0945	accuracy_val: 0.1145	accuracy_test: 0.0947
[server]	loss_train: 2.3946	loss_val: 2.4021	loss_test: 2.3890	accuracy_train: 0.0609	accuracy_val: 0.1079	accuracy_test: 0.0868
[server]	loss_train: 2.2895	loss_val: 2.2933	loss_test: 2.3176	accuracy_train: 0.1504	accuracy_val: 0.1223	accuracy_test: 0.1032
[server]	loss_train: 2.3428	loss_val: 2.3536	loss_test: 2.3436	accuracy_train: 0.0880	accuracy_val: 0.1158	accuracy_test: 0.0992
[server]	loss_train: 2.3404	loss_val: 2.3415	loss_test: 2.3347	accuracy_train: 0.1095	accuracy_val: 0.0883	accuracy_test: 0.1049
[server]	loss_train: 2.3546	loss_val: 2.3257	loss_test: 2.3258	accuracy_train: 0.0763	accuracy_val: 0.1045	accuracy_test: 0.0882
[server]	loss_train: 2.3064	loss_val: 2.3143	loss_test: 2.3198	accuracy_train: 0.0833	accuracy_val: 0.1095	accuracy_test: 0.1159
[server]	loss_train: 2.3541	loss_val: 2.3844	loss_test: 2.3755	accuracy_train: 0.1045	accuracy_val: 0.0903	accuracy_test: 0.0821
[server]	loss_train: 2.2988	loss_val: 2.3100	loss_test: 2.3112	accuracy_train: 0.1103	accuracy_val: 0.1000	accuracy_test: 0.1404
[server]	loss_train: 2.3535	loss_val: 2.3719	loss_test: 2.3651	accuracy_train: 0.1224	accuracy_val: 0.0872	accuracy_test: 0.1000
[server]	loss_train: 2.2717	loss_val: 2.2768	loss_test: 2.2717	accuracy_train: 0.1071	accuracy_val: 0.1038	accuracy_test: 0.0959
[server]	loss_train: 2.3449	loss_val: 2.3229	loss_test: 2.3546	accuracy_train: 0.0809	accuracy_val: 0.0929	accuracy_test: 0.1127
[server]	loss_train: 2.2917	loss_val: 2.3083	loss_test: 2.2887	accuracy_train: 0.1081	accuracy_val: 0.1478	accuracy_test: 0.0983
[server]	loss_train: 2.2396	loss_val: 2.2482	loss_test: 2.2472	accuracy_train: 0.1489	accuracy_val: 0.1359	accuracy_test: 0.1276
[server]	loss_train: 2.3565	loss_val: 2.3494	loss_test: 2.3542	accuracy_train: 0.0861	accuracy_val: 0.0452	accuracy_test: 0.0540
curr_round: 8	curr_val_accuracy: 0.0984	curr_test_accuracy: 0.1003
best_round: 0	best_val_accuracy: 0.0984	best_test_accuracy: 0.1003
--------------------------------------------------
round # 9		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 1.0000	loss_train: 0.0246	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.2565	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 1.0000	loss_train: 0.0236	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.2360	loss_other: 0.0000
[client 0 neighGen phase]	acc_degree: 0.7388	acc_cls: 1.0000	loss_train: 0.0226	loss_degree: 0.2351	loss_feat: 0.0000	loss_cls: 0.2169	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0189	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.1573	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0182	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.1429	loss_other: 0.0000
[client 1 neighGen phase]	acc_degree: 0.7288	acc_cls: 1.0000	loss_train: 0.0175	loss_degree: 0.2203	loss_feat: 0.0000	loss_cls: 0.1302	loss_other: 0.0000
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.9939	loss_train: 0.0178	loss_degree: 0.1768	loss_feat: 0.0002	loss_cls: 0.1714	loss_other: 0.0067
[client 2 neighGen phase]	acc_degree: 0.7117	acc_cls: 0.9939	loss_train: 0.0169	loss_degree: 0.1740	loss_feat: 0.0002	loss_cls: 0.1572	loss_other: 0.0061
[client 2 neighGen phase]	acc_degree: 0.7178	acc_cls: 0.9939	loss_train: 0.0169	loss_degree: 0.1653	loss_feat: 0.0013	loss_cls: 0.1445	loss_other: 0.0279
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9926	loss_train: 0.0279	loss_degree: 0.3744	loss_feat: 0.0000	loss_cls: 0.1833	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9926	loss_train: 0.0266	loss_degree: 0.3675	loss_feat: 0.0000	loss_cls: 0.1652	loss_other: 0.0000
[client 3 neighGen phase]	acc_degree: 0.7185	acc_cls: 0.9926	loss_train: 0.0255	loss_degree: 0.3602	loss_feat: 0.0000	loss_cls: 0.1491	loss_other: 0.0000
[client 4 neighGen phase]	acc_degree: 0.8400	acc_cls: 0.9920	loss_train: 0.0343	loss_degree: 0.2200	loss_feat: 0.0106	loss_cls: 0.2469	loss_other: 0.2085
[client 4 neighGen phase]	acc_degree: 0.7520	acc_cls: 0.9920	loss_train: 0.0271	loss_degree: 0.2096	loss_feat: 0.0049	loss_cls: 0.2256	loss_other: 0.1011
[client 4 neighGen phase]	acc_degree: 0.7840	acc_cls: 1.0000	loss_train: 0.0272	loss_degree: 0.2013	loss_feat: 0.0064	loss_cls: 0.2067	loss_other: 0.1290
[client 5 neighGen phase]	acc_degree: 0.8976	acc_cls: 1.0000	loss_train: 0.0264	loss_degree: 0.0298	loss_feat: 0.0107	loss_cls: 0.2657	loss_other: 0.2226
[client 5 neighGen phase]	acc_degree: 0.8819	acc_cls: 1.0000	loss_train: 0.0238	loss_degree: 0.0268	loss_feat: 0.0084	loss_cls: 0.2423	loss_other: 0.1978
[client 5 neighGen phase]	acc_degree: 0.8110	acc_cls: 1.0000	loss_train: 0.0179	loss_degree: 0.0251	loss_feat: 0.0046	loss_cls: 0.2210	loss_other: 0.1066
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 1.0000	loss_train: 0.0217	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.1870	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 1.0000	loss_train: 0.0210	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.1718	loss_other: 0.0000
[client 6 neighGen phase]	acc_degree: 0.7478	acc_cls: 1.0000	loss_train: 0.0203	loss_degree: 0.2478	loss_feat: 0.0000	loss_cls: 0.1585	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 1.0000	loss_train: 0.0199	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.1754	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 1.0000	loss_train: 0.0190	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.1591	loss_other: 0.0000
[client 7 neighGen phase]	acc_degree: 0.7970	acc_cls: 1.0000	loss_train: 0.0183	loss_degree: 0.2218	loss_feat: 0.0000	loss_cls: 0.1450	loss_other: 0.0000
[client 8 neighGen phase]	acc_degree: 0.7840	acc_cls: 1.0000	loss_train: 0.0276	loss_degree: 0.0742	loss_feat: 0.0090	loss_cls: 0.2787	loss_other: 0.1895
[client 8 neighGen phase]	acc_degree: 0.7920	acc_cls: 1.0000	loss_train: 0.0267	loss_degree: 0.0632	loss_feat: 0.0106	loss_cls: 0.2576	loss_other: 0.2030
[client 8 neighGen phase]	acc_degree: 0.8320	acc_cls: 1.0000	loss_train: 0.0289	loss_degree: 0.0587	loss_feat: 0.0139	loss_cls: 0.2372	loss_other: 0.2678
[client 9 neighGen phase]	acc_degree: 0.7737	acc_cls: 1.0000	loss_train: 0.0172	loss_degree: 0.0468	loss_feat: 0.0078	loss_cls: 0.1427	loss_other: 0.1476
[client 9 neighGen phase]	acc_degree: 0.7956	acc_cls: 1.0000	loss_train: 0.0174	loss_degree: 0.0369	loss_feat: 0.0090	loss_cls: 0.1288	loss_other: 0.1727
[client 9 neighGen phase]	acc_degree: 0.9416	acc_cls: 1.0000	loss_train: 0.0249	loss_degree: 0.0444	loss_feat: 0.0164	loss_cls: 0.1164	loss_other: 0.3200
[client 10 neighGen phase]	acc_degree: 0.8855	acc_cls: 1.0000	loss_train: 0.0199	loss_degree: 0.0733	loss_feat: 0.0064	loss_cls: 0.1556	loss_other: 0.1624
[client 10 neighGen phase]	acc_degree: 0.8397	acc_cls: 1.0000	loss_train: 0.0135	loss_degree: 0.0722	loss_feat: 0.0016	loss_cls: 0.1417	loss_other: 0.0554
[client 10 neighGen phase]	acc_degree: 0.9008	acc_cls: 1.0000	loss_train: 0.0181	loss_degree: 0.0576	loss_feat: 0.0065	loss_cls: 0.1291	loss_other: 0.1689
[client 11 neighGen phase]	acc_degree: 0.8409	acc_cls: 1.0000	loss_train: 0.0164	loss_degree: 0.1028	loss_feat: 0.0037	loss_cls: 0.1323	loss_other: 0.0885
[client 11 neighGen phase]	acc_degree: 0.8712	acc_cls: 1.0000	loss_train: 0.0185	loss_degree: 0.0643	loss_feat: 0.0090	loss_cls: 0.1192	loss_other: 0.1775
[client 11 neighGen phase]	acc_degree: 0.8258	acc_cls: 1.0000	loss_train: 0.0312	loss_degree: 0.1696	loss_feat: 0.0154	loss_cls: 0.1076	loss_other: 0.3324
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 1.0000	loss_train: 0.0162	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.1703	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 1.0000	loss_train: 0.0153	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.1535	loss_other: 0.0000
[client 12 neighGen phase]	acc_degree: 0.8134	acc_cls: 1.0000	loss_train: 0.0146	loss_degree: 0.1530	loss_feat: 0.0000	loss_cls: 0.1384	loss_other: 0.0000
[client 13 neighGen phase]	acc_degree: 0.8603	acc_cls: 1.0000	loss_train: 0.0237	loss_degree: 0.0379	loss_feat: 0.0110	loss_cls: 0.1948	loss_other: 0.2304
[client 13 neighGen phase]	acc_degree: 0.8676	acc_cls: 1.0000	loss_train: 0.0220	loss_degree: 0.0327	loss_feat: 0.0113	loss_cls: 0.1760	loss_other: 0.2204
[client 13 neighGen phase]	acc_degree: 0.8529	acc_cls: 1.0000	loss_train: 0.0202	loss_degree: 0.0254	loss_feat: 0.0105	loss_cls: 0.1594	loss_other: 0.2087
[client 14 neighGen phase]	acc_degree: 0.8707	acc_cls: 0.9932	loss_train: 0.0256	loss_degree: 0.0731	loss_feat: 0.0132	loss_cls: 0.1949	loss_other: 0.2317
[client 14 neighGen phase]	acc_degree: 0.7211	acc_cls: 0.9932	loss_train: 0.0173	loss_degree: 0.0885	loss_feat: 0.0039	loss_cls: 0.1787	loss_other: 0.0757
[client 14 neighGen phase]	acc_degree: 0.8095	acc_cls: 0.9932	loss_train: 0.0228	loss_degree: 0.0590	loss_feat: 0.0123	loss_cls: 0.1640	loss_other: 0.2208
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9857	loss_train: 0.0252	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.2604	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9857	loss_train: 0.0242	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.2411	loss_other: 0.0000
[client 15 neighGen phase]	acc_degree: 0.7571	acc_cls: 0.9857	loss_train: 0.0232	loss_degree: 0.2429	loss_feat: 0.0000	loss_cls: 0.2219	loss_other: 0.0000
[client 16 neighGen phase]	acc_degree: 0.7868	acc_cls: 0.9706	loss_train: 0.0297	loss_degree: 0.1246	loss_feat: 0.0063	loss_cls: 0.3160	loss_other: 0.1471
[client 16 neighGen phase]	acc_degree: 0.8382	acc_cls: 0.9706	loss_train: 0.0316	loss_degree: 0.1125	loss_feat: 0.0096	loss_cls: 0.2930	loss_other: 0.2162
[client 16 neighGen phase]	acc_degree: 0.8456	acc_cls: 0.9853	loss_train: 0.0315	loss_degree: 0.1058	loss_feat: 0.0115	loss_cls: 0.2706	loss_other: 0.2416
[client 17 neighGen phase]	acc_degree: 0.8919	acc_cls: 0.9910	loss_train: 0.0149	loss_degree: 0.0760	loss_feat: 0.0022	loss_cls: 0.1578	loss_other: 0.0611
[client 17 neighGen phase]	acc_degree: 0.8829	acc_cls: 1.0000	loss_train: 0.0129	loss_degree: 0.0757	loss_feat: 0.0018	loss_cls: 0.1419	loss_other: 0.0381
[client 17 neighGen phase]	acc_degree: 0.8739	acc_cls: 1.0000	loss_train: 0.0113	loss_degree: 0.0754	loss_feat: 0.0015	loss_cls: 0.1278	loss_other: 0.0217
[client 18 neighGen phase]	acc_degree: 0.7801	acc_cls: 0.9858	loss_train: 0.0210	loss_degree: 0.1106	loss_feat: 0.0067	loss_cls: 0.1646	loss_other: 0.1378
[client 18 neighGen phase]	acc_degree: 0.7447	acc_cls: 0.9858	loss_train: 0.0179	loss_degree: 0.1066	loss_feat: 0.0050	loss_cls: 0.1497	loss_other: 0.0964
[client 18 neighGen phase]	acc_degree: 0.8369	acc_cls: 0.9858	loss_train: 0.0233	loss_degree: 0.1004	loss_feat: 0.0113	loss_cls: 0.1365	loss_other: 0.2176
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 1.0000	loss_train: 0.0191	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.2006	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 1.0000	loss_train: 0.0183	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.1839	loss_other: 0.0000
[client 19 neighGen phase]	acc_degree: 0.7682	acc_cls: 1.0000	loss_train: 0.0176	loss_degree: 0.1821	loss_feat: 0.0000	loss_cls: 0.1690	loss_other: 0.0000
[server]	loss_train: 1.9984	loss_val: 2.0039	loss_test: 2.0710	accuracy_train: 0.3433	accuracy_val: 0.3382	accuracy_test: 0.3333
[server]	loss_train: 2.2146	loss_val: 2.1805	loss_test: 2.1910	accuracy_train: 0.3136	accuracy_val: 0.3036	accuracy_test: 0.3040
[server]	loss_train: 1.9959	loss_val: 1.9623	loss_test: 1.9931	accuracy_train: 0.3129	accuracy_val: 0.3084	accuracy_test: 0.3065
[server]	loss_train: 1.8239	loss_val: 1.8369	loss_test: 1.7968	accuracy_train: 0.4815	accuracy_val: 0.4645	accuracy_test: 0.4645
[server]	loss_train: 2.3705	loss_val: 2.2636	loss_test: 2.3115	accuracy_train: 0.2720	accuracy_val: 0.2734	accuracy_test: 0.2682
[server]	loss_train: 1.7828	loss_val: 1.8787	loss_test: 1.8628	accuracy_train: 0.4488	accuracy_val: 0.4351	accuracy_test: 0.4318
[server]	loss_train: 2.1129	loss_val: 2.1429	loss_test: 2.0705	accuracy_train: 0.2870	accuracy_val: 0.2822	accuracy_test: 0.2810
[server]	loss_train: 1.9256	loss_val: 1.8789	loss_test: 2.0000	accuracy_train: 0.4662	accuracy_val: 0.4496	accuracy_test: 0.4484
[server]	loss_train: 1.8949	loss_val: 1.9427	loss_test: 2.0031	accuracy_train: 0.4000	accuracy_val: 0.3861	accuracy_test: 0.3817
[server]	loss_train: 1.8515	loss_val: 1.8433	loss_test: 1.8718	accuracy_train: 0.4161	accuracy_val: 0.4064	accuracy_test: 0.4091
[server]	loss_train: 2.0375	loss_val: 2.1601	loss_test: 2.1146	accuracy_train: 0.3435	accuracy_val: 0.3433	accuracy_test: 0.3346
[server]	loss_train: 2.1024	loss_val: 2.1632	loss_test: 2.1668	accuracy_train: 0.3485	accuracy_val: 0.3394	accuracy_test: 0.3406
[server]	loss_train: 2.2125	loss_val: 2.2293	loss_test: 2.1829	accuracy_train: 0.3209	accuracy_val: 0.3141	accuracy_test: 0.3107
[server]	loss_train: 1.8725	loss_val: 1.9344	loss_test: 2.0428	accuracy_train: 0.4338	accuracy_val: 0.4250	accuracy_test: 0.4246
[server]	loss_train: 1.9357	loss_val: 1.9696	loss_test: 2.0354	accuracy_train: 0.3333	accuracy_val: 0.3322	accuracy_test: 0.3267
[server]	loss_train: 1.6911	loss_val: 1.7568	loss_test: 1.7270	accuracy_train: 0.5500	accuracy_val: 0.5363	accuracy_test: 0.5342
[server]	loss_train: 1.9396	loss_val: 1.9545	loss_test: 2.0347	accuracy_train: 0.4118	accuracy_val: 0.4036	accuracy_test: 0.4014
[server]	loss_train: 1.7751	loss_val: 1.9683	loss_test: 2.0036	accuracy_train: 0.4505	accuracy_val: 0.4348	accuracy_test: 0.4274
[server]	loss_train: 1.6841	loss_val: 1.7248	loss_test: 1.6550	accuracy_train: 0.5390	accuracy_val: 0.5331	accuracy_test: 0.5310
[server]	loss_train: 2.1231	loss_val: 2.0923	loss_test: 2.1378	accuracy_train: 0.1987	accuracy_val: 0.1968	accuracy_test: 0.1968
curr_round: 9	curr_val_accuracy: 0.3749	curr_test_accuracy: 0.3725
best_round: 9	best_val_accuracy: 0.3749	best_test_accuracy: 0.3725
--------------------------------------------------
round # 10		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.8299	loss_val: 1.8566	loss_test: 1.8750	accuracy_train: 0.3731	accuracy_val: 0.4000	accuracy_test: 0.3763
[server]	loss_train: 1.9878	loss_val: 1.9754	loss_test: 2.0212	accuracy_train: 0.3729	accuracy_val: 0.3522	accuracy_test: 0.3280
[server]	loss_train: 1.8574	loss_val: 1.8295	loss_test: 1.8607	accuracy_train: 0.3558	accuracy_val: 0.3683	accuracy_test: 0.3601
[server]	loss_train: 1.7575	loss_val: 1.7483	loss_test: 1.7404	accuracy_train: 0.5185	accuracy_val: 0.5248	accuracy_test: 0.5000
[server]	loss_train: 2.0524	loss_val: 1.9808	loss_test: 2.0331	accuracy_train: 0.3200	accuracy_val: 0.3164	accuracy_test: 0.2912
[server]	loss_train: 1.7633	loss_val: 1.8187	loss_test: 1.7944	accuracy_train: 0.4724	accuracy_val: 0.4695	accuracy_test: 0.4773
[server]	loss_train: 1.8738	loss_val: 1.8541	loss_test: 1.8444	accuracy_train: 0.3913	accuracy_val: 0.3610	accuracy_test: 0.3223
[server]	loss_train: 1.8118	loss_val: 1.7823	loss_test: 1.8381	accuracy_train: 0.5113	accuracy_val: 0.4820	accuracy_test: 0.4840
[server]	loss_train: 1.7935	loss_val: 1.8226	loss_test: 1.8387	accuracy_train: 0.4640	accuracy_val: 0.4363	accuracy_test: 0.4389
[server]	loss_train: 1.7616	loss_val: 1.7670	loss_test: 1.7643	accuracy_train: 0.4818	accuracy_val: 0.4594	accuracy_test: 0.4755
[server]	loss_train: 1.8618	loss_val: 1.9468	loss_test: 1.9351	accuracy_train: 0.3893	accuracy_val: 0.3843	accuracy_test: 0.3897
[server]	loss_train: 1.9401	loss_val: 1.9717	loss_test: 2.0112	accuracy_train: 0.4015	accuracy_val: 0.3869	accuracy_test: 0.3841
[server]	loss_train: 1.9411	loss_val: 1.9136	loss_test: 1.8894	accuracy_train: 0.3806	accuracy_val: 0.4043	accuracy_test: 0.3679
[server]	loss_train: 1.7583	loss_val: 1.8329	loss_test: 1.8584	accuracy_train: 0.4853	accuracy_val: 0.4714	accuracy_test: 0.4877
[server]	loss_train: 1.7851	loss_val: 1.7622	loss_test: 1.7918	accuracy_train: 0.4014	accuracy_val: 0.3826	accuracy_test: 0.3967
[server]	loss_train: 1.6778	loss_val: 1.7071	loss_test: 1.6809	accuracy_train: 0.5500	accuracy_val: 0.5329	accuracy_test: 0.5411
[server]	loss_train: 1.7589	loss_val: 1.8083	loss_test: 1.8294	accuracy_train: 0.4485	accuracy_val: 0.4357	accuracy_test: 0.4472
[server]	loss_train: 1.7215	loss_val: 1.8294	loss_test: 1.8729	accuracy_train: 0.5045	accuracy_val: 0.5000	accuracy_test: 0.4701
[server]	loss_train: 1.7612	loss_val: 1.7688	loss_test: 1.7443	accuracy_train: 0.5603	accuracy_val: 0.5540	accuracy_test: 0.5414
[server]	loss_train: 1.9114	loss_val: 1.9272	loss_test: 1.9163	accuracy_train: 0.2384	accuracy_val: 0.2645	accuracy_test: 0.2508
curr_round: 10	curr_val_accuracy: 0.4237	curr_test_accuracy: 0.4165
best_round: 10	best_val_accuracy: 0.4237	best_test_accuracy: 0.4165
--------------------------------------------------
round # 11		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.6893	loss_val: 1.7546	loss_test: 1.7770	accuracy_train: 0.4030	accuracy_val: 0.4109	accuracy_test: 0.3871
[server]	loss_train: 1.9042	loss_val: 1.9074	loss_test: 1.9362	accuracy_train: 0.4068	accuracy_val: 0.3725	accuracy_test: 0.3480
[server]	loss_train: 1.6958	loss_val: 1.6965	loss_test: 1.7263	accuracy_train: 0.4172	accuracy_val: 0.4072	accuracy_test: 0.3929
[server]	loss_train: 1.5723	loss_val: 1.6020	loss_test: 1.5827	accuracy_train: 0.5037	accuracy_val: 0.5177	accuracy_test: 0.5071
[server]	loss_train: 2.0002	loss_val: 1.9166	loss_test: 1.9796	accuracy_train: 0.3520	accuracy_val: 0.3477	accuracy_test: 0.3180
[server]	loss_train: 1.5712	loss_val: 1.6586	loss_test: 1.6207	accuracy_train: 0.5039	accuracy_val: 0.4847	accuracy_test: 0.4773
[server]	loss_train: 1.7673	loss_val: 1.7680	loss_test: 1.7492	accuracy_train: 0.3913	accuracy_val: 0.3610	accuracy_test: 0.3223
[server]	loss_train: 1.6730	loss_val: 1.6482	loss_test: 1.7323	accuracy_train: 0.4812	accuracy_val: 0.4820	accuracy_test: 0.4555
[server]	loss_train: 1.6310	loss_val: 1.6892	loss_test: 1.7268	accuracy_train: 0.5120	accuracy_val: 0.4363	accuracy_test: 0.4656
[server]	loss_train: 1.6297	loss_val: 1.6412	loss_test: 1.6299	accuracy_train: 0.4891	accuracy_val: 0.4382	accuracy_test: 0.4895
[server]	loss_train: 1.7316	loss_val: 1.8661	loss_test: 1.8385	accuracy_train: 0.4809	accuracy_val: 0.4366	accuracy_test: 0.3934
[server]	loss_train: 1.8281	loss_val: 1.8837	loss_test: 1.9421	accuracy_train: 0.4015	accuracy_val: 0.4088	accuracy_test: 0.4022
[server]	loss_train: 1.8583	loss_val: 1.8385	loss_test: 1.8037	accuracy_train: 0.3507	accuracy_val: 0.3791	accuracy_test: 0.3714
[server]	loss_train: 1.6444	loss_val: 1.7207	loss_test: 1.7650	accuracy_train: 0.5000	accuracy_val: 0.4929	accuracy_test: 0.4842
[server]	loss_train: 1.6567	loss_val: 1.6420	loss_test: 1.6783	accuracy_train: 0.4082	accuracy_val: 0.4060	accuracy_test: 0.4167
[server]	loss_train: 1.5159	loss_val: 1.5250	loss_test: 1.5084	accuracy_train: 0.5786	accuracy_val: 0.5640	accuracy_test: 0.5445
[server]	loss_train: 1.6367	loss_val: 1.6927	loss_test: 1.7351	accuracy_train: 0.5147	accuracy_val: 0.4393	accuracy_test: 0.4331
[server]	loss_train: 1.5777	loss_val: 1.7352	loss_test: 1.7654	accuracy_train: 0.4955	accuracy_val: 0.4739	accuracy_test: 0.4829
[server]	loss_train: 1.5606	loss_val: 1.5647	loss_test: 1.5179	accuracy_train: 0.5603	accuracy_val: 0.5610	accuracy_test: 0.5448
[server]	loss_train: 1.7919	loss_val: 1.8048	loss_test: 1.7956	accuracy_train: 0.2649	accuracy_val: 0.3194	accuracy_test: 0.3175
curr_round: 11	curr_val_accuracy: 0.4372	curr_test_accuracy: 0.4282
best_round: 11	best_val_accuracy: 0.4372	best_test_accuracy: 0.4282
--------------------------------------------------
round # 12		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.5590	loss_val: 1.6287	loss_test: 1.6400	accuracy_train: 0.4925	accuracy_val: 0.4655	accuracy_test: 0.4767
[server]	loss_train: 1.7575	loss_val: 1.7766	loss_test: 1.8112	accuracy_train: 0.4407	accuracy_val: 0.4251	accuracy_test: 0.4120
[server]	loss_train: 1.5596	loss_val: 1.5712	loss_test: 1.6081	accuracy_train: 0.4847	accuracy_val: 0.4611	accuracy_test: 0.4375
[server]	loss_train: 1.4318	loss_val: 1.4746	loss_test: 1.4631	accuracy_train: 0.5556	accuracy_val: 0.5603	accuracy_test: 0.5709
[server]	loss_train: 1.8504	loss_val: 1.7854	loss_test: 1.8313	accuracy_train: 0.4000	accuracy_val: 0.4062	accuracy_test: 0.3640
[server]	loss_train: 1.4589	loss_val: 1.5515	loss_test: 1.5087	accuracy_train: 0.5118	accuracy_val: 0.5229	accuracy_test: 0.5265
[server]	loss_train: 1.6169	loss_val: 1.6206	loss_test: 1.6163	accuracy_train: 0.4522	accuracy_val: 0.4315	accuracy_test: 0.4256
[server]	loss_train: 1.5226	loss_val: 1.5174	loss_test: 1.5841	accuracy_train: 0.5564	accuracy_val: 0.5432	accuracy_test: 0.5409
[server]	loss_train: 1.4928	loss_val: 1.5755	loss_test: 1.5954	accuracy_train: 0.5680	accuracy_val: 0.5058	accuracy_test: 0.5458
[server]	loss_train: 1.4770	loss_val: 1.5060	loss_test: 1.4923	accuracy_train: 0.5620	accuracy_val: 0.5230	accuracy_test: 0.5594
[server]	loss_train: 1.5848	loss_val: 1.7266	loss_test: 1.6980	accuracy_train: 0.4962	accuracy_val: 0.4739	accuracy_test: 0.4743
[server]	loss_train: 1.6907	loss_val: 1.7558	loss_test: 1.8147	accuracy_train: 0.4091	accuracy_val: 0.4672	accuracy_test: 0.4420
[server]	loss_train: 1.7327	loss_val: 1.6994	loss_test: 1.6772	accuracy_train: 0.4627	accuracy_val: 0.4693	accuracy_test: 0.4750
[server]	loss_train: 1.4974	loss_val: 1.5817	loss_test: 1.6170	accuracy_train: 0.5662	accuracy_val: 0.5321	accuracy_test: 0.5298
[server]	loss_train: 1.5189	loss_val: 1.5092	loss_test: 1.5383	accuracy_train: 0.5102	accuracy_val: 0.4530	accuracy_test: 0.5133
[server]	loss_train: 1.3535	loss_val: 1.3654	loss_test: 1.3492	accuracy_train: 0.6357	accuracy_val: 0.6021	accuracy_test: 0.5856
[server]	loss_train: 1.4887	loss_val: 1.5580	loss_test: 1.5892	accuracy_train: 0.5662	accuracy_val: 0.5036	accuracy_test: 0.5211
[server]	loss_train: 1.4372	loss_val: 1.5993	loss_test: 1.6278	accuracy_train: 0.5766	accuracy_val: 0.5565	accuracy_test: 0.5427
[server]	loss_train: 1.4119	loss_val: 1.4285	loss_test: 1.3906	accuracy_train: 0.6170	accuracy_val: 0.6098	accuracy_test: 0.5759
[server]	loss_train: 1.6649	loss_val: 1.6815	loss_test: 1.6715	accuracy_train: 0.3709	accuracy_val: 0.3871	accuracy_test: 0.4063
curr_round: 12	curr_val_accuracy: 0.4949	curr_test_accuracy: 0.4965
best_round: 12	best_val_accuracy: 0.4949	best_test_accuracy: 0.4965
--------------------------------------------------
round # 13		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.4172	loss_val: 1.5000	loss_test: 1.5007	accuracy_train: 0.5448	accuracy_val: 0.5709	accuracy_test: 0.5627
[server]	loss_train: 1.6070	loss_val: 1.6246	loss_test: 1.6778	accuracy_train: 0.5339	accuracy_val: 0.5142	accuracy_test: 0.4920
[server]	loss_train: 1.4007	loss_val: 1.4270	loss_test: 1.4737	accuracy_train: 0.5890	accuracy_val: 0.5838	accuracy_test: 0.5417
[server]	loss_train: 1.3022	loss_val: 1.3586	loss_test: 1.3669	accuracy_train: 0.6741	accuracy_val: 0.6348	accuracy_test: 0.6312
[server]	loss_train: 1.6737	loss_val: 1.6482	loss_test: 1.6620	accuracy_train: 0.5520	accuracy_val: 0.5234	accuracy_test: 0.4943
[server]	loss_train: 1.3419	loss_val: 1.4435	loss_test: 1.4001	accuracy_train: 0.5984	accuracy_val: 0.5840	accuracy_test: 0.5795
[server]	loss_train: 1.4398	loss_val: 1.4448	loss_test: 1.4537	accuracy_train: 0.6087	accuracy_val: 0.6224	accuracy_test: 0.5744
[server]	loss_train: 1.3949	loss_val: 1.4018	loss_test: 1.4442	accuracy_train: 0.6992	accuracy_val: 0.6367	accuracy_test: 0.6263
[server]	loss_train: 1.3597	loss_val: 1.4495	loss_test: 1.4500	accuracy_train: 0.6640	accuracy_val: 0.6216	accuracy_test: 0.6183
[server]	loss_train: 1.3159	loss_val: 1.3603	loss_test: 1.3450	accuracy_train: 0.6934	accuracy_val: 0.6643	accuracy_test: 0.6748
[server]	loss_train: 1.4393	loss_val: 1.5918	loss_test: 1.5614	accuracy_train: 0.6107	accuracy_val: 0.5634	accuracy_test: 0.5846
[server]	loss_train: 1.5462	loss_val: 1.6212	loss_test: 1.6848	accuracy_train: 0.5227	accuracy_val: 0.5219	accuracy_test: 0.5217
[server]	loss_train: 1.5714	loss_val: 1.5221	loss_test: 1.5179	accuracy_train: 0.6045	accuracy_val: 0.6137	accuracy_test: 0.5857
[server]	loss_train: 1.3658	loss_val: 1.4421	loss_test: 1.4655	accuracy_train: 0.5809	accuracy_val: 0.5857	accuracy_test: 0.5754
[server]	loss_train: 1.3614	loss_val: 1.3530	loss_test: 1.3687	accuracy_train: 0.6327	accuracy_val: 0.6309	accuracy_test: 0.6633
[server]	loss_train: 1.2271	loss_val: 1.2368	loss_test: 1.2311	accuracy_train: 0.6857	accuracy_val: 0.6540	accuracy_test: 0.6507
[server]	loss_train: 1.3291	loss_val: 1.4255	loss_test: 1.4436	accuracy_train: 0.6618	accuracy_val: 0.5821	accuracy_test: 0.6056
[server]	loss_train: 1.3187	loss_val: 1.4626	loss_test: 1.4873	accuracy_train: 0.6486	accuracy_val: 0.6435	accuracy_test: 0.6239
[server]	loss_train: 1.2673	loss_val: 1.3049	loss_test: 1.2780	accuracy_train: 0.6383	accuracy_val: 0.6307	accuracy_test: 0.6172
[server]	loss_train: 1.5085	loss_val: 1.5279	loss_test: 1.5235	accuracy_train: 0.5430	accuracy_val: 0.5484	accuracy_test: 0.5429
curr_round: 13	curr_val_accuracy: 0.5967	curr_test_accuracy: 0.5888
best_round: 13	best_val_accuracy: 0.5967	best_test_accuracy: 0.5888
--------------------------------------------------
round # 14		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.3001	loss_val: 1.3837	loss_test: 1.4031	accuracy_train: 0.5373	accuracy_val: 0.5636	accuracy_test: 0.5591
[server]	loss_train: 1.4967	loss_val: 1.5324	loss_test: 1.5809	accuracy_train: 0.5424	accuracy_val: 0.5304	accuracy_test: 0.5120
[server]	loss_train: 1.2590	loss_val: 1.2992	loss_test: 1.3546	accuracy_train: 0.6074	accuracy_val: 0.5988	accuracy_test: 0.5625
[server]	loss_train: 1.1486	loss_val: 1.2327	loss_test: 1.2421	accuracy_train: 0.6815	accuracy_val: 0.6312	accuracy_test: 0.6383
[server]	loss_train: 1.5590	loss_val: 1.5402	loss_test: 1.5368	accuracy_train: 0.5440	accuracy_val: 0.5156	accuracy_test: 0.5134
[server]	loss_train: 1.2110	loss_val: 1.3341	loss_test: 1.2983	accuracy_train: 0.6142	accuracy_val: 0.5954	accuracy_test: 0.5758
[server]	loss_train: 1.3181	loss_val: 1.3346	loss_test: 1.3467	accuracy_train: 0.6348	accuracy_val: 0.6224	accuracy_test: 0.5785
[server]	loss_train: 1.2670	loss_val: 1.2812	loss_test: 1.3394	accuracy_train: 0.6692	accuracy_val: 0.6115	accuracy_test: 0.6157
[server]	loss_train: 1.2328	loss_val: 1.3533	loss_test: 1.3577	accuracy_train: 0.6880	accuracy_val: 0.6023	accuracy_test: 0.6107
[server]	loss_train: 1.1800	loss_val: 1.2428	loss_test: 1.2297	accuracy_train: 0.6788	accuracy_val: 0.6608	accuracy_test: 0.6748
[server]	loss_train: 1.3263	loss_val: 1.5016	loss_test: 1.4524	accuracy_train: 0.6031	accuracy_val: 0.5560	accuracy_test: 0.5956
[server]	loss_train: 1.4311	loss_val: 1.5340	loss_test: 1.5887	accuracy_train: 0.5303	accuracy_val: 0.5146	accuracy_test: 0.4928
[server]	loss_train: 1.4888	loss_val: 1.4259	loss_test: 1.4317	accuracy_train: 0.5821	accuracy_val: 0.5993	accuracy_test: 0.5679
[server]	loss_train: 1.2342	loss_val: 1.3019	loss_test: 1.3446	accuracy_train: 0.5735	accuracy_val: 0.5964	accuracy_test: 0.6000
[server]	loss_train: 1.2265	loss_val: 1.2361	loss_test: 1.2346	accuracy_train: 0.6735	accuracy_val: 0.6376	accuracy_test: 0.6567
[server]	loss_train: 1.0731	loss_val: 1.0971	loss_test: 1.0886	accuracy_train: 0.7071	accuracy_val: 0.6782	accuracy_test: 0.6473
[server]	loss_train: 1.2120	loss_val: 1.3106	loss_test: 1.3454	accuracy_train: 0.6471	accuracy_val: 0.5750	accuracy_test: 0.5986
[server]	loss_train: 1.1845	loss_val: 1.3456	loss_test: 1.3768	accuracy_train: 0.6667	accuracy_val: 0.6478	accuracy_test: 0.6239
[server]	loss_train: 1.0878	loss_val: 1.1363	loss_test: 1.1222	accuracy_train: 0.6879	accuracy_val: 0.6725	accuracy_test: 0.6586
[server]	loss_train: 1.3499	loss_val: 1.3750	loss_test: 1.3801	accuracy_train: 0.5629	accuracy_val: 0.5677	accuracy_test: 0.5587
curr_round: 14	curr_val_accuracy: 0.5994	curr_test_accuracy: 0.5928
best_round: 14	best_val_accuracy: 0.5994	best_test_accuracy: 0.5928
--------------------------------------------------
round # 15		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.1655	loss_val: 1.2578	loss_test: 1.2554	accuracy_train: 0.6418	accuracy_val: 0.6327	accuracy_test: 0.6487
[server]	loss_train: 1.3445	loss_val: 1.3650	loss_test: 1.4402	accuracy_train: 0.6102	accuracy_val: 0.5870	accuracy_test: 0.5800
[server]	loss_train: 1.1087	loss_val: 1.1658	loss_test: 1.2302	accuracy_train: 0.6748	accuracy_val: 0.6796	accuracy_test: 0.6548
[server]	loss_train: 1.0228	loss_val: 1.1155	loss_test: 1.1433	accuracy_train: 0.7481	accuracy_val: 0.6844	accuracy_test: 0.6915
[server]	loss_train: 1.3738	loss_val: 1.3916	loss_test: 1.3589	accuracy_train: 0.6160	accuracy_val: 0.5898	accuracy_test: 0.6092
[server]	loss_train: 1.0994	loss_val: 1.2206	loss_test: 1.1807	accuracy_train: 0.6772	accuracy_val: 0.6641	accuracy_test: 0.6591
[server]	loss_train: 1.1404	loss_val: 1.1573	loss_test: 1.1893	accuracy_train: 0.6870	accuracy_val: 0.6888	accuracy_test: 0.6653
[server]	loss_train: 1.1509	loss_val: 1.1779	loss_test: 1.2120	accuracy_train: 0.7444	accuracy_val: 0.6763	accuracy_test: 0.6655
[server]	loss_train: 1.1066	loss_val: 1.2363	loss_test: 1.2110	accuracy_train: 0.7120	accuracy_val: 0.6525	accuracy_test: 0.6641
[server]	loss_train: 1.0346	loss_val: 1.1071	loss_test: 1.0914	accuracy_train: 0.7372	accuracy_val: 0.7208	accuracy_test: 0.7343
[server]	loss_train: 1.1702	loss_val: 1.3631	loss_test: 1.3160	accuracy_train: 0.6489	accuracy_val: 0.6231	accuracy_test: 0.6581
[server]	loss_train: 1.2778	loss_val: 1.3812	loss_test: 1.4513	accuracy_train: 0.6439	accuracy_val: 0.5876	accuracy_test: 0.5833
[server]	loss_train: 1.3339	loss_val: 1.2476	loss_test: 1.2787	accuracy_train: 0.6493	accuracy_val: 0.6570	accuracy_test: 0.6321
[server]	loss_train: 1.1398	loss_val: 1.1866	loss_test: 1.2039	accuracy_train: 0.6471	accuracy_val: 0.6250	accuracy_test: 0.6491
[server]	loss_train: 1.0765	loss_val: 1.0905	loss_test: 1.0712	accuracy_train: 0.7415	accuracy_val: 0.7114	accuracy_test: 0.7300
[server]	loss_train: 0.9784	loss_val: 0.9817	loss_test: 0.9973	accuracy_train: 0.7286	accuracy_val: 0.7093	accuracy_test: 0.6918
[server]	loss_train: 1.0742	loss_val: 1.2023	loss_test: 1.2147	accuracy_train: 0.7500	accuracy_val: 0.6607	accuracy_test: 0.6725
[server]	loss_train: 1.0946	loss_val: 1.2276	loss_test: 1.2468	accuracy_train: 0.6937	accuracy_val: 0.6652	accuracy_test: 0.6667
[server]	loss_train: 0.9753	loss_val: 1.0373	loss_test: 1.0347	accuracy_train: 0.7447	accuracy_val: 0.7456	accuracy_test: 0.7172
[server]	loss_train: 1.1873	loss_val: 1.2247	loss_test: 1.2239	accuracy_train: 0.6755	accuracy_val: 0.6710	accuracy_test: 0.6540
curr_round: 15	curr_val_accuracy: 0.6630	curr_test_accuracy: 0.6624
best_round: 15	best_val_accuracy: 0.6630	best_test_accuracy: 0.6624
--------------------------------------------------
round # 16		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 1.0897	loss_val: 1.1641	loss_test: 1.1789	accuracy_train: 0.6418	accuracy_val: 0.6473	accuracy_test: 0.6380
[server]	loss_train: 1.2290	loss_val: 1.2711	loss_test: 1.3442	accuracy_train: 0.6525	accuracy_val: 0.6113	accuracy_test: 0.6080
[server]	loss_train: 0.9892	loss_val: 1.0531	loss_test: 1.1210	accuracy_train: 0.6994	accuracy_val: 0.6856	accuracy_test: 0.6667
[server]	loss_train: 0.9005	loss_val: 1.0176	loss_test: 1.0366	accuracy_train: 0.7778	accuracy_val: 0.7057	accuracy_test: 0.7021
[server]	loss_train: 1.2509	loss_val: 1.2798	loss_test: 1.2345	accuracy_train: 0.6320	accuracy_val: 0.6094	accuracy_test: 0.6169
[server]	loss_train: 1.0017	loss_val: 1.1292	loss_test: 1.1016	accuracy_train: 0.7008	accuracy_val: 0.6565	accuracy_test: 0.6477
[server]	loss_train: 1.0298	loss_val: 1.0602	loss_test: 1.0986	accuracy_train: 0.7217	accuracy_val: 0.7054	accuracy_test: 0.6942
[server]	loss_train: 1.0254	loss_val: 1.0741	loss_test: 1.1267	accuracy_train: 0.7594	accuracy_val: 0.6727	accuracy_test: 0.6619
[server]	loss_train: 0.9771	loss_val: 1.1427	loss_test: 1.1317	accuracy_train: 0.7360	accuracy_val: 0.6641	accuracy_test: 0.6679
[server]	loss_train: 0.9276	loss_val: 1.0155	loss_test: 0.9962	accuracy_train: 0.7445	accuracy_val: 0.7138	accuracy_test: 0.7343
[server]	loss_train: 1.0693	loss_val: 1.2711	loss_test: 1.2127	accuracy_train: 0.6870	accuracy_val: 0.6231	accuracy_test: 0.6581
[server]	loss_train: 1.1693	loss_val: 1.2955	loss_test: 1.3481	accuracy_train: 0.6439	accuracy_val: 0.6022	accuracy_test: 0.5942
[server]	loss_train: 1.2629	loss_val: 1.1676	loss_test: 1.2169	accuracy_train: 0.6418	accuracy_val: 0.6534	accuracy_test: 0.6250
[server]	loss_train: 1.0391	loss_val: 1.0780	loss_test: 1.1065	accuracy_train: 0.6765	accuracy_val: 0.6536	accuracy_test: 0.6807
[server]	loss_train: 0.9712	loss_val: 1.0045	loss_test: 0.9703	accuracy_train: 0.7347	accuracy_val: 0.7282	accuracy_test: 0.7367
[server]	loss_train: 0.8711	loss_val: 0.8775	loss_test: 0.8930	accuracy_train: 0.7429	accuracy_val: 0.7266	accuracy_test: 0.7089
[server]	loss_train: 0.9893	loss_val: 1.1124	loss_test: 1.1299	accuracy_train: 0.7574	accuracy_val: 0.6714	accuracy_test: 0.6620
[server]	loss_train: 0.9965	loss_val: 1.1381	loss_test: 1.1621	accuracy_train: 0.7297	accuracy_val: 0.6652	accuracy_test: 0.6709
[server]	loss_train: 0.8429	loss_val: 0.9077	loss_test: 0.9188	accuracy_train: 0.7730	accuracy_val: 0.7875	accuracy_test: 0.7483
[server]	loss_train: 1.0575	loss_val: 1.0960	loss_test: 1.1022	accuracy_train: 0.6689	accuracy_val: 0.6645	accuracy_test: 0.6635
curr_round: 16	curr_val_accuracy: 0.6737	curr_test_accuracy: 0.6703
best_round: 16	best_val_accuracy: 0.6737	best_test_accuracy: 0.6703
--------------------------------------------------
round # 17		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9875	loss_val: 1.0749	loss_test: 1.0723	accuracy_train: 0.7015	accuracy_val: 0.7055	accuracy_test: 0.6882
[server]	loss_train: 1.1033	loss_val: 1.1381	loss_test: 1.2324	accuracy_train: 0.6949	accuracy_val: 0.6397	accuracy_test: 0.6520
[server]	loss_train: 0.8685	loss_val: 0.9555	loss_test: 1.0288	accuracy_train: 0.7914	accuracy_val: 0.7305	accuracy_test: 0.7321
[server]	loss_train: 0.8053	loss_val: 0.9320	loss_test: 0.9610	accuracy_train: 0.8370	accuracy_val: 0.7411	accuracy_test: 0.7376
[server]	loss_train: 1.1047	loss_val: 1.1659	loss_test: 1.0957	accuracy_train: 0.6960	accuracy_val: 0.6484	accuracy_test: 0.6935
[server]	loss_train: 0.9059	loss_val: 1.0424	loss_test: 1.0105	accuracy_train: 0.7795	accuracy_val: 0.7061	accuracy_test: 0.7159
[server]	loss_train: 0.9036	loss_val: 0.9441	loss_test: 0.9918	accuracy_train: 0.7652	accuracy_val: 0.7220	accuracy_test: 0.7397
[server]	loss_train: 0.9441	loss_val: 1.0010	loss_test: 1.0399	accuracy_train: 0.7744	accuracy_val: 0.7122	accuracy_test: 0.7117
[server]	loss_train: 0.8836	loss_val: 1.0517	loss_test: 1.0195	accuracy_train: 0.7360	accuracy_val: 0.6911	accuracy_test: 0.6985
[server]	loss_train: 0.8253	loss_val: 0.9156	loss_test: 0.8945	accuracy_train: 0.8175	accuracy_val: 0.7774	accuracy_test: 0.8042
[server]	loss_train: 0.9622	loss_val: 1.1725	loss_test: 1.1167	accuracy_train: 0.7557	accuracy_val: 0.6866	accuracy_test: 0.6838
[server]	loss_train: 1.0452	loss_val: 1.1777	loss_test: 1.2341	accuracy_train: 0.7273	accuracy_val: 0.6825	accuracy_test: 0.6522
[server]	loss_train: 1.1391	loss_val: 1.0461	loss_test: 1.1110	accuracy_train: 0.6940	accuracy_val: 0.7076	accuracy_test: 0.6786
[server]	loss_train: 0.9765	loss_val: 0.9967	loss_test: 1.0042	accuracy_train: 0.7279	accuracy_val: 0.7000	accuracy_test: 0.7368
[server]	loss_train: 0.8620	loss_val: 0.9050	loss_test: 0.8633	accuracy_train: 0.7959	accuracy_val: 0.7483	accuracy_test: 0.7767
[server]	loss_train: 0.8059	loss_val: 0.7956	loss_test: 0.8320	accuracy_train: 0.8000	accuracy_val: 0.7820	accuracy_test: 0.7466
[server]	loss_train: 0.8930	loss_val: 1.0316	loss_test: 1.0396	accuracy_train: 0.8015	accuracy_val: 0.7250	accuracy_test: 0.7183
[server]	loss_train: 0.9304	loss_val: 1.0506	loss_test: 1.0627	accuracy_train: 0.7387	accuracy_val: 0.7217	accuracy_test: 0.7009
[server]	loss_train: 0.7481	loss_val: 0.8218	loss_test: 0.8398	accuracy_train: 0.8511	accuracy_val: 0.8188	accuracy_test: 0.7828
[server]	loss_train: 0.9255	loss_val: 0.9774	loss_test: 0.9852	accuracy_train: 0.7616	accuracy_val: 0.7323	accuracy_test: 0.7048
curr_round: 17	curr_val_accuracy: 0.7205	curr_test_accuracy: 0.7190
best_round: 17	best_val_accuracy: 0.7205	best_test_accuracy: 0.7190
--------------------------------------------------
round # 18		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.9444	loss_val: 1.0014	loss_test: 1.0112	accuracy_train: 0.7090	accuracy_val: 0.7127	accuracy_test: 0.7097
[server]	loss_train: 0.9972	loss_val: 1.0567	loss_test: 1.1483	accuracy_train: 0.7119	accuracy_val: 0.6640	accuracy_test: 0.6680
[server]	loss_train: 0.7871	loss_val: 0.8815	loss_test: 0.9539	accuracy_train: 0.8098	accuracy_val: 0.7395	accuracy_test: 0.7321
[server]	loss_train: 0.7196	loss_val: 0.8600	loss_test: 0.8842	accuracy_train: 0.8519	accuracy_val: 0.7553	accuracy_test: 0.7589
[server]	loss_train: 1.0101	loss_val: 1.0750	loss_test: 0.9979	accuracy_train: 0.6960	accuracy_val: 0.6797	accuracy_test: 0.6935
[server]	loss_train: 0.8358	loss_val: 0.9785	loss_test: 0.9519	accuracy_train: 0.7795	accuracy_val: 0.7252	accuracy_test: 0.7008
[server]	loss_train: 0.8158	loss_val: 0.8720	loss_test: 0.9186	accuracy_train: 0.7826	accuracy_val: 0.7386	accuracy_test: 0.7479
[server]	loss_train: 0.8430	loss_val: 0.9146	loss_test: 0.9600	accuracy_train: 0.8195	accuracy_val: 0.7302	accuracy_test: 0.7402
[server]	loss_train: 0.7921	loss_val: 0.9725	loss_test: 0.9520	accuracy_train: 0.7920	accuracy_val: 0.7066	accuracy_test: 0.6985
[server]	loss_train: 0.7487	loss_val: 0.8482	loss_test: 0.8264	accuracy_train: 0.8248	accuracy_val: 0.7880	accuracy_test: 0.7972
[server]	loss_train: 0.8863	loss_val: 1.0917	loss_test: 1.0318	accuracy_train: 0.7634	accuracy_val: 0.6903	accuracy_test: 0.6985
[server]	loss_train: 0.9513	loss_val: 1.1021	loss_test: 1.1358	accuracy_train: 0.7424	accuracy_val: 0.7044	accuracy_test: 0.6703
[server]	loss_train: 1.0577	loss_val: 0.9743	loss_test: 1.0488	accuracy_train: 0.7015	accuracy_val: 0.7148	accuracy_test: 0.6857
[server]	loss_train: 0.8921	loss_val: 0.9150	loss_test: 0.9270	accuracy_train: 0.7574	accuracy_val: 0.7107	accuracy_test: 0.7439
[server]	loss_train: 0.7837	loss_val: 0.8449	loss_test: 0.7975	accuracy_train: 0.8095	accuracy_val: 0.7718	accuracy_test: 0.7867
[server]	loss_train: 0.7293	loss_val: 0.7241	loss_test: 0.7555	accuracy_train: 0.8143	accuracy_val: 0.7993	accuracy_test: 0.7637
[server]	loss_train: 0.8230	loss_val: 0.9564	loss_test: 0.9632	accuracy_train: 0.8162	accuracy_val: 0.7357	accuracy_test: 0.7183
[server]	loss_train: 0.8550	loss_val: 0.9698	loss_test: 0.9899	accuracy_train: 0.7568	accuracy_val: 0.7348	accuracy_test: 0.7094
[server]	loss_train: 0.6646	loss_val: 0.7378	loss_test: 0.7643	accuracy_train: 0.8652	accuracy_val: 0.8397	accuracy_test: 0.7931
[server]	loss_train: 0.8397	loss_val: 0.8960	loss_test: 0.9101	accuracy_train: 0.7748	accuracy_val: 0.7548	accuracy_test: 0.7143
curr_round: 18	curr_val_accuracy: 0.7363	curr_test_accuracy: 0.7278
best_round: 18	best_val_accuracy: 0.7363	best_test_accuracy: 0.7278
--------------------------------------------------
round # 19		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.8691	loss_val: 0.9356	loss_test: 0.9344	accuracy_train: 0.7388	accuracy_val: 0.7382	accuracy_test: 0.7276
[server]	loss_train: 0.8961	loss_val: 0.9634	loss_test: 1.0638	accuracy_train: 0.7542	accuracy_val: 0.7166	accuracy_test: 0.6880
[server]	loss_train: 0.7061	loss_val: 0.8266	loss_test: 0.8971	accuracy_train: 0.8282	accuracy_val: 0.7545	accuracy_test: 0.7470
[server]	loss_train: 0.6617	loss_val: 0.8110	loss_test: 0.8394	accuracy_train: 0.8593	accuracy_val: 0.7730	accuracy_test: 0.7695
[server]	loss_train: 0.9090	loss_val: 1.0022	loss_test: 0.9048	accuracy_train: 0.7360	accuracy_val: 0.6797	accuracy_test: 0.7395
[server]	loss_train: 0.7722	loss_val: 0.9250	loss_test: 0.8977	accuracy_train: 0.7953	accuracy_val: 0.7328	accuracy_test: 0.7197
[server]	loss_train: 0.7282	loss_val: 0.8057	loss_test: 0.8530	accuracy_train: 0.8087	accuracy_val: 0.7510	accuracy_test: 0.7562
[server]	loss_train: 0.7771	loss_val: 0.8626	loss_test: 0.9003	accuracy_train: 0.8045	accuracy_val: 0.7302	accuracy_test: 0.7473
[server]	loss_train: 0.7330	loss_val: 0.9118	loss_test: 0.8768	accuracy_train: 0.7840	accuracy_val: 0.7181	accuracy_test: 0.7328
[server]	loss_train: 0.6836	loss_val: 0.7960	loss_test: 0.7711	accuracy_train: 0.8321	accuracy_val: 0.8021	accuracy_test: 0.8042
[server]	loss_train: 0.8075	loss_val: 1.0194	loss_test: 0.9542	accuracy_train: 0.8092	accuracy_val: 0.7313	accuracy_test: 0.7132
[server]	loss_train: 0.8565	loss_val: 1.0231	loss_test: 1.0443	accuracy_train: 0.7727	accuracy_val: 0.7226	accuracy_test: 0.7210
[server]	loss_train: 0.9576	loss_val: 0.8986	loss_test: 0.9794	accuracy_train: 0.7239	accuracy_val: 0.7329	accuracy_test: 0.7071
[server]	loss_train: 0.8463	loss_val: 0.8581	loss_test: 0.8654	accuracy_train: 0.7868	accuracy_val: 0.7250	accuracy_test: 0.7614
[server]	loss_train: 0.7142	loss_val: 0.7837	loss_test: 0.7343	accuracy_train: 0.8095	accuracy_val: 0.7819	accuracy_test: 0.8133
[server]	loss_train: 0.6788	loss_val: 0.6681	loss_test: 0.7100	accuracy_train: 0.8286	accuracy_val: 0.8166	accuracy_test: 0.7740
[server]	loss_train: 0.7530	loss_val: 0.9000	loss_test: 0.9008	accuracy_train: 0.8309	accuracy_val: 0.7429	accuracy_test: 0.7289
[server]	loss_train: 0.8064	loss_val: 0.9086	loss_test: 0.9170	accuracy_train: 0.7658	accuracy_val: 0.7478	accuracy_test: 0.7222
[server]	loss_train: 0.6028	loss_val: 0.6779	loss_test: 0.7039	accuracy_train: 0.8865	accuracy_val: 0.8328	accuracy_test: 0.8138
[server]	loss_train: 0.7494	loss_val: 0.8159	loss_test: 0.8325	accuracy_train: 0.7881	accuracy_val: 0.7839	accuracy_test: 0.7397
curr_round: 19	curr_val_accuracy: 0.7521	curr_test_accuracy: 0.7475
best_round: 19	best_val_accuracy: 0.7521	best_test_accuracy: 0.7475
--------------------------------------------------
round # 20		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.8409	loss_val: 0.8823	loss_test: 0.8774	accuracy_train: 0.7537	accuracy_val: 0.7527	accuracy_test: 0.7419
[server]	loss_train: 0.8019	loss_val: 0.8918	loss_test: 0.9863	accuracy_train: 0.7627	accuracy_val: 0.7166	accuracy_test: 0.6920
[server]	loss_train: 0.6561	loss_val: 0.7851	loss_test: 0.8491	accuracy_train: 0.8344	accuracy_val: 0.7665	accuracy_test: 0.7560
[server]	loss_train: 0.5978	loss_val: 0.7568	loss_test: 0.7800	accuracy_train: 0.8593	accuracy_val: 0.7801	accuracy_test: 0.7766
[server]	loss_train: 0.8336	loss_val: 0.9247	loss_test: 0.8267	accuracy_train: 0.7280	accuracy_val: 0.7148	accuracy_test: 0.7625
[server]	loss_train: 0.7144	loss_val: 0.8735	loss_test: 0.8430	accuracy_train: 0.8189	accuracy_val: 0.7557	accuracy_test: 0.7273
[server]	loss_train: 0.6601	loss_val: 0.7521	loss_test: 0.7935	accuracy_train: 0.8435	accuracy_val: 0.7635	accuracy_test: 0.7810
[server]	loss_train: 0.6958	loss_val: 0.7907	loss_test: 0.8224	accuracy_train: 0.8421	accuracy_val: 0.7410	accuracy_test: 0.7651
[server]	loss_train: 0.6687	loss_val: 0.8427	loss_test: 0.8135	accuracy_train: 0.8320	accuracy_val: 0.7413	accuracy_test: 0.7481
[server]	loss_train: 0.6308	loss_val: 0.7464	loss_test: 0.7228	accuracy_train: 0.8467	accuracy_val: 0.8304	accuracy_test: 0.8182
[server]	loss_train: 0.7452	loss_val: 0.9441	loss_test: 0.8773	accuracy_train: 0.8168	accuracy_val: 0.7351	accuracy_test: 0.7132
[server]	loss_train: 0.7742	loss_val: 0.9483	loss_test: 0.9545	accuracy_train: 0.7879	accuracy_val: 0.7299	accuracy_test: 0.7464
[server]	loss_train: 0.8686	loss_val: 0.8331	loss_test: 0.9163	accuracy_train: 0.7388	accuracy_val: 0.7509	accuracy_test: 0.7214
[server]	loss_train: 0.7820	loss_val: 0.8020	loss_test: 0.8073	accuracy_train: 0.7868	accuracy_val: 0.7393	accuracy_test: 0.7684
[server]	loss_train: 0.6599	loss_val: 0.7458	loss_test: 0.6925	accuracy_train: 0.8299	accuracy_val: 0.7953	accuracy_test: 0.8267
[server]	loss_train: 0.6258	loss_val: 0.6208	loss_test: 0.6602	accuracy_train: 0.8357	accuracy_val: 0.8235	accuracy_test: 0.7911
[server]	loss_train: 0.6926	loss_val: 0.8380	loss_test: 0.8334	accuracy_train: 0.8382	accuracy_val: 0.7500	accuracy_test: 0.7359
[server]	loss_train: 0.7516	loss_val: 0.8434	loss_test: 0.8555	accuracy_train: 0.7838	accuracy_val: 0.7783	accuracy_test: 0.7265
[server]	loss_train: 0.5514	loss_val: 0.6266	loss_test: 0.6587	accuracy_train: 0.8865	accuracy_val: 0.8537	accuracy_test: 0.8103
[server]	loss_train: 0.6941	loss_val: 0.7679	loss_test: 0.7852	accuracy_train: 0.8013	accuracy_val: 0.7968	accuracy_test: 0.7587
curr_round: 20	curr_val_accuracy: 0.7670	curr_test_accuracy: 0.7595
best_round: 20	best_val_accuracy: 0.7670	best_test_accuracy: 0.7595
--------------------------------------------------
round # 21		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.7914	loss_val: 0.8375	loss_test: 0.8290	accuracy_train: 0.7761	accuracy_val: 0.7600	accuracy_test: 0.7419
[server]	loss_train: 0.7271	loss_val: 0.8355	loss_test: 0.9324	accuracy_train: 0.7542	accuracy_val: 0.7449	accuracy_test: 0.6920
[server]	loss_train: 0.6027	loss_val: 0.7468	loss_test: 0.8074	accuracy_train: 0.8528	accuracy_val: 0.7784	accuracy_test: 0.7649
[server]	loss_train: 0.5584	loss_val: 0.7294	loss_test: 0.7487	accuracy_train: 0.8741	accuracy_val: 0.7837	accuracy_test: 0.7695
[server]	loss_train: 0.7641	loss_val: 0.8743	loss_test: 0.7670	accuracy_train: 0.7760	accuracy_val: 0.7227	accuracy_test: 0.7663
[server]	loss_train: 0.6708	loss_val: 0.8406	loss_test: 0.8150	accuracy_train: 0.8346	accuracy_val: 0.7557	accuracy_test: 0.7386
[server]	loss_train: 0.6002	loss_val: 0.7076	loss_test: 0.7493	accuracy_train: 0.8435	accuracy_val: 0.7759	accuracy_test: 0.7645
[server]	loss_train: 0.6340	loss_val: 0.7546	loss_test: 0.7852	accuracy_train: 0.8496	accuracy_val: 0.7482	accuracy_test: 0.7651
[server]	loss_train: 0.6197	loss_val: 0.7965	loss_test: 0.7625	accuracy_train: 0.8400	accuracy_val: 0.7490	accuracy_test: 0.7519
[server]	loss_train: 0.5847	loss_val: 0.7173	loss_test: 0.6902	accuracy_train: 0.8467	accuracy_val: 0.8198	accuracy_test: 0.8182
[server]	loss_train: 0.6891	loss_val: 0.8968	loss_test: 0.8210	accuracy_train: 0.8244	accuracy_val: 0.7537	accuracy_test: 0.7279
[server]	loss_train: 0.7077	loss_val: 0.9014	loss_test: 0.8892	accuracy_train: 0.7955	accuracy_val: 0.7372	accuracy_test: 0.7536
[server]	loss_train: 0.7983	loss_val: 0.7897	loss_test: 0.8722	accuracy_train: 0.7388	accuracy_val: 0.7581	accuracy_test: 0.7107
[server]	loss_train: 0.7423	loss_val: 0.7610	loss_test: 0.7713	accuracy_train: 0.8088	accuracy_val: 0.7679	accuracy_test: 0.7719
[server]	loss_train: 0.6126	loss_val: 0.7020	loss_test: 0.6477	accuracy_train: 0.8299	accuracy_val: 0.8121	accuracy_test: 0.8333
[server]	loss_train: 0.5866	loss_val: 0.5870	loss_test: 0.6309	accuracy_train: 0.8357	accuracy_val: 0.8270	accuracy_test: 0.8014
[server]	loss_train: 0.6399	loss_val: 0.7980	loss_test: 0.7904	accuracy_train: 0.8603	accuracy_val: 0.7536	accuracy_test: 0.7394
[server]	loss_train: 0.7077	loss_val: 0.7977	loss_test: 0.8074	accuracy_train: 0.8108	accuracy_val: 0.7870	accuracy_test: 0.7521
[server]	loss_train: 0.5116	loss_val: 0.5910	loss_test: 0.6197	accuracy_train: 0.8865	accuracy_val: 0.8502	accuracy_test: 0.8345
[server]	loss_train: 0.6345	loss_val: 0.7198	loss_test: 0.7359	accuracy_train: 0.8344	accuracy_val: 0.8129	accuracy_test: 0.7841
curr_round: 21	curr_val_accuracy: 0.7761	curr_test_accuracy: 0.7654
best_round: 21	best_val_accuracy: 0.7761	best_test_accuracy: 0.7654
--------------------------------------------------
round # 22		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.7600	loss_val: 0.8095	loss_test: 0.7862	accuracy_train: 0.7836	accuracy_val: 0.7745	accuracy_test: 0.7563
[server]	loss_train: 0.6655	loss_val: 0.7757	loss_test: 0.8736	accuracy_train: 0.7797	accuracy_val: 0.7530	accuracy_test: 0.7160
[server]	loss_train: 0.5672	loss_val: 0.7318	loss_test: 0.7790	accuracy_train: 0.8650	accuracy_val: 0.7844	accuracy_test: 0.7679
[server]	loss_train: 0.5148	loss_val: 0.6863	loss_test: 0.7062	accuracy_train: 0.8741	accuracy_val: 0.7837	accuracy_test: 0.7801
[server]	loss_train: 0.7035	loss_val: 0.8225	loss_test: 0.7112	accuracy_train: 0.7520	accuracy_val: 0.7383	accuracy_test: 0.7893
[server]	loss_train: 0.6279	loss_val: 0.8069	loss_test: 0.7761	accuracy_train: 0.8583	accuracy_val: 0.7672	accuracy_test: 0.7500
[server]	loss_train: 0.5517	loss_val: 0.6791	loss_test: 0.7156	accuracy_train: 0.8696	accuracy_val: 0.7925	accuracy_test: 0.7769
[server]	loss_train: 0.5904	loss_val: 0.7122	loss_test: 0.7397	accuracy_train: 0.8722	accuracy_val: 0.7770	accuracy_test: 0.7829
[server]	loss_train: 0.5832	loss_val: 0.7579	loss_test: 0.7223	accuracy_train: 0.8480	accuracy_val: 0.7490	accuracy_test: 0.7672
[server]	loss_train: 0.5449	loss_val: 0.6813	loss_test: 0.6579	accuracy_train: 0.8540	accuracy_val: 0.8233	accuracy_test: 0.8357
[server]	loss_train: 0.6507	loss_val: 0.8521	loss_test: 0.7724	accuracy_train: 0.8244	accuracy_val: 0.7649	accuracy_test: 0.7390
[server]	loss_train: 0.6468	loss_val: 0.8441	loss_test: 0.8291	accuracy_train: 0.8409	accuracy_val: 0.7555	accuracy_test: 0.7681
[server]	loss_train: 0.7328	loss_val: 0.7485	loss_test: 0.8332	accuracy_train: 0.7537	accuracy_val: 0.7834	accuracy_test: 0.7143
[server]	loss_train: 0.6966	loss_val: 0.7197	loss_test: 0.7261	accuracy_train: 0.8088	accuracy_val: 0.7857	accuracy_test: 0.7754
[server]	loss_train: 0.5699	loss_val: 0.6808	loss_test: 0.6211	accuracy_train: 0.8299	accuracy_val: 0.8188	accuracy_test: 0.8400
[server]	loss_train: 0.5425	loss_val: 0.5459	loss_test: 0.5919	accuracy_train: 0.8286	accuracy_val: 0.8304	accuracy_test: 0.8185
[server]	loss_train: 0.6006	loss_val: 0.7612	loss_test: 0.7508	accuracy_train: 0.8676	accuracy_val: 0.7714	accuracy_test: 0.7465
[server]	loss_train: 0.6760	loss_val: 0.7560	loss_test: 0.7626	accuracy_train: 0.8288	accuracy_val: 0.7957	accuracy_test: 0.7521
[server]	loss_train: 0.4739	loss_val: 0.5542	loss_test: 0.5855	accuracy_train: 0.8936	accuracy_val: 0.8606	accuracy_test: 0.8379
[server]	loss_train: 0.5890	loss_val: 0.6773	loss_test: 0.6949	accuracy_train: 0.8344	accuracy_val: 0.8194	accuracy_test: 0.8032
curr_round: 22	curr_val_accuracy: 0.7875	curr_test_accuracy: 0.7771
best_round: 22	best_val_accuracy: 0.7875	best_test_accuracy: 0.7771
--------------------------------------------------
round # 23		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.7346	loss_val: 0.7780	loss_test: 0.7600	accuracy_train: 0.7836	accuracy_val: 0.7745	accuracy_test: 0.7563
[server]	loss_train: 0.6154	loss_val: 0.7466	loss_test: 0.8446	accuracy_train: 0.8136	accuracy_val: 0.7530	accuracy_test: 0.7200
[server]	loss_train: 0.5325	loss_val: 0.6979	loss_test: 0.7438	accuracy_train: 0.8650	accuracy_val: 0.7844	accuracy_test: 0.7768
[server]	loss_train: 0.4797	loss_val: 0.6654	loss_test: 0.6784	accuracy_train: 0.8741	accuracy_val: 0.7837	accuracy_test: 0.7766
[server]	loss_train: 0.6597	loss_val: 0.7858	loss_test: 0.6762	accuracy_train: 0.7600	accuracy_val: 0.7344	accuracy_test: 0.7969
[server]	loss_train: 0.5942	loss_val: 0.7823	loss_test: 0.7591	accuracy_train: 0.8504	accuracy_val: 0.7634	accuracy_test: 0.7538
[server]	loss_train: 0.5073	loss_val: 0.6420	loss_test: 0.6798	accuracy_train: 0.8783	accuracy_val: 0.7925	accuracy_test: 0.7934
[server]	loss_train: 0.5367	loss_val: 0.6810	loss_test: 0.7107	accuracy_train: 0.8722	accuracy_val: 0.7950	accuracy_test: 0.7900
[server]	loss_train: 0.5432	loss_val: 0.7207	loss_test: 0.6912	accuracy_train: 0.8480	accuracy_val: 0.7722	accuracy_test: 0.7786
[server]	loss_train: 0.5064	loss_val: 0.6568	loss_test: 0.6323	accuracy_train: 0.8759	accuracy_val: 0.8410	accuracy_test: 0.8357
[server]	loss_train: 0.6144	loss_val: 0.8246	loss_test: 0.7391	accuracy_train: 0.8321	accuracy_val: 0.7687	accuracy_test: 0.7426
[server]	loss_train: 0.6033	loss_val: 0.8188	loss_test: 0.7871	accuracy_train: 0.8409	accuracy_val: 0.7628	accuracy_test: 0.7717
[server]	loss_train: 0.6880	loss_val: 0.7220	loss_test: 0.8053	accuracy_train: 0.7612	accuracy_val: 0.7762	accuracy_test: 0.7321
[server]	loss_train: 0.6536	loss_val: 0.6854	loss_test: 0.6993	accuracy_train: 0.8088	accuracy_val: 0.7929	accuracy_test: 0.7754
[server]	loss_train: 0.5333	loss_val: 0.6460	loss_test: 0.5863	accuracy_train: 0.8571	accuracy_val: 0.8356	accuracy_test: 0.8533
[server]	loss_train: 0.5071	loss_val: 0.5252	loss_test: 0.5672	accuracy_train: 0.8286	accuracy_val: 0.8304	accuracy_test: 0.8253
[server]	loss_train: 0.5609	loss_val: 0.7309	loss_test: 0.7180	accuracy_train: 0.8750	accuracy_val: 0.7750	accuracy_test: 0.7570
[server]	loss_train: 0.6358	loss_val: 0.7191	loss_test: 0.7321	accuracy_train: 0.8378	accuracy_val: 0.8087	accuracy_test: 0.7650
[server]	loss_train: 0.4426	loss_val: 0.5293	loss_test: 0.5588	accuracy_train: 0.8865	accuracy_val: 0.8780	accuracy_test: 0.8310
[server]	loss_train: 0.5515	loss_val: 0.6533	loss_test: 0.6660	accuracy_train: 0.8543	accuracy_val: 0.8129	accuracy_test: 0.8190
curr_round: 23	curr_val_accuracy: 0.7928	curr_test_accuracy: 0.7837
best_round: 23	best_val_accuracy: 0.7928	best_test_accuracy: 0.7837
--------------------------------------------------
round # 24		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.6957	loss_val: 0.7602	loss_test: 0.7248	accuracy_train: 0.8134	accuracy_val: 0.7782	accuracy_test: 0.7706
[server]	loss_train: 0.5685	loss_val: 0.7029	loss_test: 0.8044	accuracy_train: 0.8305	accuracy_val: 0.7895	accuracy_test: 0.7320
[server]	loss_train: 0.5000	loss_val: 0.6890	loss_test: 0.7248	accuracy_train: 0.8650	accuracy_val: 0.7874	accuracy_test: 0.7708
[server]	loss_train: 0.4502	loss_val: 0.6378	loss_test: 0.6512	accuracy_train: 0.8889	accuracy_val: 0.7943	accuracy_test: 0.7943
[server]	loss_train: 0.6072	loss_val: 0.7515	loss_test: 0.6356	accuracy_train: 0.8080	accuracy_val: 0.7656	accuracy_test: 0.8084
[server]	loss_train: 0.5584	loss_val: 0.7595	loss_test: 0.7342	accuracy_train: 0.8740	accuracy_val: 0.7672	accuracy_test: 0.7500
[server]	loss_train: 0.4712	loss_val: 0.6212	loss_test: 0.6571	accuracy_train: 0.8957	accuracy_val: 0.7884	accuracy_test: 0.8017
[server]	loss_train: 0.5059	loss_val: 0.6586	loss_test: 0.6846	accuracy_train: 0.8797	accuracy_val: 0.7914	accuracy_test: 0.7936
[server]	loss_train: 0.5202	loss_val: 0.6944	loss_test: 0.6589	accuracy_train: 0.8640	accuracy_val: 0.7683	accuracy_test: 0.7901
[server]	loss_train: 0.4758	loss_val: 0.6347	loss_test: 0.6111	accuracy_train: 0.8759	accuracy_val: 0.8375	accuracy_test: 0.8322
[server]	loss_train: 0.5807	loss_val: 0.7970	loss_test: 0.7043	accuracy_train: 0.8473	accuracy_val: 0.7687	accuracy_test: 0.7647
[server]	loss_train: 0.5546	loss_val: 0.7784	loss_test: 0.7454	accuracy_train: 0.8636	accuracy_val: 0.7737	accuracy_test: 0.7790
[server]	loss_train: 0.6360	loss_val: 0.6941	loss_test: 0.7765	accuracy_train: 0.7985	accuracy_val: 0.7870	accuracy_test: 0.7321
[server]	loss_train: 0.6287	loss_val: 0.6605	loss_test: 0.6714	accuracy_train: 0.8235	accuracy_val: 0.8036	accuracy_test: 0.7719
[server]	loss_train: 0.5007	loss_val: 0.6281	loss_test: 0.5642	accuracy_train: 0.8503	accuracy_val: 0.8389	accuracy_test: 0.8500
[server]	loss_train: 0.4738	loss_val: 0.4982	loss_test: 0.5445	accuracy_train: 0.8429	accuracy_val: 0.8408	accuracy_test: 0.8356
[server]	loss_train: 0.5276	loss_val: 0.7057	loss_test: 0.6926	accuracy_train: 0.8824	accuracy_val: 0.7857	accuracy_test: 0.7746
[server]	loss_train: 0.6133	loss_val: 0.6915	loss_test: 0.7002	accuracy_train: 0.8559	accuracy_val: 0.8261	accuracy_test: 0.7906
[server]	loss_train: 0.4160	loss_val: 0.5071	loss_test: 0.5364	accuracy_train: 0.9078	accuracy_val: 0.8676	accuracy_test: 0.8448
[server]	loss_train: 0.5145	loss_val: 0.6219	loss_test: 0.6343	accuracy_train: 0.8609	accuracy_val: 0.8290	accuracy_test: 0.8286
curr_round: 24	curr_val_accuracy: 0.8002	curr_test_accuracy: 0.7916
best_round: 24	best_val_accuracy: 0.8002	best_test_accuracy: 0.7916
--------------------------------------------------
round # 25		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.6770	loss_val: 0.7429	loss_test: 0.7057	accuracy_train: 0.8284	accuracy_val: 0.7855	accuracy_test: 0.7814
[server]	loss_train: 0.5268	loss_val: 0.6750	loss_test: 0.7721	accuracy_train: 0.8475	accuracy_val: 0.7935	accuracy_test: 0.7400
[server]	loss_train: 0.4793	loss_val: 0.6759	loss_test: 0.7055	accuracy_train: 0.8712	accuracy_val: 0.7874	accuracy_test: 0.7768
[server]	loss_train: 0.4222	loss_val: 0.6170	loss_test: 0.6271	accuracy_train: 0.8889	accuracy_val: 0.7943	accuracy_test: 0.7979
[server]	loss_train: 0.5733	loss_val: 0.7198	loss_test: 0.6067	accuracy_train: 0.8000	accuracy_val: 0.7695	accuracy_test: 0.8046
[server]	loss_train: 0.5295	loss_val: 0.7376	loss_test: 0.7139	accuracy_train: 0.8740	accuracy_val: 0.7710	accuracy_test: 0.7652
[server]	loss_train: 0.4411	loss_val: 0.6015	loss_test: 0.6344	accuracy_train: 0.9217	accuracy_val: 0.7967	accuracy_test: 0.8099
[server]	loss_train: 0.4664	loss_val: 0.6276	loss_test: 0.6540	accuracy_train: 0.8872	accuracy_val: 0.8129	accuracy_test: 0.8007
[server]	loss_train: 0.4925	loss_val: 0.6712	loss_test: 0.6389	accuracy_train: 0.8720	accuracy_val: 0.7876	accuracy_test: 0.8015
[server]	loss_train: 0.4484	loss_val: 0.6156	loss_test: 0.5946	accuracy_train: 0.8759	accuracy_val: 0.8410	accuracy_test: 0.8322
[server]	loss_train: 0.5533	loss_val: 0.7709	loss_test: 0.6727	accuracy_train: 0.8626	accuracy_val: 0.7724	accuracy_test: 0.7794
[server]	loss_train: 0.5144	loss_val: 0.7511	loss_test: 0.7081	accuracy_train: 0.8788	accuracy_val: 0.7847	accuracy_test: 0.7790
[server]	loss_train: 0.5965	loss_val: 0.6735	loss_test: 0.7570	accuracy_train: 0.8209	accuracy_val: 0.7798	accuracy_test: 0.7500
[server]	loss_train: 0.5890	loss_val: 0.6313	loss_test: 0.6490	accuracy_train: 0.8309	accuracy_val: 0.8036	accuracy_test: 0.7754
[server]	loss_train: 0.4735	loss_val: 0.6135	loss_test: 0.5464	accuracy_train: 0.8571	accuracy_val: 0.8389	accuracy_test: 0.8533
[server]	loss_train: 0.4404	loss_val: 0.4759	loss_test: 0.5168	accuracy_train: 0.8571	accuracy_val: 0.8512	accuracy_test: 0.8459
[server]	loss_train: 0.5007	loss_val: 0.6833	loss_test: 0.6695	accuracy_train: 0.8824	accuracy_val: 0.8071	accuracy_test: 0.7887
[server]	loss_train: 0.5842	loss_val: 0.6622	loss_test: 0.6759	accuracy_train: 0.8559	accuracy_val: 0.8348	accuracy_test: 0.8034
[server]	loss_train: 0.3875	loss_val: 0.4856	loss_test: 0.5143	accuracy_train: 0.9149	accuracy_val: 0.8780	accuracy_test: 0.8483
[server]	loss_train: 0.4880	loss_val: 0.6035	loss_test: 0.6135	accuracy_train: 0.8609	accuracy_val: 0.8290	accuracy_test: 0.8222
curr_round: 25	curr_val_accuracy: 0.8065	curr_test_accuracy: 0.7984
best_round: 25	best_val_accuracy: 0.8065	best_test_accuracy: 0.7984
--------------------------------------------------
round # 26		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.6409	loss_val: 0.7227	loss_test: 0.6807	accuracy_train: 0.8284	accuracy_val: 0.7855	accuracy_test: 0.7921
[server]	loss_train: 0.4908	loss_val: 0.6545	loss_test: 0.7538	accuracy_train: 0.8644	accuracy_val: 0.7976	accuracy_test: 0.7480
[server]	loss_train: 0.4514	loss_val: 0.6555	loss_test: 0.6856	accuracy_train: 0.8773	accuracy_val: 0.7964	accuracy_test: 0.7857
[server]	loss_train: 0.3995	loss_val: 0.6027	loss_test: 0.6089	accuracy_train: 0.9037	accuracy_val: 0.8014	accuracy_test: 0.7979
[server]	loss_train: 0.5348	loss_val: 0.6946	loss_test: 0.5818	accuracy_train: 0.8080	accuracy_val: 0.7695	accuracy_test: 0.8276
[server]	loss_train: 0.4997	loss_val: 0.7201	loss_test: 0.6989	accuracy_train: 0.8740	accuracy_val: 0.7748	accuracy_test: 0.7727
[server]	loss_train: 0.4076	loss_val: 0.5756	loss_test: 0.6118	accuracy_train: 0.9304	accuracy_val: 0.8050	accuracy_test: 0.8223
[server]	loss_train: 0.4349	loss_val: 0.6115	loss_test: 0.6359	accuracy_train: 0.8872	accuracy_val: 0.8129	accuracy_test: 0.8043
[server]	loss_train: 0.4701	loss_val: 0.6455	loss_test: 0.6120	accuracy_train: 0.8640	accuracy_val: 0.7876	accuracy_test: 0.8168
[server]	loss_train: 0.4191	loss_val: 0.5987	loss_test: 0.5761	accuracy_train: 0.8905	accuracy_val: 0.8445	accuracy_test: 0.8357
[server]	loss_train: 0.5211	loss_val: 0.7532	loss_test: 0.6499	accuracy_train: 0.8931	accuracy_val: 0.7836	accuracy_test: 0.7978
[server]	loss_train: 0.4797	loss_val: 0.7298	loss_test: 0.6807	accuracy_train: 0.8939	accuracy_val: 0.7847	accuracy_test: 0.8080
[server]	loss_train: 0.5566	loss_val: 0.6523	loss_test: 0.7324	accuracy_train: 0.8433	accuracy_val: 0.7834	accuracy_test: 0.7643
[server]	loss_train: 0.5696	loss_val: 0.6169	loss_test: 0.6333	accuracy_train: 0.8235	accuracy_val: 0.8179	accuracy_test: 0.7789
[server]	loss_train: 0.4471	loss_val: 0.5900	loss_test: 0.5217	accuracy_train: 0.8707	accuracy_val: 0.8423	accuracy_test: 0.8533
[server]	loss_train: 0.4177	loss_val: 0.4667	loss_test: 0.5084	accuracy_train: 0.8714	accuracy_val: 0.8512	accuracy_test: 0.8390
[server]	loss_train: 0.4678	loss_val: 0.6631	loss_test: 0.6486	accuracy_train: 0.8824	accuracy_val: 0.8036	accuracy_test: 0.7852
[server]	loss_train: 0.5575	loss_val: 0.6392	loss_test: 0.6546	accuracy_train: 0.8559	accuracy_val: 0.8435	accuracy_test: 0.8034
[server]	loss_train: 0.3677	loss_val: 0.4743	loss_test: 0.5024	accuracy_train: 0.9149	accuracy_val: 0.8780	accuracy_test: 0.8448
[server]	loss_train: 0.4615	loss_val: 0.5893	loss_test: 0.5949	accuracy_train: 0.8808	accuracy_val: 0.8355	accuracy_test: 0.8317
curr_round: 26	curr_val_accuracy: 0.8105	curr_test_accuracy: 0.8060
best_round: 26	best_val_accuracy: 0.8105	best_test_accuracy: 0.8060
--------------------------------------------------
round # 27		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.6200	loss_val: 0.7164	loss_test: 0.6647	accuracy_train: 0.8358	accuracy_val: 0.7855	accuracy_test: 0.7885
[server]	loss_train: 0.4576	loss_val: 0.6281	loss_test: 0.7241	accuracy_train: 0.8814	accuracy_val: 0.7976	accuracy_test: 0.7600
[server]	loss_train: 0.4339	loss_val: 0.6562	loss_test: 0.6757	accuracy_train: 0.8957	accuracy_val: 0.7934	accuracy_test: 0.7768
[server]	loss_train: 0.3788	loss_val: 0.5837	loss_test: 0.5902	accuracy_train: 0.9037	accuracy_val: 0.7979	accuracy_test: 0.8121
[server]	loss_train: 0.5045	loss_val: 0.6711	loss_test: 0.5577	accuracy_train: 0.8240	accuracy_val: 0.7773	accuracy_test: 0.8391
[server]	loss_train: 0.4744	loss_val: 0.7032	loss_test: 0.6810	accuracy_train: 0.8819	accuracy_val: 0.7786	accuracy_test: 0.7689
[server]	loss_train: 0.3870	loss_val: 0.5676	loss_test: 0.6004	accuracy_train: 0.9391	accuracy_val: 0.8050	accuracy_test: 0.8264
[server]	loss_train: 0.4094	loss_val: 0.5894	loss_test: 0.6135	accuracy_train: 0.8947	accuracy_val: 0.8129	accuracy_test: 0.8114
[server]	loss_train: 0.4529	loss_val: 0.6326	loss_test: 0.5968	accuracy_train: 0.8800	accuracy_val: 0.7954	accuracy_test: 0.8244
[server]	loss_train: 0.3984	loss_val: 0.5844	loss_test: 0.5658	accuracy_train: 0.8978	accuracy_val: 0.8410	accuracy_test: 0.8287
[server]	loss_train: 0.4995	loss_val: 0.7333	loss_test: 0.6238	accuracy_train: 0.8855	accuracy_val: 0.7910	accuracy_test: 0.8051
[server]	loss_train: 0.4433	loss_val: 0.7038	loss_test: 0.6512	accuracy_train: 0.9091	accuracy_val: 0.7956	accuracy_test: 0.8152
[server]	loss_train: 0.5243	loss_val: 0.6379	loss_test: 0.7199	accuracy_train: 0.8358	accuracy_val: 0.7942	accuracy_test: 0.7679
[server]	loss_train: 0.5417	loss_val: 0.5953	loss_test: 0.6154	accuracy_train: 0.8382	accuracy_val: 0.8214	accuracy_test: 0.7895
[server]	loss_train: 0.4247	loss_val: 0.5857	loss_test: 0.5129	accuracy_train: 0.8776	accuracy_val: 0.8389	accuracy_test: 0.8567
[server]	loss_train: 0.3886	loss_val: 0.4440	loss_test: 0.4842	accuracy_train: 0.8929	accuracy_val: 0.8547	accuracy_test: 0.8596
[server]	loss_train: 0.4496	loss_val: 0.6474	loss_test: 0.6347	accuracy_train: 0.8971	accuracy_val: 0.8107	accuracy_test: 0.7887
[server]	loss_train: 0.5367	loss_val: 0.6182	loss_test: 0.6347	accuracy_train: 0.8649	accuracy_val: 0.8304	accuracy_test: 0.7991
[server]	loss_train: 0.3439	loss_val: 0.4579	loss_test: 0.4850	accuracy_train: 0.9149	accuracy_val: 0.8780	accuracy_test: 0.8517
[server]	loss_train: 0.4379	loss_val: 0.5698	loss_test: 0.5768	accuracy_train: 0.8742	accuracy_val: 0.8355	accuracy_test: 0.8317
curr_round: 27	curr_val_accuracy: 0.8124	curr_test_accuracy: 0.8105
best_round: 27	best_val_accuracy: 0.8124	best_test_accuracy: 0.8105
--------------------------------------------------
round # 28		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.5942	loss_val: 0.7019	loss_test: 0.6491	accuracy_train: 0.8433	accuracy_val: 0.7855	accuracy_test: 0.7921
[server]	loss_train: 0.4289	loss_val: 0.6137	loss_test: 0.7093	accuracy_train: 0.8898	accuracy_val: 0.7976	accuracy_test: 0.7600
[server]	loss_train: 0.4140	loss_val: 0.6408	loss_test: 0.6603	accuracy_train: 0.8896	accuracy_val: 0.8054	accuracy_test: 0.7857
[server]	loss_train: 0.3590	loss_val: 0.5718	loss_test: 0.5750	accuracy_train: 0.9259	accuracy_val: 0.8050	accuracy_test: 0.8121
[server]	loss_train: 0.4753	loss_val: 0.6501	loss_test: 0.5397	accuracy_train: 0.8400	accuracy_val: 0.7852	accuracy_test: 0.8429
[server]	loss_train: 0.4495	loss_val: 0.6872	loss_test: 0.6678	accuracy_train: 0.8819	accuracy_val: 0.7748	accuracy_test: 0.7803
[server]	loss_train: 0.3618	loss_val: 0.5481	loss_test: 0.5828	accuracy_train: 0.9391	accuracy_val: 0.8091	accuracy_test: 0.8306
[server]	loss_train: 0.3823	loss_val: 0.5729	loss_test: 0.5962	accuracy_train: 0.9023	accuracy_val: 0.8129	accuracy_test: 0.8114
[server]	loss_train: 0.4322	loss_val: 0.6138	loss_test: 0.5796	accuracy_train: 0.8880	accuracy_val: 0.7992	accuracy_test: 0.8282
[server]	loss_train: 0.3735	loss_val: 0.5699	loss_test: 0.5518	accuracy_train: 0.9197	accuracy_val: 0.8410	accuracy_test: 0.8357
[server]	loss_train: 0.4751	loss_val: 0.7186	loss_test: 0.6057	accuracy_train: 0.8931	accuracy_val: 0.7948	accuracy_test: 0.8088
[server]	loss_train: 0.4158	loss_val: 0.6879	loss_test: 0.6297	accuracy_train: 0.9091	accuracy_val: 0.7956	accuracy_test: 0.8188
[server]	loss_train: 0.4944	loss_val: 0.6219	loss_test: 0.7036	accuracy_train: 0.8582	accuracy_val: 0.7978	accuracy_test: 0.7679
[server]	loss_train: 0.5187	loss_val: 0.5807	loss_test: 0.6021	accuracy_train: 0.8382	accuracy_val: 0.8179	accuracy_test: 0.7825
[server]	loss_train: 0.4037	loss_val: 0.5696	loss_test: 0.4959	accuracy_train: 0.8844	accuracy_val: 0.8456	accuracy_test: 0.8533
[server]	loss_train: 0.3674	loss_val: 0.4348	loss_test: 0.4729	accuracy_train: 0.9143	accuracy_val: 0.8547	accuracy_test: 0.8562
[server]	loss_train: 0.4249	loss_val: 0.6315	loss_test: 0.6188	accuracy_train: 0.8971	accuracy_val: 0.8071	accuracy_test: 0.7887
[server]	loss_train: 0.5119	loss_val: 0.5989	loss_test: 0.6187	accuracy_train: 0.8739	accuracy_val: 0.8304	accuracy_test: 0.8034
[server]	loss_train: 0.3246	loss_val: 0.4475	loss_test: 0.4740	accuracy_train: 0.9149	accuracy_val: 0.8850	accuracy_test: 0.8552
[server]	loss_train: 0.4177	loss_val: 0.5608	loss_test: 0.5641	accuracy_train: 0.8874	accuracy_val: 0.8355	accuracy_test: 0.8381
curr_round: 28	curr_val_accuracy: 0.8147	curr_test_accuracy: 0.8130
best_round: 28	best_val_accuracy: 0.8147	best_test_accuracy: 0.8130
--------------------------------------------------
round # 29		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.5680	loss_val: 0.6925	loss_test: 0.6336	accuracy_train: 0.8433	accuracy_val: 0.7818	accuracy_test: 0.8029
[server]	loss_train: 0.4032	loss_val: 0.5986	loss_test: 0.6941	accuracy_train: 0.8898	accuracy_val: 0.8016	accuracy_test: 0.7600
[server]	loss_train: 0.3946	loss_val: 0.6342	loss_test: 0.6502	accuracy_train: 0.9018	accuracy_val: 0.8084	accuracy_test: 0.7887
[server]	loss_train: 0.3423	loss_val: 0.5614	loss_test: 0.5621	accuracy_train: 0.9259	accuracy_val: 0.8085	accuracy_test: 0.8121
[server]	loss_train: 0.4474	loss_val: 0.6332	loss_test: 0.5227	accuracy_train: 0.8720	accuracy_val: 0.8086	accuracy_test: 0.8429
[server]	loss_train: 0.4262	loss_val: 0.6744	loss_test: 0.6568	accuracy_train: 0.8976	accuracy_val: 0.7748	accuracy_test: 0.7841
[server]	loss_train: 0.3414	loss_val: 0.5352	loss_test: 0.5717	accuracy_train: 0.9565	accuracy_val: 0.8174	accuracy_test: 0.8306
[server]	loss_train: 0.3608	loss_val: 0.5613	loss_test: 0.5837	accuracy_train: 0.9023	accuracy_val: 0.8201	accuracy_test: 0.8114
[server]	loss_train: 0.4173	loss_val: 0.6009	loss_test: 0.5643	accuracy_train: 0.8960	accuracy_val: 0.7954	accuracy_test: 0.8282
[server]	loss_train: 0.3530	loss_val: 0.5588	loss_test: 0.5422	accuracy_train: 0.9197	accuracy_val: 0.8410	accuracy_test: 0.8322
[server]	loss_train: 0.4524	loss_val: 0.7061	loss_test: 0.5884	accuracy_train: 0.9008	accuracy_val: 0.7948	accuracy_test: 0.8162
[server]	loss_train: 0.3888	loss_val: 0.6719	loss_test: 0.6107	accuracy_train: 0.9167	accuracy_val: 0.7993	accuracy_test: 0.8261
[server]	loss_train: 0.4669	loss_val: 0.6087	loss_test: 0.6907	accuracy_train: 0.8657	accuracy_val: 0.8014	accuracy_test: 0.7821
[server]	loss_train: 0.5024	loss_val: 0.5688	loss_test: 0.5912	accuracy_train: 0.8456	accuracy_val: 0.8250	accuracy_test: 0.7895
[server]	loss_train: 0.3846	loss_val: 0.5593	loss_test: 0.4833	accuracy_train: 0.8980	accuracy_val: 0.8423	accuracy_test: 0.8533
[server]	loss_train: 0.3476	loss_val: 0.4237	loss_test: 0.4623	accuracy_train: 0.9143	accuracy_val: 0.8547	accuracy_test: 0.8562
[server]	loss_train: 0.4048	loss_val: 0.6190	loss_test: 0.6077	accuracy_train: 0.8971	accuracy_val: 0.8179	accuracy_test: 0.7887
[server]	loss_train: 0.4903	loss_val: 0.5836	loss_test: 0.6042	accuracy_train: 0.8739	accuracy_val: 0.8304	accuracy_test: 0.8120
[server]	loss_train: 0.3075	loss_val: 0.4392	loss_test: 0.4646	accuracy_train: 0.9220	accuracy_val: 0.8850	accuracy_test: 0.8621
[server]	loss_train: 0.3977	loss_val: 0.5494	loss_test: 0.5512	accuracy_train: 0.8874	accuracy_val: 0.8419	accuracy_test: 0.8413
curr_round: 29	curr_val_accuracy: 0.8182	curr_test_accuracy: 0.8164
best_round: 29	best_val_accuracy: 0.8182	best_test_accuracy: 0.8164
--------------------------------------------------
round # 30		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.5516	loss_val: 0.6867	loss_test: 0.6238	accuracy_train: 0.8433	accuracy_val: 0.7818	accuracy_test: 0.7957
[server]	loss_train: 0.3787	loss_val: 0.5842	loss_test: 0.6764	accuracy_train: 0.8814	accuracy_val: 0.8016	accuracy_test: 0.7680
[server]	loss_train: 0.3818	loss_val: 0.6304	loss_test: 0.6412	accuracy_train: 0.9141	accuracy_val: 0.8054	accuracy_test: 0.7857
[server]	loss_train: 0.3247	loss_val: 0.5491	loss_test: 0.5489	accuracy_train: 0.9259	accuracy_val: 0.8050	accuracy_test: 0.8191
[server]	loss_train: 0.4255	loss_val: 0.6150	loss_test: 0.5077	accuracy_train: 0.8640	accuracy_val: 0.8242	accuracy_test: 0.8621
[server]	loss_train: 0.4050	loss_val: 0.6599	loss_test: 0.6427	accuracy_train: 0.8976	accuracy_val: 0.7824	accuracy_test: 0.7803
[server]	loss_train: 0.3251	loss_val: 0.5264	loss_test: 0.5612	accuracy_train: 0.9652	accuracy_val: 0.8216	accuracy_test: 0.8347
[server]	loss_train: 0.3398	loss_val: 0.5441	loss_test: 0.5650	accuracy_train: 0.9098	accuracy_val: 0.8237	accuracy_test: 0.8185
[server]	loss_train: 0.4017	loss_val: 0.5897	loss_test: 0.5535	accuracy_train: 0.8960	accuracy_val: 0.8069	accuracy_test: 0.8321
[server]	loss_train: 0.3350	loss_val: 0.5467	loss_test: 0.5331	accuracy_train: 0.9197	accuracy_val: 0.8410	accuracy_test: 0.8357
[server]	loss_train: 0.4343	loss_val: 0.6916	loss_test: 0.5707	accuracy_train: 0.9084	accuracy_val: 0.7985	accuracy_test: 0.8162
[server]	loss_train: 0.3639	loss_val: 0.6545	loss_test: 0.5912	accuracy_train: 0.9318	accuracy_val: 0.8066	accuracy_test: 0.8333
[server]	loss_train: 0.4428	loss_val: 0.5972	loss_test: 0.6806	accuracy_train: 0.8806	accuracy_val: 0.7978	accuracy_test: 0.7750
[server]	loss_train: 0.4796	loss_val: 0.5545	loss_test: 0.5796	accuracy_train: 0.8529	accuracy_val: 0.8321	accuracy_test: 0.7965
[server]	loss_train: 0.3685	loss_val: 0.5552	loss_test: 0.4765	accuracy_train: 0.8980	accuracy_val: 0.8456	accuracy_test: 0.8600
[server]	loss_train: 0.3266	loss_val: 0.4109	loss_test: 0.4470	accuracy_train: 0.9143	accuracy_val: 0.8616	accuracy_test: 0.8630
[server]	loss_train: 0.3891	loss_val: 0.6065	loss_test: 0.5959	accuracy_train: 0.9044	accuracy_val: 0.8250	accuracy_test: 0.7852
[server]	loss_train: 0.4695	loss_val: 0.5676	loss_test: 0.5907	accuracy_train: 0.8829	accuracy_val: 0.8348	accuracy_test: 0.8077
[server]	loss_train: 0.2887	loss_val: 0.4285	loss_test: 0.4539	accuracy_train: 0.9220	accuracy_val: 0.8920	accuracy_test: 0.8690
[server]	loss_train: 0.3807	loss_val: 0.5402	loss_test: 0.5404	accuracy_train: 0.8874	accuracy_val: 0.8452	accuracy_test: 0.8381
curr_round: 30	curr_val_accuracy: 0.8222	curr_test_accuracy: 0.8191
best_round: 30	best_val_accuracy: 0.8222	best_test_accuracy: 0.8191
--------------------------------------------------
round # 31		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.5257	loss_val: 0.6770	loss_test: 0.6108	accuracy_train: 0.8433	accuracy_val: 0.7855	accuracy_test: 0.8029
[server]	loss_train: 0.3586	loss_val: 0.5745	loss_test: 0.6675	accuracy_train: 0.8898	accuracy_val: 0.8016	accuracy_test: 0.7680
[server]	loss_train: 0.3636	loss_val: 0.6235	loss_test: 0.6328	accuracy_train: 0.9264	accuracy_val: 0.8024	accuracy_test: 0.7917
[server]	loss_train: 0.3108	loss_val: 0.5424	loss_test: 0.5384	accuracy_train: 0.9259	accuracy_val: 0.8191	accuracy_test: 0.8156
[server]	loss_train: 0.4012	loss_val: 0.6028	loss_test: 0.4954	accuracy_train: 0.8800	accuracy_val: 0.8281	accuracy_test: 0.8544
[server]	loss_train: 0.3853	loss_val: 0.6499	loss_test: 0.6357	accuracy_train: 0.9134	accuracy_val: 0.7786	accuracy_test: 0.7841
[server]	loss_train: 0.3066	loss_val: 0.5139	loss_test: 0.5525	accuracy_train: 0.9652	accuracy_val: 0.8257	accuracy_test: 0.8388
[server]	loss_train: 0.3224	loss_val: 0.5372	loss_test: 0.5575	accuracy_train: 0.9173	accuracy_val: 0.8237	accuracy_test: 0.8114
[server]	loss_train: 0.3883	loss_val: 0.5795	loss_test: 0.5409	accuracy_train: 0.9120	accuracy_val: 0.8108	accuracy_test: 0.8282
[server]	loss_train: 0.3154	loss_val: 0.5382	loss_test: 0.5261	accuracy_train: 0.9270	accuracy_val: 0.8445	accuracy_test: 0.8392
[server]	loss_train: 0.4138	loss_val: 0.6842	loss_test: 0.5588	accuracy_train: 0.9084	accuracy_val: 0.7985	accuracy_test: 0.8162
[server]	loss_train: 0.3423	loss_val: 0.6442	loss_test: 0.5781	accuracy_train: 0.9318	accuracy_val: 0.8066	accuracy_test: 0.8297
[server]	loss_train: 0.4203	loss_val: 0.5864	loss_test: 0.6710	accuracy_train: 0.8806	accuracy_val: 0.7978	accuracy_test: 0.7786
[server]	loss_train: 0.4662	loss_val: 0.5464	loss_test: 0.5715	accuracy_train: 0.8529	accuracy_val: 0.8286	accuracy_test: 0.7965
[server]	loss_train: 0.3516	loss_val: 0.5448	loss_test: 0.4650	accuracy_train: 0.9116	accuracy_val: 0.8557	accuracy_test: 0.8633
[server]	loss_train: 0.3115	loss_val: 0.4032	loss_test: 0.4408	accuracy_train: 0.9143	accuracy_val: 0.8651	accuracy_test: 0.8630
[server]	loss_train: 0.3707	loss_val: 0.5973	loss_test: 0.5885	accuracy_train: 0.9044	accuracy_val: 0.8250	accuracy_test: 0.7958
[server]	loss_train: 0.4489	loss_val: 0.5567	loss_test: 0.5798	accuracy_train: 0.8919	accuracy_val: 0.8391	accuracy_test: 0.8120
[server]	loss_train: 0.2748	loss_val: 0.4241	loss_test: 0.4476	accuracy_train: 0.9291	accuracy_val: 0.8885	accuracy_test: 0.8690
[server]	loss_train: 0.3633	loss_val: 0.5325	loss_test: 0.5314	accuracy_train: 0.8874	accuracy_val: 0.8452	accuracy_test: 0.8413
curr_round: 31	curr_val_accuracy: 0.8240	curr_test_accuracy: 0.8203
best_round: 31	best_val_accuracy: 0.8240	best_test_accuracy: 0.8203
--------------------------------------------------
round # 32		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.5093	loss_val: 0.6713	loss_test: 0.6029	accuracy_train: 0.8358	accuracy_val: 0.7855	accuracy_test: 0.8065
[server]	loss_train: 0.3380	loss_val: 0.5646	loss_test: 0.6554	accuracy_train: 0.8983	accuracy_val: 0.7976	accuracy_test: 0.7720
[server]	loss_train: 0.3517	loss_val: 0.6182	loss_test: 0.6247	accuracy_train: 0.9264	accuracy_val: 0.8084	accuracy_test: 0.7917
[server]	loss_train: 0.2956	loss_val: 0.5332	loss_test: 0.5282	accuracy_train: 0.9259	accuracy_val: 0.8227	accuracy_test: 0.8191
[server]	loss_train: 0.3821	loss_val: 0.5880	loss_test: 0.4842	accuracy_train: 0.8800	accuracy_val: 0.8281	accuracy_test: 0.8621
[server]	loss_train: 0.3669	loss_val: 0.6376	loss_test: 0.6243	accuracy_train: 0.9213	accuracy_val: 0.7824	accuracy_test: 0.7955
[server]	loss_train: 0.2917	loss_val: 0.5049	loss_test: 0.5435	accuracy_train: 0.9652	accuracy_val: 0.8340	accuracy_test: 0.8388
[server]	loss_train: 0.3054	loss_val: 0.5240	loss_test: 0.5430	accuracy_train: 0.9323	accuracy_val: 0.8273	accuracy_test: 0.8149
[server]	loss_train: 0.3744	loss_val: 0.5700	loss_test: 0.5318	accuracy_train: 0.9200	accuracy_val: 0.8147	accuracy_test: 0.8282
[server]	loss_train: 0.2990	loss_val: 0.5282	loss_test: 0.5179	accuracy_train: 0.9270	accuracy_val: 0.8445	accuracy_test: 0.8497
[server]	loss_train: 0.3975	loss_val: 0.6732	loss_test: 0.5455	accuracy_train: 0.9084	accuracy_val: 0.8022	accuracy_test: 0.8199
[server]	loss_train: 0.3226	loss_val: 0.6312	loss_test: 0.5637	accuracy_train: 0.9394	accuracy_val: 0.8066	accuracy_test: 0.8370
[server]	loss_train: 0.4000	loss_val: 0.5764	loss_test: 0.6623	accuracy_train: 0.8881	accuracy_val: 0.8014	accuracy_test: 0.7857
[server]	loss_train: 0.4467	loss_val: 0.5360	loss_test: 0.5625	accuracy_train: 0.8676	accuracy_val: 0.8357	accuracy_test: 0.8000
[server]	loss_train: 0.3373	loss_val: 0.5401	loss_test: 0.4584	accuracy_train: 0.9184	accuracy_val: 0.8591	accuracy_test: 0.8633
[server]	loss_train: 0.2951	loss_val: 0.3946	loss_test: 0.4298	accuracy_train: 0.9143	accuracy_val: 0.8685	accuracy_test: 0.8630
[server]	loss_train: 0.3558	loss_val: 0.5867	loss_test: 0.5787	accuracy_train: 0.9191	accuracy_val: 0.8250	accuracy_test: 0.7887
[server]	loss_train: 0.4293	loss_val: 0.5437	loss_test: 0.5690	accuracy_train: 0.9189	accuracy_val: 0.8435	accuracy_test: 0.8077
[server]	loss_train: 0.2591	loss_val: 0.4168	loss_test: 0.4400	accuracy_train: 0.9291	accuracy_val: 0.8850	accuracy_test: 0.8724
[server]	loss_train: 0.3482	loss_val: 0.5266	loss_test: 0.5230	accuracy_train: 0.8940	accuracy_val: 0.8484	accuracy_test: 0.8381
curr_round: 32	curr_val_accuracy: 0.8265	curr_test_accuracy: 0.8230
best_round: 32	best_val_accuracy: 0.8265	best_test_accuracy: 0.8230
--------------------------------------------------
round # 33		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.4898	loss_val: 0.6664	loss_test: 0.5943	accuracy_train: 0.8433	accuracy_val: 0.7891	accuracy_test: 0.8065
[server]	loss_train: 0.3205	loss_val: 0.5562	loss_test: 0.6457	accuracy_train: 0.8898	accuracy_val: 0.7976	accuracy_test: 0.7760
[server]	loss_train: 0.3378	loss_val: 0.6168	loss_test: 0.6189	accuracy_train: 0.9264	accuracy_val: 0.8084	accuracy_test: 0.7917
[server]	loss_train: 0.2831	loss_val: 0.5267	loss_test: 0.5192	accuracy_train: 0.9259	accuracy_val: 0.8227	accuracy_test: 0.8227
[server]	loss_train: 0.3632	loss_val: 0.5773	loss_test: 0.4742	accuracy_train: 0.8880	accuracy_val: 0.8281	accuracy_test: 0.8659
[server]	loss_train: 0.3502	loss_val: 0.6290	loss_test: 0.6172	accuracy_train: 0.9213	accuracy_val: 0.7824	accuracy_test: 0.7917
[server]	loss_train: 0.2785	loss_val: 0.4977	loss_test: 0.5384	accuracy_train: 0.9652	accuracy_val: 0.8382	accuracy_test: 0.8388
[server]	loss_train: 0.2912	loss_val: 0.5165	loss_test: 0.5346	accuracy_train: 0.9398	accuracy_val: 0.8345	accuracy_test: 0.8185
[server]	loss_train: 0.3639	loss_val: 0.5631	loss_test: 0.5226	accuracy_train: 0.9280	accuracy_val: 0.8108	accuracy_test: 0.8359
[server]	loss_train: 0.2841	loss_val: 0.5213	loss_test: 0.5129	accuracy_train: 0.9343	accuracy_val: 0.8481	accuracy_test: 0.8497
[server]	loss_train: 0.3806	loss_val: 0.6658	loss_test: 0.5342	accuracy_train: 0.9084	accuracy_val: 0.8022	accuracy_test: 0.8272
[server]	loss_train: 0.3036	loss_val: 0.6206	loss_test: 0.5524	accuracy_train: 0.9394	accuracy_val: 0.8066	accuracy_test: 0.8333
[server]	loss_train: 0.3814	loss_val: 0.5686	loss_test: 0.6557	accuracy_train: 0.8955	accuracy_val: 0.8014	accuracy_test: 0.7857
[server]	loss_train: 0.4328	loss_val: 0.5286	loss_test: 0.5563	accuracy_train: 0.8750	accuracy_val: 0.8357	accuracy_test: 0.8000
[server]	loss_train: 0.3236	loss_val: 0.5361	loss_test: 0.4521	accuracy_train: 0.9184	accuracy_val: 0.8591	accuracy_test: 0.8633
[server]	loss_train: 0.2813	loss_val: 0.3863	loss_test: 0.4224	accuracy_train: 0.9143	accuracy_val: 0.8685	accuracy_test: 0.8630
[server]	loss_train: 0.3421	loss_val: 0.5789	loss_test: 0.5729	accuracy_train: 0.9118	accuracy_val: 0.8250	accuracy_test: 0.7923
[server]	loss_train: 0.4102	loss_val: 0.5343	loss_test: 0.5599	accuracy_train: 0.9279	accuracy_val: 0.8435	accuracy_test: 0.8205
[server]	loss_train: 0.2460	loss_val: 0.4123	loss_test: 0.4344	accuracy_train: 0.9291	accuracy_val: 0.8850	accuracy_test: 0.8759
[server]	loss_train: 0.3325	loss_val: 0.5198	loss_test: 0.5154	accuracy_train: 0.9007	accuracy_val: 0.8484	accuracy_test: 0.8444
curr_round: 33	curr_val_accuracy: 0.8272	curr_test_accuracy: 0.8254
best_round: 33	best_val_accuracy: 0.8272	best_test_accuracy: 0.8254
--------------------------------------------------
round # 34		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.4719	loss_val: 0.6602	loss_test: 0.5871	accuracy_train: 0.8507	accuracy_val: 0.7891	accuracy_test: 0.8100
[server]	loss_train: 0.3038	loss_val: 0.5494	loss_test: 0.6387	accuracy_train: 0.9322	accuracy_val: 0.7976	accuracy_test: 0.7720
[server]	loss_train: 0.3254	loss_val: 0.6115	loss_test: 0.6127	accuracy_train: 0.9264	accuracy_val: 0.8114	accuracy_test: 0.7917
[server]	loss_train: 0.2708	loss_val: 0.5211	loss_test: 0.5121	accuracy_train: 0.9333	accuracy_val: 0.8191	accuracy_test: 0.8227
[server]	loss_train: 0.3456	loss_val: 0.5669	loss_test: 0.4658	accuracy_train: 0.8960	accuracy_val: 0.8320	accuracy_test: 0.8659
[server]	loss_train: 0.3345	loss_val: 0.6203	loss_test: 0.6099	accuracy_train: 0.9213	accuracy_val: 0.7786	accuracy_test: 0.7917
[server]	loss_train: 0.2649	loss_val: 0.4887	loss_test: 0.5318	accuracy_train: 0.9652	accuracy_val: 0.8423	accuracy_test: 0.8388
[server]	loss_train: 0.2775	loss_val: 0.5089	loss_test: 0.5266	accuracy_train: 0.9474	accuracy_val: 0.8309	accuracy_test: 0.8221
[server]	loss_train: 0.3524	loss_val: 0.5561	loss_test: 0.5151	accuracy_train: 0.9280	accuracy_val: 0.8147	accuracy_test: 0.8397
[server]	loss_train: 0.2691	loss_val: 0.5147	loss_test: 0.5072	accuracy_train: 0.9416	accuracy_val: 0.8481	accuracy_test: 0.8497
[server]	loss_train: 0.3657	loss_val: 0.6589	loss_test: 0.5251	accuracy_train: 0.9160	accuracy_val: 0.8097	accuracy_test: 0.8235
[server]	loss_train: 0.2876	loss_val: 0.6122	loss_test: 0.5425	accuracy_train: 0.9545	accuracy_val: 0.8139	accuracy_test: 0.8333
[server]	loss_train: 0.3643	loss_val: 0.5602	loss_test: 0.6494	accuracy_train: 0.9104	accuracy_val: 0.8014	accuracy_test: 0.7857
[server]	loss_train: 0.4178	loss_val: 0.5216	loss_test: 0.5498	accuracy_train: 0.8750	accuracy_val: 0.8357	accuracy_test: 0.8070
[server]	loss_train: 0.3105	loss_val: 0.5301	loss_test: 0.4452	accuracy_train: 0.9252	accuracy_val: 0.8591	accuracy_test: 0.8700
[server]	loss_train: 0.2686	loss_val: 0.3806	loss_test: 0.4151	accuracy_train: 0.9143	accuracy_val: 0.8685	accuracy_test: 0.8630
[server]	loss_train: 0.3280	loss_val: 0.5711	loss_test: 0.5665	accuracy_train: 0.9265	accuracy_val: 0.8286	accuracy_test: 0.7958
[server]	loss_train: 0.3923	loss_val: 0.5248	loss_test: 0.5515	accuracy_train: 0.9279	accuracy_val: 0.8435	accuracy_test: 0.8205
[server]	loss_train: 0.2335	loss_val: 0.4085	loss_test: 0.4293	accuracy_train: 0.9362	accuracy_val: 0.8920	accuracy_test: 0.8759
[server]	loss_train: 0.3187	loss_val: 0.5155	loss_test: 0.5091	accuracy_train: 0.9007	accuracy_val: 0.8484	accuracy_test: 0.8444
curr_round: 34	curr_val_accuracy: 0.8287	curr_test_accuracy: 0.8264
best_round: 34	best_val_accuracy: 0.8287	best_test_accuracy: 0.8264
--------------------------------------------------
round # 35		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.4567	loss_val: 0.6563	loss_test: 0.5813	accuracy_train: 0.8582	accuracy_val: 0.7927	accuracy_test: 0.8029
[server]	loss_train: 0.2886	loss_val: 0.5430	loss_test: 0.6301	accuracy_train: 0.9237	accuracy_val: 0.8016	accuracy_test: 0.7760
[server]	loss_train: 0.3146	loss_val: 0.6102	loss_test: 0.6068	accuracy_train: 0.9264	accuracy_val: 0.8114	accuracy_test: 0.7917
[server]	loss_train: 0.2585	loss_val: 0.5149	loss_test: 0.5036	accuracy_train: 0.9333	accuracy_val: 0.8227	accuracy_test: 0.8262
[server]	loss_train: 0.3308	loss_val: 0.5566	loss_test: 0.4582	accuracy_train: 0.8960	accuracy_val: 0.8320	accuracy_test: 0.8659
[server]	loss_train: 0.3198	loss_val: 0.6117	loss_test: 0.6026	accuracy_train: 0.9134	accuracy_val: 0.7824	accuracy_test: 0.7955
[server]	loss_train: 0.2536	loss_val: 0.4830	loss_test: 0.5269	accuracy_train: 0.9652	accuracy_val: 0.8382	accuracy_test: 0.8347
[server]	loss_train: 0.2651	loss_val: 0.5005	loss_test: 0.5164	accuracy_train: 0.9549	accuracy_val: 0.8345	accuracy_test: 0.8292
[server]	loss_train: 0.3417	loss_val: 0.5498	loss_test: 0.5078	accuracy_train: 0.9360	accuracy_val: 0.8108	accuracy_test: 0.8397
[server]	loss_train: 0.2560	loss_val: 0.5081	loss_test: 0.5025	accuracy_train: 0.9562	accuracy_val: 0.8551	accuracy_test: 0.8531
[server]	loss_train: 0.3512	loss_val: 0.6522	loss_test: 0.5153	accuracy_train: 0.9160	accuracy_val: 0.8172	accuracy_test: 0.8235
[server]	loss_train: 0.2718	loss_val: 0.6027	loss_test: 0.5326	accuracy_train: 0.9545	accuracy_val: 0.8102	accuracy_test: 0.8370
[server]	loss_train: 0.3486	loss_val: 0.5535	loss_test: 0.6441	accuracy_train: 0.9179	accuracy_val: 0.8051	accuracy_test: 0.7893
[server]	loss_train: 0.4031	loss_val: 0.5149	loss_test: 0.5438	accuracy_train: 0.8750	accuracy_val: 0.8321	accuracy_test: 0.8105
[server]	loss_train: 0.2994	loss_val: 0.5284	loss_test: 0.4413	accuracy_train: 0.9252	accuracy_val: 0.8624	accuracy_test: 0.8667
[server]	loss_train: 0.2565	loss_val: 0.3733	loss_test: 0.4081	accuracy_train: 0.9214	accuracy_val: 0.8754	accuracy_test: 0.8596
[server]	loss_train: 0.3164	loss_val: 0.5642	loss_test: 0.5610	accuracy_train: 0.9338	accuracy_val: 0.8286	accuracy_test: 0.7958
[server]	loss_train: 0.3739	loss_val: 0.5164	loss_test: 0.5437	accuracy_train: 0.9279	accuracy_val: 0.8478	accuracy_test: 0.8248
[server]	loss_train: 0.2214	loss_val: 0.4041	loss_test: 0.4244	accuracy_train: 0.9504	accuracy_val: 0.8920	accuracy_test: 0.8793
[server]	loss_train: 0.3052	loss_val: 0.5112	loss_test: 0.5033	accuracy_train: 0.9007	accuracy_val: 0.8452	accuracy_test: 0.8444
curr_round: 35	curr_val_accuracy: 0.8303	curr_test_accuracy: 0.8275
best_round: 35	best_val_accuracy: 0.8303	best_test_accuracy: 0.8275
--------------------------------------------------
round # 36		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.4395	loss_val: 0.6517	loss_test: 0.5746	accuracy_train: 0.8731	accuracy_val: 0.7964	accuracy_test: 0.8065
[server]	loss_train: 0.2745	loss_val: 0.5374	loss_test: 0.6250	accuracy_train: 0.9322	accuracy_val: 0.8016	accuracy_test: 0.7760
[server]	loss_train: 0.3027	loss_val: 0.6076	loss_test: 0.6028	accuracy_train: 0.9325	accuracy_val: 0.8174	accuracy_test: 0.7917
[server]	loss_train: 0.2481	loss_val: 0.5108	loss_test: 0.4981	accuracy_train: 0.9333	accuracy_val: 0.8191	accuracy_test: 0.8262
[server]	loss_train: 0.3152	loss_val: 0.5492	loss_test: 0.4515	accuracy_train: 0.8960	accuracy_val: 0.8320	accuracy_test: 0.8659
[server]	loss_train: 0.3062	loss_val: 0.6055	loss_test: 0.5974	accuracy_train: 0.9134	accuracy_val: 0.7786	accuracy_test: 0.7917
[server]	loss_train: 0.2421	loss_val: 0.4760	loss_test: 0.5229	accuracy_train: 0.9739	accuracy_val: 0.8382	accuracy_test: 0.8347
[server]	loss_train: 0.2541	loss_val: 0.4959	loss_test: 0.5116	accuracy_train: 0.9549	accuracy_val: 0.8345	accuracy_test: 0.8292
[server]	loss_train: 0.3332	loss_val: 0.5450	loss_test: 0.5013	accuracy_train: 0.9440	accuracy_val: 0.8147	accuracy_test: 0.8435
[server]	loss_train: 0.2434	loss_val: 0.5034	loss_test: 0.4987	accuracy_train: 0.9562	accuracy_val: 0.8551	accuracy_test: 0.8497
[server]	loss_train: 0.3377	loss_val: 0.6475	loss_test: 0.5083	accuracy_train: 0.9237	accuracy_val: 0.8134	accuracy_test: 0.8272
[server]	loss_train: 0.2580	loss_val: 0.5960	loss_test: 0.5253	accuracy_train: 0.9545	accuracy_val: 0.8102	accuracy_test: 0.8333
[server]	loss_train: 0.3336	loss_val: 0.5468	loss_test: 0.6393	accuracy_train: 0.9179	accuracy_val: 0.8087	accuracy_test: 0.7893
[server]	loss_train: 0.3918	loss_val: 0.5101	loss_test: 0.5390	accuracy_train: 0.8750	accuracy_val: 0.8286	accuracy_test: 0.8105
[server]	loss_train: 0.2875	loss_val: 0.5240	loss_test: 0.4359	accuracy_train: 0.9320	accuracy_val: 0.8624	accuracy_test: 0.8700
[server]	loss_train: 0.2459	loss_val: 0.3685	loss_test: 0.4028	accuracy_train: 0.9286	accuracy_val: 0.8754	accuracy_test: 0.8630
[server]	loss_train: 0.3041	loss_val: 0.5582	loss_test: 0.5568	accuracy_train: 0.9412	accuracy_val: 0.8286	accuracy_test: 0.7958
[server]	loss_train: 0.3579	loss_val: 0.5093	loss_test: 0.5368	accuracy_train: 0.9279	accuracy_val: 0.8522	accuracy_test: 0.8248
[server]	loss_train: 0.2112	loss_val: 0.4021	loss_test: 0.4210	accuracy_train: 0.9504	accuracy_val: 0.8920	accuracy_test: 0.8828
[server]	loss_train: 0.2922	loss_val: 0.5070	loss_test: 0.4978	accuracy_train: 0.9139	accuracy_val: 0.8452	accuracy_test: 0.8508
curr_round: 36	curr_val_accuracy: 0.8307	curr_test_accuracy: 0.8284
best_round: 36	best_val_accuracy: 0.8307	best_test_accuracy: 0.8284
--------------------------------------------------
round # 37		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.4265	loss_val: 0.6484	loss_test: 0.5712	accuracy_train: 0.8806	accuracy_val: 0.7927	accuracy_test: 0.8065
[server]	loss_train: 0.2615	loss_val: 0.5332	loss_test: 0.6186	accuracy_train: 0.9322	accuracy_val: 0.8097	accuracy_test: 0.7760
[server]	loss_train: 0.2932	loss_val: 0.6064	loss_test: 0.5979	accuracy_train: 0.9264	accuracy_val: 0.8204	accuracy_test: 0.7946
[server]	loss_train: 0.2372	loss_val: 0.5067	loss_test: 0.4916	accuracy_train: 0.9333	accuracy_val: 0.8227	accuracy_test: 0.8298
[server]	loss_train: 0.3028	loss_val: 0.5409	loss_test: 0.4459	accuracy_train: 0.9040	accuracy_val: 0.8359	accuracy_test: 0.8659
[server]	loss_train: 0.2932	loss_val: 0.5985	loss_test: 0.5919	accuracy_train: 0.9134	accuracy_val: 0.7786	accuracy_test: 0.7917
[server]	loss_train: 0.2324	loss_val: 0.4710	loss_test: 0.5192	accuracy_train: 0.9739	accuracy_val: 0.8423	accuracy_test: 0.8347
[server]	loss_train: 0.2430	loss_val: 0.4889	loss_test: 0.5035	accuracy_train: 0.9549	accuracy_val: 0.8381	accuracy_test: 0.8292
[server]	loss_train: 0.3232	loss_val: 0.5405	loss_test: 0.4965	accuracy_train: 0.9440	accuracy_val: 0.8108	accuracy_test: 0.8473
[server]	loss_train: 0.2322	loss_val: 0.4990	loss_test: 0.4957	accuracy_train: 0.9635	accuracy_val: 0.8551	accuracy_test: 0.8497
[server]	loss_train: 0.3253	loss_val: 0.6422	loss_test: 0.5004	accuracy_train: 0.9313	accuracy_val: 0.8134	accuracy_test: 0.8272
[server]	loss_train: 0.2448	loss_val: 0.5894	loss_test: 0.5174	accuracy_train: 0.9621	accuracy_val: 0.8102	accuracy_test: 0.8333
[server]	loss_train: 0.3208	loss_val: 0.5415	loss_test: 0.6365	accuracy_train: 0.9254	accuracy_val: 0.8087	accuracy_test: 0.7964
[server]	loss_train: 0.3774	loss_val: 0.5039	loss_test: 0.5346	accuracy_train: 0.8750	accuracy_val: 0.8321	accuracy_test: 0.8140
[server]	loss_train: 0.2780	loss_val: 0.5227	loss_test: 0.4327	accuracy_train: 0.9388	accuracy_val: 0.8624	accuracy_test: 0.8700
[server]	loss_train: 0.2354	loss_val: 0.3624	loss_test: 0.3963	accuracy_train: 0.9286	accuracy_val: 0.8754	accuracy_test: 0.8664
[server]	loss_train: 0.2942	loss_val: 0.5531	loss_test: 0.5528	accuracy_train: 0.9338	accuracy_val: 0.8250	accuracy_test: 0.7958
[server]	loss_train: 0.3406	loss_val: 0.5024	loss_test: 0.5307	accuracy_train: 0.9279	accuracy_val: 0.8522	accuracy_test: 0.8291
[server]	loss_train: 0.2004	loss_val: 0.3987	loss_test: 0.4168	accuracy_train: 0.9504	accuracy_val: 0.8955	accuracy_test: 0.8828
[server]	loss_train: 0.2804	loss_val: 0.5045	loss_test: 0.4937	accuracy_train: 0.9205	accuracy_val: 0.8484	accuracy_test: 0.8476
curr_round: 37	curr_val_accuracy: 0.8320	curr_test_accuracy: 0.8297
best_round: 37	best_val_accuracy: 0.8320	best_test_accuracy: 0.8297
--------------------------------------------------
round # 38		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.4107	loss_val: 0.6446	loss_test: 0.5653	accuracy_train: 0.8806	accuracy_val: 0.7964	accuracy_test: 0.8100
[server]	loss_train: 0.2490	loss_val: 0.5283	loss_test: 0.6143	accuracy_train: 0.9322	accuracy_val: 0.8178	accuracy_test: 0.7800
[server]	loss_train: 0.2826	loss_val: 0.6042	loss_test: 0.5941	accuracy_train: 0.9325	accuracy_val: 0.8204	accuracy_test: 0.7976
[server]	loss_train: 0.2273	loss_val: 0.5025	loss_test: 0.4864	accuracy_train: 0.9333	accuracy_val: 0.8227	accuracy_test: 0.8298
[server]	loss_train: 0.2892	loss_val: 0.5342	loss_test: 0.4402	accuracy_train: 0.9120	accuracy_val: 0.8359	accuracy_test: 0.8697
[server]	loss_train: 0.2810	loss_val: 0.5929	loss_test: 0.5865	accuracy_train: 0.9134	accuracy_val: 0.7901	accuracy_test: 0.7917
[server]	loss_train: 0.2222	loss_val: 0.4649	loss_test: 0.5156	accuracy_train: 0.9826	accuracy_val: 0.8423	accuracy_test: 0.8347
[server]	loss_train: 0.2339	loss_val: 0.4848	loss_test: 0.4984	accuracy_train: 0.9549	accuracy_val: 0.8381	accuracy_test: 0.8292
[server]	loss_train: 0.3155	loss_val: 0.5358	loss_test: 0.4900	accuracy_train: 0.9440	accuracy_val: 0.8108	accuracy_test: 0.8511
[server]	loss_train: 0.2212	loss_val: 0.4942	loss_test: 0.4915	accuracy_train: 0.9635	accuracy_val: 0.8622	accuracy_test: 0.8462
[server]	loss_train: 0.3125	loss_val: 0.6380	loss_test: 0.4942	accuracy_train: 0.9466	accuracy_val: 0.8097	accuracy_test: 0.8272
[server]	loss_train: 0.2332	loss_val: 0.5827	loss_test: 0.5114	accuracy_train: 0.9621	accuracy_val: 0.8175	accuracy_test: 0.8333
[server]	loss_train: 0.3068	loss_val: 0.5353	loss_test: 0.6313	accuracy_train: 0.9328	accuracy_val: 0.8159	accuracy_test: 0.7964
[server]	loss_train: 0.3681	loss_val: 0.5009	loss_test: 0.5301	accuracy_train: 0.8750	accuracy_val: 0.8250	accuracy_test: 0.8140
[server]	loss_train: 0.2678	loss_val: 0.5198	loss_test: 0.4285	accuracy_train: 0.9456	accuracy_val: 0.8658	accuracy_test: 0.8733
[server]	loss_train: 0.2266	loss_val: 0.3588	loss_test: 0.3928	accuracy_train: 0.9357	accuracy_val: 0.8754	accuracy_test: 0.8664
[server]	loss_train: 0.2826	loss_val: 0.5473	loss_test: 0.5487	accuracy_train: 0.9412	accuracy_val: 0.8250	accuracy_test: 0.7958
[server]	loss_train: 0.3259	loss_val: 0.4960	loss_test: 0.5244	accuracy_train: 0.9279	accuracy_val: 0.8522	accuracy_test: 0.8333
[server]	loss_train: 0.1916	loss_val: 0.3972	loss_test: 0.4148	accuracy_train: 0.9504	accuracy_val: 0.8955	accuracy_test: 0.8793
[server]	loss_train: 0.2687	loss_val: 0.5012	loss_test: 0.4888	accuracy_train: 0.9272	accuracy_val: 0.8484	accuracy_test: 0.8476
curr_round: 38	curr_val_accuracy: 0.8338	curr_test_accuracy: 0.8306
best_round: 38	best_val_accuracy: 0.8338	best_test_accuracy: 0.8306
--------------------------------------------------
round # 39		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.3991	loss_val: 0.6421	loss_test: 0.5633	accuracy_train: 0.8806	accuracy_val: 0.7964	accuracy_test: 0.8100
[server]	loss_train: 0.2381	loss_val: 0.5253	loss_test: 0.6096	accuracy_train: 0.9322	accuracy_val: 0.8178	accuracy_test: 0.7800
[server]	loss_train: 0.2740	loss_val: 0.6047	loss_test: 0.5911	accuracy_train: 0.9325	accuracy_val: 0.8204	accuracy_test: 0.7976
[server]	loss_train: 0.2182	loss_val: 0.5000	loss_test: 0.4817	accuracy_train: 0.9333	accuracy_val: 0.8262	accuracy_test: 0.8298
[server]	loss_train: 0.2788	loss_val: 0.5283	loss_test: 0.4361	accuracy_train: 0.9120	accuracy_val: 0.8359	accuracy_test: 0.8736
[server]	loss_train: 0.2698	loss_val: 0.5880	loss_test: 0.5831	accuracy_train: 0.9213	accuracy_val: 0.7901	accuracy_test: 0.7917
[server]	loss_train: 0.2141	loss_val: 0.4612	loss_test: 0.5139	accuracy_train: 0.9913	accuracy_val: 0.8423	accuracy_test: 0.8347
[server]	loss_train: 0.2241	loss_val: 0.4798	loss_test: 0.4931	accuracy_train: 0.9549	accuracy_val: 0.8381	accuracy_test: 0.8363
[server]	loss_train: 0.3070	loss_val: 0.5334	loss_test: 0.4874	accuracy_train: 0.9440	accuracy_val: 0.8147	accuracy_test: 0.8511
[server]	loss_train: 0.2118	loss_val: 0.4921	loss_test: 0.4908	accuracy_train: 0.9635	accuracy_val: 0.8551	accuracy_test: 0.8462
[server]	loss_train: 0.3020	loss_val: 0.6346	loss_test: 0.4882	accuracy_train: 0.9542	accuracy_val: 0.8134	accuracy_test: 0.8309
[server]	loss_train: 0.2217	loss_val: 0.5785	loss_test: 0.5051	accuracy_train: 0.9621	accuracy_val: 0.8212	accuracy_test: 0.8297
[server]	loss_train: 0.2963	loss_val: 0.5317	loss_test: 0.6311	accuracy_train: 0.9328	accuracy_val: 0.8159	accuracy_test: 0.7929
[server]	loss_train: 0.3550	loss_val: 0.4954	loss_test: 0.5271	accuracy_train: 0.8897	accuracy_val: 0.8250	accuracy_test: 0.8175
[server]	loss_train: 0.2593	loss_val: 0.5192	loss_test: 0.4263	accuracy_train: 0.9524	accuracy_val: 0.8658	accuracy_test: 0.8733
[server]	loss_train: 0.2174	loss_val: 0.3530	loss_test: 0.3865	accuracy_train: 0.9357	accuracy_val: 0.8789	accuracy_test: 0.8664
[server]	loss_train: 0.2746	loss_val: 0.5441	loss_test: 0.5470	accuracy_train: 0.9338	accuracy_val: 0.8286	accuracy_test: 0.7993
[server]	loss_train: 0.3101	loss_val: 0.4911	loss_test: 0.5198	accuracy_train: 0.9279	accuracy_val: 0.8522	accuracy_test: 0.8333
[server]	loss_train: 0.1822	loss_val: 0.3951	loss_test: 0.4110	accuracy_train: 0.9504	accuracy_val: 0.8955	accuracy_test: 0.8793
[server]	loss_train: 0.2580	loss_val: 0.4992	loss_test: 0.4860	accuracy_train: 0.9338	accuracy_val: 0.8548	accuracy_test: 0.8540
curr_round: 39	curr_val_accuracy: 0.8349	curr_test_accuracy: 0.8316
best_round: 39	best_val_accuracy: 0.8349	best_test_accuracy: 0.8316
--------------------------------------------------
round # 40		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.3846	loss_val: 0.6389	loss_test: 0.5586	accuracy_train: 0.8806	accuracy_val: 0.7964	accuracy_test: 0.8100
[server]	loss_train: 0.2270	loss_val: 0.5216	loss_test: 0.6064	accuracy_train: 0.9407	accuracy_val: 0.8178	accuracy_test: 0.7800
[server]	loss_train: 0.2645	loss_val: 0.6024	loss_test: 0.5874	accuracy_train: 0.9325	accuracy_val: 0.8204	accuracy_test: 0.7976
[server]	loss_train: 0.2089	loss_val: 0.4964	loss_test: 0.4771	accuracy_train: 0.9333	accuracy_val: 0.8333	accuracy_test: 0.8262
[server]	loss_train: 0.2669	loss_val: 0.5222	loss_test: 0.4317	accuracy_train: 0.9200	accuracy_val: 0.8438	accuracy_test: 0.8736
[server]	loss_train: 0.2588	loss_val: 0.5828	loss_test: 0.5779	accuracy_train: 0.9291	accuracy_val: 0.7901	accuracy_test: 0.7955
[server]	loss_train: 0.2048	loss_val: 0.4557	loss_test: 0.5106	accuracy_train: 0.9913	accuracy_val: 0.8465	accuracy_test: 0.8347
[server]	loss_train: 0.2163	loss_val: 0.4760	loss_test: 0.4880	accuracy_train: 0.9624	accuracy_val: 0.8381	accuracy_test: 0.8363
[server]	loss_train: 0.3000	loss_val: 0.5289	loss_test: 0.4812	accuracy_train: 0.9520	accuracy_val: 0.8185	accuracy_test: 0.8511
[server]	loss_train: 0.2023	loss_val: 0.4876	loss_test: 0.4864	accuracy_train: 0.9708	accuracy_val: 0.8551	accuracy_test: 0.8462
[server]	loss_train: 0.2902	loss_val: 0.6311	loss_test: 0.4831	accuracy_train: 0.9542	accuracy_val: 0.8209	accuracy_test: 0.8309
[server]	loss_train: 0.2120	loss_val: 0.5725	loss_test: 0.5004	accuracy_train: 0.9621	accuracy_val: 0.8212	accuracy_test: 0.8297
[server]	loss_train: 0.2836	loss_val: 0.5263	loss_test: 0.6260	accuracy_train: 0.9328	accuracy_val: 0.8159	accuracy_test: 0.7929
[server]	loss_train: 0.3466	loss_val: 0.4936	loss_test: 0.5233	accuracy_train: 0.8971	accuracy_val: 0.8250	accuracy_test: 0.8211
[server]	loss_train: 0.2506	loss_val: 0.5172	loss_test: 0.4228	accuracy_train: 0.9524	accuracy_val: 0.8658	accuracy_test: 0.8733
[server]	loss_train: 0.2100	loss_val: 0.3506	loss_test: 0.3841	accuracy_train: 0.9357	accuracy_val: 0.8754	accuracy_test: 0.8664
[server]	loss_train: 0.2637	loss_val: 0.5388	loss_test: 0.5428	accuracy_train: 0.9338	accuracy_val: 0.8321	accuracy_test: 0.7993
[server]	loss_train: 0.2962	loss_val: 0.4852	loss_test: 0.5144	accuracy_train: 0.9279	accuracy_val: 0.8522	accuracy_test: 0.8419
[server]	loss_train: 0.1744	loss_val: 0.3938	loss_test: 0.4099	accuracy_train: 0.9504	accuracy_val: 0.8955	accuracy_test: 0.8793
[server]	loss_train: 0.2475	loss_val: 0.4971	loss_test: 0.4817	accuracy_train: 0.9404	accuracy_val: 0.8548	accuracy_test: 0.8508
curr_round: 40	curr_val_accuracy: 0.8363	curr_test_accuracy: 0.8320
best_round: 40	best_val_accuracy: 0.8363	best_test_accuracy: 0.8320
--------------------------------------------------
round # 41		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.3742	loss_val: 0.6370	loss_test: 0.5574	accuracy_train: 0.8806	accuracy_val: 0.7964	accuracy_test: 0.8100
[server]	loss_train: 0.2177	loss_val: 0.5195	loss_test: 0.6026	accuracy_train: 0.9407	accuracy_val: 0.8219	accuracy_test: 0.7800
[server]	loss_train: 0.2568	loss_val: 0.6038	loss_test: 0.5856	accuracy_train: 0.9325	accuracy_val: 0.8204	accuracy_test: 0.8006
[server]	loss_train: 0.2010	loss_val: 0.4946	loss_test: 0.4734	accuracy_train: 0.9481	accuracy_val: 0.8369	accuracy_test: 0.8333
[server]	loss_train: 0.2578	loss_val: 0.5178	loss_test: 0.4287	accuracy_train: 0.9120	accuracy_val: 0.8438	accuracy_test: 0.8736
[server]	loss_train: 0.2488	loss_val: 0.5790	loss_test: 0.5755	accuracy_train: 0.9291	accuracy_val: 0.7939	accuracy_test: 0.7955
[server]	loss_train: 0.1980	loss_val: 0.4529	loss_test: 0.5098	accuracy_train: 1.0000	accuracy_val: 0.8465	accuracy_test: 0.8347
[server]	loss_train: 0.2076	loss_val: 0.4721	loss_test: 0.4840	accuracy_train: 0.9624	accuracy_val: 0.8345	accuracy_test: 0.8399
[server]	loss_train: 0.2926	loss_val: 0.5276	loss_test: 0.4798	accuracy_train: 0.9520	accuracy_val: 0.8147	accuracy_test: 0.8588
[server]	loss_train: 0.1942	loss_val: 0.4866	loss_test: 0.4868	accuracy_train: 0.9708	accuracy_val: 0.8551	accuracy_test: 0.8427
[server]	loss_train: 0.2810	loss_val: 0.6288	loss_test: 0.4783	accuracy_train: 0.9542	accuracy_val: 0.8246	accuracy_test: 0.8309
[server]	loss_train: 0.2021	loss_val: 0.5694	loss_test: 0.4952	accuracy_train: 0.9697	accuracy_val: 0.8212	accuracy_test: 0.8297
[server]	loss_train: 0.2745	loss_val: 0.5235	loss_test: 0.6270	accuracy_train: 0.9328	accuracy_val: 0.8159	accuracy_test: 0.7929
[server]	loss_train: 0.3345	loss_val: 0.4888	loss_test: 0.5209	accuracy_train: 0.8971	accuracy_val: 0.8250	accuracy_test: 0.8211
[server]	loss_train: 0.2431	loss_val: 0.5171	loss_test: 0.4214	accuracy_train: 0.9524	accuracy_val: 0.8658	accuracy_test: 0.8733
[server]	loss_train: 0.2018	loss_val: 0.3453	loss_test: 0.3785	accuracy_train: 0.9357	accuracy_val: 0.8789	accuracy_test: 0.8664
[server]	loss_train: 0.2568	loss_val: 0.5366	loss_test: 0.5421	accuracy_train: 0.9338	accuracy_val: 0.8321	accuracy_test: 0.7993
[server]	loss_train: 0.2820	loss_val: 0.4816	loss_test: 0.5107	accuracy_train: 0.9279	accuracy_val: 0.8522	accuracy_test: 0.8376
[server]	loss_train: 0.1661	loss_val: 0.3922	loss_test: 0.4067	accuracy_train: 0.9504	accuracy_val: 0.8990	accuracy_test: 0.8793
[server]	loss_train: 0.2379	loss_val: 0.4957	loss_test: 0.4798	accuracy_train: 0.9404	accuracy_val: 0.8548	accuracy_test: 0.8540
curr_round: 41	curr_val_accuracy: 0.8370	curr_test_accuracy: 0.8329
best_round: 41	best_val_accuracy: 0.8370	best_test_accuracy: 0.8329
--------------------------------------------------
round # 42		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.3610	loss_val: 0.6342	loss_test: 0.5537	accuracy_train: 0.8955	accuracy_val: 0.8000	accuracy_test: 0.8136
[server]	loss_train: 0.2078	loss_val: 0.5168	loss_test: 0.6006	accuracy_train: 0.9576	accuracy_val: 0.8219	accuracy_test: 0.7800
[server]	loss_train: 0.2480	loss_val: 0.6018	loss_test: 0.5824	accuracy_train: 0.9325	accuracy_val: 0.8204	accuracy_test: 0.8036
[server]	loss_train: 0.1927	loss_val: 0.4918	loss_test: 0.4698	accuracy_train: 0.9481	accuracy_val: 0.8369	accuracy_test: 0.8298
[server]	loss_train: 0.2474	loss_val: 0.5127	loss_test: 0.4252	accuracy_train: 0.9200	accuracy_val: 0.8477	accuracy_test: 0.8736
[server]	loss_train: 0.2390	loss_val: 0.5750	loss_test: 0.5714	accuracy_train: 0.9291	accuracy_val: 0.7939	accuracy_test: 0.7955
[server]	loss_train: 0.1897	loss_val: 0.4479	loss_test: 0.5072	accuracy_train: 1.0000	accuracy_val: 0.8506	accuracy_test: 0.8347
[server]	loss_train: 0.2007	loss_val: 0.4692	loss_test: 0.4799	accuracy_train: 0.9624	accuracy_val: 0.8345	accuracy_test: 0.8399
[server]	loss_train: 0.2865	loss_val: 0.5239	loss_test: 0.4745	accuracy_train: 0.9600	accuracy_val: 0.8147	accuracy_test: 0.8511
[server]	loss_train: 0.1859	loss_val: 0.4832	loss_test: 0.4832	accuracy_train: 0.9708	accuracy_val: 0.8551	accuracy_test: 0.8427
[server]	loss_train: 0.2703	loss_val: 0.6263	loss_test: 0.4743	accuracy_train: 0.9542	accuracy_val: 0.8284	accuracy_test: 0.8346
[server]	loss_train: 0.1937	loss_val: 0.5646	loss_test: 0.4915	accuracy_train: 0.9697	accuracy_val: 0.8248	accuracy_test: 0.8297
[server]	loss_train: 0.2632	loss_val: 0.5191	loss_test: 0.6231	accuracy_train: 0.9328	accuracy_val: 0.8159	accuracy_test: 0.7929
[server]	loss_train: 0.3273	loss_val: 0.4877	loss_test: 0.5180	accuracy_train: 0.8971	accuracy_val: 0.8250	accuracy_test: 0.8211
[server]	loss_train: 0.2353	loss_val: 0.5156	loss_test: 0.4184	accuracy_train: 0.9524	accuracy_val: 0.8624	accuracy_test: 0.8733
[server]	loss_train: 0.1954	loss_val: 0.3434	loss_test: 0.3768	accuracy_train: 0.9357	accuracy_val: 0.8789	accuracy_test: 0.8664
[server]	loss_train: 0.2470	loss_val: 0.5323	loss_test: 0.5387	accuracy_train: 0.9338	accuracy_val: 0.8321	accuracy_test: 0.7993
[server]	loss_train: 0.2691	loss_val: 0.4766	loss_test: 0.5062	accuracy_train: 0.9279	accuracy_val: 0.8522	accuracy_test: 0.8462
[server]	loss_train: 0.1593	loss_val: 0.3915	loss_test: 0.4063	accuracy_train: 0.9504	accuracy_val: 0.8990	accuracy_test: 0.8793
[server]	loss_train: 0.2285	loss_val: 0.4944	loss_test: 0.4762	accuracy_train: 0.9404	accuracy_val: 0.8548	accuracy_test: 0.8540
curr_round: 42	curr_val_accuracy: 0.8378	curr_test_accuracy: 0.8333
best_round: 42	best_val_accuracy: 0.8378	best_test_accuracy: 0.8333
--------------------------------------------------
round # 43		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.3514	loss_val: 0.6330	loss_test: 0.5528	accuracy_train: 0.8955	accuracy_val: 0.8000	accuracy_test: 0.8172
[server]	loss_train: 0.1997	loss_val: 0.5148	loss_test: 0.5971	accuracy_train: 0.9576	accuracy_val: 0.8219	accuracy_test: 0.7840
[server]	loss_train: 0.2412	loss_val: 0.6037	loss_test: 0.5811	accuracy_train: 0.9325	accuracy_val: 0.8204	accuracy_test: 0.8036
[server]	loss_train: 0.1853	loss_val: 0.4901	loss_test: 0.4664	accuracy_train: 0.9481	accuracy_val: 0.8369	accuracy_test: 0.8440
[server]	loss_train: 0.2395	loss_val: 0.5090	loss_test: 0.4226	accuracy_train: 0.9200	accuracy_val: 0.8555	accuracy_test: 0.8736
[server]	loss_train: 0.2299	loss_val: 0.5718	loss_test: 0.5688	accuracy_train: 0.9449	accuracy_val: 0.7939	accuracy_test: 0.8068
[server]	loss_train: 0.1838	loss_val: 0.4458	loss_test: 0.5069	accuracy_train: 1.0000	accuracy_val: 0.8506	accuracy_test: 0.8347
[server]	loss_train: 0.1932	loss_val: 0.4657	loss_test: 0.4760	accuracy_train: 0.9624	accuracy_val: 0.8381	accuracy_test: 0.8399
[server]	loss_train: 0.2795	loss_val: 0.5228	loss_test: 0.4734	accuracy_train: 0.9600	accuracy_val: 0.8147	accuracy_test: 0.8550
[server]	loss_train: 0.1790	loss_val: 0.4824	loss_test: 0.4836	accuracy_train: 0.9708	accuracy_val: 0.8587	accuracy_test: 0.8427
[server]	loss_train: 0.2616	loss_val: 0.6240	loss_test: 0.4697	accuracy_train: 0.9542	accuracy_val: 0.8321	accuracy_test: 0.8346
[server]	loss_train: 0.1851	loss_val: 0.5614	loss_test: 0.4870	accuracy_train: 0.9773	accuracy_val: 0.8321	accuracy_test: 0.8297
[server]	loss_train: 0.2548	loss_val: 0.5166	loss_test: 0.6240	accuracy_train: 0.9328	accuracy_val: 0.8159	accuracy_test: 0.7893
[server]	loss_train: 0.3166	loss_val: 0.4837	loss_test: 0.5159	accuracy_train: 0.8971	accuracy_val: 0.8250	accuracy_test: 0.8211
[server]	loss_train: 0.2289	loss_val: 0.5162	loss_test: 0.4178	accuracy_train: 0.9524	accuracy_val: 0.8624	accuracy_test: 0.8767
[server]	loss_train: 0.1881	loss_val: 0.3387	loss_test: 0.3720	accuracy_train: 0.9357	accuracy_val: 0.8824	accuracy_test: 0.8699
[server]	loss_train: 0.2407	loss_val: 0.5302	loss_test: 0.5382	accuracy_train: 0.9338	accuracy_val: 0.8321	accuracy_test: 0.8028
[server]	loss_train: 0.2561	loss_val: 0.4736	loss_test: 0.5030	accuracy_train: 0.9369	accuracy_val: 0.8565	accuracy_test: 0.8419
[server]	loss_train: 0.1520	loss_val: 0.3902	loss_test: 0.4039	accuracy_train: 0.9574	accuracy_val: 0.8920	accuracy_test: 0.8793
[server]	loss_train: 0.2200	loss_val: 0.4932	loss_test: 0.4747	accuracy_train: 0.9404	accuracy_val: 0.8516	accuracy_test: 0.8540
curr_round: 43	curr_val_accuracy: 0.8389	curr_test_accuracy: 0.8352
best_round: 43	best_val_accuracy: 0.8389	best_test_accuracy: 0.8352
--------------------------------------------------
round # 44		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.3390	loss_val: 0.6306	loss_test: 0.5504	accuracy_train: 0.9030	accuracy_val: 0.8000	accuracy_test: 0.8172
[server]	loss_train: 0.1911	loss_val: 0.5132	loss_test: 0.5964	accuracy_train: 0.9661	accuracy_val: 0.8219	accuracy_test: 0.7880
[server]	loss_train: 0.2329	loss_val: 0.6018	loss_test: 0.5786	accuracy_train: 0.9325	accuracy_val: 0.8204	accuracy_test: 0.8036
[server]	loss_train: 0.1781	loss_val: 0.4887	loss_test: 0.4639	accuracy_train: 0.9481	accuracy_val: 0.8369	accuracy_test: 0.8404
[server]	loss_train: 0.2302	loss_val: 0.5050	loss_test: 0.4202	accuracy_train: 0.9280	accuracy_val: 0.8516	accuracy_test: 0.8736
[server]	loss_train: 0.2212	loss_val: 0.5688	loss_test: 0.5662	accuracy_train: 0.9449	accuracy_val: 0.7977	accuracy_test: 0.8182
[server]	loss_train: 0.1762	loss_val: 0.4413	loss_test: 0.5052	accuracy_train: 1.0000	accuracy_val: 0.8548	accuracy_test: 0.8347
[server]	loss_train: 0.1868	loss_val: 0.4640	loss_test: 0.4736	accuracy_train: 0.9624	accuracy_val: 0.8417	accuracy_test: 0.8399
[server]	loss_train: 0.2738	loss_val: 0.5202	loss_test: 0.4696	accuracy_train: 0.9600	accuracy_val: 0.8185	accuracy_test: 0.8550
[server]	loss_train: 0.1717	loss_val: 0.4804	loss_test: 0.4811	accuracy_train: 0.9708	accuracy_val: 0.8587	accuracy_test: 0.8427
[server]	loss_train: 0.2520	loss_val: 0.6226	loss_test: 0.4669	accuracy_train: 0.9542	accuracy_val: 0.8284	accuracy_test: 0.8382
[server]	loss_train: 0.1778	loss_val: 0.5585	loss_test: 0.4843	accuracy_train: 0.9773	accuracy_val: 0.8321	accuracy_test: 0.8297
[server]	loss_train: 0.2450	loss_val: 0.5134	loss_test: 0.6215	accuracy_train: 0.9403	accuracy_val: 0.8123	accuracy_test: 0.7893
[server]	loss_train: 0.3096	loss_val: 0.4828	loss_test: 0.5140	accuracy_train: 0.8971	accuracy_val: 0.8286	accuracy_test: 0.8281
[server]	loss_train: 0.2217	loss_val: 0.5146	loss_test: 0.4151	accuracy_train: 0.9592	accuracy_val: 0.8624	accuracy_test: 0.8767
[server]	loss_train: 0.1828	loss_val: 0.3375	loss_test: 0.3706	accuracy_train: 0.9357	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.2319	loss_val: 0.5272	loss_test: 0.5360	accuracy_train: 0.9338	accuracy_val: 0.8286	accuracy_test: 0.8028
[server]	loss_train: 0.2439	loss_val: 0.4694	loss_test: 0.4995	accuracy_train: 0.9459	accuracy_val: 0.8565	accuracy_test: 0.8462
[server]	loss_train: 0.1461	loss_val: 0.3901	loss_test: 0.4036	accuracy_train: 0.9574	accuracy_val: 0.8920	accuracy_test: 0.8793
[server]	loss_train: 0.2115	loss_val: 0.4926	loss_test: 0.4720	accuracy_train: 0.9536	accuracy_val: 0.8484	accuracy_test: 0.8540
curr_round: 44	curr_val_accuracy: 0.8390	curr_test_accuracy: 0.8363
best_round: 44	best_val_accuracy: 0.8390	best_test_accuracy: 0.8363
--------------------------------------------------
round # 45		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.3300	loss_val: 0.6296	loss_test: 0.5496	accuracy_train: 0.9030	accuracy_val: 0.8000	accuracy_test: 0.8172
[server]	loss_train: 0.1840	loss_val: 0.5116	loss_test: 0.5932	accuracy_train: 0.9661	accuracy_val: 0.8219	accuracy_test: 0.7880
[server]	loss_train: 0.2268	loss_val: 0.6042	loss_test: 0.5777	accuracy_train: 0.9325	accuracy_val: 0.8174	accuracy_test: 0.8036
[server]	loss_train: 0.1714	loss_val: 0.4869	loss_test: 0.4607	accuracy_train: 0.9556	accuracy_val: 0.8404	accuracy_test: 0.8404
[server]	loss_train: 0.2230	loss_val: 0.5019	loss_test: 0.4182	accuracy_train: 0.9280	accuracy_val: 0.8633	accuracy_test: 0.8736
[server]	loss_train: 0.2130	loss_val: 0.5659	loss_test: 0.5636	accuracy_train: 0.9449	accuracy_val: 0.8053	accuracy_test: 0.8144
[server]	loss_train: 0.1711	loss_val: 0.4397	loss_test: 0.5050	accuracy_train: 1.0000	accuracy_val: 0.8631	accuracy_test: 0.8306
[server]	loss_train: 0.1803	loss_val: 0.4609	loss_test: 0.4698	accuracy_train: 0.9624	accuracy_val: 0.8345	accuracy_test: 0.8399
[server]	loss_train: 0.2677	loss_val: 0.5192	loss_test: 0.4683	accuracy_train: 0.9600	accuracy_val: 0.8185	accuracy_test: 0.8511
[server]	loss_train: 0.1658	loss_val: 0.4794	loss_test: 0.4812	accuracy_train: 0.9708	accuracy_val: 0.8587	accuracy_test: 0.8392
[server]	loss_train: 0.2438	loss_val: 0.6209	loss_test: 0.4631	accuracy_train: 0.9618	accuracy_val: 0.8284	accuracy_test: 0.8346
[server]	loss_train: 0.1703	loss_val: 0.5552	loss_test: 0.4806	accuracy_train: 0.9848	accuracy_val: 0.8321	accuracy_test: 0.8297
[server]	loss_train: 0.2371	loss_val: 0.5112	loss_test: 0.6221	accuracy_train: 0.9403	accuracy_val: 0.8123	accuracy_test: 0.7929
[server]	loss_train: 0.3001	loss_val: 0.4800	loss_test: 0.5119	accuracy_train: 0.8971	accuracy_val: 0.8250	accuracy_test: 0.8281
[server]	loss_train: 0.2161	loss_val: 0.5157	loss_test: 0.4150	accuracy_train: 0.9592	accuracy_val: 0.8591	accuracy_test: 0.8767
[server]	loss_train: 0.1763	loss_val: 0.3335	loss_test: 0.3668	accuracy_train: 0.9429	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.2260	loss_val: 0.5253	loss_test: 0.5355	accuracy_train: 0.9338	accuracy_val: 0.8250	accuracy_test: 0.8028
[server]	loss_train: 0.2322	loss_val: 0.4670	loss_test: 0.4966	accuracy_train: 0.9459	accuracy_val: 0.8565	accuracy_test: 0.8462
[server]	loss_train: 0.1397	loss_val: 0.3891	loss_test: 0.4020	accuracy_train: 0.9645	accuracy_val: 0.8885	accuracy_test: 0.8828
[server]	loss_train: 0.2039	loss_val: 0.4918	loss_test: 0.4708	accuracy_train: 0.9603	accuracy_val: 0.8484	accuracy_test: 0.8540
curr_round: 45	curr_val_accuracy: 0.8392	curr_test_accuracy: 0.8358
best_round: 45	best_val_accuracy: 0.8392	best_test_accuracy: 0.8358
--------------------------------------------------
round # 46		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.3192	loss_val: 0.6278	loss_test: 0.5483	accuracy_train: 0.9030	accuracy_val: 0.8000	accuracy_test: 0.8172
[server]	loss_train: 0.1763	loss_val: 0.5108	loss_test: 0.5932	accuracy_train: 0.9661	accuracy_val: 0.8219	accuracy_test: 0.7880
[server]	loss_train: 0.2193	loss_val: 0.6030	loss_test: 0.5759	accuracy_train: 0.9325	accuracy_val: 0.8174	accuracy_test: 0.8036
[server]	loss_train: 0.1651	loss_val: 0.4863	loss_test: 0.4589	accuracy_train: 0.9630	accuracy_val: 0.8369	accuracy_test: 0.8404
[server]	loss_train: 0.2151	loss_val: 0.4987	loss_test: 0.4165	accuracy_train: 0.9280	accuracy_val: 0.8633	accuracy_test: 0.8736
[server]	loss_train: 0.2052	loss_val: 0.5637	loss_test: 0.5622	accuracy_train: 0.9449	accuracy_val: 0.8092	accuracy_test: 0.8144
[server]	loss_train: 0.1645	loss_val: 0.4359	loss_test: 0.5040	accuracy_train: 1.0000	accuracy_val: 0.8631	accuracy_test: 0.8306
[server]	loss_train: 0.1744	loss_val: 0.4596	loss_test: 0.4681	accuracy_train: 0.9624	accuracy_val: 0.8381	accuracy_test: 0.8363
[server]	loss_train: 0.2626	loss_val: 0.5176	loss_test: 0.4659	accuracy_train: 0.9600	accuracy_val: 0.8224	accuracy_test: 0.8550
[server]	loss_train: 0.1594	loss_val: 0.4785	loss_test: 0.4799	accuracy_train: 0.9708	accuracy_val: 0.8587	accuracy_test: 0.8427
[server]	loss_train: 0.2355	loss_val: 0.6203	loss_test: 0.4612	accuracy_train: 0.9618	accuracy_val: 0.8284	accuracy_test: 0.8382
[server]	loss_train: 0.1639	loss_val: 0.5536	loss_test: 0.4783	accuracy_train: 0.9848	accuracy_val: 0.8358	accuracy_test: 0.8297
[server]	loss_train: 0.2286	loss_val: 0.5090	loss_test: 0.6212	accuracy_train: 0.9403	accuracy_val: 0.8087	accuracy_test: 0.7964
[server]	loss_train: 0.2933	loss_val: 0.4790	loss_test: 0.5107	accuracy_train: 0.8971	accuracy_val: 0.8250	accuracy_test: 0.8281
[server]	loss_train: 0.2096	loss_val: 0.5146	loss_test: 0.4128	accuracy_train: 0.9592	accuracy_val: 0.8591	accuracy_test: 0.8800
[server]	loss_train: 0.1714	loss_val: 0.3321	loss_test: 0.3651	accuracy_train: 0.9429	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.2186	loss_val: 0.5234	loss_test: 0.5343	accuracy_train: 0.9412	accuracy_val: 0.8250	accuracy_test: 0.8028
[server]	loss_train: 0.2210	loss_val: 0.4637	loss_test: 0.4941	accuracy_train: 0.9459	accuracy_val: 0.8565	accuracy_test: 0.8462
[server]	loss_train: 0.1343	loss_val: 0.3892	loss_test: 0.4018	accuracy_train: 0.9645	accuracy_val: 0.8885	accuracy_test: 0.8828
[server]	loss_train: 0.1962	loss_val: 0.4918	loss_test: 0.4688	accuracy_train: 0.9603	accuracy_val: 0.8484	accuracy_test: 0.8571
curr_round: 46	curr_val_accuracy: 0.8396	curr_test_accuracy: 0.8367
best_round: 46	best_val_accuracy: 0.8396	best_test_accuracy: 0.8367
--------------------------------------------------
round # 47		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.3101	loss_val: 0.6269	loss_test: 0.5474	accuracy_train: 0.9179	accuracy_val: 0.8000	accuracy_test: 0.8172
[server]	loss_train: 0.1701	loss_val: 0.5095	loss_test: 0.5908	accuracy_train: 0.9661	accuracy_val: 0.8219	accuracy_test: 0.7880
[server]	loss_train: 0.2133	loss_val: 0.6052	loss_test: 0.5751	accuracy_train: 0.9325	accuracy_val: 0.8174	accuracy_test: 0.8036
[server]	loss_train: 0.1589	loss_val: 0.4846	loss_test: 0.4560	accuracy_train: 0.9630	accuracy_val: 0.8369	accuracy_test: 0.8404
[server]	loss_train: 0.2082	loss_val: 0.4962	loss_test: 0.4148	accuracy_train: 0.9280	accuracy_val: 0.8633	accuracy_test: 0.8736
[server]	loss_train: 0.1978	loss_val: 0.5615	loss_test: 0.5598	accuracy_train: 0.9528	accuracy_val: 0.8092	accuracy_test: 0.8106
[server]	loss_train: 0.1599	loss_val: 0.4343	loss_test: 0.5038	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8306
[server]	loss_train: 0.1688	loss_val: 0.4573	loss_test: 0.4651	accuracy_train: 0.9624	accuracy_val: 0.8417	accuracy_test: 0.8399
[server]	loss_train: 0.2572	loss_val: 0.5165	loss_test: 0.4642	accuracy_train: 0.9600	accuracy_val: 0.8147	accuracy_test: 0.8550
[server]	loss_train: 0.1540	loss_val: 0.4775	loss_test: 0.4799	accuracy_train: 0.9708	accuracy_val: 0.8587	accuracy_test: 0.8392
[server]	loss_train: 0.2275	loss_val: 0.6190	loss_test: 0.4579	accuracy_train: 0.9618	accuracy_val: 0.8284	accuracy_test: 0.8346
[server]	loss_train: 0.1574	loss_val: 0.5504	loss_test: 0.4754	accuracy_train: 0.9848	accuracy_val: 0.8358	accuracy_test: 0.8370
[server]	loss_train: 0.2211	loss_val: 0.5068	loss_test: 0.6211	accuracy_train: 0.9403	accuracy_val: 0.8051	accuracy_test: 0.7964
[server]	loss_train: 0.2853	loss_val: 0.4774	loss_test: 0.5089	accuracy_train: 0.8971	accuracy_val: 0.8250	accuracy_test: 0.8281
[server]	loss_train: 0.2044	loss_val: 0.5156	loss_test: 0.4127	accuracy_train: 0.9592	accuracy_val: 0.8624	accuracy_test: 0.8800
[server]	loss_train: 0.1658	loss_val: 0.3291	loss_test: 0.3628	accuracy_train: 0.9500	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.2125	loss_val: 0.5214	loss_test: 0.5336	accuracy_train: 0.9412	accuracy_val: 0.8250	accuracy_test: 0.8099
[server]	loss_train: 0.2104	loss_val: 0.4616	loss_test: 0.4914	accuracy_train: 0.9550	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.1289	loss_val: 0.3886	loss_test: 0.4010	accuracy_train: 0.9645	accuracy_val: 0.8885	accuracy_test: 0.8828
[server]	loss_train: 0.1893	loss_val: 0.4913	loss_test: 0.4679	accuracy_train: 0.9669	accuracy_val: 0.8452	accuracy_test: 0.8540
curr_round: 47	curr_val_accuracy: 0.8396	curr_test_accuracy: 0.8368
best_round: 46	best_val_accuracy: 0.8396	best_test_accuracy: 0.8367
--------------------------------------------------
round # 48		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.3011	loss_val: 0.6261	loss_test: 0.5472	accuracy_train: 0.9254	accuracy_val: 0.8000	accuracy_test: 0.8172
[server]	loss_train: 0.1632	loss_val: 0.5092	loss_test: 0.5910	accuracy_train: 0.9661	accuracy_val: 0.8219	accuracy_test: 0.7880
[server]	loss_train: 0.2068	loss_val: 0.6047	loss_test: 0.5739	accuracy_train: 0.9325	accuracy_val: 0.8174	accuracy_test: 0.8065
[server]	loss_train: 0.1534	loss_val: 0.4846	loss_test: 0.4551	accuracy_train: 0.9630	accuracy_val: 0.8369	accuracy_test: 0.8404
[server]	loss_train: 0.2016	loss_val: 0.4935	loss_test: 0.4136	accuracy_train: 0.9360	accuracy_val: 0.8633	accuracy_test: 0.8736
[server]	loss_train: 0.1908	loss_val: 0.5599	loss_test: 0.5588	accuracy_train: 0.9528	accuracy_val: 0.8092	accuracy_test: 0.8144
[server]	loss_train: 0.1541	loss_val: 0.4315	loss_test: 0.5036	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8347
[server]	loss_train: 0.1633	loss_val: 0.4562	loss_test: 0.4638	accuracy_train: 0.9624	accuracy_val: 0.8417	accuracy_test: 0.8399
[server]	loss_train: 0.2523	loss_val: 0.5158	loss_test: 0.4630	accuracy_train: 0.9600	accuracy_val: 0.8185	accuracy_test: 0.8550
[server]	loss_train: 0.1486	loss_val: 0.4775	loss_test: 0.4793	accuracy_train: 0.9708	accuracy_val: 0.8622	accuracy_test: 0.8427
[server]	loss_train: 0.2203	loss_val: 0.6187	loss_test: 0.4563	accuracy_train: 0.9618	accuracy_val: 0.8284	accuracy_test: 0.8382
[server]	loss_train: 0.1516	loss_val: 0.5496	loss_test: 0.4734	accuracy_train: 0.9924	accuracy_val: 0.8358	accuracy_test: 0.8370
[server]	loss_train: 0.2136	loss_val: 0.5055	loss_test: 0.6215	accuracy_train: 0.9403	accuracy_val: 0.8087	accuracy_test: 0.7964
[server]	loss_train: 0.2785	loss_val: 0.4763	loss_test: 0.5084	accuracy_train: 0.8971	accuracy_val: 0.8321	accuracy_test: 0.8281
[server]	loss_train: 0.1987	loss_val: 0.5152	loss_test: 0.4113	accuracy_train: 0.9592	accuracy_val: 0.8624	accuracy_test: 0.8800
[server]	loss_train: 0.1612	loss_val: 0.3278	loss_test: 0.3606	accuracy_train: 0.9500	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.2064	loss_val: 0.5203	loss_test: 0.5332	accuracy_train: 0.9412	accuracy_val: 0.8250	accuracy_test: 0.8028
[server]	loss_train: 0.2004	loss_val: 0.4588	loss_test: 0.4896	accuracy_train: 0.9640	accuracy_val: 0.8565	accuracy_test: 0.8419
[server]	loss_train: 0.1239	loss_val: 0.3889	loss_test: 0.4007	accuracy_train: 0.9645	accuracy_val: 0.8850	accuracy_test: 0.8828
[server]	loss_train: 0.1825	loss_val: 0.4917	loss_test: 0.4664	accuracy_train: 0.9669	accuracy_val: 0.8484	accuracy_test: 0.8571
curr_round: 48	curr_val_accuracy: 0.8403	curr_test_accuracy: 0.8374
best_round: 48	best_val_accuracy: 0.8403	best_test_accuracy: 0.8374
--------------------------------------------------
round # 49		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2919	loss_val: 0.6251	loss_test: 0.5461	accuracy_train: 0.9254	accuracy_val: 0.8000	accuracy_test: 0.8172
[server]	loss_train: 0.1577	loss_val: 0.5081	loss_test: 0.5892	accuracy_train: 0.9661	accuracy_val: 0.8219	accuracy_test: 0.7920
[server]	loss_train: 0.2010	loss_val: 0.6066	loss_test: 0.5732	accuracy_train: 0.9325	accuracy_val: 0.8174	accuracy_test: 0.8065
[server]	loss_train: 0.1477	loss_val: 0.4832	loss_test: 0.4523	accuracy_train: 0.9704	accuracy_val: 0.8404	accuracy_test: 0.8440
[server]	loss_train: 0.1951	loss_val: 0.4913	loss_test: 0.4122	accuracy_train: 0.9360	accuracy_val: 0.8633	accuracy_test: 0.8736
[server]	loss_train: 0.1841	loss_val: 0.5581	loss_test: 0.5567	accuracy_train: 0.9606	accuracy_val: 0.8053	accuracy_test: 0.8182
[server]	loss_train: 0.1497	loss_val: 0.4298	loss_test: 0.5033	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8430
[server]	loss_train: 0.1583	loss_val: 0.4546	loss_test: 0.4612	accuracy_train: 0.9624	accuracy_val: 0.8417	accuracy_test: 0.8399
[server]	loss_train: 0.2473	loss_val: 0.5146	loss_test: 0.4611	accuracy_train: 0.9600	accuracy_val: 0.8147	accuracy_test: 0.8511
[server]	loss_train: 0.1436	loss_val: 0.4763	loss_test: 0.4790	accuracy_train: 0.9708	accuracy_val: 0.8622	accuracy_test: 0.8427
[server]	loss_train: 0.2125	loss_val: 0.6178	loss_test: 0.4536	accuracy_train: 0.9618	accuracy_val: 0.8284	accuracy_test: 0.8382
[server]	loss_train: 0.1459	loss_val: 0.5468	loss_test: 0.4712	accuracy_train: 0.9924	accuracy_val: 0.8358	accuracy_test: 0.8370
[server]	loss_train: 0.2064	loss_val: 0.5033	loss_test: 0.6208	accuracy_train: 0.9403	accuracy_val: 0.8087	accuracy_test: 0.7964
[server]	loss_train: 0.2720	loss_val: 0.4756	loss_test: 0.5067	accuracy_train: 0.9044	accuracy_val: 0.8357	accuracy_test: 0.8281
[server]	loss_train: 0.1938	loss_val: 0.5159	loss_test: 0.4111	accuracy_train: 0.9592	accuracy_val: 0.8624	accuracy_test: 0.8767
[server]	loss_train: 0.1566	loss_val: 0.3256	loss_test: 0.3593	accuracy_train: 0.9500	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.2004	loss_val: 0.5185	loss_test: 0.5326	accuracy_train: 0.9485	accuracy_val: 0.8250	accuracy_test: 0.8063
[server]	loss_train: 0.1909	loss_val: 0.4570	loss_test: 0.4871	accuracy_train: 0.9640	accuracy_val: 0.8609	accuracy_test: 0.8419
[server]	loss_train: 0.1193	loss_val: 0.3886	loss_test: 0.4007	accuracy_train: 0.9645	accuracy_val: 0.8850	accuracy_test: 0.8862
[server]	loss_train: 0.1763	loss_val: 0.4913	loss_test: 0.4656	accuracy_train: 0.9735	accuracy_val: 0.8452	accuracy_test: 0.8508
curr_round: 49	curr_val_accuracy: 0.8403	curr_test_accuracy: 0.8379
best_round: 48	best_val_accuracy: 0.8403	best_test_accuracy: 0.8374
--------------------------------------------------
round # 50		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2838	loss_val: 0.6246	loss_test: 0.5465	accuracy_train: 0.9254	accuracy_val: 0.8000	accuracy_test: 0.8172
[server]	loss_train: 0.1516	loss_val: 0.5082	loss_test: 0.5896	accuracy_train: 0.9661	accuracy_val: 0.8219	accuracy_test: 0.7920
[server]	loss_train: 0.1953	loss_val: 0.6069	loss_test: 0.5727	accuracy_train: 0.9387	accuracy_val: 0.8174	accuracy_test: 0.8065
[server]	loss_train: 0.1428	loss_val: 0.4836	loss_test: 0.4519	accuracy_train: 0.9704	accuracy_val: 0.8404	accuracy_test: 0.8440
[server]	loss_train: 0.1893	loss_val: 0.4893	loss_test: 0.4115	accuracy_train: 0.9360	accuracy_val: 0.8633	accuracy_test: 0.8774
[server]	loss_train: 0.1778	loss_val: 0.5569	loss_test: 0.5564	accuracy_train: 0.9606	accuracy_val: 0.8092	accuracy_test: 0.8220
[server]	loss_train: 0.1448	loss_val: 0.4277	loss_test: 0.5037	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8347
[server]	loss_train: 0.1531	loss_val: 0.4537	loss_test: 0.4604	accuracy_train: 0.9624	accuracy_val: 0.8417	accuracy_test: 0.8434
[server]	loss_train: 0.2428	loss_val: 0.5146	loss_test: 0.4609	accuracy_train: 0.9600	accuracy_val: 0.8185	accuracy_test: 0.8550
[server]	loss_train: 0.1390	loss_val: 0.4770	loss_test: 0.4793	accuracy_train: 0.9708	accuracy_val: 0.8622	accuracy_test: 0.8427
[server]	loss_train: 0.2061	loss_val: 0.6179	loss_test: 0.4525	accuracy_train: 0.9618	accuracy_val: 0.8284	accuracy_test: 0.8346
[server]	loss_train: 0.1407	loss_val: 0.5465	loss_test: 0.4694	accuracy_train: 0.9924	accuracy_val: 0.8358	accuracy_test: 0.8333
[server]	loss_train: 0.2000	loss_val: 0.5026	loss_test: 0.6222	accuracy_train: 0.9403	accuracy_val: 0.8087	accuracy_test: 0.7964
[server]	loss_train: 0.2650	loss_val: 0.4744	loss_test: 0.5066	accuracy_train: 0.9044	accuracy_val: 0.8393	accuracy_test: 0.8281
[server]	loss_train: 0.1886	loss_val: 0.5160	loss_test: 0.4102	accuracy_train: 0.9592	accuracy_val: 0.8624	accuracy_test: 0.8800
[server]	loss_train: 0.1522	loss_val: 0.3241	loss_test: 0.3570	accuracy_train: 0.9571	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.1952	loss_val: 0.5181	loss_test: 0.5329	accuracy_train: 0.9485	accuracy_val: 0.8250	accuracy_test: 0.8028
[server]	loss_train: 0.1819	loss_val: 0.4549	loss_test: 0.4858	accuracy_train: 0.9640	accuracy_val: 0.8565	accuracy_test: 0.8376
[server]	loss_train: 0.1148	loss_val: 0.3889	loss_test: 0.4002	accuracy_train: 0.9645	accuracy_val: 0.8850	accuracy_test: 0.8862
[server]	loss_train: 0.1702	loss_val: 0.4921	loss_test: 0.4649	accuracy_train: 0.9735	accuracy_val: 0.8452	accuracy_test: 0.8540
curr_round: 50	curr_val_accuracy: 0.8408	curr_test_accuracy: 0.8379
best_round: 50	best_val_accuracy: 0.8408	best_test_accuracy: 0.8379
--------------------------------------------------
round # 51		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2750	loss_val: 0.6236	loss_test: 0.5454	accuracy_train: 0.9254	accuracy_val: 0.8000	accuracy_test: 0.8136
[server]	loss_train: 0.1467	loss_val: 0.5075	loss_test: 0.5885	accuracy_train: 0.9661	accuracy_val: 0.8219	accuracy_test: 0.7920
[server]	loss_train: 0.1897	loss_val: 0.6084	loss_test: 0.5719	accuracy_train: 0.9387	accuracy_val: 0.8174	accuracy_test: 0.8065
[server]	loss_train: 0.1375	loss_val: 0.4825	loss_test: 0.4494	accuracy_train: 0.9704	accuracy_val: 0.8404	accuracy_test: 0.8511
[server]	loss_train: 0.1832	loss_val: 0.4873	loss_test: 0.4104	accuracy_train: 0.9360	accuracy_val: 0.8672	accuracy_test: 0.8774
[server]	loss_train: 0.1717	loss_val: 0.5552	loss_test: 0.5544	accuracy_train: 0.9606	accuracy_val: 0.8092	accuracy_test: 0.8220
[server]	loss_train: 0.1406	loss_val: 0.4258	loss_test: 0.5032	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8388
[server]	loss_train: 0.1487	loss_val: 0.4524	loss_test: 0.4580	accuracy_train: 0.9624	accuracy_val: 0.8417	accuracy_test: 0.8434
[server]	loss_train: 0.2381	loss_val: 0.5134	loss_test: 0.4588	accuracy_train: 0.9600	accuracy_val: 0.8224	accuracy_test: 0.8550
[server]	loss_train: 0.1343	loss_val: 0.4758	loss_test: 0.4787	accuracy_train: 0.9781	accuracy_val: 0.8622	accuracy_test: 0.8427
[server]	loss_train: 0.1987	loss_val: 0.6174	loss_test: 0.4503	accuracy_train: 0.9618	accuracy_val: 0.8284	accuracy_test: 0.8346
[server]	loss_train: 0.1357	loss_val: 0.5440	loss_test: 0.4677	accuracy_train: 1.0000	accuracy_val: 0.8358	accuracy_test: 0.8333
[server]	loss_train: 0.1932	loss_val: 0.5005	loss_test: 0.6211	accuracy_train: 0.9403	accuracy_val: 0.8087	accuracy_test: 0.7964
[server]	loss_train: 0.2593	loss_val: 0.4744	loss_test: 0.5050	accuracy_train: 0.9044	accuracy_val: 0.8393	accuracy_test: 0.8316
[server]	loss_train: 0.1841	loss_val: 0.5166	loss_test: 0.4099	accuracy_train: 0.9660	accuracy_val: 0.8624	accuracy_test: 0.8767
[server]	loss_train: 0.1482	loss_val: 0.3227	loss_test: 0.3565	accuracy_train: 0.9571	accuracy_val: 0.8893	accuracy_test: 0.8664
[server]	loss_train: 0.1893	loss_val: 0.5164	loss_test: 0.5322	accuracy_train: 0.9485	accuracy_val: 0.8286	accuracy_test: 0.8063
[server]	loss_train: 0.1734	loss_val: 0.4532	loss_test: 0.4835	accuracy_train: 0.9640	accuracy_val: 0.8609	accuracy_test: 0.8376
[server]	loss_train: 0.1108	loss_val: 0.3889	loss_test: 0.4007	accuracy_train: 0.9645	accuracy_val: 0.8850	accuracy_test: 0.8862
[server]	loss_train: 0.1645	loss_val: 0.4922	loss_test: 0.4641	accuracy_train: 0.9801	accuracy_val: 0.8484	accuracy_test: 0.8540
curr_round: 51	curr_val_accuracy: 0.8419	curr_test_accuracy: 0.8385
best_round: 51	best_val_accuracy: 0.8419	best_test_accuracy: 0.8385
--------------------------------------------------
round # 52		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2679	loss_val: 0.6237	loss_test: 0.5463	accuracy_train: 0.9254	accuracy_val: 0.8000	accuracy_test: 0.8172
[server]	loss_train: 0.1413	loss_val: 0.5078	loss_test: 0.5890	accuracy_train: 0.9746	accuracy_val: 0.8259	accuracy_test: 0.7920
[server]	loss_train: 0.1846	loss_val: 0.6094	loss_test: 0.5721	accuracy_train: 0.9387	accuracy_val: 0.8174	accuracy_test: 0.8095
[server]	loss_train: 0.1334	loss_val: 0.4834	loss_test: 0.4494	accuracy_train: 0.9778	accuracy_val: 0.8404	accuracy_test: 0.8511
[server]	loss_train: 0.1781	loss_val: 0.4859	loss_test: 0.4101	accuracy_train: 0.9440	accuracy_val: 0.8672	accuracy_test: 0.8774
[server]	loss_train: 0.1661	loss_val: 0.5547	loss_test: 0.5546	accuracy_train: 0.9606	accuracy_val: 0.8092	accuracy_test: 0.8258
[server]	loss_train: 0.1364	loss_val: 0.4244	loss_test: 0.5042	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.1439	loss_val: 0.4519	loss_test: 0.4578	accuracy_train: 0.9699	accuracy_val: 0.8453	accuracy_test: 0.8399
[server]	loss_train: 0.2343	loss_val: 0.5141	loss_test: 0.4592	accuracy_train: 0.9600	accuracy_val: 0.8224	accuracy_test: 0.8511
[server]	loss_train: 0.1303	loss_val: 0.4771	loss_test: 0.4797	accuracy_train: 0.9781	accuracy_val: 0.8622	accuracy_test: 0.8392
[server]	loss_train: 0.1931	loss_val: 0.6179	loss_test: 0.4496	accuracy_train: 0.9618	accuracy_val: 0.8284	accuracy_test: 0.8346
[server]	loss_train: 0.1309	loss_val: 0.5443	loss_test: 0.4664	accuracy_train: 1.0000	accuracy_val: 0.8358	accuracy_test: 0.8370
[server]	loss_train: 0.1875	loss_val: 0.5005	loss_test: 0.6233	accuracy_train: 0.9403	accuracy_val: 0.8087	accuracy_test: 0.7964
[server]	loss_train: 0.2529	loss_val: 0.4733	loss_test: 0.5055	accuracy_train: 0.9118	accuracy_val: 0.8393	accuracy_test: 0.8351
[server]	loss_train: 0.1793	loss_val: 0.5172	loss_test: 0.4095	accuracy_train: 0.9660	accuracy_val: 0.8557	accuracy_test: 0.8800
[server]	loss_train: 0.1441	loss_val: 0.3212	loss_test: 0.3542	accuracy_train: 0.9643	accuracy_val: 0.8893	accuracy_test: 0.8664
[server]	loss_train: 0.1849	loss_val: 0.5166	loss_test: 0.5331	accuracy_train: 0.9559	accuracy_val: 0.8286	accuracy_test: 0.7993
[server]	loss_train: 0.1655	loss_val: 0.4517	loss_test: 0.4828	accuracy_train: 0.9820	accuracy_val: 0.8609	accuracy_test: 0.8376
[server]	loss_train: 0.1066	loss_val: 0.3894	loss_test: 0.4004	accuracy_train: 0.9716	accuracy_val: 0.8850	accuracy_test: 0.8862
[server]	loss_train: 0.1589	loss_val: 0.4930	loss_test: 0.4638	accuracy_train: 0.9801	accuracy_val: 0.8484	accuracy_test: 0.8540
curr_round: 52	curr_val_accuracy: 0.8419	curr_test_accuracy: 0.8388
best_round: 51	best_val_accuracy: 0.8419	best_test_accuracy: 0.8385
--------------------------------------------------
round # 53		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2598	loss_val: 0.6230	loss_test: 0.5455	accuracy_train: 0.9328	accuracy_val: 0.8000	accuracy_test: 0.8244
[server]	loss_train: 0.1367	loss_val: 0.5071	loss_test: 0.5881	accuracy_train: 0.9746	accuracy_val: 0.8340	accuracy_test: 0.7880
[server]	loss_train: 0.1794	loss_val: 0.6105	loss_test: 0.5712	accuracy_train: 0.9387	accuracy_val: 0.8204	accuracy_test: 0.8095
[server]	loss_train: 0.1286	loss_val: 0.4824	loss_test: 0.4470	accuracy_train: 0.9778	accuracy_val: 0.8404	accuracy_test: 0.8546
[server]	loss_train: 0.1725	loss_val: 0.4840	loss_test: 0.4092	accuracy_train: 0.9520	accuracy_val: 0.8672	accuracy_test: 0.8774
[server]	loss_train: 0.1605	loss_val: 0.5531	loss_test: 0.5526	accuracy_train: 0.9685	accuracy_val: 0.8168	accuracy_test: 0.8258
[server]	loss_train: 0.1325	loss_val: 0.4225	loss_test: 0.5036	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.1399	loss_val: 0.4509	loss_test: 0.4557	accuracy_train: 0.9699	accuracy_val: 0.8453	accuracy_test: 0.8399
[server]	loss_train: 0.2297	loss_val: 0.5128	loss_test: 0.4571	accuracy_train: 0.9600	accuracy_val: 0.8224	accuracy_test: 0.8511
[server]	loss_train: 0.1261	loss_val: 0.4758	loss_test: 0.4789	accuracy_train: 0.9781	accuracy_val: 0.8622	accuracy_test: 0.8392
[server]	loss_train: 0.1862	loss_val: 0.6175	loss_test: 0.4477	accuracy_train: 0.9618	accuracy_val: 0.8284	accuracy_test: 0.8346
[server]	loss_train: 0.1264	loss_val: 0.5420	loss_test: 0.4649	accuracy_train: 1.0000	accuracy_val: 0.8358	accuracy_test: 0.8406
[server]	loss_train: 0.1812	loss_val: 0.4985	loss_test: 0.6222	accuracy_train: 0.9403	accuracy_val: 0.8087	accuracy_test: 0.7964
[server]	loss_train: 0.2479	loss_val: 0.4737	loss_test: 0.5040	accuracy_train: 0.9118	accuracy_val: 0.8393	accuracy_test: 0.8351
[server]	loss_train: 0.1751	loss_val: 0.5179	loss_test: 0.4093	accuracy_train: 0.9660	accuracy_val: 0.8591	accuracy_test: 0.8800
[server]	loss_train: 0.1406	loss_val: 0.3200	loss_test: 0.3539	accuracy_train: 0.9643	accuracy_val: 0.8893	accuracy_test: 0.8630
[server]	loss_train: 0.1793	loss_val: 0.5150	loss_test: 0.5325	accuracy_train: 0.9632	accuracy_val: 0.8286	accuracy_test: 0.8028
[server]	loss_train: 0.1580	loss_val: 0.4502	loss_test: 0.4808	accuracy_train: 0.9820	accuracy_val: 0.8609	accuracy_test: 0.8376
[server]	loss_train: 0.1031	loss_val: 0.3895	loss_test: 0.4011	accuracy_train: 0.9787	accuracy_val: 0.8850	accuracy_test: 0.8862
[server]	loss_train: 0.1537	loss_val: 0.4932	loss_test: 0.4631	accuracy_train: 0.9801	accuracy_val: 0.8484	accuracy_test: 0.8540
curr_round: 53	curr_val_accuracy: 0.8430	curr_test_accuracy: 0.8394
best_round: 53	best_val_accuracy: 0.8430	best_test_accuracy: 0.8394
--------------------------------------------------
round # 54		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2530	loss_val: 0.6231	loss_test: 0.5466	accuracy_train: 0.9328	accuracy_val: 0.8000	accuracy_test: 0.8244
[server]	loss_train: 0.1320	loss_val: 0.5078	loss_test: 0.5889	accuracy_train: 0.9746	accuracy_val: 0.8259	accuracy_test: 0.7920
[server]	loss_train: 0.1747	loss_val: 0.6117	loss_test: 0.5716	accuracy_train: 0.9509	accuracy_val: 0.8204	accuracy_test: 0.8125
[server]	loss_train: 0.1247	loss_val: 0.4834	loss_test: 0.4472	accuracy_train: 0.9778	accuracy_val: 0.8404	accuracy_test: 0.8546
[server]	loss_train: 0.1679	loss_val: 0.4830	loss_test: 0.4092	accuracy_train: 0.9600	accuracy_val: 0.8711	accuracy_test: 0.8774
[server]	loss_train: 0.1554	loss_val: 0.5529	loss_test: 0.5532	accuracy_train: 0.9685	accuracy_val: 0.8168	accuracy_test: 0.8258
[server]	loss_train: 0.1287	loss_val: 0.4213	loss_test: 0.5048	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.1355	loss_val: 0.4508	loss_test: 0.4559	accuracy_train: 0.9699	accuracy_val: 0.8453	accuracy_test: 0.8399
[server]	loss_train: 0.2261	loss_val: 0.5137	loss_test: 0.4579	accuracy_train: 0.9600	accuracy_val: 0.8224	accuracy_test: 0.8473
[server]	loss_train: 0.1225	loss_val: 0.4773	loss_test: 0.4802	accuracy_train: 0.9781	accuracy_val: 0.8657	accuracy_test: 0.8357
[server]	loss_train: 0.1809	loss_val: 0.6184	loss_test: 0.4474	accuracy_train: 0.9695	accuracy_val: 0.8284	accuracy_test: 0.8419
[server]	loss_train: 0.1221	loss_val: 0.5427	loss_test: 0.4638	accuracy_train: 1.0000	accuracy_val: 0.8358	accuracy_test: 0.8406
[server]	loss_train: 0.1761	loss_val: 0.4987	loss_test: 0.6246	accuracy_train: 0.9403	accuracy_val: 0.8087	accuracy_test: 0.7964
[server]	loss_train: 0.2417	loss_val: 0.4728	loss_test: 0.5046	accuracy_train: 0.9191	accuracy_val: 0.8393	accuracy_test: 0.8351
[server]	loss_train: 0.1707	loss_val: 0.5184	loss_test: 0.4091	accuracy_train: 0.9660	accuracy_val: 0.8557	accuracy_test: 0.8833
[server]	loss_train: 0.1368	loss_val: 0.3188	loss_test: 0.3520	accuracy_train: 0.9714	accuracy_val: 0.8893	accuracy_test: 0.8630
[server]	loss_train: 0.1752	loss_val: 0.5155	loss_test: 0.5337	accuracy_train: 0.9632	accuracy_val: 0.8286	accuracy_test: 0.8028
[server]	loss_train: 0.1510	loss_val: 0.4491	loss_test: 0.4802	accuracy_train: 0.9820	accuracy_val: 0.8609	accuracy_test: 0.8376
[server]	loss_train: 0.0994	loss_val: 0.3901	loss_test: 0.4010	accuracy_train: 0.9787	accuracy_val: 0.8850	accuracy_test: 0.8862
[server]	loss_train: 0.1487	loss_val: 0.4941	loss_test: 0.4632	accuracy_train: 0.9801	accuracy_val: 0.8484	accuracy_test: 0.8540
curr_round: 54	curr_val_accuracy: 0.8428	curr_test_accuracy: 0.8399
best_round: 53	best_val_accuracy: 0.8430	best_test_accuracy: 0.8394
--------------------------------------------------
round # 55		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2455	loss_val: 0.6225	loss_test: 0.5461	accuracy_train: 0.9328	accuracy_val: 0.7964	accuracy_test: 0.8208
[server]	loss_train: 0.1278	loss_val: 0.5074	loss_test: 0.5884	accuracy_train: 0.9746	accuracy_val: 0.8300	accuracy_test: 0.7920
[server]	loss_train: 0.1700	loss_val: 0.6128	loss_test: 0.5710	accuracy_train: 0.9509	accuracy_val: 0.8234	accuracy_test: 0.8125
[server]	loss_train: 0.1204	loss_val: 0.4829	loss_test: 0.4454	accuracy_train: 0.9778	accuracy_val: 0.8404	accuracy_test: 0.8546
[server]	loss_train: 0.1627	loss_val: 0.4814	loss_test: 0.4085	accuracy_train: 0.9600	accuracy_val: 0.8711	accuracy_test: 0.8774
[server]	loss_train: 0.1504	loss_val: 0.5516	loss_test: 0.5515	accuracy_train: 0.9685	accuracy_val: 0.8168	accuracy_test: 0.8220
[server]	loss_train: 0.1251	loss_val: 0.4197	loss_test: 0.5043	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.1318	loss_val: 0.4498	loss_test: 0.4539	accuracy_train: 0.9699	accuracy_val: 0.8453	accuracy_test: 0.8399
[server]	loss_train: 0.2219	loss_val: 0.5128	loss_test: 0.4562	accuracy_train: 0.9600	accuracy_val: 0.8301	accuracy_test: 0.8588
[server]	loss_train: 0.1187	loss_val: 0.4764	loss_test: 0.4796	accuracy_train: 0.9781	accuracy_val: 0.8622	accuracy_test: 0.8357
[server]	loss_train: 0.1746	loss_val: 0.6182	loss_test: 0.4459	accuracy_train: 0.9695	accuracy_val: 0.8284	accuracy_test: 0.8419
[server]	loss_train: 0.1181	loss_val: 0.5407	loss_test: 0.4626	accuracy_train: 1.0000	accuracy_val: 0.8358	accuracy_test: 0.8406
[server]	loss_train: 0.1704	loss_val: 0.4971	loss_test: 0.6237	accuracy_train: 0.9403	accuracy_val: 0.8087	accuracy_test: 0.7964
[server]	loss_train: 0.2371	loss_val: 0.4734	loss_test: 0.5034	accuracy_train: 0.9265	accuracy_val: 0.8393	accuracy_test: 0.8351
[server]	loss_train: 0.1668	loss_val: 0.5192	loss_test: 0.4090	accuracy_train: 0.9660	accuracy_val: 0.8591	accuracy_test: 0.8833
[server]	loss_train: 0.1336	loss_val: 0.3179	loss_test: 0.3520	accuracy_train: 0.9714	accuracy_val: 0.8893	accuracy_test: 0.8630
[server]	loss_train: 0.1701	loss_val: 0.5142	loss_test: 0.5332	accuracy_train: 0.9632	accuracy_val: 0.8286	accuracy_test: 0.8028
[server]	loss_train: 0.1442	loss_val: 0.4477	loss_test: 0.4784	accuracy_train: 0.9820	accuracy_val: 0.8652	accuracy_test: 0.8376
[server]	loss_train: 0.0962	loss_val: 0.3904	loss_test: 0.4019	accuracy_train: 0.9787	accuracy_val: 0.8850	accuracy_test: 0.8862
[server]	loss_train: 0.1439	loss_val: 0.4947	loss_test: 0.4627	accuracy_train: 0.9801	accuracy_val: 0.8484	accuracy_test: 0.8540
curr_round: 55	curr_val_accuracy: 0.8436	curr_test_accuracy: 0.8401
best_round: 55	best_val_accuracy: 0.8436	best_test_accuracy: 0.8401
--------------------------------------------------
round # 56		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2392	loss_val: 0.6230	loss_test: 0.5472	accuracy_train: 0.9328	accuracy_val: 0.7964	accuracy_test: 0.8244
[server]	loss_train: 0.1235	loss_val: 0.5081	loss_test: 0.5893	accuracy_train: 0.9746	accuracy_val: 0.8259	accuracy_test: 0.7920
[server]	loss_train: 0.1656	loss_val: 0.6145	loss_test: 0.5718	accuracy_train: 0.9509	accuracy_val: 0.8234	accuracy_test: 0.8125
[server]	loss_train: 0.1170	loss_val: 0.4841	loss_test: 0.4458	accuracy_train: 0.9778	accuracy_val: 0.8404	accuracy_test: 0.8582
[server]	loss_train: 0.1585	loss_val: 0.4808	loss_test: 0.4087	accuracy_train: 0.9680	accuracy_val: 0.8711	accuracy_test: 0.8774
[server]	loss_train: 0.1457	loss_val: 0.5518	loss_test: 0.5523	accuracy_train: 0.9764	accuracy_val: 0.8206	accuracy_test: 0.8182
[server]	loss_train: 0.1218	loss_val: 0.4188	loss_test: 0.5058	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.1277	loss_val: 0.4499	loss_test: 0.4544	accuracy_train: 0.9774	accuracy_val: 0.8489	accuracy_test: 0.8399
[server]	loss_train: 0.2188	loss_val: 0.5140	loss_test: 0.4572	accuracy_train: 0.9600	accuracy_val: 0.8263	accuracy_test: 0.8550
[server]	loss_train: 0.1155	loss_val: 0.4781	loss_test: 0.4812	accuracy_train: 0.9781	accuracy_val: 0.8657	accuracy_test: 0.8392
[server]	loss_train: 0.1698	loss_val: 0.6193	loss_test: 0.4458	accuracy_train: 0.9695	accuracy_val: 0.8284	accuracy_test: 0.8456
[server]	loss_train: 0.1141	loss_val: 0.5416	loss_test: 0.4617	accuracy_train: 1.0000	accuracy_val: 0.8394	accuracy_test: 0.8406
[server]	loss_train: 0.1657	loss_val: 0.4975	loss_test: 0.6263	accuracy_train: 0.9478	accuracy_val: 0.8087	accuracy_test: 0.7929
[server]	loss_train: 0.2314	loss_val: 0.4727	loss_test: 0.5042	accuracy_train: 0.9265	accuracy_val: 0.8393	accuracy_test: 0.8351
[server]	loss_train: 0.1627	loss_val: 0.5200	loss_test: 0.4090	accuracy_train: 0.9660	accuracy_val: 0.8591	accuracy_test: 0.8833
[server]	loss_train: 0.1301	loss_val: 0.3168	loss_test: 0.3502	accuracy_train: 0.9714	accuracy_val: 0.8893	accuracy_test: 0.8630
[server]	loss_train: 0.1665	loss_val: 0.5150	loss_test: 0.5347	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8028
[server]	loss_train: 0.1380	loss_val: 0.4470	loss_test: 0.4781	accuracy_train: 0.9820	accuracy_val: 0.8609	accuracy_test: 0.8333
[server]	loss_train: 0.0929	loss_val: 0.3911	loss_test: 0.4019	accuracy_train: 0.9787	accuracy_val: 0.8850	accuracy_test: 0.8862
[server]	loss_train: 0.1394	loss_val: 0.4956	loss_test: 0.4629	accuracy_train: 0.9801	accuracy_val: 0.8516	accuracy_test: 0.8540
curr_round: 56	curr_val_accuracy: 0.8441	curr_test_accuracy: 0.8401
best_round: 56	best_val_accuracy: 0.8441	best_test_accuracy: 0.8401
--------------------------------------------------
round # 57		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2322	loss_val: 0.6225	loss_test: 0.5469	accuracy_train: 0.9328	accuracy_val: 0.7964	accuracy_test: 0.8244
[server]	loss_train: 0.1197	loss_val: 0.5079	loss_test: 0.5891	accuracy_train: 0.9746	accuracy_val: 0.8259	accuracy_test: 0.7920
[server]	loss_train: 0.1611	loss_val: 0.6152	loss_test: 0.5712	accuracy_train: 0.9571	accuracy_val: 0.8263	accuracy_test: 0.8155
[server]	loss_train: 0.1129	loss_val: 0.4837	loss_test: 0.4441	accuracy_train: 0.9778	accuracy_val: 0.8404	accuracy_test: 0.8546
[server]	loss_train: 0.1538	loss_val: 0.4792	loss_test: 0.4082	accuracy_train: 0.9680	accuracy_val: 0.8750	accuracy_test: 0.8851
[server]	loss_train: 0.1410	loss_val: 0.5505	loss_test: 0.5509	accuracy_train: 0.9764	accuracy_val: 0.8168	accuracy_test: 0.8182
[server]	loss_train: 0.1184	loss_val: 0.4171	loss_test: 0.5053	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.1243	loss_val: 0.4491	loss_test: 0.4526	accuracy_train: 0.9774	accuracy_val: 0.8525	accuracy_test: 0.8434
[server]	loss_train: 0.2146	loss_val: 0.5131	loss_test: 0.4555	accuracy_train: 0.9600	accuracy_val: 0.8301	accuracy_test: 0.8588
[server]	loss_train: 0.1120	loss_val: 0.4773	loss_test: 0.4806	accuracy_train: 0.9781	accuracy_val: 0.8657	accuracy_test: 0.8392
[server]	loss_train: 0.1639	loss_val: 0.6192	loss_test: 0.4446	accuracy_train: 0.9695	accuracy_val: 0.8284	accuracy_test: 0.8456
[server]	loss_train: 0.1105	loss_val: 0.5400	loss_test: 0.4607	accuracy_train: 1.0000	accuracy_val: 0.8394	accuracy_test: 0.8370
[server]	loss_train: 0.1605	loss_val: 0.4960	loss_test: 0.6255	accuracy_train: 0.9701	accuracy_val: 0.8087	accuracy_test: 0.7964
[server]	loss_train: 0.2272	loss_val: 0.4736	loss_test: 0.5032	accuracy_train: 0.9338	accuracy_val: 0.8393	accuracy_test: 0.8351
[server]	loss_train: 0.1591	loss_val: 0.5208	loss_test: 0.4089	accuracy_train: 0.9728	accuracy_val: 0.8591	accuracy_test: 0.8833
[server]	loss_train: 0.1272	loss_val: 0.3161	loss_test: 0.3503	accuracy_train: 0.9714	accuracy_val: 0.8893	accuracy_test: 0.8630
[server]	loss_train: 0.1617	loss_val: 0.5139	loss_test: 0.5343	accuracy_train: 0.9706	accuracy_val: 0.8321	accuracy_test: 0.8028
[server]	loss_train: 0.1321	loss_val: 0.4457	loss_test: 0.4766	accuracy_train: 0.9820	accuracy_val: 0.8609	accuracy_test: 0.8333
[server]	loss_train: 0.0901	loss_val: 0.3915	loss_test: 0.4029	accuracy_train: 0.9787	accuracy_val: 0.8850	accuracy_test: 0.8862
[server]	loss_train: 0.1350	loss_val: 0.4964	loss_test: 0.4625	accuracy_train: 0.9801	accuracy_val: 0.8548	accuracy_test: 0.8540
curr_round: 57	curr_val_accuracy: 0.8448	curr_test_accuracy: 0.8408
best_round: 57	best_val_accuracy: 0.8448	best_test_accuracy: 0.8408
--------------------------------------------------
round # 58		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2265	loss_val: 0.6230	loss_test: 0.5481	accuracy_train: 0.9328	accuracy_val: 0.7964	accuracy_test: 0.8208
[server]	loss_train: 0.1160	loss_val: 0.5087	loss_test: 0.5900	accuracy_train: 0.9746	accuracy_val: 0.8259	accuracy_test: 0.7880
[server]	loss_train: 0.1571	loss_val: 0.6172	loss_test: 0.5723	accuracy_train: 0.9571	accuracy_val: 0.8234	accuracy_test: 0.8155
[server]	loss_train: 0.1098	loss_val: 0.4850	loss_test: 0.4445	accuracy_train: 0.9778	accuracy_val: 0.8404	accuracy_test: 0.8582
[server]	loss_train: 0.1499	loss_val: 0.4790	loss_test: 0.4086	accuracy_train: 0.9680	accuracy_val: 0.8750	accuracy_test: 0.8851
[server]	loss_train: 0.1367	loss_val: 0.5510	loss_test: 0.5520	accuracy_train: 0.9764	accuracy_val: 0.8244	accuracy_test: 0.8182
[server]	loss_train: 0.1155	loss_val: 0.4165	loss_test: 0.5069	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.1205	loss_val: 0.4495	loss_test: 0.4533	accuracy_train: 0.9774	accuracy_val: 0.8525	accuracy_test: 0.8434
[server]	loss_train: 0.2116	loss_val: 0.5145	loss_test: 0.4568	accuracy_train: 0.9600	accuracy_val: 0.8301	accuracy_test: 0.8588
[server]	loss_train: 0.1090	loss_val: 0.4790	loss_test: 0.4825	accuracy_train: 0.9854	accuracy_val: 0.8657	accuracy_test: 0.8392
[server]	loss_train: 0.1594	loss_val: 0.6205	loss_test: 0.4447	accuracy_train: 0.9695	accuracy_val: 0.8284	accuracy_test: 0.8456
[server]	loss_train: 0.1069	loss_val: 0.5410	loss_test: 0.4600	accuracy_train: 1.0000	accuracy_val: 0.8394	accuracy_test: 0.8370
[server]	loss_train: 0.1564	loss_val: 0.4965	loss_test: 0.6281	accuracy_train: 0.9701	accuracy_val: 0.8123	accuracy_test: 0.7929
[server]	loss_train: 0.2219	loss_val: 0.4731	loss_test: 0.5042	accuracy_train: 0.9338	accuracy_val: 0.8393	accuracy_test: 0.8351
[server]	loss_train: 0.1554	loss_val: 0.5217	loss_test: 0.4092	accuracy_train: 0.9728	accuracy_val: 0.8591	accuracy_test: 0.8867
[server]	loss_train: 0.1240	loss_val: 0.3150	loss_test: 0.3488	accuracy_train: 0.9714	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.1584	loss_val: 0.5150	loss_test: 0.5361	accuracy_train: 0.9706	accuracy_val: 0.8321	accuracy_test: 0.8028
[server]	loss_train: 0.1266	loss_val: 0.4454	loss_test: 0.4765	accuracy_train: 0.9820	accuracy_val: 0.8652	accuracy_test: 0.8333
[server]	loss_train: 0.0871	loss_val: 0.3923	loss_test: 0.4031	accuracy_train: 0.9787	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.1309	loss_val: 0.4974	loss_test: 0.4630	accuracy_train: 0.9868	accuracy_val: 0.8548	accuracy_test: 0.8508
curr_round: 58	curr_val_accuracy: 0.8454	curr_test_accuracy: 0.8406
best_round: 58	best_val_accuracy: 0.8454	best_test_accuracy: 0.8406
--------------------------------------------------
round # 59		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2200	loss_val: 0.6228	loss_test: 0.5480	accuracy_train: 0.9328	accuracy_val: 0.7927	accuracy_test: 0.8244
[server]	loss_train: 0.1124	loss_val: 0.5086	loss_test: 0.5901	accuracy_train: 0.9746	accuracy_val: 0.8259	accuracy_test: 0.7880
[server]	loss_train: 0.1530	loss_val: 0.6179	loss_test: 0.5717	accuracy_train: 0.9571	accuracy_val: 0.8234	accuracy_test: 0.8185
[server]	loss_train: 0.1062	loss_val: 0.4848	loss_test: 0.4432	accuracy_train: 0.9778	accuracy_val: 0.8440	accuracy_test: 0.8582
[server]	loss_train: 0.1455	loss_val: 0.4776	loss_test: 0.4082	accuracy_train: 0.9680	accuracy_val: 0.8789	accuracy_test: 0.8812
[server]	loss_train: 0.1325	loss_val: 0.5499	loss_test: 0.5504	accuracy_train: 0.9843	accuracy_val: 0.8168	accuracy_test: 0.8182
[server]	loss_train: 0.1123	loss_val: 0.4150	loss_test: 0.5064	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.1174	loss_val: 0.4488	loss_test: 0.4518	accuracy_train: 0.9774	accuracy_val: 0.8525	accuracy_test: 0.8434
[server]	loss_train: 0.2077	loss_val: 0.5138	loss_test: 0.4552	accuracy_train: 0.9600	accuracy_val: 0.8301	accuracy_test: 0.8588
[server]	loss_train: 0.1058	loss_val: 0.4783	loss_test: 0.4818	accuracy_train: 0.9854	accuracy_val: 0.8657	accuracy_test: 0.8392
[server]	loss_train: 0.1540	loss_val: 0.6207	loss_test: 0.4438	accuracy_train: 0.9771	accuracy_val: 0.8284	accuracy_test: 0.8456
[server]	loss_train: 0.1036	loss_val: 0.5396	loss_test: 0.4591	accuracy_train: 1.0000	accuracy_val: 0.8394	accuracy_test: 0.8370
[server]	loss_train: 0.1516	loss_val: 0.4952	loss_test: 0.6273	accuracy_train: 0.9701	accuracy_val: 0.8159	accuracy_test: 0.7929
[server]	loss_train: 0.2181	loss_val: 0.4743	loss_test: 0.5033	accuracy_train: 0.9338	accuracy_val: 0.8393	accuracy_test: 0.8351
[server]	loss_train: 0.1519	loss_val: 0.5226	loss_test: 0.4091	accuracy_train: 0.9728	accuracy_val: 0.8591	accuracy_test: 0.8833
[server]	loss_train: 0.1214	loss_val: 0.3147	loss_test: 0.3491	accuracy_train: 0.9714	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.1538	loss_val: 0.5141	loss_test: 0.5357	accuracy_train: 0.9706	accuracy_val: 0.8357	accuracy_test: 0.8028
[server]	loss_train: 0.1214	loss_val: 0.4441	loss_test: 0.4751	accuracy_train: 0.9820	accuracy_val: 0.8652	accuracy_test: 0.8333
[server]	loss_train: 0.0846	loss_val: 0.3927	loss_test: 0.4043	accuracy_train: 0.9787	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.1270	loss_val: 0.4983	loss_test: 0.4627	accuracy_train: 0.9868	accuracy_val: 0.8548	accuracy_test: 0.8540
curr_round: 59	curr_val_accuracy: 0.8456	curr_test_accuracy: 0.8408
best_round: 59	best_val_accuracy: 0.8456	best_test_accuracy: 0.8408
--------------------------------------------------
round # 60		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2148	loss_val: 0.6236	loss_test: 0.5496	accuracy_train: 0.9403	accuracy_val: 0.7927	accuracy_test: 0.8244
[server]	loss_train: 0.1089	loss_val: 0.5096	loss_test: 0.5911	accuracy_train: 0.9746	accuracy_val: 0.8259	accuracy_test: 0.7920
[server]	loss_train: 0.1494	loss_val: 0.6200	loss_test: 0.5730	accuracy_train: 0.9571	accuracy_val: 0.8234	accuracy_test: 0.8155
[server]	loss_train: 0.1035	loss_val: 0.4863	loss_test: 0.4440	accuracy_train: 0.9778	accuracy_val: 0.8440	accuracy_test: 0.8546
[server]	loss_train: 0.1420	loss_val: 0.4775	loss_test: 0.4087	accuracy_train: 0.9680	accuracy_val: 0.8789	accuracy_test: 0.8774
[server]	loss_train: 0.1286	loss_val: 0.5505	loss_test: 0.5517	accuracy_train: 0.9843	accuracy_val: 0.8206	accuracy_test: 0.8182
[server]	loss_train: 0.1098	loss_val: 0.4148	loss_test: 0.5084	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.1139	loss_val: 0.4492	loss_test: 0.4528	accuracy_train: 0.9774	accuracy_val: 0.8525	accuracy_test: 0.8434
[server]	loss_train: 0.2050	loss_val: 0.5155	loss_test: 0.4568	accuracy_train: 0.9600	accuracy_val: 0.8301	accuracy_test: 0.8550
[server]	loss_train: 0.1032	loss_val: 0.4803	loss_test: 0.4839	accuracy_train: 0.9927	accuracy_val: 0.8622	accuracy_test: 0.8357
[server]	loss_train: 0.1499	loss_val: 0.6220	loss_test: 0.4441	accuracy_train: 0.9771	accuracy_val: 0.8284	accuracy_test: 0.8529
[server]	loss_train: 0.1003	loss_val: 0.5409	loss_test: 0.4585	accuracy_train: 1.0000	accuracy_val: 0.8431	accuracy_test: 0.8370
[server]	loss_train: 0.1479	loss_val: 0.4961	loss_test: 0.6304	accuracy_train: 0.9701	accuracy_val: 0.8159	accuracy_test: 0.7929
[server]	loss_train: 0.2128	loss_val: 0.4737	loss_test: 0.5045	accuracy_train: 0.9338	accuracy_val: 0.8357	accuracy_test: 0.8351
[server]	loss_train: 0.1484	loss_val: 0.5236	loss_test: 0.4095	accuracy_train: 0.9728	accuracy_val: 0.8557	accuracy_test: 0.8867
[server]	loss_train: 0.1184	loss_val: 0.3136	loss_test: 0.3476	accuracy_train: 0.9786	accuracy_val: 0.8893	accuracy_test: 0.8664
[server]	loss_train: 0.1510	loss_val: 0.5154	loss_test: 0.5378	accuracy_train: 0.9706	accuracy_val: 0.8357	accuracy_test: 0.8063
[server]	loss_train: 0.1166	loss_val: 0.4439	loss_test: 0.4752	accuracy_train: 0.9820	accuracy_val: 0.8652	accuracy_test: 0.8333
[server]	loss_train: 0.0819	loss_val: 0.3936	loss_test: 0.4044	accuracy_train: 0.9858	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.1233	loss_val: 0.4994	loss_test: 0.4635	accuracy_train: 0.9868	accuracy_val: 0.8548	accuracy_test: 0.8508
curr_round: 60	curr_val_accuracy: 0.8456	curr_test_accuracy: 0.8406
best_round: 59	best_val_accuracy: 0.8456	best_test_accuracy: 0.8408
--------------------------------------------------
round # 61		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2086	loss_val: 0.6235	loss_test: 0.5495	accuracy_train: 0.9403	accuracy_val: 0.7927	accuracy_test: 0.8244
[server]	loss_train: 0.1057	loss_val: 0.5096	loss_test: 0.5914	accuracy_train: 0.9746	accuracy_val: 0.8259	accuracy_test: 0.7920
[server]	loss_train: 0.1454	loss_val: 0.6206	loss_test: 0.5724	accuracy_train: 0.9693	accuracy_val: 0.8263	accuracy_test: 0.8155
[server]	loss_train: 0.1000	loss_val: 0.4862	loss_test: 0.4426	accuracy_train: 0.9778	accuracy_val: 0.8440	accuracy_test: 0.8582
[server]	loss_train: 0.1378	loss_val: 0.4762	loss_test: 0.4085	accuracy_train: 0.9760	accuracy_val: 0.8789	accuracy_test: 0.8774
[server]	loss_train: 0.1246	loss_val: 0.5496	loss_test: 0.5505	accuracy_train: 0.9843	accuracy_val: 0.8168	accuracy_test: 0.8220
[server]	loss_train: 0.1068	loss_val: 0.4132	loss_test: 0.5078	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.1111	loss_val: 0.4488	loss_test: 0.4514	accuracy_train: 0.9774	accuracy_val: 0.8525	accuracy_test: 0.8434
[server]	loss_train: 0.2014	loss_val: 0.5147	loss_test: 0.4550	accuracy_train: 0.9600	accuracy_val: 0.8301	accuracy_test: 0.8511
[server]	loss_train: 0.1001	loss_val: 0.4796	loss_test: 0.4832	accuracy_train: 1.0000	accuracy_val: 0.8622	accuracy_test: 0.8392
[server]	loss_train: 0.1448	loss_val: 0.6223	loss_test: 0.4433	accuracy_train: 0.9771	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0974	loss_val: 0.5398	loss_test: 0.4578	accuracy_train: 1.0000	accuracy_val: 0.8431	accuracy_test: 0.8370
[server]	loss_train: 0.1434	loss_val: 0.4949	loss_test: 0.6294	accuracy_train: 0.9701	accuracy_val: 0.8159	accuracy_test: 0.7964
[server]	loss_train: 0.2096	loss_val: 0.4751	loss_test: 0.5036	accuracy_train: 0.9338	accuracy_val: 0.8393	accuracy_test: 0.8386
[server]	loss_train: 0.1451	loss_val: 0.5244	loss_test: 0.4094	accuracy_train: 0.9728	accuracy_val: 0.8591	accuracy_test: 0.8867
[server]	loss_train: 0.1161	loss_val: 0.3135	loss_test: 0.3482	accuracy_train: 0.9786	accuracy_val: 0.8893	accuracy_test: 0.8664
[server]	loss_train: 0.1465	loss_val: 0.5145	loss_test: 0.5374	accuracy_train: 0.9706	accuracy_val: 0.8357	accuracy_test: 0.8063
[server]	loss_train: 0.1120	loss_val: 0.4429	loss_test: 0.4740	accuracy_train: 0.9820	accuracy_val: 0.8652	accuracy_test: 0.8376
[server]	loss_train: 0.0796	loss_val: 0.3942	loss_test: 0.4057	accuracy_train: 0.9858	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.1196	loss_val: 0.5004	loss_test: 0.4631	accuracy_train: 0.9868	accuracy_val: 0.8548	accuracy_test: 0.8540
curr_round: 61	curr_val_accuracy: 0.8459	curr_test_accuracy: 0.8415
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 62		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.2039	loss_val: 0.6243	loss_test: 0.5510	accuracy_train: 0.9403	accuracy_val: 0.7927	accuracy_test: 0.8244
[server]	loss_train: 0.1026	loss_val: 0.5106	loss_test: 0.5924	accuracy_train: 0.9746	accuracy_val: 0.8259	accuracy_test: 0.7960
[server]	loss_train: 0.1422	loss_val: 0.6229	loss_test: 0.5740	accuracy_train: 0.9693	accuracy_val: 0.8234	accuracy_test: 0.8155
[server]	loss_train: 0.0975	loss_val: 0.4877	loss_test: 0.4432	accuracy_train: 0.9778	accuracy_val: 0.8404	accuracy_test: 0.8617
[server]	loss_train: 0.1346	loss_val: 0.4764	loss_test: 0.4091	accuracy_train: 0.9680	accuracy_val: 0.8711	accuracy_test: 0.8774
[server]	loss_train: 0.1211	loss_val: 0.5503	loss_test: 0.5518	accuracy_train: 0.9843	accuracy_val: 0.8206	accuracy_test: 0.8220
[server]	loss_train: 0.1045	loss_val: 0.4131	loss_test: 0.5097	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8388
[server]	loss_train: 0.1078	loss_val: 0.4493	loss_test: 0.4523	accuracy_train: 0.9774	accuracy_val: 0.8525	accuracy_test: 0.8470
[server]	loss_train: 0.1986	loss_val: 0.5165	loss_test: 0.4568	accuracy_train: 0.9600	accuracy_val: 0.8301	accuracy_test: 0.8511
[server]	loss_train: 0.0978	loss_val: 0.4816	loss_test: 0.4856	accuracy_train: 1.0000	accuracy_val: 0.8622	accuracy_test: 0.8392
[server]	loss_train: 0.1411	loss_val: 0.6236	loss_test: 0.4437	accuracy_train: 0.9771	accuracy_val: 0.8284	accuracy_test: 0.8529
[server]	loss_train: 0.0943	loss_val: 0.5411	loss_test: 0.4572	accuracy_train: 1.0000	accuracy_val: 0.8431	accuracy_test: 0.8370
[server]	loss_train: 0.1401	loss_val: 0.4957	loss_test: 0.6326	accuracy_train: 0.9776	accuracy_val: 0.8195	accuracy_test: 0.7929
[server]	loss_train: 0.2046	loss_val: 0.4746	loss_test: 0.5047	accuracy_train: 0.9338	accuracy_val: 0.8357	accuracy_test: 0.8386
[server]	loss_train: 0.1420	loss_val: 0.5255	loss_test: 0.4100	accuracy_train: 0.9728	accuracy_val: 0.8523	accuracy_test: 0.8833
[server]	loss_train: 0.1132	loss_val: 0.3123	loss_test: 0.3466	accuracy_train: 0.9786	accuracy_val: 0.8893	accuracy_test: 0.8664
[server]	loss_train: 0.1440	loss_val: 0.5160	loss_test: 0.5397	accuracy_train: 0.9706	accuracy_val: 0.8357	accuracy_test: 0.8063
[server]	loss_train: 0.1077	loss_val: 0.4430	loss_test: 0.4742	accuracy_train: 0.9820	accuracy_val: 0.8652	accuracy_test: 0.8376
[server]	loss_train: 0.0772	loss_val: 0.3951	loss_test: 0.4059	accuracy_train: 0.9858	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.1162	loss_val: 0.5014	loss_test: 0.4640	accuracy_train: 0.9868	accuracy_val: 0.8548	accuracy_test: 0.8540
curr_round: 62	curr_val_accuracy: 0.8450	curr_test_accuracy: 0.8417
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 63		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1980	loss_val: 0.6242	loss_test: 0.5510	accuracy_train: 0.9403	accuracy_val: 0.7927	accuracy_test: 0.8244
[server]	loss_train: 0.0996	loss_val: 0.5108	loss_test: 0.5931	accuracy_train: 0.9746	accuracy_val: 0.8259	accuracy_test: 0.7920
[server]	loss_train: 0.1384	loss_val: 0.6230	loss_test: 0.5734	accuracy_train: 0.9755	accuracy_val: 0.8263	accuracy_test: 0.8155
[server]	loss_train: 0.0944	loss_val: 0.4878	loss_test: 0.4422	accuracy_train: 0.9778	accuracy_val: 0.8404	accuracy_test: 0.8582
[server]	loss_train: 0.1306	loss_val: 0.4751	loss_test: 0.4091	accuracy_train: 0.9760	accuracy_val: 0.8750	accuracy_test: 0.8774
[server]	loss_train: 0.1174	loss_val: 0.5495	loss_test: 0.5507	accuracy_train: 0.9843	accuracy_val: 0.8168	accuracy_test: 0.8220
[server]	loss_train: 0.1016	loss_val: 0.4115	loss_test: 0.5092	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8388
[server]	loss_train: 0.1052	loss_val: 0.4491	loss_test: 0.4512	accuracy_train: 0.9774	accuracy_val: 0.8525	accuracy_test: 0.8505
[server]	loss_train: 0.1951	loss_val: 0.5157	loss_test: 0.4551	accuracy_train: 0.9600	accuracy_val: 0.8301	accuracy_test: 0.8511
[server]	loss_train: 0.0949	loss_val: 0.4809	loss_test: 0.4847	accuracy_train: 1.0000	accuracy_val: 0.8587	accuracy_test: 0.8392
[server]	loss_train: 0.1363	loss_val: 0.6241	loss_test: 0.4433	accuracy_train: 0.9771	accuracy_val: 0.8284	accuracy_test: 0.8529
[server]	loss_train: 0.0916	loss_val: 0.5402	loss_test: 0.4568	accuracy_train: 1.0000	accuracy_val: 0.8431	accuracy_test: 0.8370
[server]	loss_train: 0.1359	loss_val: 0.4946	loss_test: 0.6315	accuracy_train: 0.9776	accuracy_val: 0.8195	accuracy_test: 0.7929
[server]	loss_train: 0.2018	loss_val: 0.4764	loss_test: 0.5041	accuracy_train: 0.9338	accuracy_val: 0.8393	accuracy_test: 0.8386
[server]	loss_train: 0.1388	loss_val: 0.5261	loss_test: 0.4098	accuracy_train: 0.9728	accuracy_val: 0.8591	accuracy_test: 0.8867
[server]	loss_train: 0.1112	loss_val: 0.3126	loss_test: 0.3476	accuracy_train: 0.9786	accuracy_val: 0.8893	accuracy_test: 0.8664
[server]	loss_train: 0.1397	loss_val: 0.5152	loss_test: 0.5393	accuracy_train: 0.9706	accuracy_val: 0.8357	accuracy_test: 0.8063
[server]	loss_train: 0.1036	loss_val: 0.4419	loss_test: 0.4731	accuracy_train: 0.9820	accuracy_val: 0.8652	accuracy_test: 0.8419
[server]	loss_train: 0.0751	loss_val: 0.3957	loss_test: 0.4075	accuracy_train: 0.9858	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.1128	loss_val: 0.5027	loss_test: 0.4636	accuracy_train: 0.9868	accuracy_val: 0.8548	accuracy_test: 0.8603
curr_round: 63	curr_val_accuracy: 0.8456	curr_test_accuracy: 0.8422
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 64		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1939	loss_val: 0.6255	loss_test: 0.5528	accuracy_train: 0.9403	accuracy_val: 0.7927	accuracy_test: 0.8244
[server]	loss_train: 0.0969	loss_val: 0.5117	loss_test: 0.5939	accuracy_train: 0.9746	accuracy_val: 0.8259	accuracy_test: 0.7960
[server]	loss_train: 0.1356	loss_val: 0.6260	loss_test: 0.5753	accuracy_train: 0.9755	accuracy_val: 0.8234	accuracy_test: 0.8155
[server]	loss_train: 0.0922	loss_val: 0.4894	loss_test: 0.4430	accuracy_train: 0.9778	accuracy_val: 0.8440	accuracy_test: 0.8652
[server]	loss_train: 0.1278	loss_val: 0.4756	loss_test: 0.4098	accuracy_train: 0.9760	accuracy_val: 0.8711	accuracy_test: 0.8774
[server]	loss_train: 0.1141	loss_val: 0.5504	loss_test: 0.5522	accuracy_train: 0.9843	accuracy_val: 0.8206	accuracy_test: 0.8258
[server]	loss_train: 0.0998	loss_val: 0.4120	loss_test: 0.5115	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8388
[server]	loss_train: 0.1021	loss_val: 0.4495	loss_test: 0.4523	accuracy_train: 0.9774	accuracy_val: 0.8489	accuracy_test: 0.8505
[server]	loss_train: 0.1928	loss_val: 0.5178	loss_test: 0.4573	accuracy_train: 0.9600	accuracy_val: 0.8301	accuracy_test: 0.8473
[server]	loss_train: 0.0929	loss_val: 0.4831	loss_test: 0.4873	accuracy_train: 1.0000	accuracy_val: 0.8622	accuracy_test: 0.8392
[server]	loss_train: 0.1329	loss_val: 0.6255	loss_test: 0.4437	accuracy_train: 0.9771	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0887	loss_val: 0.5415	loss_test: 0.4563	accuracy_train: 1.0000	accuracy_val: 0.8431	accuracy_test: 0.8370
[server]	loss_train: 0.1330	loss_val: 0.4957	loss_test: 0.6350	accuracy_train: 0.9776	accuracy_val: 0.8195	accuracy_test: 0.7929
[server]	loss_train: 0.1969	loss_val: 0.4759	loss_test: 0.5055	accuracy_train: 0.9412	accuracy_val: 0.8357	accuracy_test: 0.8386
[server]	loss_train: 0.1359	loss_val: 0.5277	loss_test: 0.4108	accuracy_train: 0.9728	accuracy_val: 0.8490	accuracy_test: 0.8833
[server]	loss_train: 0.1084	loss_val: 0.3113	loss_test: 0.3459	accuracy_train: 0.9857	accuracy_val: 0.8893	accuracy_test: 0.8664
[server]	loss_train: 0.1376	loss_val: 0.5169	loss_test: 0.5417	accuracy_train: 0.9706	accuracy_val: 0.8357	accuracy_test: 0.8063
[server]	loss_train: 0.0999	loss_val: 0.4423	loss_test: 0.4735	accuracy_train: 1.0000	accuracy_val: 0.8652	accuracy_test: 0.8419
[server]	loss_train: 0.0728	loss_val: 0.3966	loss_test: 0.4077	accuracy_train: 0.9858	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.1098	loss_val: 0.5036	loss_test: 0.4646	accuracy_train: 0.9868	accuracy_val: 0.8548	accuracy_test: 0.8603
curr_round: 64	curr_val_accuracy: 0.8446	curr_test_accuracy: 0.8424
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 65		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1882	loss_val: 0.6253	loss_test: 0.5528	accuracy_train: 0.9403	accuracy_val: 0.7964	accuracy_test: 0.8244
[server]	loss_train: 0.0941	loss_val: 0.5120	loss_test: 0.5950	accuracy_train: 0.9746	accuracy_val: 0.8259	accuracy_test: 0.7920
[server]	loss_train: 0.1319	loss_val: 0.6258	loss_test: 0.5746	accuracy_train: 0.9816	accuracy_val: 0.8234	accuracy_test: 0.8155
[server]	loss_train: 0.0892	loss_val: 0.4897	loss_test: 0.4421	accuracy_train: 0.9778	accuracy_val: 0.8404	accuracy_test: 0.8617
[server]	loss_train: 0.1240	loss_val: 0.4744	loss_test: 0.4098	accuracy_train: 0.9760	accuracy_val: 0.8672	accuracy_test: 0.8812
[server]	loss_train: 0.1108	loss_val: 0.5497	loss_test: 0.5514	accuracy_train: 0.9843	accuracy_val: 0.8168	accuracy_test: 0.8258
[server]	loss_train: 0.0969	loss_val: 0.4102	loss_test: 0.5109	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8388
[server]	loss_train: 0.0998	loss_val: 0.4496	loss_test: 0.4515	accuracy_train: 0.9774	accuracy_val: 0.8489	accuracy_test: 0.8505
[server]	loss_train: 0.1894	loss_val: 0.5170	loss_test: 0.4555	accuracy_train: 0.9600	accuracy_val: 0.8263	accuracy_test: 0.8473
[server]	loss_train: 0.0901	loss_val: 0.4824	loss_test: 0.4864	accuracy_train: 1.0000	accuracy_val: 0.8587	accuracy_test: 0.8392
[server]	loss_train: 0.1285	loss_val: 0.6262	loss_test: 0.4436	accuracy_train: 0.9771	accuracy_val: 0.8284	accuracy_test: 0.8529
[server]	loss_train: 0.0864	loss_val: 0.5409	loss_test: 0.4561	accuracy_train: 1.0000	accuracy_val: 0.8467	accuracy_test: 0.8370
[server]	loss_train: 0.1291	loss_val: 0.4948	loss_test: 0.6339	accuracy_train: 0.9776	accuracy_val: 0.8159	accuracy_test: 0.7964
[server]	loss_train: 0.1946	loss_val: 0.4779	loss_test: 0.5049	accuracy_train: 0.9412	accuracy_val: 0.8357	accuracy_test: 0.8386
[server]	loss_train: 0.1329	loss_val: 0.5281	loss_test: 0.4104	accuracy_train: 0.9728	accuracy_val: 0.8557	accuracy_test: 0.8867
[server]	loss_train: 0.1067	loss_val: 0.3118	loss_test: 0.3472	accuracy_train: 0.9857	accuracy_val: 0.8893	accuracy_test: 0.8664
[server]	loss_train: 0.1333	loss_val: 0.5163	loss_test: 0.5414	accuracy_train: 0.9706	accuracy_val: 0.8357	accuracy_test: 0.8063
[server]	loss_train: 0.0962	loss_val: 0.4413	loss_test: 0.4725	accuracy_train: 1.0000	accuracy_val: 0.8696	accuracy_test: 0.8419
[server]	loss_train: 0.0711	loss_val: 0.3974	loss_test: 0.4094	accuracy_train: 0.9929	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.1066	loss_val: 0.5051	loss_test: 0.4643	accuracy_train: 0.9868	accuracy_val: 0.8548	accuracy_test: 0.8603
curr_round: 65	curr_val_accuracy: 0.8445	curr_test_accuracy: 0.8428
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 66		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1845	loss_val: 0.6266	loss_test: 0.5546	accuracy_train: 0.9403	accuracy_val: 0.7964	accuracy_test: 0.8244
[server]	loss_train: 0.0916	loss_val: 0.5130	loss_test: 0.5957	accuracy_train: 0.9831	accuracy_val: 0.8259	accuracy_test: 0.7920
[server]	loss_train: 0.1294	loss_val: 0.6287	loss_test: 0.5765	accuracy_train: 0.9816	accuracy_val: 0.8234	accuracy_test: 0.8155
[server]	loss_train: 0.0871	loss_val: 0.4912	loss_test: 0.4428	accuracy_train: 0.9778	accuracy_val: 0.8440	accuracy_test: 0.8617
[server]	loss_train: 0.1214	loss_val: 0.4748	loss_test: 0.4105	accuracy_train: 0.9760	accuracy_val: 0.8672	accuracy_test: 0.8774
[server]	loss_train: 0.1077	loss_val: 0.5505	loss_test: 0.5528	accuracy_train: 0.9843	accuracy_val: 0.8168	accuracy_test: 0.8258
[server]	loss_train: 0.0953	loss_val: 0.4107	loss_test: 0.5131	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8388
[server]	loss_train: 0.0969	loss_val: 0.4500	loss_test: 0.4524	accuracy_train: 0.9774	accuracy_val: 0.8489	accuracy_test: 0.8505
[server]	loss_train: 0.1870	loss_val: 0.5190	loss_test: 0.4577	accuracy_train: 0.9600	accuracy_val: 0.8263	accuracy_test: 0.8473
[server]	loss_train: 0.0884	loss_val: 0.4846	loss_test: 0.4888	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8392
[server]	loss_train: 0.1253	loss_val: 0.6274	loss_test: 0.4439	accuracy_train: 0.9771	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0837	loss_val: 0.5421	loss_test: 0.4556	accuracy_train: 1.0000	accuracy_val: 0.8467	accuracy_test: 0.8370
[server]	loss_train: 0.1264	loss_val: 0.4957	loss_test: 0.6374	accuracy_train: 0.9776	accuracy_val: 0.8159	accuracy_test: 0.7964
[server]	loss_train: 0.1899	loss_val: 0.4773	loss_test: 0.5061	accuracy_train: 0.9412	accuracy_val: 0.8357	accuracy_test: 0.8386
[server]	loss_train: 0.1303	loss_val: 0.5296	loss_test: 0.4115	accuracy_train: 0.9796	accuracy_val: 0.8523	accuracy_test: 0.8833
[server]	loss_train: 0.1040	loss_val: 0.3106	loss_test: 0.3456	accuracy_train: 0.9857	accuracy_val: 0.8893	accuracy_test: 0.8664
[server]	loss_train: 0.1315	loss_val: 0.5179	loss_test: 0.5439	accuracy_train: 0.9706	accuracy_val: 0.8357	accuracy_test: 0.8063
[server]	loss_train: 0.0930	loss_val: 0.4417	loss_test: 0.4729	accuracy_train: 1.0000	accuracy_val: 0.8696	accuracy_test: 0.8419
[server]	loss_train: 0.0689	loss_val: 0.3982	loss_test: 0.4096	accuracy_train: 0.9929	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.1039	loss_val: 0.5061	loss_test: 0.4654	accuracy_train: 0.9868	accuracy_val: 0.8516	accuracy_test: 0.8603
curr_round: 66	curr_val_accuracy: 0.8441	curr_test_accuracy: 0.8422
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 67		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1790	loss_val: 0.6266	loss_test: 0.5547	accuracy_train: 0.9403	accuracy_val: 0.7964	accuracy_test: 0.8244
[server]	loss_train: 0.0890	loss_val: 0.5135	loss_test: 0.5970	accuracy_train: 0.9831	accuracy_val: 0.8259	accuracy_test: 0.7920
[server]	loss_train: 0.1260	loss_val: 0.6286	loss_test: 0.5761	accuracy_train: 0.9816	accuracy_val: 0.8263	accuracy_test: 0.8155
[server]	loss_train: 0.0844	loss_val: 0.4917	loss_test: 0.4422	accuracy_train: 0.9778	accuracy_val: 0.8404	accuracy_test: 0.8582
[server]	loss_train: 0.1179	loss_val: 0.4740	loss_test: 0.4107	accuracy_train: 0.9840	accuracy_val: 0.8711	accuracy_test: 0.8774
[server]	loss_train: 0.1046	loss_val: 0.5502	loss_test: 0.5523	accuracy_train: 0.9843	accuracy_val: 0.8206	accuracy_test: 0.8258
[server]	loss_train: 0.0927	loss_val: 0.4091	loss_test: 0.5127	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8347
[server]	loss_train: 0.0948	loss_val: 0.4503	loss_test: 0.4520	accuracy_train: 0.9774	accuracy_val: 0.8489	accuracy_test: 0.8505
[server]	loss_train: 0.1839	loss_val: 0.5184	loss_test: 0.4561	accuracy_train: 0.9600	accuracy_val: 0.8263	accuracy_test: 0.8435
[server]	loss_train: 0.0858	loss_val: 0.4842	loss_test: 0.4883	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8392
[server]	loss_train: 0.1213	loss_val: 0.6284	loss_test: 0.4441	accuracy_train: 0.9771	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0815	loss_val: 0.5418	loss_test: 0.4555	accuracy_train: 1.0000	accuracy_val: 0.8467	accuracy_test: 0.8370
[server]	loss_train: 0.1229	loss_val: 0.4951	loss_test: 0.6365	accuracy_train: 0.9776	accuracy_val: 0.8159	accuracy_test: 0.7964
[server]	loss_train: 0.1878	loss_val: 0.4794	loss_test: 0.5057	accuracy_train: 0.9412	accuracy_val: 0.8357	accuracy_test: 0.8386
[server]	loss_train: 0.1274	loss_val: 0.5300	loss_test: 0.4112	accuracy_train: 0.9796	accuracy_val: 0.8557	accuracy_test: 0.8900
[server]	loss_train: 0.1024	loss_val: 0.3112	loss_test: 0.3469	accuracy_train: 0.9857	accuracy_val: 0.8893	accuracy_test: 0.8664
[server]	loss_train: 0.1275	loss_val: 0.5175	loss_test: 0.5438	accuracy_train: 0.9779	accuracy_val: 0.8357	accuracy_test: 0.8063
[server]	loss_train: 0.0897	loss_val: 0.4409	loss_test: 0.4721	accuracy_train: 1.0000	accuracy_val: 0.8696	accuracy_test: 0.8419
[server]	loss_train: 0.0673	loss_val: 0.3991	loss_test: 0.4113	accuracy_train: 0.9929	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.1010	loss_val: 0.5074	loss_test: 0.4652	accuracy_train: 0.9868	accuracy_val: 0.8484	accuracy_test: 0.8571
curr_round: 67	curr_val_accuracy: 0.8445	curr_test_accuracy: 0.8419
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 68		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1756	loss_val: 0.6279	loss_test: 0.5566	accuracy_train: 0.9478	accuracy_val: 0.7964	accuracy_test: 0.8244
[server]	loss_train: 0.0867	loss_val: 0.5144	loss_test: 0.5977	accuracy_train: 0.9831	accuracy_val: 0.8259	accuracy_test: 0.7880
[server]	loss_train: 0.1236	loss_val: 0.6313	loss_test: 0.5777	accuracy_train: 0.9816	accuracy_val: 0.8234	accuracy_test: 0.8155
[server]	loss_train: 0.0825	loss_val: 0.4931	loss_test: 0.4429	accuracy_train: 0.9778	accuracy_val: 0.8440	accuracy_test: 0.8582
[server]	loss_train: 0.1154	loss_val: 0.4742	loss_test: 0.4114	accuracy_train: 0.9840	accuracy_val: 0.8750	accuracy_test: 0.8774
[server]	loss_train: 0.1018	loss_val: 0.5508	loss_test: 0.5535	accuracy_train: 0.9843	accuracy_val: 0.8168	accuracy_test: 0.8258
[server]	loss_train: 0.0911	loss_val: 0.4097	loss_test: 0.5147	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8388
[server]	loss_train: 0.0921	loss_val: 0.4505	loss_test: 0.4526	accuracy_train: 0.9774	accuracy_val: 0.8489	accuracy_test: 0.8505
[server]	loss_train: 0.1816	loss_val: 0.5202	loss_test: 0.4581	accuracy_train: 0.9600	accuracy_val: 0.8263	accuracy_test: 0.8435
[server]	loss_train: 0.0842	loss_val: 0.4861	loss_test: 0.4904	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8392
[server]	loss_train: 0.1183	loss_val: 0.6295	loss_test: 0.4444	accuracy_train: 0.9771	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0791	loss_val: 0.5429	loss_test: 0.4551	accuracy_train: 1.0000	accuracy_val: 0.8467	accuracy_test: 0.8370
[server]	loss_train: 0.1203	loss_val: 0.4960	loss_test: 0.6395	accuracy_train: 0.9776	accuracy_val: 0.8123	accuracy_test: 0.8000
[server]	loss_train: 0.1833	loss_val: 0.4792	loss_test: 0.5069	accuracy_train: 0.9412	accuracy_val: 0.8357	accuracy_test: 0.8386
[server]	loss_train: 0.1249	loss_val: 0.5317	loss_test: 0.4123	accuracy_train: 0.9796	accuracy_val: 0.8523	accuracy_test: 0.8867
[server]	loss_train: 0.0999	loss_val: 0.3102	loss_test: 0.3456	accuracy_train: 0.9857	accuracy_val: 0.8893	accuracy_test: 0.8664
[server]	loss_train: 0.1256	loss_val: 0.5190	loss_test: 0.5459	accuracy_train: 0.9853	accuracy_val: 0.8357	accuracy_test: 0.8063
[server]	loss_train: 0.0868	loss_val: 0.4412	loss_test: 0.4725	accuracy_train: 1.0000	accuracy_val: 0.8652	accuracy_test: 0.8419
[server]	loss_train: 0.0654	loss_val: 0.3998	loss_test: 0.4117	accuracy_train: 0.9929	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0984	loss_val: 0.5086	loss_test: 0.4662	accuracy_train: 0.9868	accuracy_val: 0.8484	accuracy_test: 0.8571
curr_round: 68	curr_val_accuracy: 0.8439	curr_test_accuracy: 0.8419
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 69		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1706	loss_val: 0.6280	loss_test: 0.5568	accuracy_train: 0.9552	accuracy_val: 0.7964	accuracy_test: 0.8280
[server]	loss_train: 0.0843	loss_val: 0.5150	loss_test: 0.5992	accuracy_train: 0.9831	accuracy_val: 0.8259	accuracy_test: 0.7880
[server]	loss_train: 0.1204	loss_val: 0.6317	loss_test: 0.5778	accuracy_train: 0.9816	accuracy_val: 0.8234	accuracy_test: 0.8185
[server]	loss_train: 0.0802	loss_val: 0.4939	loss_test: 0.4424	accuracy_train: 0.9778	accuracy_val: 0.8404	accuracy_test: 0.8617
[server]	loss_train: 0.1122	loss_val: 0.4739	loss_test: 0.4117	accuracy_train: 0.9920	accuracy_val: 0.8750	accuracy_test: 0.8736
[server]	loss_train: 0.0989	loss_val: 0.5508	loss_test: 0.5536	accuracy_train: 0.9921	accuracy_val: 0.8168	accuracy_test: 0.8258
[server]	loss_train: 0.0888	loss_val: 0.4083	loss_test: 0.5148	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8388
[server]	loss_train: 0.0901	loss_val: 0.4512	loss_test: 0.4528	accuracy_train: 0.9774	accuracy_val: 0.8489	accuracy_test: 0.8505
[server]	loss_train: 0.1787	loss_val: 0.5201	loss_test: 0.4571	accuracy_train: 0.9600	accuracy_val: 0.8263	accuracy_test: 0.8435
[server]	loss_train: 0.0818	loss_val: 0.4860	loss_test: 0.4906	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8427
[server]	loss_train: 0.1148	loss_val: 0.6308	loss_test: 0.4448	accuracy_train: 0.9771	accuracy_val: 0.8284	accuracy_test: 0.8529
[server]	loss_train: 0.0770	loss_val: 0.5431	loss_test: 0.4551	accuracy_train: 1.0000	accuracy_val: 0.8504	accuracy_test: 0.8370
[server]	loss_train: 0.1172	loss_val: 0.4957	loss_test: 0.6394	accuracy_train: 0.9776	accuracy_val: 0.8231	accuracy_test: 0.8000
[server]	loss_train: 0.1813	loss_val: 0.4810	loss_test: 0.5068	accuracy_train: 0.9485	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.1222	loss_val: 0.5321	loss_test: 0.4120	accuracy_train: 0.9796	accuracy_val: 0.8557	accuracy_test: 0.8900
[server]	loss_train: 0.0985	loss_val: 0.3106	loss_test: 0.3466	accuracy_train: 0.9857	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.1222	loss_val: 0.5191	loss_test: 0.5465	accuracy_train: 0.9853	accuracy_val: 0.8357	accuracy_test: 0.8063
[server]	loss_train: 0.0839	loss_val: 0.4409	loss_test: 0.4719	accuracy_train: 1.0000	accuracy_val: 0.8652	accuracy_test: 0.8419
[server]	loss_train: 0.0639	loss_val: 0.4010	loss_test: 0.4133	accuracy_train: 0.9929	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0957	loss_val: 0.5099	loss_test: 0.4663	accuracy_train: 0.9868	accuracy_val: 0.8484	accuracy_test: 0.8571
curr_round: 69	curr_val_accuracy: 0.8443	curr_test_accuracy: 0.8426
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 70		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1673	loss_val: 0.6292	loss_test: 0.5586	accuracy_train: 0.9552	accuracy_val: 0.8000	accuracy_test: 0.8280
[server]	loss_train: 0.0822	loss_val: 0.5158	loss_test: 0.5997	accuracy_train: 0.9831	accuracy_val: 0.8259	accuracy_test: 0.7880
[server]	loss_train: 0.1182	loss_val: 0.6338	loss_test: 0.5790	accuracy_train: 0.9816	accuracy_val: 0.8234	accuracy_test: 0.8214
[server]	loss_train: 0.0782	loss_val: 0.4950	loss_test: 0.4429	accuracy_train: 0.9778	accuracy_val: 0.8440	accuracy_test: 0.8652
[server]	loss_train: 0.1099	loss_val: 0.4738	loss_test: 0.4124	accuracy_train: 0.9920	accuracy_val: 0.8750	accuracy_test: 0.8774
[server]	loss_train: 0.0963	loss_val: 0.5512	loss_test: 0.5543	accuracy_train: 0.9921	accuracy_val: 0.8168	accuracy_test: 0.8258
[server]	loss_train: 0.0872	loss_val: 0.4087	loss_test: 0.5163	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8388
[server]	loss_train: 0.0877	loss_val: 0.4511	loss_test: 0.4529	accuracy_train: 0.9774	accuracy_val: 0.8489	accuracy_test: 0.8505
[server]	loss_train: 0.1762	loss_val: 0.5215	loss_test: 0.4585	accuracy_train: 0.9600	accuracy_val: 0.8263	accuracy_test: 0.8435
[server]	loss_train: 0.0802	loss_val: 0.4875	loss_test: 0.4919	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8427
[server]	loss_train: 0.1118	loss_val: 0.6316	loss_test: 0.4449	accuracy_train: 0.9771	accuracy_val: 0.8284	accuracy_test: 0.8529
[server]	loss_train: 0.0749	loss_val: 0.5437	loss_test: 0.4546	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8370
[server]	loss_train: 0.1147	loss_val: 0.4962	loss_test: 0.6416	accuracy_train: 0.9776	accuracy_val: 0.8195	accuracy_test: 0.8000
[server]	loss_train: 0.1773	loss_val: 0.4811	loss_test: 0.5076	accuracy_train: 0.9559	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.1199	loss_val: 0.5338	loss_test: 0.4131	accuracy_train: 0.9796	accuracy_val: 0.8557	accuracy_test: 0.8833
[server]	loss_train: 0.0961	loss_val: 0.3099	loss_test: 0.3457	accuracy_train: 0.9857	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.1201	loss_val: 0.5201	loss_test: 0.5480	accuracy_train: 0.9853	accuracy_val: 0.8357	accuracy_test: 0.8063
[server]	loss_train: 0.0812	loss_val: 0.4409	loss_test: 0.4721	accuracy_train: 1.0000	accuracy_val: 0.8652	accuracy_test: 0.8419
[server]	loss_train: 0.0621	loss_val: 0.4015	loss_test: 0.4138	accuracy_train: 0.9929	accuracy_val: 0.8920	accuracy_test: 0.8862
[server]	loss_train: 0.0934	loss_val: 0.5111	loss_test: 0.4671	accuracy_train: 0.9868	accuracy_val: 0.8484	accuracy_test: 0.8540
curr_round: 70	curr_val_accuracy: 0.8448	curr_test_accuracy: 0.8426
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 71		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1627	loss_val: 0.6295	loss_test: 0.5591	accuracy_train: 0.9552	accuracy_val: 0.8000	accuracy_test: 0.8280
[server]	loss_train: 0.0800	loss_val: 0.5166	loss_test: 0.6015	accuracy_train: 0.9915	accuracy_val: 0.8259	accuracy_test: 0.7880
[server]	loss_train: 0.1153	loss_val: 0.6345	loss_test: 0.5796	accuracy_train: 0.9816	accuracy_val: 0.8234	accuracy_test: 0.8214
[server]	loss_train: 0.0761	loss_val: 0.4962	loss_test: 0.4429	accuracy_train: 0.9778	accuracy_val: 0.8404	accuracy_test: 0.8652
[server]	loss_train: 0.1069	loss_val: 0.4738	loss_test: 0.4129	accuracy_train: 0.9920	accuracy_val: 0.8750	accuracy_test: 0.8736
[server]	loss_train: 0.0936	loss_val: 0.5517	loss_test: 0.5550	accuracy_train: 0.9921	accuracy_val: 0.8168	accuracy_test: 0.8258
[server]	loss_train: 0.0852	loss_val: 0.4077	loss_test: 0.5169	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8388
[server]	loss_train: 0.0858	loss_val: 0.4521	loss_test: 0.4537	accuracy_train: 0.9774	accuracy_val: 0.8489	accuracy_test: 0.8505
[server]	loss_train: 0.1737	loss_val: 0.5220	loss_test: 0.4583	accuracy_train: 0.9600	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0780	loss_val: 0.4880	loss_test: 0.4928	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8427
[server]	loss_train: 0.1087	loss_val: 0.6332	loss_test: 0.4457	accuracy_train: 0.9847	accuracy_val: 0.8321	accuracy_test: 0.8529
[server]	loss_train: 0.0729	loss_val: 0.5445	loss_test: 0.4548	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8370
[server]	loss_train: 0.1119	loss_val: 0.4964	loss_test: 0.6423	accuracy_train: 0.9776	accuracy_val: 0.8231	accuracy_test: 0.7964
[server]	loss_train: 0.1751	loss_val: 0.4826	loss_test: 0.5080	accuracy_train: 0.9559	accuracy_val: 0.8286	accuracy_test: 0.8351
[server]	loss_train: 0.1173	loss_val: 0.5341	loss_test: 0.4130	accuracy_train: 0.9796	accuracy_val: 0.8591	accuracy_test: 0.8867
[server]	loss_train: 0.0947	loss_val: 0.3102	loss_test: 0.3465	accuracy_train: 0.9857	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.1171	loss_val: 0.5208	loss_test: 0.5491	accuracy_train: 0.9853	accuracy_val: 0.8321	accuracy_test: 0.8063
[server]	loss_train: 0.0787	loss_val: 0.4409	loss_test: 0.4719	accuracy_train: 1.0000	accuracy_val: 0.8696	accuracy_test: 0.8419
[server]	loss_train: 0.0607	loss_val: 0.4027	loss_test: 0.4152	accuracy_train: 0.9929	accuracy_val: 0.8920	accuracy_test: 0.8828
[server]	loss_train: 0.0910	loss_val: 0.5124	loss_test: 0.4675	accuracy_train: 0.9868	accuracy_val: 0.8484	accuracy_test: 0.8571
curr_round: 71	curr_val_accuracy: 0.8452	curr_test_accuracy: 0.8424
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 72		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1596	loss_val: 0.6309	loss_test: 0.5608	accuracy_train: 0.9552	accuracy_val: 0.8000	accuracy_test: 0.8280
[server]	loss_train: 0.0781	loss_val: 0.5175	loss_test: 0.6020	accuracy_train: 0.9915	accuracy_val: 0.8259	accuracy_test: 0.7880
[server]	loss_train: 0.1132	loss_val: 0.6368	loss_test: 0.5807	accuracy_train: 0.9877	accuracy_val: 0.8204	accuracy_test: 0.8214
[server]	loss_train: 0.0743	loss_val: 0.4972	loss_test: 0.4434	accuracy_train: 0.9926	accuracy_val: 0.8404	accuracy_test: 0.8652
[server]	loss_train: 0.1047	loss_val: 0.4737	loss_test: 0.4136	accuracy_train: 0.9920	accuracy_val: 0.8750	accuracy_test: 0.8736
[server]	loss_train: 0.0912	loss_val: 0.5521	loss_test: 0.5555	accuracy_train: 0.9921	accuracy_val: 0.8130	accuracy_test: 0.8258
[server]	loss_train: 0.0838	loss_val: 0.4082	loss_test: 0.5183	accuracy_train: 1.0000	accuracy_val: 0.8631	accuracy_test: 0.8388
[server]	loss_train: 0.0836	loss_val: 0.4520	loss_test: 0.4537	accuracy_train: 0.9774	accuracy_val: 0.8489	accuracy_test: 0.8470
[server]	loss_train: 0.1715	loss_val: 0.5232	loss_test: 0.4594	accuracy_train: 0.9600	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0766	loss_val: 0.4893	loss_test: 0.4940	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8427
[server]	loss_train: 0.1059	loss_val: 0.6340	loss_test: 0.4457	accuracy_train: 0.9847	accuracy_val: 0.8321	accuracy_test: 0.8529
[server]	loss_train: 0.0710	loss_val: 0.5448	loss_test: 0.4545	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8370
[server]	loss_train: 0.1096	loss_val: 0.4969	loss_test: 0.6442	accuracy_train: 0.9776	accuracy_val: 0.8231	accuracy_test: 0.7964
[server]	loss_train: 0.1716	loss_val: 0.4831	loss_test: 0.5087	accuracy_train: 0.9559	accuracy_val: 0.8250	accuracy_test: 0.8351
[server]	loss_train: 0.1152	loss_val: 0.5359	loss_test: 0.4141	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8833
[server]	loss_train: 0.0925	loss_val: 0.3097	loss_test: 0.3458	accuracy_train: 0.9857	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.1151	loss_val: 0.5216	loss_test: 0.5505	accuracy_train: 0.9853	accuracy_val: 0.8321	accuracy_test: 0.8028
[server]	loss_train: 0.0763	loss_val: 0.4408	loss_test: 0.4721	accuracy_train: 1.0000	accuracy_val: 0.8696	accuracy_test: 0.8419
[server]	loss_train: 0.0591	loss_val: 0.4032	loss_test: 0.4159	accuracy_train: 1.0000	accuracy_val: 0.8920	accuracy_test: 0.8828
[server]	loss_train: 0.0889	loss_val: 0.5136	loss_test: 0.4682	accuracy_train: 0.9868	accuracy_val: 0.8484	accuracy_test: 0.8603
curr_round: 72	curr_val_accuracy: 0.8447	curr_test_accuracy: 0.8421
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 73		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1553	loss_val: 0.6313	loss_test: 0.5614	accuracy_train: 0.9627	accuracy_val: 0.8000	accuracy_test: 0.8280
[server]	loss_train: 0.0761	loss_val: 0.5183	loss_test: 0.6037	accuracy_train: 1.0000	accuracy_val: 0.8219	accuracy_test: 0.7880
[server]	loss_train: 0.1105	loss_val: 0.6377	loss_test: 0.5814	accuracy_train: 0.9877	accuracy_val: 0.8204	accuracy_test: 0.8244
[server]	loss_train: 0.0724	loss_val: 0.4984	loss_test: 0.4433	accuracy_train: 1.0000	accuracy_val: 0.8404	accuracy_test: 0.8652
[server]	loss_train: 0.1021	loss_val: 0.4739	loss_test: 0.4142	accuracy_train: 0.9920	accuracy_val: 0.8750	accuracy_test: 0.8736
[server]	loss_train: 0.0888	loss_val: 0.5525	loss_test: 0.5563	accuracy_train: 0.9921	accuracy_val: 0.8130	accuracy_test: 0.8258
[server]	loss_train: 0.0819	loss_val: 0.4073	loss_test: 0.5191	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8430
[server]	loss_train: 0.0818	loss_val: 0.4531	loss_test: 0.4546	accuracy_train: 0.9850	accuracy_val: 0.8489	accuracy_test: 0.8470
[server]	loss_train: 0.1690	loss_val: 0.5238	loss_test: 0.4594	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8473
[server]	loss_train: 0.0746	loss_val: 0.4899	loss_test: 0.4950	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8462
[server]	loss_train: 0.1031	loss_val: 0.6356	loss_test: 0.4466	accuracy_train: 0.9847	accuracy_val: 0.8321	accuracy_test: 0.8529
[server]	loss_train: 0.0691	loss_val: 0.5458	loss_test: 0.4546	accuracy_train: 1.0000	accuracy_val: 0.8577	accuracy_test: 0.8370
[server]	loss_train: 0.1070	loss_val: 0.4971	loss_test: 0.6452	accuracy_train: 0.9776	accuracy_val: 0.8231	accuracy_test: 0.7964
[server]	loss_train: 0.1694	loss_val: 0.4845	loss_test: 0.5091	accuracy_train: 0.9559	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.1128	loss_val: 0.5363	loss_test: 0.4141	accuracy_train: 0.9796	accuracy_val: 0.8591	accuracy_test: 0.8867
[server]	loss_train: 0.0912	loss_val: 0.3098	loss_test: 0.3465	accuracy_train: 0.9857	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.1124	loss_val: 0.5225	loss_test: 0.5518	accuracy_train: 0.9853	accuracy_val: 0.8321	accuracy_test: 0.8028
[server]	loss_train: 0.0740	loss_val: 0.4411	loss_test: 0.4720	accuracy_train: 1.0000	accuracy_val: 0.8652	accuracy_test: 0.8419
[server]	loss_train: 0.0578	loss_val: 0.4045	loss_test: 0.4173	accuracy_train: 1.0000	accuracy_val: 0.8920	accuracy_test: 0.8828
[server]	loss_train: 0.0865	loss_val: 0.5149	loss_test: 0.4687	accuracy_train: 0.9868	accuracy_val: 0.8484	accuracy_test: 0.8571
curr_round: 73	curr_val_accuracy: 0.8448	curr_test_accuracy: 0.8428
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 74		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1523	loss_val: 0.6325	loss_test: 0.5631	accuracy_train: 0.9627	accuracy_val: 0.8000	accuracy_test: 0.8280
[server]	loss_train: 0.0743	loss_val: 0.5192	loss_test: 0.6044	accuracy_train: 1.0000	accuracy_val: 0.8219	accuracy_test: 0.7880
[server]	loss_train: 0.1086	loss_val: 0.6396	loss_test: 0.5825	accuracy_train: 0.9877	accuracy_val: 0.8204	accuracy_test: 0.8214
[server]	loss_train: 0.0707	loss_val: 0.4994	loss_test: 0.4439	accuracy_train: 1.0000	accuracy_val: 0.8404	accuracy_test: 0.8652
[server]	loss_train: 0.1000	loss_val: 0.4738	loss_test: 0.4149	accuracy_train: 0.9920	accuracy_val: 0.8750	accuracy_test: 0.8736
[server]	loss_train: 0.0865	loss_val: 0.5529	loss_test: 0.5569	accuracy_train: 0.9921	accuracy_val: 0.8130	accuracy_test: 0.8258
[server]	loss_train: 0.0805	loss_val: 0.4077	loss_test: 0.5204	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8430
[server]	loss_train: 0.0798	loss_val: 0.4530	loss_test: 0.4547	accuracy_train: 0.9925	accuracy_val: 0.8489	accuracy_test: 0.8470
[server]	loss_train: 0.1667	loss_val: 0.5249	loss_test: 0.4605	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8473
[server]	loss_train: 0.0733	loss_val: 0.4911	loss_test: 0.4960	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8462
[server]	loss_train: 0.1005	loss_val: 0.6364	loss_test: 0.4467	accuracy_train: 0.9847	accuracy_val: 0.8321	accuracy_test: 0.8493
[server]	loss_train: 0.0673	loss_val: 0.5462	loss_test: 0.4543	accuracy_train: 1.0000	accuracy_val: 0.8577	accuracy_test: 0.8406
[server]	loss_train: 0.1048	loss_val: 0.4976	loss_test: 0.6469	accuracy_train: 0.9776	accuracy_val: 0.8231	accuracy_test: 0.7964
[server]	loss_train: 0.1659	loss_val: 0.4850	loss_test: 0.5098	accuracy_train: 0.9559	accuracy_val: 0.8286	accuracy_test: 0.8351
[server]	loss_train: 0.1108	loss_val: 0.5379	loss_test: 0.4152	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8833
[server]	loss_train: 0.0892	loss_val: 0.3094	loss_test: 0.3460	accuracy_train: 0.9857	accuracy_val: 0.8858	accuracy_test: 0.8664
[server]	loss_train: 0.1105	loss_val: 0.5233	loss_test: 0.5531	accuracy_train: 0.9853	accuracy_val: 0.8321	accuracy_test: 0.8028
[server]	loss_train: 0.0718	loss_val: 0.4411	loss_test: 0.4721	accuracy_train: 1.0000	accuracy_val: 0.8696	accuracy_test: 0.8419
[server]	loss_train: 0.0564	loss_val: 0.4049	loss_test: 0.4180	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8828
[server]	loss_train: 0.0846	loss_val: 0.5162	loss_test: 0.4695	accuracy_train: 0.9868	accuracy_val: 0.8452	accuracy_test: 0.8571
curr_round: 74	curr_val_accuracy: 0.8446	curr_test_accuracy: 0.8424
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 75		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1483	loss_val: 0.6330	loss_test: 0.5639	accuracy_train: 0.9701	accuracy_val: 0.7964	accuracy_test: 0.8280
[server]	loss_train: 0.0724	loss_val: 0.5202	loss_test: 0.6063	accuracy_train: 1.0000	accuracy_val: 0.8219	accuracy_test: 0.7880
[server]	loss_train: 0.1061	loss_val: 0.6403	loss_test: 0.5832	accuracy_train: 0.9939	accuracy_val: 0.8234	accuracy_test: 0.8274
[server]	loss_train: 0.0690	loss_val: 0.5007	loss_test: 0.4441	accuracy_train: 1.0000	accuracy_val: 0.8404	accuracy_test: 0.8652
[server]	loss_train: 0.0975	loss_val: 0.4740	loss_test: 0.4156	accuracy_train: 0.9920	accuracy_val: 0.8750	accuracy_test: 0.8736
[server]	loss_train: 0.0843	loss_val: 0.5535	loss_test: 0.5578	accuracy_train: 0.9921	accuracy_val: 0.8168	accuracy_test: 0.8295
[server]	loss_train: 0.0788	loss_val: 0.4069	loss_test: 0.5212	accuracy_train: 1.0000	accuracy_val: 0.8672	accuracy_test: 0.8430
[server]	loss_train: 0.0781	loss_val: 0.4541	loss_test: 0.4556	accuracy_train: 0.9925	accuracy_val: 0.8489	accuracy_test: 0.8470
[server]	loss_train: 0.1644	loss_val: 0.5257	loss_test: 0.4606	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0714	loss_val: 0.4919	loss_test: 0.4970	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8462
[server]	loss_train: 0.0981	loss_val: 0.6382	loss_test: 0.4477	accuracy_train: 0.9847	accuracy_val: 0.8321	accuracy_test: 0.8493
[server]	loss_train: 0.0656	loss_val: 0.5472	loss_test: 0.4546	accuracy_train: 1.0000	accuracy_val: 0.8577	accuracy_test: 0.8370
[server]	loss_train: 0.1025	loss_val: 0.4981	loss_test: 0.6480	accuracy_train: 0.9776	accuracy_val: 0.8231	accuracy_test: 0.7964
[server]	loss_train: 0.1638	loss_val: 0.4865	loss_test: 0.5104	accuracy_train: 0.9559	accuracy_val: 0.8286	accuracy_test: 0.8351
[server]	loss_train: 0.1085	loss_val: 0.5384	loss_test: 0.4152	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8867
[server]	loss_train: 0.0879	loss_val: 0.3097	loss_test: 0.3468	accuracy_train: 0.9857	accuracy_val: 0.8858	accuracy_test: 0.8630
[server]	loss_train: 0.1079	loss_val: 0.5242	loss_test: 0.5544	accuracy_train: 0.9853	accuracy_val: 0.8321	accuracy_test: 0.8028
[server]	loss_train: 0.0697	loss_val: 0.4413	loss_test: 0.4721	accuracy_train: 1.0000	accuracy_val: 0.8696	accuracy_test: 0.8419
[server]	loss_train: 0.0552	loss_val: 0.4062	loss_test: 0.4194	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8828
[server]	loss_train: 0.0825	loss_val: 0.5177	loss_test: 0.4701	accuracy_train: 0.9868	accuracy_val: 0.8452	accuracy_test: 0.8571
curr_round: 75	curr_val_accuracy: 0.8448	curr_test_accuracy: 0.8426
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 76		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1455	loss_val: 0.6343	loss_test: 0.5653	accuracy_train: 0.9701	accuracy_val: 0.8000	accuracy_test: 0.8280
[server]	loss_train: 0.0708	loss_val: 0.5209	loss_test: 0.6069	accuracy_train: 1.0000	accuracy_val: 0.8219	accuracy_test: 0.7840
[server]	loss_train: 0.1042	loss_val: 0.6426	loss_test: 0.5845	accuracy_train: 0.9939	accuracy_val: 0.8234	accuracy_test: 0.8244
[server]	loss_train: 0.0674	loss_val: 0.5017	loss_test: 0.4445	accuracy_train: 1.0000	accuracy_val: 0.8440	accuracy_test: 0.8652
[server]	loss_train: 0.0956	loss_val: 0.4742	loss_test: 0.4163	accuracy_train: 0.9920	accuracy_val: 0.8750	accuracy_test: 0.8736
[server]	loss_train: 0.0822	loss_val: 0.5541	loss_test: 0.5584	accuracy_train: 0.9921	accuracy_val: 0.8168	accuracy_test: 0.8295
[server]	loss_train: 0.0775	loss_val: 0.4075	loss_test: 0.5226	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0763	loss_val: 0.4542	loss_test: 0.4559	accuracy_train: 1.0000	accuracy_val: 0.8561	accuracy_test: 0.8470
[server]	loss_train: 0.1625	loss_val: 0.5269	loss_test: 0.4616	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0702	loss_val: 0.4930	loss_test: 0.4983	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8497
[server]	loss_train: 0.0956	loss_val: 0.6391	loss_test: 0.4478	accuracy_train: 0.9847	accuracy_val: 0.8321	accuracy_test: 0.8493
[server]	loss_train: 0.0639	loss_val: 0.5476	loss_test: 0.4544	accuracy_train: 1.0000	accuracy_val: 0.8577	accuracy_test: 0.8370
[server]	loss_train: 0.1004	loss_val: 0.4986	loss_test: 0.6497	accuracy_train: 0.9776	accuracy_val: 0.8231	accuracy_test: 0.7964
[server]	loss_train: 0.1609	loss_val: 0.4871	loss_test: 0.5112	accuracy_train: 0.9559	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.1066	loss_val: 0.5402	loss_test: 0.4163	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8833
[server]	loss_train: 0.0861	loss_val: 0.3093	loss_test: 0.3463	accuracy_train: 0.9857	accuracy_val: 0.8858	accuracy_test: 0.8630
[server]	loss_train: 0.1062	loss_val: 0.5250	loss_test: 0.5558	accuracy_train: 0.9853	accuracy_val: 0.8321	accuracy_test: 0.8028
[server]	loss_train: 0.0678	loss_val: 0.4414	loss_test: 0.4723	accuracy_train: 1.0000	accuracy_val: 0.8696	accuracy_test: 0.8419
[server]	loss_train: 0.0538	loss_val: 0.4068	loss_test: 0.4202	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8828
[server]	loss_train: 0.0806	loss_val: 0.5187	loss_test: 0.4707	accuracy_train: 0.9868	accuracy_val: 0.8452	accuracy_test: 0.8571
curr_round: 76	curr_val_accuracy: 0.8459	curr_test_accuracy: 0.8422
best_round: 61	best_val_accuracy: 0.8459	best_test_accuracy: 0.8415
--------------------------------------------------
round # 77		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1418	loss_val: 0.6347	loss_test: 0.5663	accuracy_train: 0.9701	accuracy_val: 0.8000	accuracy_test: 0.8280
[server]	loss_train: 0.0691	loss_val: 0.5220	loss_test: 0.6088	accuracy_train: 1.0000	accuracy_val: 0.8259	accuracy_test: 0.7840
[server]	loss_train: 0.1019	loss_val: 0.6432	loss_test: 0.5851	accuracy_train: 0.9939	accuracy_val: 0.8204	accuracy_test: 0.8274
[server]	loss_train: 0.0657	loss_val: 0.5031	loss_test: 0.4447	accuracy_train: 1.0000	accuracy_val: 0.8440	accuracy_test: 0.8652
[server]	loss_train: 0.0932	loss_val: 0.4741	loss_test: 0.4170	accuracy_train: 0.9920	accuracy_val: 0.8750	accuracy_test: 0.8736
[server]	loss_train: 0.0801	loss_val: 0.5545	loss_test: 0.5594	accuracy_train: 1.0000	accuracy_val: 0.8168	accuracy_test: 0.8295
[server]	loss_train: 0.0759	loss_val: 0.4067	loss_test: 0.5233	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0747	loss_val: 0.4552	loss_test: 0.4567	accuracy_train: 1.0000	accuracy_val: 0.8561	accuracy_test: 0.8505
[server]	loss_train: 0.1599	loss_val: 0.5275	loss_test: 0.4618	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0685	loss_val: 0.4938	loss_test: 0.4993	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8427
[server]	loss_train: 0.0933	loss_val: 0.6406	loss_test: 0.4487	accuracy_train: 0.9847	accuracy_val: 0.8321	accuracy_test: 0.8493
[server]	loss_train: 0.0624	loss_val: 0.5488	loss_test: 0.4546	accuracy_train: 1.0000	accuracy_val: 0.8577	accuracy_test: 0.8370
[server]	loss_train: 0.0982	loss_val: 0.4990	loss_test: 0.6508	accuracy_train: 0.9776	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1586	loss_val: 0.4885	loss_test: 0.5117	accuracy_train: 0.9559	accuracy_val: 0.8321	accuracy_test: 0.8386
[server]	loss_train: 0.1044	loss_val: 0.5405	loss_test: 0.4163	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8833
[server]	loss_train: 0.0848	loss_val: 0.3097	loss_test: 0.3470	accuracy_train: 0.9857	accuracy_val: 0.8858	accuracy_test: 0.8630
[server]	loss_train: 0.1037	loss_val: 0.5259	loss_test: 0.5571	accuracy_train: 0.9853	accuracy_val: 0.8321	accuracy_test: 0.8028
[server]	loss_train: 0.0659	loss_val: 0.4417	loss_test: 0.4723	accuracy_train: 1.0000	accuracy_val: 0.8696	accuracy_test: 0.8419
[server]	loss_train: 0.0527	loss_val: 0.4079	loss_test: 0.4215	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8828
[server]	loss_train: 0.0787	loss_val: 0.5203	loss_test: 0.4714	accuracy_train: 0.9868	accuracy_val: 0.8452	accuracy_test: 0.8603
curr_round: 77	curr_val_accuracy: 0.8461	curr_test_accuracy: 0.8428
best_round: 77	best_val_accuracy: 0.8461	best_test_accuracy: 0.8428
--------------------------------------------------
round # 78		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1392	loss_val: 0.6361	loss_test: 0.5677	accuracy_train: 0.9701	accuracy_val: 0.8000	accuracy_test: 0.8280
[server]	loss_train: 0.0676	loss_val: 0.5227	loss_test: 0.6093	accuracy_train: 1.0000	accuracy_val: 0.8259	accuracy_test: 0.7840
[server]	loss_train: 0.1002	loss_val: 0.6455	loss_test: 0.5865	accuracy_train: 0.9939	accuracy_val: 0.8204	accuracy_test: 0.8274
[server]	loss_train: 0.0643	loss_val: 0.5039	loss_test: 0.4451	accuracy_train: 1.0000	accuracy_val: 0.8440	accuracy_test: 0.8652
[server]	loss_train: 0.0914	loss_val: 0.4745	loss_test: 0.4177	accuracy_train: 0.9920	accuracy_val: 0.8750	accuracy_test: 0.8736
[server]	loss_train: 0.0781	loss_val: 0.5552	loss_test: 0.5600	accuracy_train: 1.0000	accuracy_val: 0.8168	accuracy_test: 0.8295
[server]	loss_train: 0.0747	loss_val: 0.4072	loss_test: 0.5248	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0730	loss_val: 0.4554	loss_test: 0.4572	accuracy_train: 1.0000	accuracy_val: 0.8561	accuracy_test: 0.8541
[server]	loss_train: 0.1581	loss_val: 0.5287	loss_test: 0.4628	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8397
[server]	loss_train: 0.0673	loss_val: 0.4948	loss_test: 0.5005	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8462
[server]	loss_train: 0.0910	loss_val: 0.6416	loss_test: 0.4489	accuracy_train: 0.9847	accuracy_val: 0.8321	accuracy_test: 0.8493
[server]	loss_train: 0.0608	loss_val: 0.5492	loss_test: 0.4545	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8406
[server]	loss_train: 0.0963	loss_val: 0.4995	loss_test: 0.6524	accuracy_train: 0.9776	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1559	loss_val: 0.4892	loss_test: 0.5124	accuracy_train: 0.9559	accuracy_val: 0.8321	accuracy_test: 0.8386
[server]	loss_train: 0.1026	loss_val: 0.5422	loss_test: 0.4175	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8800
[server]	loss_train: 0.0831	loss_val: 0.3092	loss_test: 0.3467	accuracy_train: 0.9857	accuracy_val: 0.8858	accuracy_test: 0.8630
[server]	loss_train: 0.1021	loss_val: 0.5268	loss_test: 0.5586	accuracy_train: 0.9853	accuracy_val: 0.8286	accuracy_test: 0.8028
[server]	loss_train: 0.0642	loss_val: 0.4419	loss_test: 0.4725	accuracy_train: 1.0000	accuracy_val: 0.8696	accuracy_test: 0.8462
[server]	loss_train: 0.0515	loss_val: 0.4085	loss_test: 0.4224	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0770	loss_val: 0.5212	loss_test: 0.4721	accuracy_train: 0.9868	accuracy_val: 0.8452	accuracy_test: 0.8603
curr_round: 78	curr_val_accuracy: 0.8457	curr_test_accuracy: 0.8433
best_round: 77	best_val_accuracy: 0.8461	best_test_accuracy: 0.8428
--------------------------------------------------
round # 79		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1358	loss_val: 0.6366	loss_test: 0.5689	accuracy_train: 0.9701	accuracy_val: 0.8000	accuracy_test: 0.8280
[server]	loss_train: 0.0659	loss_val: 0.5240	loss_test: 0.6112	accuracy_train: 1.0000	accuracy_val: 0.8259	accuracy_test: 0.7840
[server]	loss_train: 0.0981	loss_val: 0.6461	loss_test: 0.5871	accuracy_train: 0.9939	accuracy_val: 0.8204	accuracy_test: 0.8304
[server]	loss_train: 0.0628	loss_val: 0.5054	loss_test: 0.4456	accuracy_train: 1.0000	accuracy_val: 0.8440	accuracy_test: 0.8617
[server]	loss_train: 0.0893	loss_val: 0.4744	loss_test: 0.4185	accuracy_train: 0.9920	accuracy_val: 0.8789	accuracy_test: 0.8736
[server]	loss_train: 0.0762	loss_val: 0.5556	loss_test: 0.5610	accuracy_train: 1.0000	accuracy_val: 0.8168	accuracy_test: 0.8295
[server]	loss_train: 0.0732	loss_val: 0.4066	loss_test: 0.5255	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0714	loss_val: 0.4562	loss_test: 0.4578	accuracy_train: 1.0000	accuracy_val: 0.8561	accuracy_test: 0.8505
[server]	loss_train: 0.1557	loss_val: 0.5296	loss_test: 0.4631	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8397
[server]	loss_train: 0.0658	loss_val: 0.4958	loss_test: 0.5015	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8462
[server]	loss_train: 0.0890	loss_val: 0.6431	loss_test: 0.4499	accuracy_train: 0.9847	accuracy_val: 0.8321	accuracy_test: 0.8493
[server]	loss_train: 0.0594	loss_val: 0.5504	loss_test: 0.4547	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8406
[server]	loss_train: 0.0942	loss_val: 0.5001	loss_test: 0.6537	accuracy_train: 0.9776	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1536	loss_val: 0.4905	loss_test: 0.5130	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.1006	loss_val: 0.5428	loss_test: 0.4176	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8833
[server]	loss_train: 0.0819	loss_val: 0.3096	loss_test: 0.3473	accuracy_train: 0.9857	accuracy_val: 0.8858	accuracy_test: 0.8630
[server]	loss_train: 0.0998	loss_val: 0.5278	loss_test: 0.5599	accuracy_train: 0.9853	accuracy_val: 0.8286	accuracy_test: 0.8028
[server]	loss_train: 0.0624	loss_val: 0.4421	loss_test: 0.4727	accuracy_train: 1.0000	accuracy_val: 0.8696	accuracy_test: 0.8462
[server]	loss_train: 0.0504	loss_val: 0.4095	loss_test: 0.4236	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0752	loss_val: 0.5230	loss_test: 0.4728	accuracy_train: 0.9868	accuracy_val: 0.8452	accuracy_test: 0.8603
curr_round: 79	curr_val_accuracy: 0.8459	curr_test_accuracy: 0.8431
best_round: 77	best_val_accuracy: 0.8461	best_test_accuracy: 0.8428
--------------------------------------------------
round # 80		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1331	loss_val: 0.6379	loss_test: 0.5701	accuracy_train: 0.9701	accuracy_val: 0.8000	accuracy_test: 0.8280
[server]	loss_train: 0.0646	loss_val: 0.5246	loss_test: 0.6120	accuracy_train: 1.0000	accuracy_val: 0.8259	accuracy_test: 0.7840
[server]	loss_train: 0.0963	loss_val: 0.6482	loss_test: 0.5885	accuracy_train: 0.9939	accuracy_val: 0.8204	accuracy_test: 0.8304
[server]	loss_train: 0.0614	loss_val: 0.5063	loss_test: 0.4460	accuracy_train: 1.0000	accuracy_val: 0.8404	accuracy_test: 0.8617
[server]	loss_train: 0.0875	loss_val: 0.4749	loss_test: 0.4192	accuracy_train: 0.9920	accuracy_val: 0.8789	accuracy_test: 0.8736
[server]	loss_train: 0.0744	loss_val: 0.5564	loss_test: 0.5618	accuracy_train: 1.0000	accuracy_val: 0.8168	accuracy_test: 0.8295
[server]	loss_train: 0.0720	loss_val: 0.4071	loss_test: 0.5271	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0699	loss_val: 0.4568	loss_test: 0.4585	accuracy_train: 1.0000	accuracy_val: 0.8561	accuracy_test: 0.8541
[server]	loss_train: 0.1541	loss_val: 0.5307	loss_test: 0.4640	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8397
[server]	loss_train: 0.0646	loss_val: 0.4967	loss_test: 0.5027	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8462
[server]	loss_train: 0.0869	loss_val: 0.6442	loss_test: 0.4503	accuracy_train: 0.9847	accuracy_val: 0.8321	accuracy_test: 0.8493
[server]	loss_train: 0.0579	loss_val: 0.5508	loss_test: 0.4547	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8406
[server]	loss_train: 0.0924	loss_val: 0.5006	loss_test: 0.6551	accuracy_train: 0.9776	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1513	loss_val: 0.4915	loss_test: 0.5138	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.0988	loss_val: 0.5443	loss_test: 0.4187	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8800
[server]	loss_train: 0.0804	loss_val: 0.3094	loss_test: 0.3473	accuracy_train: 0.9929	accuracy_val: 0.8858	accuracy_test: 0.8630
[server]	loss_train: 0.0982	loss_val: 0.5287	loss_test: 0.5614	accuracy_train: 0.9853	accuracy_val: 0.8321	accuracy_test: 0.8028
[server]	loss_train: 0.0608	loss_val: 0.4425	loss_test: 0.4728	accuracy_train: 1.0000	accuracy_val: 0.8696	accuracy_test: 0.8462
[server]	loss_train: 0.0493	loss_val: 0.4104	loss_test: 0.4246	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0736	loss_val: 0.5238	loss_test: 0.4734	accuracy_train: 0.9868	accuracy_val: 0.8452	accuracy_test: 0.8571
curr_round: 80	curr_val_accuracy: 0.8459	curr_test_accuracy: 0.8430
best_round: 77	best_val_accuracy: 0.8461	best_test_accuracy: 0.8428
--------------------------------------------------
round # 81		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1301	loss_val: 0.6385	loss_test: 0.5713	accuracy_train: 0.9701	accuracy_val: 0.8036	accuracy_test: 0.8244
[server]	loss_train: 0.0631	loss_val: 0.5258	loss_test: 0.6137	accuracy_train: 1.0000	accuracy_val: 0.8259	accuracy_test: 0.7800
[server]	loss_train: 0.0945	loss_val: 0.6489	loss_test: 0.5891	accuracy_train: 0.9939	accuracy_val: 0.8234	accuracy_test: 0.8304
[server]	loss_train: 0.0600	loss_val: 0.5077	loss_test: 0.4463	accuracy_train: 1.0000	accuracy_val: 0.8404	accuracy_test: 0.8617
[server]	loss_train: 0.0856	loss_val: 0.4749	loss_test: 0.4200	accuracy_train: 0.9920	accuracy_val: 0.8789	accuracy_test: 0.8736
[server]	loss_train: 0.0726	loss_val: 0.5568	loss_test: 0.5628	accuracy_train: 1.0000	accuracy_val: 0.8168	accuracy_test: 0.8295
[server]	loss_train: 0.0706	loss_val: 0.4067	loss_test: 0.5278	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0685	loss_val: 0.4575	loss_test: 0.4591	accuracy_train: 1.0000	accuracy_val: 0.8561	accuracy_test: 0.8541
[server]	loss_train: 0.1517	loss_val: 0.5315	loss_test: 0.4644	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8397
[server]	loss_train: 0.0632	loss_val: 0.4976	loss_test: 0.5037	accuracy_train: 1.0000	accuracy_val: 0.8551	accuracy_test: 0.8462
[server]	loss_train: 0.0850	loss_val: 0.6456	loss_test: 0.4511	accuracy_train: 0.9847	accuracy_val: 0.8321	accuracy_test: 0.8493
[server]	loss_train: 0.0566	loss_val: 0.5519	loss_test: 0.4548	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8406
[server]	loss_train: 0.0905	loss_val: 0.5012	loss_test: 0.6563	accuracy_train: 0.9851	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1489	loss_val: 0.4926	loss_test: 0.5144	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.0970	loss_val: 0.5450	loss_test: 0.4188	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8833
[server]	loss_train: 0.0792	loss_val: 0.3097	loss_test: 0.3478	accuracy_train: 0.9929	accuracy_val: 0.8858	accuracy_test: 0.8630
[server]	loss_train: 0.0962	loss_val: 0.5296	loss_test: 0.5626	accuracy_train: 0.9853	accuracy_val: 0.8321	accuracy_test: 0.8028
[server]	loss_train: 0.0592	loss_val: 0.4428	loss_test: 0.4730	accuracy_train: 1.0000	accuracy_val: 0.8652	accuracy_test: 0.8462
[server]	loss_train: 0.0483	loss_val: 0.4112	loss_test: 0.4258	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0719	loss_val: 0.5256	loss_test: 0.4742	accuracy_train: 0.9868	accuracy_val: 0.8452	accuracy_test: 0.8540
curr_round: 81	curr_val_accuracy: 0.8461	curr_test_accuracy: 0.8426
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 82		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1275	loss_val: 0.6397	loss_test: 0.5725	accuracy_train: 0.9701	accuracy_val: 0.8036	accuracy_test: 0.8244
[server]	loss_train: 0.0618	loss_val: 0.5265	loss_test: 0.6146	accuracy_train: 1.0000	accuracy_val: 0.8259	accuracy_test: 0.7800
[server]	loss_train: 0.0928	loss_val: 0.6510	loss_test: 0.5904	accuracy_train: 0.9939	accuracy_val: 0.8204	accuracy_test: 0.8304
[server]	loss_train: 0.0587	loss_val: 0.5087	loss_test: 0.4467	accuracy_train: 1.0000	accuracy_val: 0.8404	accuracy_test: 0.8617
[server]	loss_train: 0.0838	loss_val: 0.4754	loss_test: 0.4207	accuracy_train: 0.9920	accuracy_val: 0.8789	accuracy_test: 0.8736
[server]	loss_train: 0.0709	loss_val: 0.5576	loss_test: 0.5636	accuracy_train: 1.0000	accuracy_val: 0.8168	accuracy_test: 0.8295
[server]	loss_train: 0.0696	loss_val: 0.4071	loss_test: 0.5292	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0671	loss_val: 0.4581	loss_test: 0.4599	accuracy_train: 1.0000	accuracy_val: 0.8561	accuracy_test: 0.8541
[server]	loss_train: 0.1502	loss_val: 0.5327	loss_test: 0.4652	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8397
[server]	loss_train: 0.0621	loss_val: 0.4986	loss_test: 0.5049	accuracy_train: 1.0000	accuracy_val: 0.8516	accuracy_test: 0.8462
[server]	loss_train: 0.0831	loss_val: 0.6468	loss_test: 0.4516	accuracy_train: 0.9847	accuracy_val: 0.8321	accuracy_test: 0.8493
[server]	loss_train: 0.0552	loss_val: 0.5525	loss_test: 0.4549	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8406
[server]	loss_train: 0.0888	loss_val: 0.5017	loss_test: 0.6578	accuracy_train: 0.9851	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1467	loss_val: 0.4936	loss_test: 0.5151	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.0953	loss_val: 0.5464	loss_test: 0.4198	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8800
[server]	loss_train: 0.0778	loss_val: 0.3095	loss_test: 0.3479	accuracy_train: 0.9929	accuracy_val: 0.8858	accuracy_test: 0.8630
[server]	loss_train: 0.0946	loss_val: 0.5305	loss_test: 0.5641	accuracy_train: 0.9853	accuracy_val: 0.8321	accuracy_test: 0.7993
[server]	loss_train: 0.0578	loss_val: 0.4432	loss_test: 0.4731	accuracy_train: 1.0000	accuracy_val: 0.8652	accuracy_test: 0.8462
[server]	loss_train: 0.0473	loss_val: 0.4120	loss_test: 0.4268	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0704	loss_val: 0.5265	loss_test: 0.4749	accuracy_train: 0.9868	accuracy_val: 0.8452	accuracy_test: 0.8540
curr_round: 82	curr_val_accuracy: 0.8457	curr_test_accuracy: 0.8422
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 83		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1247	loss_val: 0.6404	loss_test: 0.5739	accuracy_train: 0.9701	accuracy_val: 0.8036	accuracy_test: 0.8244
[server]	loss_train: 0.0604	loss_val: 0.5278	loss_test: 0.6164	accuracy_train: 1.0000	accuracy_val: 0.8259	accuracy_test: 0.7800
[server]	loss_train: 0.0911	loss_val: 0.6516	loss_test: 0.5911	accuracy_train: 0.9939	accuracy_val: 0.8204	accuracy_test: 0.8304
[server]	loss_train: 0.0573	loss_val: 0.5101	loss_test: 0.4473	accuracy_train: 1.0000	accuracy_val: 0.8404	accuracy_test: 0.8617
[server]	loss_train: 0.0821	loss_val: 0.4753	loss_test: 0.4217	accuracy_train: 0.9920	accuracy_val: 0.8789	accuracy_test: 0.8736
[server]	loss_train: 0.0693	loss_val: 0.5580	loss_test: 0.5646	accuracy_train: 1.0000	accuracy_val: 0.8092	accuracy_test: 0.8295
[server]	loss_train: 0.0682	loss_val: 0.4068	loss_test: 0.5300	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0657	loss_val: 0.4587	loss_test: 0.4604	accuracy_train: 1.0000	accuracy_val: 0.8561	accuracy_test: 0.8541
[server]	loss_train: 0.1479	loss_val: 0.5336	loss_test: 0.4657	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8397
[server]	loss_train: 0.0608	loss_val: 0.4996	loss_test: 0.5059	accuracy_train: 1.0000	accuracy_val: 0.8516	accuracy_test: 0.8462
[server]	loss_train: 0.0814	loss_val: 0.6482	loss_test: 0.4525	accuracy_train: 0.9847	accuracy_val: 0.8321	accuracy_test: 0.8493
[server]	loss_train: 0.0540	loss_val: 0.5537	loss_test: 0.4550	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8406
[server]	loss_train: 0.0870	loss_val: 0.5024	loss_test: 0.6591	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1445	loss_val: 0.4948	loss_test: 0.5158	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.0936	loss_val: 0.5471	loss_test: 0.4201	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8867
[server]	loss_train: 0.0766	loss_val: 0.3098	loss_test: 0.3482	accuracy_train: 0.9929	accuracy_val: 0.8858	accuracy_test: 0.8630
[server]	loss_train: 0.0927	loss_val: 0.5315	loss_test: 0.5654	accuracy_train: 0.9853	accuracy_val: 0.8321	accuracy_test: 0.7993
[server]	loss_train: 0.0563	loss_val: 0.4434	loss_test: 0.4734	accuracy_train: 1.0000	accuracy_val: 0.8652	accuracy_test: 0.8462
[server]	loss_train: 0.0464	loss_val: 0.4129	loss_test: 0.4279	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0689	loss_val: 0.5282	loss_test: 0.4756	accuracy_train: 0.9934	accuracy_val: 0.8452	accuracy_test: 0.8571
curr_round: 83	curr_val_accuracy: 0.8454	curr_test_accuracy: 0.8428
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 84		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1222	loss_val: 0.6416	loss_test: 0.5750	accuracy_train: 0.9701	accuracy_val: 0.8073	accuracy_test: 0.8244
[server]	loss_train: 0.0592	loss_val: 0.5285	loss_test: 0.6174	accuracy_train: 1.0000	accuracy_val: 0.8340	accuracy_test: 0.7840
[server]	loss_train: 0.0894	loss_val: 0.6537	loss_test: 0.5926	accuracy_train: 0.9939	accuracy_val: 0.8204	accuracy_test: 0.8304
[server]	loss_train: 0.0562	loss_val: 0.5112	loss_test: 0.4477	accuracy_train: 1.0000	accuracy_val: 0.8404	accuracy_test: 0.8617
[server]	loss_train: 0.0805	loss_val: 0.4760	loss_test: 0.4223	accuracy_train: 0.9920	accuracy_val: 0.8789	accuracy_test: 0.8736
[server]	loss_train: 0.0677	loss_val: 0.5591	loss_test: 0.5655	accuracy_train: 1.0000	accuracy_val: 0.8053	accuracy_test: 0.8295
[server]	loss_train: 0.0672	loss_val: 0.4072	loss_test: 0.5315	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0644	loss_val: 0.4595	loss_test: 0.4615	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8541
[server]	loss_train: 0.1465	loss_val: 0.5348	loss_test: 0.4666	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8397
[server]	loss_train: 0.0597	loss_val: 0.5006	loss_test: 0.5073	accuracy_train: 1.0000	accuracy_val: 0.8516	accuracy_test: 0.8462
[server]	loss_train: 0.0796	loss_val: 0.6495	loss_test: 0.4531	accuracy_train: 0.9924	accuracy_val: 0.8321	accuracy_test: 0.8493
[server]	loss_train: 0.0527	loss_val: 0.5543	loss_test: 0.4552	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8406
[server]	loss_train: 0.0854	loss_val: 0.5030	loss_test: 0.6606	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1425	loss_val: 0.4959	loss_test: 0.5167	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.0919	loss_val: 0.5485	loss_test: 0.4211	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8867
[server]	loss_train: 0.0753	loss_val: 0.3096	loss_test: 0.3485	accuracy_train: 0.9929	accuracy_val: 0.8858	accuracy_test: 0.8596
[server]	loss_train: 0.0912	loss_val: 0.5326	loss_test: 0.5671	accuracy_train: 0.9853	accuracy_val: 0.8357	accuracy_test: 0.7993
[server]	loss_train: 0.0550	loss_val: 0.4440	loss_test: 0.4736	accuracy_train: 1.0000	accuracy_val: 0.8652	accuracy_test: 0.8462
[server]	loss_train: 0.0455	loss_val: 0.4138	loss_test: 0.4290	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0675	loss_val: 0.5290	loss_test: 0.4763	accuracy_train: 0.9934	accuracy_val: 0.8452	accuracy_test: 0.8571
curr_round: 84	curr_val_accuracy: 0.8457	curr_test_accuracy: 0.8428
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 85		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1196	loss_val: 0.6422	loss_test: 0.5764	accuracy_train: 0.9701	accuracy_val: 0.8073	accuracy_test: 0.8208
[server]	loss_train: 0.0579	loss_val: 0.5297	loss_test: 0.6188	accuracy_train: 1.0000	accuracy_val: 0.8300	accuracy_test: 0.7840
[server]	loss_train: 0.0879	loss_val: 0.6545	loss_test: 0.5931	accuracy_train: 0.9939	accuracy_val: 0.8204	accuracy_test: 0.8304
[server]	loss_train: 0.0549	loss_val: 0.5124	loss_test: 0.4481	accuracy_train: 1.0000	accuracy_val: 0.8440	accuracy_test: 0.8652
[server]	loss_train: 0.0789	loss_val: 0.4758	loss_test: 0.4231	accuracy_train: 0.9920	accuracy_val: 0.8789	accuracy_test: 0.8736
[server]	loss_train: 0.0662	loss_val: 0.5594	loss_test: 0.5663	accuracy_train: 1.0000	accuracy_val: 0.8053	accuracy_test: 0.8295
[server]	loss_train: 0.0660	loss_val: 0.4070	loss_test: 0.5322	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0631	loss_val: 0.4599	loss_test: 0.4617	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8541
[server]	loss_train: 0.1442	loss_val: 0.5356	loss_test: 0.4670	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0586	loss_val: 0.5015	loss_test: 0.5081	accuracy_train: 1.0000	accuracy_val: 0.8481	accuracy_test: 0.8462
[server]	loss_train: 0.0780	loss_val: 0.6506	loss_test: 0.4537	accuracy_train: 0.9924	accuracy_val: 0.8321	accuracy_test: 0.8493
[server]	loss_train: 0.0516	loss_val: 0.5552	loss_test: 0.4552	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8406
[server]	loss_train: 0.0837	loss_val: 0.5035	loss_test: 0.6618	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1402	loss_val: 0.4969	loss_test: 0.5172	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.0904	loss_val: 0.5494	loss_test: 0.4215	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8867
[server]	loss_train: 0.0741	loss_val: 0.3099	loss_test: 0.3488	accuracy_train: 0.9929	accuracy_val: 0.8858	accuracy_test: 0.8596
[server]	loss_train: 0.0894	loss_val: 0.5333	loss_test: 0.5681	accuracy_train: 0.9853	accuracy_val: 0.8357	accuracy_test: 0.7958
[server]	loss_train: 0.0536	loss_val: 0.4442	loss_test: 0.4738	accuracy_train: 1.0000	accuracy_val: 0.8652	accuracy_test: 0.8462
[server]	loss_train: 0.0445	loss_val: 0.4145	loss_test: 0.4300	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0660	loss_val: 0.5307	loss_test: 0.4771	accuracy_train: 0.9934	accuracy_val: 0.8452	accuracy_test: 0.8571
curr_round: 85	curr_val_accuracy: 0.8456	curr_test_accuracy: 0.8428
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 86		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1173	loss_val: 0.6434	loss_test: 0.5775	accuracy_train: 0.9776	accuracy_val: 0.8073	accuracy_test: 0.8208
[server]	loss_train: 0.0568	loss_val: 0.5304	loss_test: 0.6201	accuracy_train: 1.0000	accuracy_val: 0.8340	accuracy_test: 0.7840
[server]	loss_train: 0.0863	loss_val: 0.6562	loss_test: 0.5945	accuracy_train: 0.9939	accuracy_val: 0.8204	accuracy_test: 0.8304
[server]	loss_train: 0.0538	loss_val: 0.5135	loss_test: 0.4486	accuracy_train: 1.0000	accuracy_val: 0.8440	accuracy_test: 0.8652
[server]	loss_train: 0.0773	loss_val: 0.4765	loss_test: 0.4238	accuracy_train: 0.9920	accuracy_val: 0.8789	accuracy_test: 0.8736
[server]	loss_train: 0.0647	loss_val: 0.5603	loss_test: 0.5673	accuracy_train: 1.0000	accuracy_val: 0.8053	accuracy_test: 0.8295
[server]	loss_train: 0.0650	loss_val: 0.4072	loss_test: 0.5336	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0619	loss_val: 0.4609	loss_test: 0.4629	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8541
[server]	loss_train: 0.1428	loss_val: 0.5368	loss_test: 0.4678	accuracy_train: 0.9680	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0575	loss_val: 0.5024	loss_test: 0.5095	accuracy_train: 1.0000	accuracy_val: 0.8481	accuracy_test: 0.8497
[server]	loss_train: 0.0764	loss_val: 0.6519	loss_test: 0.4545	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0504	loss_val: 0.5561	loss_test: 0.4555	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8406
[server]	loss_train: 0.0822	loss_val: 0.5042	loss_test: 0.6633	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1385	loss_val: 0.4981	loss_test: 0.5180	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.0888	loss_val: 0.5504	loss_test: 0.4223	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8833
[server]	loss_train: 0.0731	loss_val: 0.3099	loss_test: 0.3491	accuracy_train: 0.9929	accuracy_val: 0.8927	accuracy_test: 0.8596
[server]	loss_train: 0.0880	loss_val: 0.5344	loss_test: 0.5698	accuracy_train: 0.9853	accuracy_val: 0.8357	accuracy_test: 0.7958
[server]	loss_train: 0.0524	loss_val: 0.4448	loss_test: 0.4741	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0437	loss_val: 0.4155	loss_test: 0.4312	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0646	loss_val: 0.5316	loss_test: 0.4778	accuracy_train: 0.9934	accuracy_val: 0.8419	accuracy_test: 0.8571
curr_round: 86	curr_val_accuracy: 0.8456	curr_test_accuracy: 0.8428
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 87		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1149	loss_val: 0.6441	loss_test: 0.5790	accuracy_train: 0.9776	accuracy_val: 0.8073	accuracy_test: 0.8208
[server]	loss_train: 0.0556	loss_val: 0.5316	loss_test: 0.6214	accuracy_train: 1.0000	accuracy_val: 0.8300	accuracy_test: 0.7840
[server]	loss_train: 0.0849	loss_val: 0.6571	loss_test: 0.5950	accuracy_train: 0.9939	accuracy_val: 0.8204	accuracy_test: 0.8333
[server]	loss_train: 0.0527	loss_val: 0.5148	loss_test: 0.4491	accuracy_train: 1.0000	accuracy_val: 0.8440	accuracy_test: 0.8652
[server]	loss_train: 0.0759	loss_val: 0.4764	loss_test: 0.4247	accuracy_train: 0.9920	accuracy_val: 0.8750	accuracy_test: 0.8736
[server]	loss_train: 0.0633	loss_val: 0.5606	loss_test: 0.5682	accuracy_train: 1.0000	accuracy_val: 0.8053	accuracy_test: 0.8295
[server]	loss_train: 0.0638	loss_val: 0.4073	loss_test: 0.5344	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0607	loss_val: 0.4612	loss_test: 0.4631	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8541
[server]	loss_train: 0.1406	loss_val: 0.5376	loss_test: 0.4683	accuracy_train: 0.9760	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0565	loss_val: 0.5033	loss_test: 0.5103	accuracy_train: 1.0000	accuracy_val: 0.8445	accuracy_test: 0.8497
[server]	loss_train: 0.0749	loss_val: 0.6531	loss_test: 0.4552	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0494	loss_val: 0.5570	loss_test: 0.4556	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8406
[server]	loss_train: 0.0806	loss_val: 0.5047	loss_test: 0.6644	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1362	loss_val: 0.4992	loss_test: 0.5185	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.0873	loss_val: 0.5515	loss_test: 0.4228	accuracy_train: 0.9796	accuracy_val: 0.8624	accuracy_test: 0.8867
[server]	loss_train: 0.0719	loss_val: 0.3102	loss_test: 0.3494	accuracy_train: 0.9929	accuracy_val: 0.8962	accuracy_test: 0.8596
[server]	loss_train: 0.0863	loss_val: 0.5352	loss_test: 0.5708	accuracy_train: 0.9853	accuracy_val: 0.8357	accuracy_test: 0.7923
[server]	loss_train: 0.0512	loss_val: 0.4449	loss_test: 0.4744	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0428	loss_val: 0.4161	loss_test: 0.4322	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0634	loss_val: 0.5333	loss_test: 0.4786	accuracy_train: 0.9934	accuracy_val: 0.8452	accuracy_test: 0.8571
curr_round: 87	curr_val_accuracy: 0.8454	curr_test_accuracy: 0.8430
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 88		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1126	loss_val: 0.6453	loss_test: 0.5800	accuracy_train: 0.9776	accuracy_val: 0.8073	accuracy_test: 0.8208
[server]	loss_train: 0.0546	loss_val: 0.5324	loss_test: 0.6229	accuracy_train: 1.0000	accuracy_val: 0.8340	accuracy_test: 0.7840
[server]	loss_train: 0.0833	loss_val: 0.6590	loss_test: 0.5967	accuracy_train: 0.9939	accuracy_val: 0.8204	accuracy_test: 0.8333
[server]	loss_train: 0.0516	loss_val: 0.5160	loss_test: 0.4497	accuracy_train: 1.0000	accuracy_val: 0.8440	accuracy_test: 0.8652
[server]	loss_train: 0.0744	loss_val: 0.4773	loss_test: 0.4255	accuracy_train: 0.9920	accuracy_val: 0.8750	accuracy_test: 0.8774
[server]	loss_train: 0.0619	loss_val: 0.5619	loss_test: 0.5695	accuracy_train: 1.0000	accuracy_val: 0.8053	accuracy_test: 0.8295
[server]	loss_train: 0.0629	loss_val: 0.4076	loss_test: 0.5361	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0595	loss_val: 0.4623	loss_test: 0.4646	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8541
[server]	loss_train: 0.1394	loss_val: 0.5391	loss_test: 0.4694	accuracy_train: 0.9760	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0555	loss_val: 0.5044	loss_test: 0.5120	accuracy_train: 1.0000	accuracy_val: 0.8445	accuracy_test: 0.8462
[server]	loss_train: 0.0735	loss_val: 0.6548	loss_test: 0.4562	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0483	loss_val: 0.5580	loss_test: 0.4559	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8406
[server]	loss_train: 0.0792	loss_val: 0.5056	loss_test: 0.6661	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1346	loss_val: 0.5003	loss_test: 0.5196	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8351
[server]	loss_train: 0.0858	loss_val: 0.5525	loss_test: 0.4237	accuracy_train: 0.9864	accuracy_val: 0.8624	accuracy_test: 0.8833
[server]	loss_train: 0.0708	loss_val: 0.3101	loss_test: 0.3497	accuracy_train: 0.9929	accuracy_val: 0.8962	accuracy_test: 0.8596
[server]	loss_train: 0.0851	loss_val: 0.5366	loss_test: 0.5727	accuracy_train: 0.9853	accuracy_val: 0.8357	accuracy_test: 0.7923
[server]	loss_train: 0.0501	loss_val: 0.4457	loss_test: 0.4746	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0421	loss_val: 0.4172	loss_test: 0.4333	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0621	loss_val: 0.5341	loss_test: 0.4794	accuracy_train: 0.9934	accuracy_val: 0.8419	accuracy_test: 0.8571
curr_round: 88	curr_val_accuracy: 0.8454	curr_test_accuracy: 0.8428
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 89		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1103	loss_val: 0.6459	loss_test: 0.5815	accuracy_train: 0.9776	accuracy_val: 0.8073	accuracy_test: 0.8208
[server]	loss_train: 0.0534	loss_val: 0.5336	loss_test: 0.6241	accuracy_train: 1.0000	accuracy_val: 0.8340	accuracy_test: 0.7840
[server]	loss_train: 0.0820	loss_val: 0.6597	loss_test: 0.5971	accuracy_train: 0.9939	accuracy_val: 0.8234	accuracy_test: 0.8333
[server]	loss_train: 0.0505	loss_val: 0.5172	loss_test: 0.4501	accuracy_train: 1.0000	accuracy_val: 0.8475	accuracy_test: 0.8652
[server]	loss_train: 0.0731	loss_val: 0.4770	loss_test: 0.4263	accuracy_train: 0.9920	accuracy_val: 0.8750	accuracy_test: 0.8774
[server]	loss_train: 0.0606	loss_val: 0.5621	loss_test: 0.5701	accuracy_train: 1.0000	accuracy_val: 0.8053	accuracy_test: 0.8258
[server]	loss_train: 0.0618	loss_val: 0.4076	loss_test: 0.5366	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0585	loss_val: 0.4626	loss_test: 0.4646	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8541
[server]	loss_train: 0.1372	loss_val: 0.5397	loss_test: 0.4696	accuracy_train: 0.9760	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0545	loss_val: 0.5052	loss_test: 0.5126	accuracy_train: 1.0000	accuracy_val: 0.8481	accuracy_test: 0.8462
[server]	loss_train: 0.0720	loss_val: 0.6556	loss_test: 0.4566	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0473	loss_val: 0.5587	loss_test: 0.4559	accuracy_train: 1.0000	accuracy_val: 0.8540	accuracy_test: 0.8406
[server]	loss_train: 0.0777	loss_val: 0.5059	loss_test: 0.6669	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1325	loss_val: 0.5015	loss_test: 0.5200	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8386
[server]	loss_train: 0.0844	loss_val: 0.5535	loss_test: 0.4242	accuracy_train: 0.9864	accuracy_val: 0.8624	accuracy_test: 0.8867
[server]	loss_train: 0.0697	loss_val: 0.3105	loss_test: 0.3501	accuracy_train: 0.9929	accuracy_val: 0.8927	accuracy_test: 0.8596
[server]	loss_train: 0.0834	loss_val: 0.5372	loss_test: 0.5736	accuracy_train: 0.9853	accuracy_val: 0.8357	accuracy_test: 0.7923
[server]	loss_train: 0.0489	loss_val: 0.4458	loss_test: 0.4748	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0413	loss_val: 0.4177	loss_test: 0.4343	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0609	loss_val: 0.5358	loss_test: 0.4801	accuracy_train: 0.9934	accuracy_val: 0.8419	accuracy_test: 0.8540
curr_round: 89	curr_val_accuracy: 0.8457	curr_test_accuracy: 0.8428
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 90		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1082	loss_val: 0.6471	loss_test: 0.5825	accuracy_train: 0.9851	accuracy_val: 0.8073	accuracy_test: 0.8208
[server]	loss_train: 0.0525	loss_val: 0.5345	loss_test: 0.6254	accuracy_train: 1.0000	accuracy_val: 0.8340	accuracy_test: 0.7840
[server]	loss_train: 0.0806	loss_val: 0.6617	loss_test: 0.5987	accuracy_train: 0.9939	accuracy_val: 0.8234	accuracy_test: 0.8363
[server]	loss_train: 0.0496	loss_val: 0.5184	loss_test: 0.4506	accuracy_train: 1.0000	accuracy_val: 0.8440	accuracy_test: 0.8652
[server]	loss_train: 0.0716	loss_val: 0.4780	loss_test: 0.4271	accuracy_train: 1.0000	accuracy_val: 0.8750	accuracy_test: 0.8774
[server]	loss_train: 0.0593	loss_val: 0.5632	loss_test: 0.5714	accuracy_train: 1.0000	accuracy_val: 0.8053	accuracy_test: 0.8258
[server]	loss_train: 0.0610	loss_val: 0.4079	loss_test: 0.5382	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0573	loss_val: 0.4637	loss_test: 0.4660	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8541
[server]	loss_train: 0.1360	loss_val: 0.5411	loss_test: 0.4707	accuracy_train: 0.9760	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0536	loss_val: 0.5063	loss_test: 0.5143	accuracy_train: 1.0000	accuracy_val: 0.8481	accuracy_test: 0.8462
[server]	loss_train: 0.0707	loss_val: 0.6572	loss_test: 0.4576	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0463	loss_val: 0.5597	loss_test: 0.4563	accuracy_train: 1.0000	accuracy_val: 0.8504	accuracy_test: 0.8406
[server]	loss_train: 0.0764	loss_val: 0.5067	loss_test: 0.6687	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1309	loss_val: 0.5025	loss_test: 0.5210	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8386
[server]	loss_train: 0.0830	loss_val: 0.5545	loss_test: 0.4250	accuracy_train: 0.9864	accuracy_val: 0.8591	accuracy_test: 0.8867
[server]	loss_train: 0.0687	loss_val: 0.3104	loss_test: 0.3504	accuracy_train: 0.9929	accuracy_val: 0.8927	accuracy_test: 0.8596
[server]	loss_train: 0.0822	loss_val: 0.5385	loss_test: 0.5756	accuracy_train: 0.9853	accuracy_val: 0.8357	accuracy_test: 0.7923
[server]	loss_train: 0.0479	loss_val: 0.4467	loss_test: 0.4751	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0405	loss_val: 0.4188	loss_test: 0.4355	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0597	loss_val: 0.5367	loss_test: 0.4809	accuracy_train: 0.9934	accuracy_val: 0.8419	accuracy_test: 0.8540
curr_round: 90	curr_val_accuracy: 0.8452	curr_test_accuracy: 0.8430
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 91		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1061	loss_val: 0.6479	loss_test: 0.5840	accuracy_train: 0.9851	accuracy_val: 0.8073	accuracy_test: 0.8208
[server]	loss_train: 0.0514	loss_val: 0.5355	loss_test: 0.6267	accuracy_train: 1.0000	accuracy_val: 0.8340	accuracy_test: 0.7840
[server]	loss_train: 0.0793	loss_val: 0.6624	loss_test: 0.5990	accuracy_train: 0.9939	accuracy_val: 0.8234	accuracy_test: 0.8363
[server]	loss_train: 0.0485	loss_val: 0.5196	loss_test: 0.4511	accuracy_train: 1.0000	accuracy_val: 0.8440	accuracy_test: 0.8652
[server]	loss_train: 0.0704	loss_val: 0.4777	loss_test: 0.4279	accuracy_train: 1.0000	accuracy_val: 0.8750	accuracy_test: 0.8812
[server]	loss_train: 0.0581	loss_val: 0.5634	loss_test: 0.5719	accuracy_train: 1.0000	accuracy_val: 0.8053	accuracy_test: 0.8258
[server]	loss_train: 0.0599	loss_val: 0.4078	loss_test: 0.5387	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0563	loss_val: 0.4639	loss_test: 0.4660	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8541
[server]	loss_train: 0.1339	loss_val: 0.5418	loss_test: 0.4709	accuracy_train: 0.9760	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0527	loss_val: 0.5070	loss_test: 0.5148	accuracy_train: 1.0000	accuracy_val: 0.8481	accuracy_test: 0.8462
[server]	loss_train: 0.0693	loss_val: 0.6581	loss_test: 0.4581	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0454	loss_val: 0.5604	loss_test: 0.4562	accuracy_train: 1.0000	accuracy_val: 0.8467	accuracy_test: 0.8406
[server]	loss_train: 0.0750	loss_val: 0.5072	loss_test: 0.6696	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1289	loss_val: 0.5037	loss_test: 0.5214	accuracy_train: 0.9632	accuracy_val: 0.8321	accuracy_test: 0.8386
[server]	loss_train: 0.0817	loss_val: 0.5557	loss_test: 0.4255	accuracy_train: 0.9864	accuracy_val: 0.8624	accuracy_test: 0.8867
[server]	loss_train: 0.0677	loss_val: 0.3108	loss_test: 0.3508	accuracy_train: 0.9929	accuracy_val: 0.8927	accuracy_test: 0.8596
[server]	loss_train: 0.0806	loss_val: 0.5390	loss_test: 0.5763	accuracy_train: 0.9926	accuracy_val: 0.8357	accuracy_test: 0.7923
[server]	loss_train: 0.0468	loss_val: 0.4466	loss_test: 0.4754	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0398	loss_val: 0.4193	loss_test: 0.4365	accuracy_train: 1.0000	accuracy_val: 0.8885	accuracy_test: 0.8862
[server]	loss_train: 0.0586	loss_val: 0.5383	loss_test: 0.4815	accuracy_train: 1.0000	accuracy_val: 0.8419	accuracy_test: 0.8508
curr_round: 91	curr_val_accuracy: 0.8452	curr_test_accuracy: 0.8430
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 92		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1040	loss_val: 0.6491	loss_test: 0.5849	accuracy_train: 0.9851	accuracy_val: 0.8073	accuracy_test: 0.8208
[server]	loss_train: 0.0506	loss_val: 0.5363	loss_test: 0.6281	accuracy_train: 1.0000	accuracy_val: 0.8340	accuracy_test: 0.7840
[server]	loss_train: 0.0779	loss_val: 0.6644	loss_test: 0.6008	accuracy_train: 0.9939	accuracy_val: 0.8234	accuracy_test: 0.8363
[server]	loss_train: 0.0477	loss_val: 0.5208	loss_test: 0.4517	accuracy_train: 1.0000	accuracy_val: 0.8440	accuracy_test: 0.8652
[server]	loss_train: 0.0690	loss_val: 0.4788	loss_test: 0.4286	accuracy_train: 1.0000	accuracy_val: 0.8750	accuracy_test: 0.8812
[server]	loss_train: 0.0569	loss_val: 0.5647	loss_test: 0.5733	accuracy_train: 1.0000	accuracy_val: 0.8092	accuracy_test: 0.8258
[server]	loss_train: 0.0591	loss_val: 0.4083	loss_test: 0.5406	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0553	loss_val: 0.4652	loss_test: 0.4678	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8541
[server]	loss_train: 0.1330	loss_val: 0.5433	loss_test: 0.4721	accuracy_train: 0.9760	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0518	loss_val: 0.5081	loss_test: 0.5167	accuracy_train: 1.0000	accuracy_val: 0.8481	accuracy_test: 0.8462
[server]	loss_train: 0.0681	loss_val: 0.6596	loss_test: 0.4592	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0444	loss_val: 0.5615	loss_test: 0.4567	accuracy_train: 1.0000	accuracy_val: 0.8467	accuracy_test: 0.8406
[server]	loss_train: 0.0738	loss_val: 0.5081	loss_test: 0.6714	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1275	loss_val: 0.5047	loss_test: 0.5226	accuracy_train: 0.9706	accuracy_val: 0.8357	accuracy_test: 0.8386
[server]	loss_train: 0.0802	loss_val: 0.5566	loss_test: 0.4264	accuracy_train: 0.9864	accuracy_val: 0.8591	accuracy_test: 0.8867
[server]	loss_train: 0.0668	loss_val: 0.3107	loss_test: 0.3512	accuracy_train: 0.9929	accuracy_val: 0.8927	accuracy_test: 0.8562
[server]	loss_train: 0.0796	loss_val: 0.5405	loss_test: 0.5784	accuracy_train: 0.9926	accuracy_val: 0.8357	accuracy_test: 0.7923
[server]	loss_train: 0.0459	loss_val: 0.4476	loss_test: 0.4758	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0391	loss_val: 0.4205	loss_test: 0.4376	accuracy_train: 1.0000	accuracy_val: 0.8850	accuracy_test: 0.8862
[server]	loss_train: 0.0574	loss_val: 0.5389	loss_test: 0.4823	accuracy_train: 1.0000	accuracy_val: 0.8419	accuracy_test: 0.8508
curr_round: 92	curr_val_accuracy: 0.8452	curr_test_accuracy: 0.8428
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 93		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1021	loss_val: 0.6497	loss_test: 0.5867	accuracy_train: 0.9851	accuracy_val: 0.8073	accuracy_test: 0.8208
[server]	loss_train: 0.0495	loss_val: 0.5375	loss_test: 0.6292	accuracy_train: 1.0000	accuracy_val: 0.8340	accuracy_test: 0.7840
[server]	loss_train: 0.0769	loss_val: 0.6649	loss_test: 0.6009	accuracy_train: 0.9939	accuracy_val: 0.8234	accuracy_test: 0.8363
[server]	loss_train: 0.0467	loss_val: 0.5220	loss_test: 0.4523	accuracy_train: 1.0000	accuracy_val: 0.8440	accuracy_test: 0.8617
[server]	loss_train: 0.0680	loss_val: 0.4782	loss_test: 0.4295	accuracy_train: 1.0000	accuracy_val: 0.8750	accuracy_test: 0.8812
[server]	loss_train: 0.0557	loss_val: 0.5647	loss_test: 0.5737	accuracy_train: 1.0000	accuracy_val: 0.8092	accuracy_test: 0.8295
[server]	loss_train: 0.0581	loss_val: 0.4084	loss_test: 0.5410	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0544	loss_val: 0.4651	loss_test: 0.4674	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8541
[server]	loss_train: 0.1307	loss_val: 0.5438	loss_test: 0.4723	accuracy_train: 0.9760	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0510	loss_val: 0.5088	loss_test: 0.5169	accuracy_train: 1.0000	accuracy_val: 0.8481	accuracy_test: 0.8462
[server]	loss_train: 0.0668	loss_val: 0.6603	loss_test: 0.4595	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0436	loss_val: 0.5621	loss_test: 0.4566	accuracy_train: 1.0000	accuracy_val: 0.8467	accuracy_test: 0.8406
[server]	loss_train: 0.0724	loss_val: 0.5085	loss_test: 0.6721	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1252	loss_val: 0.5058	loss_test: 0.5228	accuracy_train: 0.9706	accuracy_val: 0.8357	accuracy_test: 0.8386
[server]	loss_train: 0.0791	loss_val: 0.5577	loss_test: 0.4270	accuracy_train: 0.9864	accuracy_val: 0.8624	accuracy_test: 0.8867
[server]	loss_train: 0.0657	loss_val: 0.3111	loss_test: 0.3514	accuracy_train: 0.9929	accuracy_val: 0.8927	accuracy_test: 0.8596
[server]	loss_train: 0.0780	loss_val: 0.5409	loss_test: 0.5790	accuracy_train: 0.9926	accuracy_val: 0.8357	accuracy_test: 0.7923
[server]	loss_train: 0.0448	loss_val: 0.4474	loss_test: 0.4760	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0383	loss_val: 0.4207	loss_test: 0.4384	accuracy_train: 1.0000	accuracy_val: 0.8850	accuracy_test: 0.8862
[server]	loss_train: 0.0565	loss_val: 0.5408	loss_test: 0.4831	accuracy_train: 1.0000	accuracy_val: 0.8419	accuracy_test: 0.8508
curr_round: 93	curr_val_accuracy: 0.8454	curr_test_accuracy: 0.8430
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 94		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.1001	loss_val: 0.6508	loss_test: 0.5873	accuracy_train: 0.9851	accuracy_val: 0.8073	accuracy_test: 0.8208
[server]	loss_train: 0.0488	loss_val: 0.5383	loss_test: 0.6307	accuracy_train: 1.0000	accuracy_val: 0.8340	accuracy_test: 0.7840
[server]	loss_train: 0.0754	loss_val: 0.6671	loss_test: 0.6029	accuracy_train: 0.9939	accuracy_val: 0.8234	accuracy_test: 0.8363
[server]	loss_train: 0.0459	loss_val: 0.5232	loss_test: 0.4527	accuracy_train: 1.0000	accuracy_val: 0.8440	accuracy_test: 0.8617
[server]	loss_train: 0.0666	loss_val: 0.4796	loss_test: 0.4303	accuracy_train: 1.0000	accuracy_val: 0.8750	accuracy_test: 0.8812
[server]	loss_train: 0.0546	loss_val: 0.5662	loss_test: 0.5752	accuracy_train: 1.0000	accuracy_val: 0.8092	accuracy_test: 0.8258
[server]	loss_train: 0.0574	loss_val: 0.4087	loss_test: 0.5428	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0534	loss_val: 0.4666	loss_test: 0.4693	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8541
[server]	loss_train: 0.1299	loss_val: 0.5454	loss_test: 0.4735	accuracy_train: 0.9840	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0501	loss_val: 0.5099	loss_test: 0.5190	accuracy_train: 1.0000	accuracy_val: 0.8516	accuracy_test: 0.8462
[server]	loss_train: 0.0657	loss_val: 0.6621	loss_test: 0.4607	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0426	loss_val: 0.5633	loss_test: 0.4572	accuracy_train: 1.0000	accuracy_val: 0.8431	accuracy_test: 0.8406
[server]	loss_train: 0.0713	loss_val: 0.5094	loss_test: 0.6739	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1242	loss_val: 0.5069	loss_test: 0.5240	accuracy_train: 0.9706	accuracy_val: 0.8357	accuracy_test: 0.8386
[server]	loss_train: 0.0777	loss_val: 0.5586	loss_test: 0.4278	accuracy_train: 0.9864	accuracy_val: 0.8591	accuracy_test: 0.8867
[server]	loss_train: 0.0649	loss_val: 0.3110	loss_test: 0.3519	accuracy_train: 0.9929	accuracy_val: 0.8927	accuracy_test: 0.8596
[server]	loss_train: 0.0771	loss_val: 0.5425	loss_test: 0.5813	accuracy_train: 0.9926	accuracy_val: 0.8357	accuracy_test: 0.7923
[server]	loss_train: 0.0440	loss_val: 0.4487	loss_test: 0.4763	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0378	loss_val: 0.4221	loss_test: 0.4397	accuracy_train: 1.0000	accuracy_val: 0.8850	accuracy_test: 0.8862
[server]	loss_train: 0.0553	loss_val: 0.5413	loss_test: 0.4839	accuracy_train: 1.0000	accuracy_val: 0.8419	accuracy_test: 0.8508
curr_round: 94	curr_val_accuracy: 0.8452	curr_test_accuracy: 0.8428
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 95		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.0984	loss_val: 0.6515	loss_test: 0.5889	accuracy_train: 0.9851	accuracy_val: 0.8073	accuracy_test: 0.8172
[server]	loss_train: 0.0478	loss_val: 0.5393	loss_test: 0.6317	accuracy_train: 1.0000	accuracy_val: 0.8340	accuracy_test: 0.7840
[server]	loss_train: 0.0744	loss_val: 0.6676	loss_test: 0.6029	accuracy_train: 0.9939	accuracy_val: 0.8234	accuracy_test: 0.8393
[server]	loss_train: 0.0449	loss_val: 0.5242	loss_test: 0.4532	accuracy_train: 1.0000	accuracy_val: 0.8511	accuracy_test: 0.8617
[server]	loss_train: 0.0656	loss_val: 0.4791	loss_test: 0.4311	accuracy_train: 1.0000	accuracy_val: 0.8750	accuracy_test: 0.8812
[server]	loss_train: 0.0535	loss_val: 0.5662	loss_test: 0.5756	accuracy_train: 1.0000	accuracy_val: 0.8092	accuracy_test: 0.8295
[server]	loss_train: 0.0564	loss_val: 0.4088	loss_test: 0.5430	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0525	loss_val: 0.4664	loss_test: 0.4689	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8505
[server]	loss_train: 0.1277	loss_val: 0.5459	loss_test: 0.4735	accuracy_train: 0.9840	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0493	loss_val: 0.5105	loss_test: 0.5192	accuracy_train: 1.0000	accuracy_val: 0.8481	accuracy_test: 0.8462
[server]	loss_train: 0.0644	loss_val: 0.6628	loss_test: 0.4610	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8493
[server]	loss_train: 0.0419	loss_val: 0.5638	loss_test: 0.4570	accuracy_train: 1.0000	accuracy_val: 0.8467	accuracy_test: 0.8406
[server]	loss_train: 0.0700	loss_val: 0.5097	loss_test: 0.6747	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1222	loss_val: 0.5080	loss_test: 0.5242	accuracy_train: 0.9706	accuracy_val: 0.8357	accuracy_test: 0.8386
[server]	loss_train: 0.0766	loss_val: 0.5598	loss_test: 0.4284	accuracy_train: 0.9864	accuracy_val: 0.8624	accuracy_test: 0.8867
[server]	loss_train: 0.0639	loss_val: 0.3113	loss_test: 0.3522	accuracy_train: 0.9929	accuracy_val: 0.8927	accuracy_test: 0.8596
[server]	loss_train: 0.0756	loss_val: 0.5428	loss_test: 0.5818	accuracy_train: 0.9926	accuracy_val: 0.8357	accuracy_test: 0.7923
[server]	loss_train: 0.0431	loss_val: 0.4485	loss_test: 0.4765	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0370	loss_val: 0.4223	loss_test: 0.4406	accuracy_train: 1.0000	accuracy_val: 0.8815	accuracy_test: 0.8862
[server]	loss_train: 0.0544	loss_val: 0.5431	loss_test: 0.4845	accuracy_train: 1.0000	accuracy_val: 0.8419	accuracy_test: 0.8508
curr_round: 95	curr_val_accuracy: 0.8456	curr_test_accuracy: 0.8428
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 96		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.0965	loss_val: 0.6528	loss_test: 0.5898	accuracy_train: 0.9851	accuracy_val: 0.8036	accuracy_test: 0.8172
[server]	loss_train: 0.0471	loss_val: 0.5402	loss_test: 0.6333	accuracy_train: 1.0000	accuracy_val: 0.8300	accuracy_test: 0.7880
[server]	loss_train: 0.0731	loss_val: 0.6696	loss_test: 0.6049	accuracy_train: 0.9939	accuracy_val: 0.8234	accuracy_test: 0.8393
[server]	loss_train: 0.0442	loss_val: 0.5256	loss_test: 0.4538	accuracy_train: 1.0000	accuracy_val: 0.8511	accuracy_test: 0.8617
[server]	loss_train: 0.0643	loss_val: 0.4804	loss_test: 0.4319	accuracy_train: 1.0000	accuracy_val: 0.8750	accuracy_test: 0.8812
[server]	loss_train: 0.0525	loss_val: 0.5676	loss_test: 0.5773	accuracy_train: 1.0000	accuracy_val: 0.8092	accuracy_test: 0.8258
[server]	loss_train: 0.0557	loss_val: 0.4092	loss_test: 0.5450	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0516	loss_val: 0.4680	loss_test: 0.4710	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8505
[server]	loss_train: 0.1269	loss_val: 0.5475	loss_test: 0.4749	accuracy_train: 0.9840	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0486	loss_val: 0.5118	loss_test: 0.5213	accuracy_train: 1.0000	accuracy_val: 0.8516	accuracy_test: 0.8462
[server]	loss_train: 0.0634	loss_val: 0.6645	loss_test: 0.4622	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8456
[server]	loss_train: 0.0410	loss_val: 0.5652	loss_test: 0.4576	accuracy_train: 1.0000	accuracy_val: 0.8467	accuracy_test: 0.8406
[server]	loss_train: 0.0689	loss_val: 0.5107	loss_test: 0.6766	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1209	loss_val: 0.5090	loss_test: 0.5256	accuracy_train: 0.9706	accuracy_val: 0.8321	accuracy_test: 0.8386
[server]	loss_train: 0.0753	loss_val: 0.5606	loss_test: 0.4291	accuracy_train: 0.9864	accuracy_val: 0.8591	accuracy_test: 0.8867
[server]	loss_train: 0.0631	loss_val: 0.3114	loss_test: 0.3526	accuracy_train: 0.9929	accuracy_val: 0.8927	accuracy_test: 0.8596
[server]	loss_train: 0.0747	loss_val: 0.5445	loss_test: 0.5840	accuracy_train: 0.9926	accuracy_val: 0.8357	accuracy_test: 0.7923
[server]	loss_train: 0.0423	loss_val: 0.4497	loss_test: 0.4770	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0365	loss_val: 0.4237	loss_test: 0.4418	accuracy_train: 1.0000	accuracy_val: 0.8815	accuracy_test: 0.8862
[server]	loss_train: 0.0534	loss_val: 0.5438	loss_test: 0.4854	accuracy_train: 1.0000	accuracy_val: 0.8452	accuracy_test: 0.8508
curr_round: 96	curr_val_accuracy: 0.8452	curr_test_accuracy: 0.8426
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 97		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.0947	loss_val: 0.6534	loss_test: 0.5914	accuracy_train: 0.9851	accuracy_val: 0.8036	accuracy_test: 0.8172
[server]	loss_train: 0.0462	loss_val: 0.5412	loss_test: 0.6343	accuracy_train: 1.0000	accuracy_val: 0.8300	accuracy_test: 0.7920
[server]	loss_train: 0.0721	loss_val: 0.6700	loss_test: 0.6049	accuracy_train: 0.9939	accuracy_val: 0.8234	accuracy_test: 0.8393
[server]	loss_train: 0.0432	loss_val: 0.5267	loss_test: 0.4543	accuracy_train: 1.0000	accuracy_val: 0.8511	accuracy_test: 0.8617
[server]	loss_train: 0.0634	loss_val: 0.4798	loss_test: 0.4326	accuracy_train: 1.0000	accuracy_val: 0.8750	accuracy_test: 0.8812
[server]	loss_train: 0.0514	loss_val: 0.5676	loss_test: 0.5774	accuracy_train: 1.0000	accuracy_val: 0.8092	accuracy_test: 0.8295
[server]	loss_train: 0.0548	loss_val: 0.4093	loss_test: 0.5452	accuracy_train: 1.0000	accuracy_val: 0.8714	accuracy_test: 0.8430
[server]	loss_train: 0.0508	loss_val: 0.4678	loss_test: 0.4704	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8505
[server]	loss_train: 0.1248	loss_val: 0.5479	loss_test: 0.4748	accuracy_train: 0.9840	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0478	loss_val: 0.5122	loss_test: 0.5212	accuracy_train: 1.0000	accuracy_val: 0.8481	accuracy_test: 0.8462
[server]	loss_train: 0.0621	loss_val: 0.6651	loss_test: 0.4625	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8456
[server]	loss_train: 0.0404	loss_val: 0.5654	loss_test: 0.4575	accuracy_train: 1.0000	accuracy_val: 0.8467	accuracy_test: 0.8406
[server]	loss_train: 0.0676	loss_val: 0.5109	loss_test: 0.6769	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1189	loss_val: 0.5104	loss_test: 0.5257	accuracy_train: 0.9706	accuracy_val: 0.8321	accuracy_test: 0.8386
[server]	loss_train: 0.0742	loss_val: 0.5617	loss_test: 0.4297	accuracy_train: 0.9864	accuracy_val: 0.8624	accuracy_test: 0.8867
[server]	loss_train: 0.0622	loss_val: 0.3119	loss_test: 0.3530	accuracy_train: 0.9929	accuracy_val: 0.8927	accuracy_test: 0.8596
[server]	loss_train: 0.0732	loss_val: 0.5448	loss_test: 0.5844	accuracy_train: 0.9926	accuracy_val: 0.8357	accuracy_test: 0.7923
[server]	loss_train: 0.0414	loss_val: 0.4494	loss_test: 0.4770	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0358	loss_val: 0.4239	loss_test: 0.4427	accuracy_train: 1.0000	accuracy_val: 0.8815	accuracy_test: 0.8862
[server]	loss_train: 0.0525	loss_val: 0.5455	loss_test: 0.4859	accuracy_train: 1.0000	accuracy_val: 0.8452	accuracy_test: 0.8508
curr_round: 97	curr_val_accuracy: 0.8452	curr_test_accuracy: 0.8430
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 98		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.0930	loss_val: 0.6545	loss_test: 0.5922	accuracy_train: 0.9851	accuracy_val: 0.8073	accuracy_test: 0.8172
[server]	loss_train: 0.0455	loss_val: 0.5422	loss_test: 0.6359	accuracy_train: 1.0000	accuracy_val: 0.8300	accuracy_test: 0.7920
[server]	loss_train: 0.0709	loss_val: 0.6723	loss_test: 0.6071	accuracy_train: 0.9939	accuracy_val: 0.8204	accuracy_test: 0.8393
[server]	loss_train: 0.0426	loss_val: 0.5280	loss_test: 0.4550	accuracy_train: 1.0000	accuracy_val: 0.8511	accuracy_test: 0.8617
[server]	loss_train: 0.0622	loss_val: 0.4813	loss_test: 0.4335	accuracy_train: 1.0000	accuracy_val: 0.8750	accuracy_test: 0.8812
[server]	loss_train: 0.0505	loss_val: 0.5691	loss_test: 0.5793	accuracy_train: 1.0000	accuracy_val: 0.8130	accuracy_test: 0.8258
[server]	loss_train: 0.0542	loss_val: 0.4098	loss_test: 0.5473	accuracy_train: 1.0000	accuracy_val: 0.8755	accuracy_test: 0.8430
[server]	loss_train: 0.0499	loss_val: 0.4693	loss_test: 0.4726	accuracy_train: 1.0000	accuracy_val: 0.8525	accuracy_test: 0.8505
[server]	loss_train: 0.1241	loss_val: 0.5498	loss_test: 0.4765	accuracy_train: 0.9840	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0471	loss_val: 0.5137	loss_test: 0.5237	accuracy_train: 1.0000	accuracy_val: 0.8481	accuracy_test: 0.8462
[server]	loss_train: 0.0613	loss_val: 0.6669	loss_test: 0.4639	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8456
[server]	loss_train: 0.0395	loss_val: 0.5669	loss_test: 0.4581	accuracy_train: 1.0000	accuracy_val: 0.8467	accuracy_test: 0.8406
[server]	loss_train: 0.0667	loss_val: 0.5121	loss_test: 0.6792	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1176	loss_val: 0.5112	loss_test: 0.5272	accuracy_train: 0.9706	accuracy_val: 0.8321	accuracy_test: 0.8386
[server]	loss_train: 0.0730	loss_val: 0.5625	loss_test: 0.4305	accuracy_train: 0.9864	accuracy_val: 0.8591	accuracy_test: 0.8867
[server]	loss_train: 0.0614	loss_val: 0.3118	loss_test: 0.3533	accuracy_train: 0.9929	accuracy_val: 0.8927	accuracy_test: 0.8596
[server]	loss_train: 0.0725	loss_val: 0.5466	loss_test: 0.5869	accuracy_train: 0.9926	accuracy_val: 0.8357	accuracy_test: 0.7923
[server]	loss_train: 0.0407	loss_val: 0.4509	loss_test: 0.4777	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0353	loss_val: 0.4252	loss_test: 0.4438	accuracy_train: 1.0000	accuracy_val: 0.8815	accuracy_test: 0.8862
[server]	loss_train: 0.0515	loss_val: 0.5461	loss_test: 0.4870	accuracy_train: 1.0000	accuracy_val: 0.8419	accuracy_test: 0.8508
curr_round: 98	curr_val_accuracy: 0.8452	curr_test_accuracy: 0.8428
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
round # 99		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[server]	loss_train: 0.0914	loss_val: 0.6551	loss_test: 0.5939	accuracy_train: 0.9851	accuracy_val: 0.8073	accuracy_test: 0.8172
[server]	loss_train: 0.0446	loss_val: 0.5431	loss_test: 0.6369	accuracy_train: 1.0000	accuracy_val: 0.8300	accuracy_test: 0.7920
[server]	loss_train: 0.0699	loss_val: 0.6726	loss_test: 0.6068	accuracy_train: 0.9939	accuracy_val: 0.8204	accuracy_test: 0.8393
[server]	loss_train: 0.0417	loss_val: 0.5290	loss_test: 0.4555	accuracy_train: 1.0000	accuracy_val: 0.8511	accuracy_test: 0.8617
[server]	loss_train: 0.0614	loss_val: 0.4805	loss_test: 0.4343	accuracy_train: 1.0000	accuracy_val: 0.8750	accuracy_test: 0.8812
[server]	loss_train: 0.0496	loss_val: 0.5691	loss_test: 0.5793	accuracy_train: 1.0000	accuracy_val: 0.8130	accuracy_test: 0.8295
[server]	loss_train: 0.0532	loss_val: 0.4098	loss_test: 0.5473	accuracy_train: 1.0000	accuracy_val: 0.8755	accuracy_test: 0.8430
[server]	loss_train: 0.0491	loss_val: 0.4689	loss_test: 0.4719	accuracy_train: 1.0000	accuracy_val: 0.8561	accuracy_test: 0.8505
[server]	loss_train: 0.1221	loss_val: 0.5500	loss_test: 0.4761	accuracy_train: 0.9840	accuracy_val: 0.8301	accuracy_test: 0.8435
[server]	loss_train: 0.0464	loss_val: 0.5139	loss_test: 0.5234	accuracy_train: 1.0000	accuracy_val: 0.8481	accuracy_test: 0.8462
[server]	loss_train: 0.0601	loss_val: 0.6675	loss_test: 0.4641	accuracy_train: 0.9924	accuracy_val: 0.8284	accuracy_test: 0.8456
[server]	loss_train: 0.0389	loss_val: 0.5671	loss_test: 0.4580	accuracy_train: 1.0000	accuracy_val: 0.8467	accuracy_test: 0.8406
[server]	loss_train: 0.0654	loss_val: 0.5123	loss_test: 0.6794	accuracy_train: 0.9925	accuracy_val: 0.8267	accuracy_test: 0.8000
[server]	loss_train: 0.1160	loss_val: 0.5125	loss_test: 0.5272	accuracy_train: 0.9706	accuracy_val: 0.8321	accuracy_test: 0.8386
[server]	loss_train: 0.0720	loss_val: 0.5638	loss_test: 0.4311	accuracy_train: 0.9864	accuracy_val: 0.8624	accuracy_test: 0.8867
[server]	loss_train: 0.0605	loss_val: 0.3123	loss_test: 0.3538	accuracy_train: 0.9929	accuracy_val: 0.8927	accuracy_test: 0.8596
[server]	loss_train: 0.0710	loss_val: 0.5466	loss_test: 0.5870	accuracy_train: 0.9926	accuracy_val: 0.8357	accuracy_test: 0.7923
[server]	loss_train: 0.0398	loss_val: 0.4504	loss_test: 0.4778	accuracy_train: 1.0000	accuracy_val: 0.8609	accuracy_test: 0.8462
[server]	loss_train: 0.0347	loss_val: 0.4253	loss_test: 0.4447	accuracy_train: 1.0000	accuracy_val: 0.8815	accuracy_test: 0.8897
[server]	loss_train: 0.0507	loss_val: 0.5479	loss_test: 0.4874	accuracy_train: 1.0000	accuracy_val: 0.8419	accuracy_test: 0.8476
curr_round: 99	curr_val_accuracy: 0.8456	curr_test_accuracy: 0.8430
best_round: 81	best_val_accuracy: 0.8461	best_test_accuracy: 0.8426
--------------------------------------------------
